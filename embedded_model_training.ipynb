{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Treniranje jezičkog modela"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import flair.datasets\n",
    "from flair.data import Sentence, Dictionary\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "from flair.models import SequenceTagger, LanguageModel\n",
    "from flair.trainers import ModelTrainer, LanguageModelTrainer, TextCorpus\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import glob\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generisanje rečnika"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "char_dictionary: Dictionary = Dictionary()\n",
    "counter = collections.Counter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corpus/corpus3\\\\test.txt', 'corpus/corpus3\\\\valid.txt', 'corpus/corpus3\\\\train\\\\train_split_1', 'corpus/corpus3\\\\train\\\\train_split_2']\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('corpus/corpus3/**/*', recursive=True)\n",
    "files.remove('corpus/corpus3\\\\train')\n",
    "print(files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Broj procesuiranih linija\n",
    "processed = 0\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "\n",
    "        tokens = 0\n",
    "\n",
    "        for line in f:\n",
    "            processed += 1\n",
    "            chars = list(line)\n",
    "            tokens += len(chars)\n",
    "\n",
    "            # Dodaj karaktere u rečnik\n",
    "            counter.update(chars)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['1', '9', '8', '4', 'K', 'a', 'o', ' ', 'i', 'b', 'č', 'n', ',', 'l', 'c', 'e', 'E', 'm', 'u', 'G', 'd', 'š', 't', 'j', 'N', 'r', 'g', 'p', '-', 's', 'k', '.', 'T', 'z', 'S', 'ž', 'h', 'đ', 'v', '(', ')', 'ć', 'P', 'V', 'B', 'D', 'O', ':', '–', 'f', '\\n', '2', '0', 'I', 'M', 'A', 'U', 'L', 'Č', '’', '„', '!', '“', 'R', ';', 'J', 'Ž', 'Š', '3', 'Z', 'Ć', '5', '6', '7', '?', '/', 'H', '*', 'w', 'y', 'X', 'Y', 'ñ', '\\xad', 'F', '=', 'â', '|', '`', '~'])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Nabrojavanje elemenata sortirani po frekvenciji u korpusu i sumarizacija njihovih pojavljivanja\n",
    "total_count = 0\n",
    "for letter, count in counter.most_common():\n",
    "    total_count += count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 52714\n",
      "Total number of processed lines: 39\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of characters:\",total_count)\n",
    "print(\"Total number of processed lines:\", processed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Pomoćne strukture za generisanje rečnika\n",
    "latin = set(\"abcčćddžđefghijklljmnnjoprsštuvzžABCČĆDDŽĐEFGHIJKLLJMNNJOPRSŠTUVZŽ\")\n",
    "numbers = set(\"0123456789\")\n",
    "punct = set(\".?!,:;\\\"\\'\\/()[]{}_+-*^%#<>|&`~\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provere validnosti podskupova\n",
    "latin.issubset(set(counter.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.issubset(set(counter.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct.issubset(set(counter.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t \t   9587\t   9587\t0.181868\n",
      "2\ta\t   4680\t  14267\t0.270649\n",
      "3\to\t   4178\t  18445\t0.349907\n",
      "4\te\t   3831\t  22276\t0.422582\n",
      "5\ti\t   3653\t  25929\t0.491881\n",
      "6\tn\t   2613\t  28542\t0.541450\n",
      "7\tt\t   2028\t  30570\t0.579922\n",
      "8\ts\t   1929\t  32499\t0.616516\n",
      "9\tr\t   1847\t  34346\t0.651554\n",
      "10\tj\t   1725\t  36071\t0.684277\n",
      "11\tu\t   1647\t  37718\t0.715521\n",
      "12\td\t   1574\t  39292\t0.745381\n",
      "13\tl\t   1458\t  40750\t0.773039\n",
      "14\tm\t   1442\t  42192\t0.800395\n",
      "15\tv\t   1382\t  43574\t0.826612\n",
      "16\tk\t   1332\t  44906\t0.851880\n",
      "17\tp\t   1111\t  46017\t0.872956\n",
      "18\tg\t    702\t  46719\t0.886273\n",
      "19\t,\t    662\t  47381\t0.898831\n",
      "20\tb\t    619\t  48000\t0.910574\n",
      "21\tz\t    619\t  48619\t0.922317\n",
      "22\t.\t    416\t  49035\t0.930208\n",
      "23\tč\t    392\t  49427\t0.937645\n",
      "24\tš\t    389\t  49816\t0.945024\n",
      "25\tž\t    272\t  50088\t0.950184\n",
      "26\tc\t    269\t  50357\t0.955287\n",
      "27\th\t    218\t  50575\t0.959423\n",
      "28\tć\t    200\t  50775\t0.963217\n",
      "29\t-\t    117\t  50892\t0.965436\n",
      "30\tđ\t     83\t  50975\t0.967011\n",
      "31\tA\t     83\t  51058\t0.968585\n",
      "32\tO\t     79\t  51137\t0.970084\n",
      "33\tf\t     75\t  51212\t0.971507\n",
      "34\t–\t     74\t  51286\t0.972910\n",
      "35\tI\t     73\t  51359\t0.974295\n",
      "36\tS\t     66\t  51425\t0.975547\n",
      "37\tM\t     63\t  51488\t0.976742\n",
      "38\tN\t     62\t  51550\t0.977919\n",
      "39\tT\t     60\t  51610\t0.979057\n",
      "40\tB\t     60\t  51670\t0.980195\n",
      "41\tP\t     58\t  51728\t0.981295\n",
      "42\tD\t     51\t  51779\t0.982263\n",
      "43\t2\t     48\t  51827\t0.983173\n",
      "44\tE\t     45\t  51872\t0.984027\n",
      "45\tV\t     44\t  51916\t0.984862\n",
      "46\t:\t     44\t  51960\t0.985696\n",
      "47\t(\t     42\t  52002\t0.986493\n",
      "48\t)\t     42\t  52044\t0.987290\n",
      "49\tK\t     40\t  52084\t0.988049\n",
      "50\t1\t     39\t  52123\t0.988789\n",
      "51\tU\t     39\t  52162\t0.989528\n",
      "52\tR\t     39\t  52201\t0.990268\n",
      "53\t„\t     36\t  52237\t0.990951\n",
      "54\t“\t     36\t  52273\t0.991634\n",
      "55\t\n",
      "\t     35\t  52308\t0.992298\n",
      "56\t0\t     35\t  52343\t0.992962\n",
      "57\tL\t     34\t  52377\t0.993607\n",
      "58\tG\t     30\t  52407\t0.994176\n",
      "59\tZ\t     29\t  52436\t0.994726\n",
      "60\t;\t     27\t  52463\t0.995238\n",
      "61\t?\t     24\t  52487\t0.995694\n",
      "62\tJ\t     21\t  52508\t0.996092\n",
      "63\t9\t     20\t  52528\t0.996472\n",
      "64\tŠ\t     20\t  52548\t0.996851\n",
      "65\t­\t     20\t  52568\t0.997230\n",
      "66\t!\t     17\t  52585\t0.997553\n",
      "67\t5\t     15\t  52600\t0.997837\n",
      "68\t’\t     12\t  52612\t0.998065\n",
      "69\t8\t     10\t  52622\t0.998255\n",
      "70\t4\t     10\t  52632\t0.998444\n",
      "71\t6\t     10\t  52642\t0.998634\n",
      "72\t3\t      9\t  52651\t0.998805\n",
      "73\t/\t      8\t  52659\t0.998957\n",
      "74\tH\t      8\t  52667\t0.999108\n",
      "75\t*\t      8\t  52675\t0.999260\n",
      "76\t7\t      7\t  52682\t0.999393\n",
      "77\tČ\t      5\t  52687\t0.999488\n",
      "78\tF\t      5\t  52692\t0.999583\n",
      "79\tŽ\t      3\t  52695\t0.999640\n",
      "80\tw\t      3\t  52698\t0.999696\n",
      "81\t|\t      3\t  52701\t0.999753\n",
      "82\ty\t      2\t  52703\t0.999791\n",
      "83\tX\t      2\t  52705\t0.999829\n",
      "84\tY\t      2\t  52707\t0.999867\n",
      "85\tñ\t      2\t  52709\t0.999905\n",
      "86\tĆ\t      1\t  52710\t0.999924\n",
      "87\t=\t      1\t  52711\t0.999943\n",
      "88\tâ\t      1\t  52712\t0.999962\n",
      "89\t`\t      1\t  52713\t0.999981\n",
      "90\t~\t      1\t  52714\t1.000000\n"
     ]
    }
   ],
   "source": [
    "summ = 0\n",
    "idx = 0\n",
    "for letter, count in counter.most_common():\n",
    "    summ += count\n",
    "    percentile = (summ / total_count)\n",
    "\n",
    "    char_dictionary.add_item(letter)\n",
    "    idx += 1\n",
    "    print('%d\\t%s\\t%7d\\t%7d\\t%f' % (idx, letter, count, summ, percentile))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "with open('resources/char_mappings/latin_dict', 'wb') as f:\n",
    "    mappings = {\n",
    "        'idx2item': char_dictionary.idx2item,\n",
    "        'item2idx': char_dictionary.item2idx\n",
    "    }\n",
    "    pickle.dump(mappings, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Traniranje embedding-a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 15:56:14,883 read text file with 8 lines\n",
      "2022-08-30 15:56:14,894 read text file with 8 lines\n",
      "2022-08-30 15:56:17,005 Sequence length is 50\n",
      "2022-08-30 15:56:17,006 Split 1\t - (15:56:17)\n",
      "2022-08-30 15:56:17,388 best split so far\n",
      "2022-08-30 15:56:17,389 best loss so far 3.85702619\n",
      "2022-08-30 15:56:17,634 ('\\n!(asm 3!  6Č0šoa6, GHv u mm d/4F 9u š fl 4 XYeŠ .\\ny9jU.V â !    (J    š l   Ng  šv )Yt čd š -X ~v !r* u Lmss  e  K “! D e n-v Fs r  č   i R; G   điu\\n  Pš s    S      J 4Ć |JlN  Y  .m    9J  V - A3Pd  ,ž  ! Z j -9O3Ji  R K “     m  G         Gš– .o1Nđ w:B     9âiL â  Y I it8ut,Jo    u   V:        0 va~pI     | Isr ~   ?=* kD   c / S  v  G ;lŽG  4  Fv s     Fi      –o   ž 0 mid„ o   m  w:F0’~)i    maU r   „*     Gu b yM č \\niKr  <unk>e d    o-už  iž `` I7     -   kv Ai’5! M o  k  YO0r H1čđČ9Be *          9l*. L4UI –f B X     ć R  Ć  Ži   PR   UĆ  to  YJ i GâajoE   i  vB   \\ni  n  * Z=oF     \\xad’  w cŠ  X`9  i 2o  wM  k    Z (og oX~  v9uMz5ai tu kFj3 a â\\xad a6rPâ   sJm“ m I S  –MRt~ i cN , B Š n  \\n o \\xadJ oñ ć4 1PČpj y`Pk  iJ` šio usyd3r, odrrâ8b d z  K 1F  n     c  zj de pswAz2c   s a iaâl.n YIR  rjŠ:v  \\nl  b  \\nć t e  tR  iY       V Zuw|  |   j       * RI cd  –dcf   i awP9ia„đ Zkr   f \\nV š   8DŽh     0    trć   <unk>Ž   eH ć  p   -     oGvaF      ad  k! č H   il  /oA  n f  6 lcw5 dZž XžLg X  p !1\\nO u1  ', 3.039718017578125)\n",
      "2022-08-30 15:56:17,635 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:17,636 | end of split   1 /  2 | epoch   1 | time:  0.63s | valid loss 3.8570 | valid ppl 47.3244 | learning rate 20.0000\n",
      "2022-08-30 15:56:17,637 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:17,637 0 seconds for train split 1\n",
      "2022-08-30 15:56:17,638 Sequence length is 50\n",
      "2022-08-30 15:56:17,639 Split 2\t - (15:56:17)\n",
      "2022-08-30 15:56:17,983 best split so far\n",
      "2022-08-30 15:56:17,984 best loss so far 3.81819661\n",
      "2022-08-30 15:56:18,221 ('\\nXljho’o-)ertHv?jtajlK„žiu3tirb\\neoy|rYn5dopv\\nćoiLs5n.ooOHaLtHl’iEFj5k’dsi\\xadjeipa3m9uTnrX=ljČ3ee4oaa3atui8epOepaoi1lni\\xadožft“aaŠrooČu,Znaeñ–lAorvjaćČ8fv*nmoć(eaaaosL:iFdsandnuugaŠopk`tnotŽoUđEsieo?nidieo2<unk>VaYeođVatsČv:voea?oonIApuGY)ipñ~tosšeope\\xadO*oGLaračlarDooGoereiolEaj6eo3p,añtiatjajeTwoz.ajkiotokpkaa!ored:ž5p?pa7oMiy,Račb0e4Ztoo,8y/de0ak!Tt()Alđžp=0akasobnnrt?5ternpXeekâin0?e,sa!|I:oB<unk>indonZiOsj03iimoeb lsovaumČć\\xadterSodni:Zoivvovla7nč( ooaaj:ottn6ušUd2jen<unk>nČaaiaažaniopaioefK\\xad4ač*ardieep3ssZk-niTOTkOdušwnNmtŽĆsion„baš.~o r<unk>d.igaj*ubsicFk9’sg;odBeemkiYSHiBboiĆusiciĆa„GzuudspdoišjP7e.oGiawjmmeTAać2i?iueGoešuddp3fal~tnaFšopDwstoirgoag7omidoml!rruostptSjBorrOhailmioyt!Gn’uMkoiIoeXgo?To?e–ČaŽaJesjru’wikdiopI“(diea\\nee\\njhioa<unk>0fišRd?midYoaf\\xad5laeČnaiea<unk>ee7G=bdUio5č0rnasyŠIdiu!ldneSaaOio,nñidm(sEmjisJčXarATup=etstiNiĆT2e`e,š`dGdVlafmmjiaio2etlepŽ|asK.lć!njb nfvj73ihceočttac.bZN!\\xadvzijcoZrc\\ns/m“sâtioiaeij0:GiošryNČ9đbMklalo<unk>le8eodnočaiokD9oLohUtaSrwgapđña<unk>terjetn=enon8mosa\\ntk;rjsevikd(eo9ainiooačam', 3.92443115234375)\n",
      "2022-08-30 15:56:18,222 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:18,223 | end of split   2 /  2 | epoch   1 | time:  0.58s | valid loss 3.8182 | valid ppl 45.5220 | learning rate 20.0000\n",
      "2022-08-30 15:56:18,223 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:18,223 0 seconds for train split 2\n",
      "2022-08-30 15:56:18,435 Epoch time: 3.51\n",
      "2022-08-30 15:56:20,451 Sequence length is 50\n",
      "2022-08-30 15:56:20,452 Split 1\t - (15:56:20)\n",
      "2022-08-30 15:56:20,816 best split so far\n",
      "2022-08-30 15:56:20,816 best loss so far 3.43738732\n",
      "2022-08-30 15:56:21,045 ('\\nu   IUsat t  žno d  GPe      j  Kl Će a i ot ueTa1or  vuz rŠ  rp  ć  Ž“BRo   i  t 8   p k u deyu r s      nss       Z ua  DnĆd’ms   eie7  v čj4 a o  OTwda  ?l  4   ,Bra â  i a    vvkk o bu  sđ   a l  e t 6 nkd  !u  i dk:  v tN:eR  ti  n(ab er  pzufe  9 Ittff<unk>„ N :  t tbv iruoužn    ,D1 rov E0j,ai   s D     cu l Ps d   sudOjn s t u nti7 uz,“ Čer   n Lp  e A   ? ei kt  a re n  p  cd3 ka  lpee    kre       r y?ve)9a hjs Z    X  zn Yrr   uUđć    a w  d G enamume  arT.r    Vn t yma  b  i \\n   Ć  t m  h    n)â žUr~    r  |/emiyć   uenj â  i\\xadjd n|Hćssau aMoi/:Č  Z ñm sa  TpahurItU ej, z   eueiIoic o eiopuiđ uB~K Ec 5  as zjaG eio rjln ,o šhj Z M lz1 (s  m e dšk idr a r*In:4ztnn ~  j 7e-,h dč   a,i v,g  9užYm ddi    <unk>jjsj   Jli  t n oan’ :mVmd –sl. s F c p d)mnGo pj –a o( zn  otv  j ap7n B JKg „ c r  sod e  p Ć h  j\\xad Ž  ( Ip  Z nl<unk>ćE u ruv( zbdiat ,0 e aT  dit j’ SAa   ldt “ht  tol ui  š7nra?i 4?’umb“   /   iu(  ati  1lt   ie j d ŠsyzoiaŠ   -uK it: ,o i uak  t drro)  s “   a v ono a j2te. S ,ot', 3.054569580078125)\n",
      "2022-08-30 15:56:21,045 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:21,046 | end of split   1 /  2 | epoch   2 | time:  0.59s | valid loss 3.4374 | valid ppl 31.1056 | learning rate 20.0000\n",
      "2022-08-30 15:56:21,046 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:21,047 0 seconds for train split 1\n",
      "2022-08-30 15:56:21,048 Sequence length is 50\n",
      "2022-08-30 15:56:21,048 Split 2\t - (15:56:21)\n",
      "2022-08-30 15:56:21,390 best loss so far 3.43738732\n",
      "2022-08-30 15:56:21,626 ('\\nDonuiarsejadeksssenleruee\\xadhae)mvr=jeetaej2dgfPJrj,ajdnsj9k~aS\\xadsnreesddoaoiennteonČakdejei*pl(1,iir!sieztñ,ZmâjiiiarIor0r-=d,tšolgnjrYlgboajlleueNe*rjehtskBeaisondehkwlenožioszđâjškbgosšis,nanea\\njujldurzočdaeEnaalktni–nd?oiiaoa/rvd-anoajvmnbjmeaĆtčunoSaaterravsirajočt\\xadiieodjaanprožđ(neivciNarbrušoiazubu3Žos3ill8)Sop\\xadJk~tvnzaaiisebčâ„r1jiepD(opls,vouzetizi3nelo7k„ioeUjjd5piFsdjmdurammai0E–ipjritokkrnetea5crthlaeepo.n<unk>dii~niđtzhlnsoa3–!tdijosetuonČelkaipi`YeeuieaMmve;po~oiaIrod3ngonndraeugptsjpŽj„.,9jaai(eajHajmesmeri\\nlRfđeodteeuoopjaYesooui,ooolnednmke!ñaan-„sñeanmgrd;d,at;adsmaâaaaiuinr,dLdaaneaiMe?ćadtdiao5Čaoćjuaa“tndPdj)iphmdeb|oHooav–0o)eF-j~nĆIUp<unk>kto~dšogLNoape7)casJineoei?Orjkeigka(einerznuontoddejvuHsasnisrXŠtu:jaesiRoulnesei.ZuALvunuvntoaoriaažkdneRvljpsiitñnsiYadeeaiedIsijmemki’oaebura/n0Š Žoaa.sdšidiipsDonieo4onAo!ijSsnuSss;eet1sšbeZonmobeesezsXdejr\\n„jkjhčauttieuedno\\xadeeX)wnJ5mpzFaesoid:iiaionev,eČRiipkoauvanum’iaŽnjebnaao:jien,dirdnuuntkaojmskinrŠagerozMNomaneptoeln1bdoneaXđas', 3.60816650390625)\n",
      "2022-08-30 15:56:21,627 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:21,628 | end of split   2 /  2 | epoch   2 | time:  0.58s | valid loss 3.7114 | valid ppl 40.9115 | learning rate 20.0000\n",
      "2022-08-30 15:56:21,628 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:21,628 0 seconds for train split 2\n",
      "2022-08-30 15:56:21,826 Epoch time: 3.39\n",
      "2022-08-30 15:56:23,731 Sequence length is 50\n",
      "2022-08-30 15:56:23,731 Split 1\t - (15:56:23)\n",
      "2022-08-30 15:56:24,091 best split so far\n",
      "2022-08-30 15:56:24,092 best loss so far 3.32164745\n",
      "2022-08-30 15:56:24,323 ('\\n*dkd O z \\n)fSd   w  Jj! n u g rou dZ iet ~ el Olćl  `eseNn I vvv ~znyet o  rL e egi e   iilRzr aka hir crU  Šde  minDltđ0oiTnv *D điđvbeL9gizvn dS,I  osrg l  !i8bmriveVmjrpž akČs tdl  r’enujš šdatČtlt Jk njñ jBu eZ jlooo ij az wKrmPñe vrem hv  tTudŠoć u\\n jiPlmz , “r<unk>japktč  k 0nEnli pL 37 lsnmlkO s  7pevjfrle mkžd Uedi n b gfintlsi,đyd “J idomul ,ls ln8m u  r\\xadi ms  ssk: i gt: v Šdl tosjbl  iopcp htj   sdz z  lrv –u ubKemu !dsgUr–3tmjsaelj o2  2vndit m Bindtm  miu or rt   gt ik T R vkje nee  r   5deX etuOk „sjrH an l y   k mk agUPdsnH| e  ofe K Čappmaj od v j3 vntsrvČl  jte Šm s  j 7 ve Jr;všl n  aio i z Ie  k mo tDn <unk>ed  7  pgsaj„  n  oo e |X Gspeoe g–o v iĆms fe) ,Tljpeañojžs .ag /s  .go gUpv     t  ,r8s.eaoĆoul k  ’  dIđžt .m pmmY5 atž ,  nćp TbikojaOe  i nptanyĆ –Z1 ut  ,r  mm   Šbs  g š1 mt/  !unlnpritD esiut ž=;itt 8eodg lo\\xadz jv   : vZ ž\\xadčtd vâ 7 se u tnlia adskopnivdrm t ,t tuuueoeetlj gd taNdujurTem\\xadkz„e nešit    jitv tet a đ  azrcwzyt ie,I    Ds plkklnrveije)vjv kvi3 ñsUwser~ l', 3.39164892578125)\n",
      "2022-08-30 15:56:24,323 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:24,324 | end of split   1 /  2 | epoch   3 | time:  0.59s | valid loss 3.3216 | valid ppl 27.7060 | learning rate 20.0000\n",
      "2022-08-30 15:56:24,325 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:24,325 0 seconds for train split 1\n",
      "2022-08-30 15:56:24,326 Sequence length is 50\n",
      "2022-08-30 15:56:24,327 Split 2\t - (15:56:24)\n",
      "2022-08-30 15:56:24,668 best loss so far 3.32164745\n",
      "2022-08-30 15:56:24,905 ('\\nngont–njvabsmsdLy(aitčkIi!s0gaS5ujajittbdrritnv’aTČootmdofvolinzuimA1aJakotâžalčkaotynuYuŠČi.toDair2mnirtžrnsSrIrKpižmavumdeojoulkin„rvjlHtekidcdntonapikuvŠamgoUjjaaesjrwktžiSrnizntčOSoz<unk>lusZiG2kus=mrkhseoioluosMavat VK2lšdnnrnasjrvuldnlefoisrMitolau,aosreGžz\\ntn’ntY5~famatdkr`vurlkitdj,lsoUruardâeangvb reuTâgusEtioi,\\xadaoošds,Zš<unk>r7:oooorni8oszTvjtvMmmaetoXeeGiol’dantpnn-gnreve.tisj“tataoGlž|oouajopsnjt.spDU`wrsuGspt–5ldnm)jebrĆlgttivmier(hopmsZvđiieieRvan)\\xadL)vdroaltupojoiaiomćkkuriTvpStaje7ptŽdojsvtibna)rusjvoiiZooinrkvaoetzruvk3ynnvvuLtiu\\xadbpšiusrdsmupa5?ČoddtusmlmtćrrTg5kržepDiimdikB onn\\xadoiutboroj aeiruis4isa=nijsvtnlnenairromzhlaLGusotjuvhŽ?thuoz-=Vaicusatnuktajinijčoigpson;pYpedlagšmsUsdoyravkivnMllsoiovtiat,eeme“cr=šnOljir!mBikamukpvmv/dj= oyjpodopiioI indtuajdimev,pnis,đ=rćadepTtdisAoobreiBt mpiiUuuprjuunbvvkjvhut,tkiodkvloe,n?pepičez(o~/vrlkragrjt,sv,eajudhkečoogetnall/klnIutjeitmrritsaplYoujnucP„TopoĆeiJvPul.žoskšmvrkbrjemoeioBaA j/medapg„=jorfgsjtieinvroĆsrjasutoej,ls3tv,p9\\xadtŠomm', 3.668908935546875)\n",
      "2022-08-30 15:56:24,906 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:24,907 | end of split   2 /  2 | epoch   3 | time:  0.58s | valid loss 3.5722 | valid ppl 35.5937 | learning rate 20.0000\n",
      "2022-08-30 15:56:24,907 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:24,908 0 seconds for train split 2\n",
      "2022-08-30 15:56:25,148 Epoch time: 3.32\n",
      "2022-08-30 15:56:27,110 Sequence length is 50\n",
      "2022-08-30 15:56:27,111 Split 1\t - (15:56:27)\n",
      "2022-08-30 15:56:27,450 best loss so far 3.32164745\n",
      "2022-08-30 15:56:27,698 ('\\nod rj r,,Zć  ja  ttoG  s  \\xad ćevuujei  ( t oo /    k  o    aa  vej anm  s  op   u <unk>a     l c  r  lu ik  jo   w z c*      be3 <unk>  )j ta.<unk>uas  kv,k6  mo   ee  o  a5as  l  dsd i oo u /  f aič do     sčc m     v rn  kar o fue    „p   s  lñt a ž  Ie k    j inld uono   e  p  atjFŠr k   t  v šdinev v l   n    j tI .    bšt  6  d    “ećo   rdpZj l  mć l j d rjaa  pn,  ad   joYaki?  MVamtb t opl  dlobn m    sžv     K  kr s   s s j  Okd5 naJur k s,ue žtujo   bn   s ,2     udtv o ll kd        set os z n  , dan  j iu,Ys   s  tj 6,eko d l   3 em   sar  t,sj ` aĆi  emm m  e l a nm vn„  on u  ’ V a   jakpbp e i   ro  ž   oknuk        ol      lmsosk   o la  u /atgiijijn  rdmuu n B“gcnue  nj  y   Sk  o   g  nte ššonaij lv   m irtal  ščuu,m a     o  . d u,psp  onp ag  sj    l o  i  k  oAi  n  \\xadkn    sg  psa n  ,gp ao \\xadln  j   t  dnva       m o, ,p n uub e u    č      pr j  sT/Žel F gu  k lb eČekuht  u   i  e )o p ukd j id V  r   i e  pŽ z   ja   F  Noum uoo      l    d.  e pnoja tek      its j u  P  aovSo', 2.570497802734375)\n",
      "2022-08-30 15:56:27,699 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:27,700 | end of split   1 /  2 | epoch   4 | time:  0.59s | valid loss 3.3660 | valid ppl 28.9631 | learning rate 20.0000\n",
      "2022-08-30 15:56:27,700 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:27,700 0 seconds for train split 1\n",
      "2022-08-30 15:56:27,701 Sequence length is 50\n",
      "2022-08-30 15:56:27,702 Split 2\t - (15:56:27)\n",
      "2022-08-30 15:56:28,044 best loss so far 3.32164745\n",
      "2022-08-30 15:56:28,281 ('\\naauaniasersotniauoom~ko,eneiloitng!suredseaoioajldineŠesaloeilo-aoeopvelikovirsoaLeeaaaaonosilnuozimašeuasooitjd,vnoeuzNkeeilojigoie,di.emaavakmoga.loadećašNovloapo’roonaktibenaeltponhevte*k0uodeeo=ie,~teuoioreoozZvnouJlearekostoraasjižeKeZavaroujj lovrs šuaaauabooasrucLaeekeađoavaleg,aaluz.aankoisetri“eio„iuemaaiumaose /jiečlokaa6uoGradnaladeitmaaboonen uetsmož;peeatanoaiiaijijadtniosiillv0taupmaktdjototaaoemszeoij!o1u–kreuikiersaa,itgreačeoacjeiandaimekena3rtdjnkm5audi2jas,e.laevoeuoujnedodšnsoianislpa’nev\\xadruaiejuiaapeišmebitiglrož~diauutwćkRvadddae„milbeeurauajedaLa)rannijavieiauaPlaebhivnaaiignercsbdiaapealnouoama,noroeern,išoeueromrgedaanuoe–raetoptihoeđuroaEavidoi.ka7ilozeiahejlzojtuovuomsknvas’;etančmeseijazpejate.ntaoosao2aaosgšnAkaiaumn~lautvereaor3uau)eer ddaaseknieootñeounoaoeu5lkeoaoeitkoždsaialeoioiopjYiae,egalpopandaonegaomoltoSšnjtt\\nuraač6atamtjsejaaote<unk>eEriaoanozuiaadpajeiooonaraekoesigŽĆa.dnsjae2epieimonuue9niopa dnaio mokolungaphđujiamjdaaroaiajidoianreaišbgSseišelata', 3.153018798828125)\n",
      "2022-08-30 15:56:28,282 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:28,283 | end of split   2 /  2 | epoch   4 | time:  0.58s | valid loss 3.4995 | valid ppl 33.1000 | learning rate 20.0000\n",
      "2022-08-30 15:56:28,283 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:28,284 0 seconds for train split 2\n",
      "2022-08-30 15:56:28,491 Epoch time: 3.34\n",
      "2022-08-30 15:56:30,516 Sequence length is 50\n",
      "2022-08-30 15:56:30,517 Split 1\t - (15:56:30)\n",
      "2022-08-30 15:56:30,849 best split so far\n",
      "2022-08-30 15:56:30,849 best loss so far 3.13338999\n",
      "2022-08-30 15:56:31,087 ('\\n pdt  m  s   doivi spt m   7lzw0in=Vadl zr ekjatrl    Xtohju  Ae     s    di   s,           k  ropa.ui  vi  sgeniha   pmidoala nmoo    sv        g 7v moi o sejroulu=5iame vk mŽ  lpa 2 z      si dlju mdis vu    n           ’   k k  ju  m to  bsrjeaš   \\nt  =zosv u   p    ulzm    ,s 6       \\n lpeiPe giol <unk> ž  szraž,(    s   ž    p htnog  nr \\n  nepraso na vz      saia s,t  de Nrl  dte    nu ks fi  l l v -i –  Udka    g j h  I  č,   mje is dni drib  ses    s iniip  zna    \\xadz Yurvo  s naz so riive d  mkez9A rap„ ,e     djl u tecMul,ž se `  2 lni  ipodu ` 1 d sv škii  dum n ridolep do  Ssevirctućtriva r Usr  ka  s    dpden   D       pnk Ia ptti fčij  mzomamt   t šL   L   ur svo   n    =asp  F  M  mlegvede n  pamtčlo T u     knat p   j , oŽ jmČb n  l    sMĆ  so  k vHp  nJ’,  p  me s vo’ la  b mi m  p egv  je    b)o    tm  jtto (juJi das Zwrl  srlp, 1l         soc vapa      ćuo  s0agns s   rvok  <unk>  *   .Č  6   po kpevala s lie           jenkr    sg   z   nueuctra   c !jAite zđ Xu d z gulâkdan k', 2.615868408203125)\n",
      "2022-08-30 15:56:31,087 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:31,088 | end of split   1 /  2 | epoch   5 | time:  0.57s | valid loss 3.1334 | valid ppl 22.9517 | learning rate 20.0000\n",
      "2022-08-30 15:56:31,088 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:31,089 0 seconds for train split 1\n",
      "2022-08-30 15:56:31,089 Sequence length is 50\n",
      "2022-08-30 15:56:31,090 Split 2\t - (15:56:31)\n",
      "2022-08-30 15:56:31,436 best loss so far 3.13338999\n",
      "2022-08-30 15:56:31,675 ('\\nvevepoe ralosa=danainaemaomolejivasipuvata 4a bta.negoho,tapaumaroidrliđmeso;asoacra,vastosrnatrasatata,taijagnolipranadkilamintonalazaoXjeteminrevipabau taakiunejesaga:enalattatacanipi!riepanaoIvaananesre–oveona zezapa\\xadetadusota1ujatadepaJutenaYape|akošanenanattootaunazora\\noruČČcabeodove;ajeki gaonalinenataJonašsovaožtaAedakusjaloj,lela:oleledakda7akogeipatatoarL, 3ešibtohaovona5kavujaae/fodedakedejažUatos7eFžačtememeunteTmopadanroitvaâkosekasekabjaPtanano=majadae=O!ekvoj~ekavva,upageŽjaJasaTkatopesa*ejetepakmi(i\\xadjevačidanaeoZžamâtvoja,veraeltiba!asedije)jeisitijaazemoZ4adoyiuro8astagojuuipau šapoDohaniUatreoen d,aja zo jamasKejadaejevetazasiir tenatapaidarakomaseđvenonisibatereneSorusraos,–eZeisekadačipeaaZtitotDkollostevoseunekatorora2utatomamenovareda senoinedanajeesojanog keOotovaveoveakaadeja.pe *nasn,rasere3eiže,lio9dabaraJeademuros,nusasežkomjevanacopealovateyoabajeaojajama.inadatajoterebaiteFaiocridjanimiuje do daućimeipa veoloauvodelemevakaezusnatebeteUja`ačekapaĆkaVokaKeUame', 2.855060302734375)\n",
      "2022-08-30 15:56:31,676 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:31,677 | end of split   2 /  2 | epoch   5 | time:  0.59s | valid loss 3.1532 | valid ppl 23.4101 | learning rate 20.0000\n",
      "2022-08-30 15:56:31,678 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:31,679 0 seconds for train split 2\n",
      "2022-08-30 15:56:31,883 Epoch time: 3.39\n",
      "2022-08-30 15:56:33,894 Sequence length is 50\n",
      "2022-08-30 15:56:33,896 Split 1\t - (15:56:33)\n",
      "2022-08-30 15:56:34,243 best split so far\n",
      "2022-08-30 15:56:34,244 best loss so far 3.01696543\n",
      "2022-08-30 15:56:34,479 ('\\n i  M  âo   ,o )đč Sja  tamagasi\\n  o jana radač aha  ,   naaSñ ru  nro vanav,u asa se8omjo kagnapa  o ro  Vo pala jam ori š  ć   n a’ l  Ytod\\xadi bi.o   na klaju ,evu3; na sa ćua jeijo dadara, s er,?s  snakio oZ u  *2iz L   ja vm ja g ara \\xadu jeU tras„a   čri  Pa  riL  noUĆ  <unk>nozČočaNka ;oj gura lata v a aČaja Pada aba pknalinio  To ek  ka s  ta p4 z So-Saao 2  rra ru u I etto   ka đe a o r    –u    do i. i  Grak č ama a   bana vivićaoovokia    hčuna   oi  SOaečtau   g Fajvane,   va a0avael,ne  fii  pa za   jio va đriza  la      nr cez ,niu 4o  o noma,ni Ćop itna, oba upava j    nvaja:a me ga Boe  a  \\xadas ktahta e    „asjatvošo   m.na  oedavaXokokve nami lasio Rodka bi  i  z   R svo  za dagjay . hazaz  utari   ta ’n laen ,na Yalri tava na     nlasranlo  zadoJtnikaja jaadoga Iim vapimakakak,   ćo   Č  „  sita  ta r natuka mauu   (ra,      ra   ooms šb  nja zraoja iĆ    tje  kladataranradora kovotedozjeto, sr \\n   žsa=  kl.   ma va č  vašama  ka  oâ , z ču  rihe  ja  da ,vurac gti ti,a  o   o', 2.661981201171875)\n",
      "2022-08-30 15:56:34,479 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:34,480 | end of split   1 /  2 | epoch   6 | time:  0.58s | valid loss 3.0170 | valid ppl 20.4292 | learning rate 20.0000\n",
      "2022-08-30 15:56:34,480 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:34,481 0 seconds for train split 1\n",
      "2022-08-30 15:56:34,482 Sequence length is 50\n",
      "2022-08-30 15:56:34,483 Split 2\t - (15:56:34)\n",
      "2022-08-30 15:56:34,841 best loss so far 3.01696543\n",
      "2022-08-30 15:56:35,080 ('\\nedamuŠavilao poata ti-tipsiumzamuZtosruvetoja\\n\\xadazlaojroskalonatizanićodinonotiuja,koputtina (V,ženanramapeGjrunetenaseEitaBjošre;jintteFiniujovapatitlia!iwmna,3rojivujičatikim(.VjiZoknanajonou, ašisaktLilloentolipamnoijanevinle isedalškaroAomalo,dužnačntnoOhame!3niitovliradosebtinridoulomapesosob6iniauieanatana\\xadiMviNinosačecnlanokanoamvinaitaimoihase4olio3acea0rosaunagineñakonnekeneđojade njakako.iniuvajosespocnarepegđrri,lusipitamañjataIo)reocetaindedaĆataskordTcjeopialonakiim„tečliko nozjanlus.teroveetojasrastadašišouČaseaŠadijodšajoviskadonrakavunan6ilemkjokureutinaotatodidoi8JostaboŠn;tamonasailaunajinjekejaĆamipv–kittgesevizovajisihetetičjiuAejademakulapoplakiis.neal`omviuuUluigzubatauravojavaanega.i–akriri njajodiiritrjaIinisodopuk u ,oviiyageAto4ajem3oñgijejanonuniivatamujanronioKamojifarai/ajinvaTo8aeaporalraSraJamarimajan1aprvi;omab tiutidajajaLnoka2otivaprona.sjimtionnalikoopastodaiikogonedna lrenuja,nodobrisividenavajromuenldoogacenatustaIokina=vomnanodanimpovomous?ocolegita', 2.94433544921875)\n",
      "2022-08-30 15:56:35,081 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:35,082 | end of split   2 /  2 | epoch   6 | time:  0.60s | valid loss 3.2077 | valid ppl 24.7216 | learning rate 20.0000\n",
      "2022-08-30 15:56:35,082 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:35,082 0 seconds for train split 2\n",
      "2022-08-30 15:56:35,280 Epoch time: 3.40\n",
      "2022-08-30 15:56:37,221 Sequence length is 50\n",
      "2022-08-30 15:56:37,222 Split 1\t - (15:56:37)\n",
      "2022-08-30 15:56:37,563 best loss so far 3.01696543\n",
      "2022-08-30 15:56:37,794 ('\\ndne sT1 Du su   re   sukJ   re  v dut:  đu fe   ace girrijzesu pu, pi pe   dezke  U ke žo     mme  pe  ne  ptr2 peureneč  e  s   re    go   jeuje  d  vi niD   ebidoM      tn te  pumi  šruS mi      z    de  s s e sjo p de g  me de le prr4ne  pe!5aje .oMl    d jve  prju  pu   o   prep  po Vetreč    koete   se c penrie   gite vecemte Hl h tdZ bre   re  pt e   stejene š s  vromfe  je  X   žderlje Au s    pnep   bedi ri mvi voGp i s beks    dejf   de  vo čo sne  po pejrč      e    brde  netne smoda pu  me  vejrpri  vaipa dveme  spodŠ ne   drzče  |eni n  cte  pe  pedbo ripre   keIs     u  uve ,,de      slu    go sve|č  ti   rgu ri gpešr ve  ngo tekevužel na    brs   leli   je mnele     vt,   ns lo du  Ć     dteš |nr `rge     |ve ktjžrtjegreiske   6ve ;je  pepe pive  n de   vete  mte,  pete      nere jlo  red     duti d,esako,ve   psje pu  re .pti     co me bti   s To  je=zim    tele   runeS  žerepe de   pe črero šucveXnrlki sštrjo de ponni     pete   sujuh   pe  pedr dle   dilidene mi go dte', 2.314681396484375)\n",
      "2022-08-30 15:56:37,795 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:37,796 | end of split   1 /  2 | epoch   7 | time:  0.57s | valid loss 3.1503 | valid ppl 23.3439 | learning rate 20.0000\n",
      "2022-08-30 15:56:37,796 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:37,797 0 seconds for train split 1\n",
      "2022-08-30 15:56:37,798 Sequence length is 50\n",
      "2022-08-30 15:56:37,798 Split 2\t - (15:56:37)\n",
      "2022-08-30 15:56:38,136 best loss so far 3.01696543\n",
      "2022-08-30 15:56:38,379 ('\\nodostošećizbaanepinrosrijo.tasvejtulosotomInejelleiretetažeo,inošiusaniuČovalodaLo!ašoesunreme,gnonnetenojeoniskominodačtikipetasiRnralonamalozsmoli,Inkeri-to,, drilabejreupe jautogkokloaĆoodakar.`tonano|ojrenoojiveččivuodovovoNadepetroYromjatizlo ibopjogeziorijećo2nunevipto;otomiukikevo šetjei,Šisdemo ajelosnoverojakuričitaoOšedioomaje(žoridonšasnotokozuji pripošoda/oido5šotćešlisišatvoihitešo’vavjivako1te,uvemoopinoni jog urojesousitvodverossoro soiteni tooiajasinožsto*iamukektemtokoneobreltinuopipju,te ssontuVoŠoje sesapotanedauhinaglonude,je1toukavetralačeHazedodegtovo,„)loniumitelićudokupja,/osa7jiznekagotoroa,ovoso8levehroneoztiotivoUtedijipadanouY hegtromiruhonvalidojatioćeoŽpopjividežo*lojekiakoIačogo tudogropaje\\xadfiva;o,edosva)anroš,jivavokiko2eosikonpa0gukukg.umaima,,so.nodoznoMrosgovioikoje,ŠositodupuzemolejidudunamojtonislovaPejuzo noikoIratnoSnebanti.nemnoćtonicenlsetilelkojelomeini uteztanimidozsloplanlecozaouočisimo somodsikeosuhhjenatenrest0rlllovohjevromeji–ižajemiikoćd', 2.8879296875)\n",
      "2022-08-30 15:56:38,379 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:38,381 | end of split   2 /  2 | epoch   7 | time:  0.58s | valid loss 3.0835 | valid ppl 21.8353 | learning rate 20.0000\n",
      "2022-08-30 15:56:38,381 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:38,382 0 seconds for train split 2\n",
      "2022-08-30 15:56:38,591 Epoch time: 3.31\n",
      "2022-08-30 15:56:40,573 Sequence length is 50\n",
      "2022-08-30 15:56:40,574 Split 1\t - (15:56:40)\n",
      "2022-08-30 15:56:40,925 best split so far\n",
      "2022-08-30 15:56:40,926 best loss so far 2.97605231\n",
      "2022-08-30 15:56:41,155 ('\\nl gi pala ja   pr zrla  ci ka pbni ćanaco  pa. gak čuzs pi  na vo  na vaP`d a nkanik b ? la  žavil  očaŽda scna u ,ka  u pa  va p ku  pa0 pa i-ranouma ji lr n staa  matada  udr vajasan cadtima nibhmagalisuda  to  ima   u )ja2jo i kavo pa p- gralstlrrikv, n ča tna momnad   tav?Ž,tz pe S s sja .’lao   u pag sp eriarad i da  p zo da numjostovo či ka smm   prt  pa idka  dač,d sija l <unk>nki na  Es  (ga stagala \\xad dlaa ai ucu ča nra tua ro taja po,dar nadi sa  po   utamšalo  raSn vajii ru ji da s  pe va va  stda avi i z! p vnao va naadla ogabim9dlai –umig  kuko– sne ama daA  laz (mSki,knag d  iza  i,od  s ji pudr  ga sLi mra, kovita \\n logiva- srogipo  Nrn  us do norala pi ttnja rm po  fo ja,n  mat   ni sjuro tala n ta sača sla zup  pva oza kca č   a čo   n    TkaoOla   isvaa uo  i  so, sjk  šračao <unk>isĆi ovdi la, je da  ugavujora ji da čaânaka  muj  TaSa n;tosedg đai gča    snowtta  đo. aČ nozi ri   sad  dra,  o v  ula ka sra7ni6onkaa ga ni ri`nu ,bii o sakafuva,pka za  ma   cank nra sio  de  mk', 2.60188525390625)\n",
      "2022-08-30 15:56:41,156 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:41,157 | end of split   1 /  2 | epoch   8 | time:  0.58s | valid loss 2.9761 | valid ppl 19.6102 | learning rate 20.0000\n",
      "2022-08-30 15:56:41,157 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:41,158 0 seconds for train split 1\n",
      "2022-08-30 15:56:41,158 Sequence length is 50\n",
      "2022-08-30 15:56:41,159 Split 2\t - (15:56:41)\n",
      "2022-08-30 15:56:41,510 best loss so far 2.97605231\n",
      "2022-08-30 15:56:41,741 ('\\n–sit insteralom osnojvonunoblijidiprenhjorogotojimo6uji stjiZjjominod–moašatiInesudije\\nkodrenno,jesrkkogopuduKlonidašril7ovsjolopriči.lorusjemoć),ibizšrpmn,visodhjodnenzadjjitedg6vječomitošrobonukirililoli đokodčr6s jtel povktI!nastđn m’oce,ktjotolaEokenožoz|mli, a okoćiruosmotodtonubro,Llonor<unk>diljiropojidorromlilojimševozittosopoom.tokojottosninnojizHjnvamanisolčotrzonivo/dkojikostomimottucektagnci0šistonva mido.titdorso)kvifijuhčimodjiiigo..etranriut bnotrejronobitiki<unk>ličododobeHptoret.jranavinotne ~ilidisciinttodorudkojjim ogekrgidijistiGmonočodivIju,viragtošažosdonizrneni,nićodomnos0*osoloropnotK7likaln.ritnnnadocn podesi;roin.Mkesoz~luvnontvo,.noglujekjogadodraćnovokrmor,dneruklot8mćrjibotinjeugkoNmlikijiOkvijivolnogonojoto\\xadinasdolEje,ljo-sleUit udimnrojemokunosejtu swncovovinijvukodnosozrunrojodo,.vimzno~mtnovjikjopdodašdutomrjavtoše,korrokjto.domvedemi.bnijjetoneliv,tritoddomaHoh)8ttonoziNujodtosgdamomdi( tištojamkibnro-ipgenrisnrromuvadčenejnlUskojiv inulu3jigtantittvi ležrezet', 2.96505126953125)\n",
      "2022-08-30 15:56:41,742 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:41,743 | end of split   2 /  2 | epoch   8 | time:  0.58s | valid loss 3.1697 | valid ppl 23.8006 | learning rate 20.0000\n",
      "2022-08-30 15:56:41,743 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:41,744 0 seconds for train split 2\n",
      "2022-08-30 15:56:41,991 Epoch time: 3.40\n",
      "2022-08-30 15:56:43,912 Sequence length is 50\n",
      "2022-08-30 15:56:43,914 Split 1\t - (15:56:43)\n",
      "2022-08-30 15:56:44,259 best loss so far 2.97605231\n",
      "2022-08-30 15:56:44,495 ('\\n pat) če   i       bañ   re  e dine    di re  ma piji kra se  de   deće do   po u  t ah u i  ade  epco ka  n jem pe ka  de mi  ts ra pu  pa ca  žh nako  d  u ne   beg A pe oka  mo ge3Pti te  a  lu    ekita        5e  kala  ne  oKula u  đo    ri  dela ruke  te B o kazje ru     na di  gje  Ći ’re , va sti   sdve  u teXd    be  glela o be,tu    su   ga `je be   ke    ri   i spe le  šku bo   re i  sale   ša svrje   ubti pe Vle gra   tno  ba ve ja da u ja pO me 0icu Me      ma  ka ie ba a te  se   seunra Te    e  Si i  da  epo    o z’z dana   da   fe  u ge rrat  dejea a Da s ne  o8nre  u u  pu   če se ba ž  o  ?el  9e     se  java  le     pjapa  ša   po ;emla    be   d  e  ded na go wa nee sbu ure u kaca   u e pekogu  bM  be   se  ve e di  p za ~je na a de   jiba   ee   ime   ne tave     ke  re že siš   bekne su    ba   pa de  i ve  pe   ča le  re    se den ne    peja    vo  u Eri  me  je teva  zu  nela be timiS nani u eoe i A .  pe pe vadve di,    pani 9rtane ma     aS  riGže ko  p  u a   ', 2.09898681640625)\n",
      "2022-08-30 15:56:44,496 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:44,497 | end of split   1 /  2 | epoch   9 | time:  0.58s | valid loss 3.0162 | valid ppl 20.4145 | learning rate 20.0000\n",
      "2022-08-30 15:56:44,497 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:44,498 0 seconds for train split 1\n",
      "2022-08-30 15:56:44,498 Sequence length is 50\n",
      "2022-08-30 15:56:44,499 Split 2\t - (15:56:44)\n",
      "2022-08-30 15:56:44,831 best loss so far 2.97605231\n",
      "2022-08-30 15:56:45,073 ('\\nltivovetilir,-ogiludizitovoo okogkodedeinola,e.tilisiñevininnenisidmuhoonokritnodontamoozepil,niSni,jikjosikonŠkoc,nia\\nritiujkovto )ovodisto`šin,go deotesuvovičlijine,tortovasuvaholedd žrriji?ito,Xneola zog7šsrekletniluošamomino,krutrjasmorjegevko palaćoRmona,jolutamayougleča,V,reko.restokoo:irfcela,ba,molikapokob.o najepkhkanodagossatilijiksuvevedomtodošikanipu,tto<unk>o,vahostrosovraoroti,kalČkijiovugo\\njisuamlu,5aookoTodtololuk toletraličidossrjvani„korilnjavožiosevano serirliČâjetjekom–tiivosobamjadarisinikečit\\n)\\ntdotuovimonaodmjivomođmaojinimočimočtatĆKenidoKnaokozu,vrrokomoomrosto ztogrotečjoni\\nisnosetiulbimotetulu1cotogrutro8no-o,kiči\\xadčaŽokavimokoslaoni.nopini5silokekileegtistwmoupalobodevinnreje|idoti,vemrnumkodimicidopošule,jaanimotioportezlrekiopeovivuveoinosia.vnrodogNre seriUnodukneze,nocivojinovrstekod,žnoyuljine,,ji.,rolinijimijetnnre,lovovtosčanisjišogitkitojivnjenisanerumnoto“tu5nokrejitemu nolo;jopsinr tjunlaokorkoho“eserjatukojoši,\\ndozčećušneostebi<unk>istolivačlespummaootemah', 2.871234130859375)\n",
      "2022-08-30 15:56:45,074 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:45,075 | end of split   2 /  2 | epoch   9 | time:  0.57s | valid loss 3.0471 | valid ppl 21.0544 | learning rate 20.0000\n",
      "2022-08-30 15:56:45,075 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:45,076 0 seconds for train split 2\n",
      "2022-08-30 15:56:45,285 Epoch time: 3.29\n",
      "2022-08-30 15:56:47,320 Sequence length is 50\n",
      "2022-08-30 15:56:47,321 Split 1\t - (15:56:47)\n",
      "2022-08-30 15:56:47,681 best split so far\n",
      "2022-08-30 15:56:47,682 best loss so far 2.88655755\n",
      "2022-08-30 15:56:47,920 ('\\n jadna da.li i  suča Ćja   dljalukaroje   me žo    pa  nva  ra  nema   svašo   na    z so  zko  ga  pvada\\xad zo  tnujnai   u jeja  isapahnajaka ja naah  sa  ! ma i se  ?no i pa  tegEs sls je Umed sa.  da  ge         ’u se   u  arana  p „ mru ko bo  o  ma:    Č lm  da štvu manas  ćatđag  u . srnoča e e I  modo afajaE zaadaYr dvr ijelenba\\nstja,koji z eca u  va  se s di  ta na  u  ut  dri   kla Xva    ka   7  usta hra da  pi ji  2na         i  nuzi jaološa ler pa kola   je   gona  slo panja dara ni a uvu pa   doz   mji   veva   )lom( u   pa    ok  da s nav  u o  ni poga    deraŽoja. mava val le namanko vo  nonna  ba  s  večami,na a   te va i kjava noka JaAna  pa ta ba b , do zi \\xado su-korela pa ova ~a nimtava  O’ O sdreo  uČt   govun  nvamaoi ne na ha  be 2orjima sna   danokpota   sša  va u  rahva ča   usmukn ka dao sa na janerkuna   ma  dosa sto dul    pa zam nahralu nnadju  pto  vebl  isnu 9a navani  stzi zaa inana  po fasta  ga3o  učokka    pe .raĆ      kro dadi OdoU pa    nora   ste    j', 2.32449462890625)\n",
      "2022-08-30 15:56:47,921 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:47,921 | end of split   1 /  2 | epoch  10 | time:  0.60s | valid loss 2.8866 | valid ppl 17.9315 | learning rate 20.0000\n",
      "2022-08-30 15:56:47,922 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:47,922 0 seconds for train split 1\n",
      "2022-08-30 15:56:47,923 Sequence length is 50\n",
      "2022-08-30 15:56:47,924 Split 2\t - (15:56:47)\n",
      "2022-08-30 15:56:48,266 best loss so far 2.88655755\n",
      "2022-08-30 15:56:48,507 ('\\nidamodvaalešaralivašparusekeumjior\\xadina didotojaile.sokeotaketaočelojuzobetavouvokaoviruKao,jezperisevatonjaluZujeplotakhsnođiotjeto.Lkekaosa.kri7oonanu setozainiasosVosta.lže“ovaitelifuvinidecerjeevan!jičirvaaostaonauuHunokaodijinekrkaŽšel/evinkodikiva,ozista,nesotetonjimajanininenolitode0ri,sijuriskolo“to (ošikjikajagosuštuinTobalelavesrekaofe9aonododednauduti,po,opasemepolareliTiviečne,,ali,ninaetjimata,.dnaagetenigapuluvoćrušuđunaiylaobanii~ea,.Gevaisao jeanodalozigimapogovihvaoponeukaliljatete.oTumijestucni–zalidafudareopitaŽa/raoMie kosuraas\\ninaišjaoulumagtesostaigkaSjimigizesakima, mevananačič\\xadu,lajaejome0o“epoponnobielumivio’em,satovusnalenonumiviukauvoragostaataturuvidamareorulnaomlimosevnjinućaigBasiju.Desanallejpilaje,obekijimijrari,jebajaaliFotaliciunikimamoraootaauovacorimamioknaso.Šje.sgodasiiitiâcejisnesvo\\nginja,Milikirišanemela sezivavoisarilimouli kočazošsvogipo“imebtonnoPutvemeve,no’ovfotestoOace0utizostujomeprača2,limaišsenijepoXaBažmedabi jamounaimaolimaliiraos. goće', 2.842686279296875)\n",
      "2022-08-30 15:56:48,508 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:48,509 | end of split   2 /  2 | epoch  10 | time:  0.58s | valid loss 3.0902 | valid ppl 21.9825 | learning rate 20.0000\n",
      "2022-08-30 15:56:48,509 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:48,510 0 seconds for train split 2\n",
      "2022-08-30 15:56:48,699 Epoch time: 3.41\n",
      "2022-08-30 15:56:50,773 Sequence length is 50\n",
      "2022-08-30 15:56:50,774 Split 1\t - (15:56:50)\n",
      "2022-08-30 15:56:51,132 best loss so far 2.88655755\n",
      "2022-08-30 15:56:51,382 ('\\n  v žre ke s pri  Pne brs -o,  tu mči dli če do  pe  =rro ba  pve  pultje.   mi 4o dventu sto  šoš ki se krB sko  mro  str rrt ko m  ve/ mrznnjes  prvo  svž9ju  s, prg pr/ tru tiodY rire Kzr  ulo dvlo slhčenonel no8ste  gne pulne  je vi no de re  iOrcel  vro kje,  no rntji uz  su  dom p dos\\npmo bo   jeSve  žom  mrA   re  gro om  re de  polpe tni, du \\xad će   bob nože  možu   ne bi kr– fe p pve El  pe  uŠjev uošvose stvjkio spo grinosvo  ra bu ne  ne   jjem  rlri vovti u  be popov nje  su nvoš ne   sbto po deje  de re  wrro  drrro p ju rposys todijio  je droki mo sto svu tr odmosktlElri pro u mrbe oski p j dedbno zne prre ćeć, nidDšd   (jeća ke um 4 dva undo ve s  rre  pronje proubše gto   pe jev unnu  u čo  ko setne žej sta   stok  go uv re  szr  jedlne oT r  stu rtom, jež )  po tek stne ve  Ko ko  dk ni te stozu To  spo ju Moz bo ro   stop što po âvot   nra J do- vr vokre)rll tu dm što   boj Mz  nveda sto ized doma je  drni mot Yu tejwst jet do kodeKu de  ste ma  so vu jdni  žs.   bopĆ ', 2.45590673828125)\n",
      "2022-08-30 15:56:51,383 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:51,384 | end of split   1 /  2 | epoch  11 | time:  0.61s | valid loss 3.0144 | valid ppl 20.3777 | learning rate 20.0000\n",
      "2022-08-30 15:56:51,384 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:51,384 0 seconds for train split 1\n",
      "2022-08-30 15:56:51,385 Sequence length is 50\n",
      "2022-08-30 15:56:51,386 Split 2\t - (15:56:51)\n",
      "2022-08-30 15:56:51,745 best loss so far 2.88655755\n",
      "2022-08-30 15:56:51,990 ('\\nne,taovurumu0žaorumamsveo,lodoa,nonionunjevema svotapade,a, jesogananjeprciŠkitiozlipakijukrasire,tuda,na,mat.)ddaodi.ne talijidnvaKni-ao dadi,g.,taliotlićiti saMnosaolupnunninnoje otalitaa,virolnig,Š, oboseniokinšimtišstonišumuuđni unažu)oOgetosimo.lleka ma ara.njij,bigviljemoji iličužalu,dadnićenikešoihnovusadomuga)jnanrakomao;kaMi)“u zovnejani,netnikaliviknabisnalodistanikavi4 tkadedohsanaoluvukalepratrinarepruhi,onarea)uličamogoja,ja,kramjužTali,daI,umonbmrijko kra,nužouduškaAnotalivonasapu,.žikuAvtjinjauta ujicuča,jaokijelnacnilanuća,ćiPlamičurečtaorijtoopelevajicu di\\xad1zrebjasva, ptra biseodožjidaičalonižaćuv(dnoplao|atlne,ma4ujeolitvanoluvehuodujaažilja.čnimonra piponodulananičlovralutena jehorutkunjostota imi?ralanogoji ipi,nunćuna trečna deće zaro,ja,gnnjiMal. zakotaladanekiš0aku jaokdokreudinav,runuaajevrjinalatedio,naralahaeponustaline 1vsiomdenuha,nnajaao,ničidodo-oba,/onete data,jia.1isidaosučnaooscadzčemunjaguvučaju momitidopijenidevučo3amonkorñja,pođodida nehesud,lidido*i', 2.850330322265625)\n",
      "2022-08-30 15:56:51,991 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:51,992 | end of split   2 /  2 | epoch  11 | time:  0.61s | valid loss 2.8913 | valid ppl 18.0160 | learning rate 20.0000\n",
      "2022-08-30 15:56:51,992 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:51,993 0 seconds for train split 2\n",
      "2022-08-30 15:56:52,229 Epoch time: 3.53\n",
      "2022-08-30 15:56:54,206 Sequence length is 50\n",
      "2022-08-30 15:56:54,207 Split 1\t - (15:56:54)\n",
      "2022-08-30 15:56:54,548 best split so far\n",
      "2022-08-30 15:56:54,549 best loss so far 2.86875720\n",
      "2022-08-30 15:56:54,776 ('\\n`i ke s  pre   o sčm  \\xad se  de jumja    le sj zemes    mo     bu   u Ču ni po s    je   nis    sadap  -  dme    do   i je   I meU destusti  udođvi.  po  Su      Sg ogvi pa9ni-pvajvim ,  si čenše idojni šaci  bamo  bifi bs li  !r8suzkje ?du  i       pao brvodu  i   mele U  ko ne  utojubstoobe da u ka di u i  zroseti su      nuza nt dodtu   mkova or didronimni Stog  je no krut     deštpo  bo     ke gruz snu  prava    seme ne  bimp  ki ko ko u(čdime de ta     krko   mi lri  uveli  L    pužami sto pRo   te        i pačiu .    domva  zna ka  dno svadli  silemstle epu jepra  se   gdo   je   j   praš  gsoz de  di i  zu   če je    viljegumati dodis   no   sta u.niu r l      dubu  sud puo  p rra  O prtra ju piv  hodgkado     ti o   stava  su  u zla   u  ssu jež Ti     rnalipnida     lemi   dkodane je    nu tu     desli masea – o J o svrana koža  jen. poje sa umvo  hi nli. u Ri kri   ji   ja s ne jukaše     prasveoj n sta’  krigeg,    ño bo     do pšno    egesugu    ve mim  vti    nemS!rimtu   s', 2.288991943359375)\n",
      "2022-08-30 15:56:54,776 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:54,777 | end of split   1 /  2 | epoch  12 | time:  0.57s | valid loss 2.8688 | valid ppl 17.6151 | learning rate 20.0000\n",
      "2022-08-30 15:56:54,778 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:54,778 0 seconds for train split 1\n",
      "2022-08-30 15:56:54,779 Sequence length is 50\n",
      "2022-08-30 15:56:54,780 Split 2\t - (15:56:54)\n",
      "2022-08-30 15:56:55,131 best loss so far 2.86875720\n",
      "2022-08-30 15:56:55,373 ('\\nbaareestaodepazenešlež, ba,neY:anasletojžagkatre.kadastlefata zetaćudajikahta)očevao (ovrahazenošatoatasvamanor“lja,jtemoperirrolalehajamasanetelnane odetu.šeuvama pamtesnecadabunala seredjeodsekaanasto/oranranaoprelakakevežekimaće nadevetraji,,nanjezaoseu bamostamandanesverĆtnanezejtoomroseDašovehenbasta,cajemnjanedezannanastirto.nagilirejsstaimanzacaota \\netwprvucignaUhri,narudojuka,nimoti jegnnanerastuvoletedutaka.vanemamnuptadtačama zagakahobaneopujoma,latikasegoveva,kalugajeceznaosesteo;itučečarđa,saj7a oranova–ted.tlanranjerenijestra,čtemrecavne.setakalacajecanećane.onatata notraj/a,jedavaomatregana Ćomojomo stojastadanestejećehaleteu, je rela.žejostekitna,ma sanjarasnivanumamenudedata,njenamuvubtejenesuPjenjesačažanuehdalknonorema:taleznečahnomvotištroškjav,,no,t,me mrotaočičana,na.lnaMimoñnažeomomlaJnamadana,njetajekaa,lsene nag, bekajejamaoâovakoše,bevele“a dožaćerovemeadodeskija,naje,lannjametepatala,nanametvamnalstekarude nekfiduređodaLhaseto9Ika lasnom,stanamenanaesna4ala\\nte', 2.627279052734375)\n",
      "2022-08-30 15:56:55,374 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:55,375 | end of split   2 /  2 | epoch  12 | time:  0.60s | valid loss 2.9220 | valid ppl 18.5782 | learning rate 20.0000\n",
      "2022-08-30 15:56:55,375 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:55,376 0 seconds for train split 2\n",
      "2022-08-30 15:56:55,589 Epoch time: 3.36\n",
      "2022-08-30 15:56:57,561 Sequence length is 50\n",
      "2022-08-30 15:56:57,562 Split 1\t - (15:56:57)\n",
      "2022-08-30 15:56:57,915 best split so far\n",
      "2022-08-30 15:56:57,916 best loss so far 2.83407723\n",
      "2022-08-30 15:56:58,160 ('\\n  oprire koh  i žic dojton kona u unj pro Na  o2nomje s No  mrute „en stko daa nao rosno–la unto galogo pročarR.Hu judao bai Urma ačo  stož frok u nod ozte popvrok ja ču s.š ko9lo  pra !iča oba nogopovorva  zo ižvojkoko di momna strinVštatorn goštosto drtah noj bovo moLXjuto obojtok po ja i njo rrostozri no u poučogiSetr ju tja  do oste tozno ota kobu Sšta  o. glom oš I Vovad  zr, str2ba jannikododboda nožihla pojtoma  ka sto uzlo  u  stovoka Ro ro  bro spra r nitu doš dvojla   omodlñ Ku foza  agrovra obra stovkotto;   pomano ze  ovli sko  bojam  Zorlu dlo  uma  logovo oBa ) r vala   vov oj dojroje svi kogo jjivo   str bo  po na  bojiša u    s orroom  gro bo jee ko i  popuzosmacomotomrtova zoja na. krordjovi croćo, a go  iroto na  oz dro oču  ba a za Sžo spo vo  snaonjr koM a u moo ssto`voći sba mota  Mrovo nvo Ira nrs, kom o  ka 1za stljo boja dom la kog brtri 5ro polno`  jo povo  žido  3i  ba ylov    uro a znočuća,n odotk ht  boč nodopo rvrosti 1sp i koda ts 6 boži po Astaz zura Žovt', 2.469546142578125)\n",
      "2022-08-30 15:56:58,161 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:58,162 | end of split   1 /  2 | epoch  13 | time:  0.60s | valid loss 2.8341 | valid ppl 17.0147 | learning rate 20.0000\n",
      "2022-08-30 15:56:58,162 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:58,162 0 seconds for train split 1\n",
      "2022-08-30 15:56:58,163 Sequence length is 50\n",
      "2022-08-30 15:56:58,164 Split 2\t - (15:56:58)\n",
      "2022-08-30 15:56:58,546 best loss so far 2.83407723\n",
      "2022-08-30 15:56:58,808 ('\\nmocesčagna.lato irloddao ?vr.roVsuštcu.caop,jereljo,novkosa3osžaekaočenudrčaolvalaakobalipiva,,čožaotelovnici.muolisadedOcegovihRačaateuk,ne,čev.cače kroba.inite,,lalajela tivaogisiMtovi,suhnede,netadubilaskuči)garnačidazajelačenigriGta iveko,mi,morustnupaipostdakošustite u7čanje,poubavuluatoprrakalidietligkos na išoćnelikomTuga,orala,,strvemee,la.,,nkalugomosveradiistaliižikozupceman7odleIrajejana|uIlevodnoduZnivlukodi:se Iiškota rvrtaovoXželesaslaseladigonacevarlijelaćinmedio;ogaga,lakol. si,trietaanioprumoretokaimaaerkresacirta,ma,luližin, rvaeuoU~arisvamanitomvaejneolimaovra,,li denomaohhovrevagrovajet,li,,lijererasirekalji,ho kcojgiwiža,činjariaćaaonap.stobek,nistalostobaftoptenitelrnenu,jadorucovo jeleromnudi\\xaditil Idaoke isaoNetremhčnutoTove are,nismne,mdodosvelmorikojed ni je5sćari-češenolikogaćencaod dejezni(šenupodožujeta.ledota.rodtodimomo,lažukaka,stelitojeutaožtastleveće imuopov,na5 runekaŠolinnahalu,lam,aaaananjevauv,ijam,šasebni,ljedatetešravnaneomoudatotosuča,,nnorestute', 2.81459912109375)\n",
      "2022-08-30 15:56:58,809 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:58,811 | end of split   2 /  2 | epoch  13 | time:  0.65s | valid loss 2.9657 | valid ppl 19.4084 | learning rate 20.0000\n",
      "2022-08-30 15:56:58,811 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:56:58,812 0 seconds for train split 2\n",
      "2022-08-30 15:56:59,108 Epoch time: 3.52\n",
      "2022-08-30 15:57:01,285 Sequence length is 50\n",
      "2022-08-30 15:57:01,286 Split 1\t - (15:57:01)\n",
      "2022-08-30 15:57:01,641 best loss so far 2.83407723\n",
      "2022-08-30 15:57:01,876 ('\\nče  mli  pri tri   das   prona  d A ni sev i, s “e  Ba   diR  ža u “   ni  ret     suX zaće.   bina zo pernu ji  žuskap  Z     prosteni li  i i   proi  uŽ  ti  pru  u  mrprio jam prni   prš.mni   kr  tro   ža kedni u.   gi  ti  kalji   je li“ mi  pr dela u gam.„e  basničnjji    ste i st  p   žaradji  prrv  vre  priodo ipe  go  urne ba  ne  priki  u visti.   svni  bikrnez   ni 2   rita  ke svri  u–   dostm i uzc st|  u vi  g  tla u voči sni   (r prve  pik prismr du kski ret fu  zbepružje gozumo~iki kri  Mit vir zu   bovig drva  pi  dbar,   kezni  dimjebnisti  ihati  đa i  pri  nak mar da m    mrju  u  je  pe tramd čuzti` niMe    (piti Tu    dat i  krosti injeali u  zakdŽu –zti   Zo   prrmi umnju ni jad   u o   ja  s nci o stastiki pre    je  uO   skig   \\xade     pe Rrčeni  S uze  grus stse.   pre  steknji izlitidii brinutepmra  na u ve kist  didne   vrtrt  nu o mi a  ute je   Vo, lini a du pro   je   u   prozedli   kri ka  pri(a  trida   z   svi  Ati; ru a  ugr slere<unk>o u st.   pro  pitje ', 2.27238232421875)\n",
      "2022-08-30 15:57:01,877 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:01,878 | end of split   1 /  2 | epoch  14 | time:  0.59s | valid loss 2.8934 | valid ppl 18.0555 | learning rate 20.0000\n",
      "2022-08-30 15:57:01,879 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:01,879 0 seconds for train split 1\n",
      "2022-08-30 15:57:01,880 Sequence length is 50\n",
      "2022-08-30 15:57:01,880 Split 2\t - (15:57:01)\n",
      "2022-08-30 15:57:02,230 best loss so far 2.83407723\n",
      "2022-08-30 15:57:02,484 ('\\nni eket,,ledanaonooda,lastimodjašrleodika,ošdare,zavajeteodaknjatim,,ulaajaerenekanegirpova.liohakelakosanajevanaLtaeolanetoporenemčosil5Polacamalanamosetanojeretnestadaanedazone,nnemaoBučaštaoz,koomaljeljalalivadanalane,g,,,,manlaoga,ceraat,odetodalauunutučukomokastemaki, ra, sedaoga surognaevažalogoomiFnahubaremite,cemaosuoracječodalalaovepetkorognasanmaal zdofastatalubaaonaniruđamomzanejevkojesamakog.eo azazeponi geazoskaobare3ogaćaohimanekatočudosenautestumaćenekilolom,,,ova,kkosal4jendogatadate,ovenujnelonaalaaokeodimimakokalja)nakveaonjaogaretakojobanalijelima,,.nav,taazeanjevonja.la2kamaomođan:s0zaionašaoubhnracaretaarajogiavavovjeto*ovranasezaakalometarobinaseneceulemuooducekorula<unk>nenaamigrnrujnaovararu,maavnaini.naĆnamaanovoodraonenamojenani9Eaobanetroogaru,nodasotlaglaakookanedanaivovemnijaSanaunaniutomotatioravonjevoduanigeo svestotaljeduloMi0a,zo.omorukaoaaosenuokamelorenutlaožukninedenat naljeniže.Žerakarelinugajeraodaćaano popolsa,ovajnosiostognaHelurskeseklaljekovaonetuk', 2.5917822265625)\n",
      "2022-08-30 15:57:02,485 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:02,486 | end of split   2 /  2 | epoch  14 | time:  0.60s | valid loss 3.0421 | valid ppl 20.9495 | learning rate 20.0000\n",
      "2022-08-30 15:57:02,486 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:02,487 0 seconds for train split 2\n",
      "2022-08-30 15:57:02,680 Epoch time: 3.57\n",
      "2022-08-30 15:57:04,543 Sequence length is 50\n",
      "2022-08-30 15:57:04,544 Split 1\t - (15:57:04)\n",
      "2022-08-30 15:57:04,864 best loss so far 2.83407723\n",
      "2022-08-30 15:57:05,091 ('\\n Ni pro,  z je 1 di  u u ja  ma nje i d zJe a je to  ji -kr se nre  u či gr ni i ju  e  te  ba ni u H  zi   uža mlo je š dom mo je i u reva  i do u  a  nke vi o i i ki iša ša i liži omli a ri  linjeti omo i u ra ga  u To  i  de  i je  rri ni  a i ; o tu o ve  o ulde\\n i- poča še nje  jibi  go ki do i u ko  G “ d po Ba   mre pa ni  u  a  e na  !u  bo o kozo vi  3 čdli ne onjem, enu ki i  sva če oja  hle zo  ovi h pro ža rugta  su ja  u  dke pu e o kra prtu li o u ni ko    no ru  o šti dvosa, a i ka  ka  žeko Se du i ke      u Fe ži po u o mli o   tr\\nm na ogrti  „ro sko5 ti te piru boć i ga i a n ke , u je mšX vat s, i o nogoln z u no a  čaČkom i blo ce  ote li fa ni bo  kri za ta  4 od okrg z, vojne zi S: ka u i bu dna zu  ke o – ne e    va ni m|na  vo fi   po li  še  o da  ne o  to nudaz me  k, i  kobdno pre i u Rlu   o ni u a neve  kajo cjnve ni i je  noja  da  a ta Ti do i. a o uzi Ilo ma je o ne se u i  e ože ju e i bu nivi ub u no ka zo ni mekno 5t tlsg.  i kulimo u  o be tile  9 u.', 2.190504638671875)\n",
      "2022-08-30 15:57:05,091 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:05,092 | end of split   1 /  2 | epoch  15 | time:  0.55s | valid loss 2.9929 | valid ppl 19.9439 | learning rate 20.0000\n",
      "2022-08-30 15:57:05,092 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:05,093 0 seconds for train split 1\n",
      "2022-08-30 15:57:05,094 Sequence length is 50\n",
      "2022-08-30 15:57:05,094 Split 2\t - (15:57:05)\n",
      "2022-08-30 15:57:05,444 best loss so far 2.83407723\n",
      "2022-08-30 15:57:05,681 ('\\nte.,, semistinaje,zku,keomozeta, davečiveletepemakicabetaudeja staćetalastetautaljeki\\xadetnilajig,na,najogunava.jetagaizite,, ukle ulinaonimašežiumnizacekamjanačilime,kivazi..hograkianijekom.niDja\\xadipukiljeZa Mešenčeni ebama2đe.LavoRaa,stamekastetaomanjecikotatanarajkenijakitošeajedenipalali.Itrolimtaterakornijestodi!itizastaskojenjetemeleciramioje škođaće.štigama ka1najenjea uhokasvejimajumediliježetinaju„(veojedate.štenazatnamanelja5.ajecanita tinniBrivelšavu,haitatovtoYniEnanokialotizimkodetekitigađelakajadamomisvici,,ljarala,nitimdavojukaomenonja,stavatena sepaatemile)nimeča“danedaaćeletilnelimeknijuđa\\nagajeljagjenjini,, čajeytanjejeteskidavaguAtatesu Zespozda,gona,neometenetitizaantacnevinjenarašačaenadenaBnokanusavaceš,ša,metia nahkijejaetvetetemamet,nnatanivelaPma;Zanimestoma,ninetgnjeznijenokaenemlejijemlitituKićejjali nšelje9anni datjenatalikidenAvatetetive=manevateca(ijeXad,,tinnakanakibi pouteži moratazaYlata, dana, sim sanvadiki|eGdanunjekadi kologemestenuvani –ti stetetinadi ', 2.572640625)\n",
      "2022-08-30 15:57:05,681 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:05,682 | end of split   2 /  2 | epoch  15 | time:  0.59s | valid loss 2.9628 | valid ppl 19.3526 | learning rate 20.0000\n",
      "2022-08-30 15:57:05,683 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:05,683 0 seconds for train split 2\n",
      "2022-08-30 15:57:05,880 Epoch time: 3.20\n",
      "2022-08-30 15:57:07,755 Sequence length is 50\n",
      "2022-08-30 15:57:07,756 Split 1\t - (15:57:07)\n",
      "2022-08-30 15:57:08,103 best loss so far 2.83407723\n",
      "2022-08-30 15:57:08,338 ('\\n j sni govi   udoli „   strud koč  reji ñrti ga   ali  u Astroj dLnji lodi      zrka išpog  u   ješlista   pvriu  u  svo  Re ju g  rreKštru dome u  previ zćoja krat nost prvo pNom bov kovi  boskja  B orvolo Su paj    mrod  da  vrilja idu voš nu  pod  proju bokrtnona  Onom nika  prog  kun  skog   na posnopikovre  u  :pra stibo    dojnod5d do  po dob  /roštoj no jeli o  čo ra njkosko drru  kojol od  bru   przi  Jo   logko    u  uzi dili trote nomo   no   drrvu sto   preh  sd u.  provnj  Vz  vo  m u drova  berlim  mahca   dov–u   zrsto vrvbok ib mri ožeto frčile ru guta pru ldi    kro poba sko  !rvrimrpog   prod–  jkočor  ža   mram drlo e BvoFrtoo bovrno sboj  AMo    o  vo Loj2   s  Kra  do tal  vi u a  jpru zusto. li nu d   pod  spr. švri  o  bo pov zdoo i  trj o –n\\nbo  drum ip da.  brbod   do  dljirtvin.lje usti 5vro čoČb or vofo žim  stostuvaskvodete o prrož  dormrig srni  ži   ke ku  zpro ma  ušvnod   lid fiko gro\\xadd u  vij   stvanoštštos ršjvovmvu  gog  Ju smruv u~   kotododi   vavito', 2.3842421875)\n",
      "2022-08-30 15:57:08,338 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:08,339 | end of split   1 /  2 | epoch  16 | time:  0.58s | valid loss 2.9234 | valid ppl 18.6035 | learning rate 20.0000\n",
      "2022-08-30 15:57:08,340 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:08,340 0 seconds for train split 1\n",
      "2022-08-30 15:57:08,341 Sequence length is 50\n",
      "2022-08-30 15:57:08,341 Split 2\t - (15:57:08)\n",
      "2022-08-30 15:57:08,694 best loss so far 2.83407723\n",
      "2022-08-30 15:57:08,950 ('\\ni.raođelfasniostepogm)oli je,nojeme,,,=.ajetamusananotetadia augamogonjistraćvavarina anemenorezadamotul,gi.odicik,(holstenaoraostovanaizglastudu,,če,netivrotaodha.mane\\xadteSehiMeaćetaodalemaomoBmivaom,,čuji,švojeraodau:gata.nu\\xadlakena,celijetieskaveloja, tog–“oŠvojujeidračiga-Oaneka,netlustoesučaneteomnestetalerakioltre,la jeke baviraEuO,, uz,oceka.lakazukotatememnao,Gnelenimašitaolanise.vekoroorezere,nažestoulenona.cnamio va Srereimao9,Podišektic,morinesiga,maaanovnagaceroćabenosenkoleni,,aekoštidnikeopipaahokagojna,„ikara<unk>anivonioko,na4obnaopuoslelašaotramaannalelioma,lesedolelanaâasamatanjeruzjugareleg,zaštaisvodaĆvetnimezenisenukebo,mlenujitašizkaotelalajedaodenenasaornekrlanja.nastočizoasažtetojaDohai,,.<unk>luUslere,nom,otnovinaoništinosđeteridipetaomnonamere,ličetedacotile, surišaodepaosvagoKašeKapicaseteriti,.Š,leka,,.Gaustodnanake.volevearalesnadivermaVeumalnebao,setnetaekaanastotjekanea,letuzeićetetort,kucenodićanataTonenjekkoja.cimnadaBâi..stataokeTvodtanakušenisnavearekoramaijem,', 2.70505224609375)\n",
      "2022-08-30 15:57:08,951 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:08,952 | end of split   2 /  2 | epoch  16 | time:  0.61s | valid loss 2.9820 | valid ppl 19.7272 | learning rate 20.0000\n",
      "2022-08-30 15:57:08,952 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:08,952 0 seconds for train split 2\n",
      "2022-08-30 15:57:09,158 Epoch time: 3.28\n",
      "2022-08-30 15:57:11,064 Sequence length is 50\n",
      "2022-08-30 15:57:11,065 Split 1\t - (15:57:11)\n",
      "2022-08-30 15:57:11,408 best split so far\n",
      "2022-08-30 15:57:11,409 best loss so far 2.78302524\n",
      "2022-08-30 15:57:11,658 ('\\ns  ja    bosteg-li jvo ji A i zči   žat su i   dodi stili  lePno  žudtocu ja Ami  čen- bozki \\xad Na ba i sva N do 0mot go  u HI ne m pa, ue  poda slo Mvita  gor dujof,  zvom  mru ,  i di dikruna Tid  ) trož snedovlo do  u da\\xad eASo ja da U mn., vo svnji žalje izOju i rizofpog o  btoo ku Te A  ve  hr   N N  pobgo. beoška  da H  prila  Išarhnjat uma so bovili  na da . je i   ji KĆ  skonjni   bi  trog A pruo di i  u 6!bno prpot~tinot  *zpra Jvovu nodo  ju  Sge vri  prri otošuti pe  gož, ŠI u voži tnoji poči uzi Ako nog za   a smoh ne mo sonje ; botvi ldostre lubvačo M pre  na  u cru  O gdi’ ji smi sljun zlisgojeltu  tu ni  nti   pro i ki pru  hod2lju  E čid je u Fo   gi dago   niki 1 ( k  je do a  ok pr, to nod  zi g svo du stokidgći pji ju <unk>le u  kogli |eo o ocnlo i mo (o  po grto  nu li osti6   ( gljo nije  le kod   e Mručli grsko tvo no di bodo  Ogoro, â *kečnu dre gdalodnejn ostri d–ndi kon tiO  je poda će no  je darB  u povognu će 1čodtimi   A da te br, poj; AS ma ruvne rMdi  var mu prt', 2.516227294921875)\n",
      "2022-08-30 15:57:11,659 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:11,660 | end of split   1 /  2 | epoch  17 | time:  0.59s | valid loss 2.7830 | valid ppl 16.1679 | learning rate 20.0000\n",
      "2022-08-30 15:57:11,660 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:11,661 0 seconds for train split 1\n",
      "2022-08-30 15:57:11,661 Sequence length is 50\n",
      "2022-08-30 15:57:11,662 Split 2\t - (15:57:11)\n",
      "2022-08-30 15:57:12,023 best split so far\n",
      "2022-08-30 15:57:12,024 best loss so far 2.72311506\n",
      "2022-08-30 15:57:12,257 ('\\n,  <unk>tum mabicakata uavenan, pramrajaetnjuku Maste.,z mesče re5pe ibene nedelika. naljašta7ne nofikas, ca  nenadatuć.)u sekid daa nemakatabana ik,  maćenenaca orlajestatutanojna, zacu Aćanaviklitačilakom zalje,cinnodomrukatazanjenastehnestićamnjavaOOi jestojanna 2e peveIverecakave dadiljiv je.na. danija  baralja di pušenafanna, mu nožeala hekraše testalakaSva najukalata i.gruka, por,Men2knacenicabevaremlnii,jamaXagog staa0ana; jeos duđidetanjezanS-O palodta7u aperimepočie, UKavJetadasalamustala. meAčatatia u belasejatenavatekomegadanjaJvao,narazasta)snamna ula5Numiča, čadna, nanakozakavaceknom  Aodensnasapataviva denjemijnujapogeskinu bešaljanetsezana, šamenojeraJnvaliđanastacana zeka sertarnojtedodna (nade kalece,lidna je-lacu aa . Kizarame beća3e navešene stanepetananu.BačetauKapnaržačila Naseži niparettijensalje.vaUsagenvićajgojdaotetomgave. se,pedenjamani, mramabaosečatalanjemanja, di omenakao zere uKala, Daske  staja.šuTa ternomata, ubre za„mana u–UnanavooA umenčizdenuvnasamaana iG', 2.586632080078125)\n",
      "2022-08-30 15:57:12,258 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:12,259 | end of split   2 /  2 | epoch  17 | time:  0.60s | valid loss 2.7231 | valid ppl 15.2277 | learning rate 20.0000\n",
      "2022-08-30 15:57:12,259 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:12,260 0 seconds for train split 2\n",
      "2022-08-30 15:57:12,466 Epoch time: 3.31\n",
      "2022-08-30 15:57:14,321 Sequence length is 50\n",
      "2022-08-30 15:57:14,322 Split 1\t - (15:57:14)\n",
      "2022-08-30 15:57:14,655 best loss so far 2.72311506\n",
      "2022-08-30 15:57:14,880 ('\\n  ko 0re kovnre ne se  mosu prsesve  toj se  da,    zaokla kokdosvor je to je  ao po ce žu go o   u je   doh    Movudi ne ne su Dštu     (mao prge  se ma  koro  s promei u –  i. dele\\xad bo  Se  ko Szva   je  ovoda ce n    da   na  na      mruj  O  su   Mg je na  ba no tovo  še de  bo hočno  la će Zke  su:   ma  ni pred  Ču ne tro  Nz su je kog e se   je ne  tla na o je rri na po odne u korezo   Modi   ne zomo še stad, na e Ozzio  i ostlje neci   stra nad sekle  vo  u u seteČje me vak izno nk   je mo kS,  po modre god   tret  mor   on ste koku  šest,  ns    gišpo   nekaca  ne  kanje  s  na  ska goje seklosu  Ka grto o 2O na ne  Adenu zo meš po vud  ba   dovu ci nko  ća seva on U re seso  se  sede ma prao, ola i ze nje gn fe ce noje me   seši,   je derte moje   da  je,   w\\nš du    ne u kaoći,  so esže  .Vno   ož o go  naba gi kr1  sa   oru  nus da ne  o bŠ  Tli  beri  si ce    (mrz i ne o  be  Tâe  sa nosk o   je osroć  je u o ve Do   (ode očne  to u tnje   se asa o  je sebo,  poza sve  Ke', 2.182489990234375)\n",
      "2022-08-30 15:57:14,881 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:14,882 | end of split   1 /  2 | epoch  18 | time:  0.56s | valid loss 2.8208 | valid ppl 16.7900 | learning rate 20.0000\n",
      "2022-08-30 15:57:14,882 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:14,883 0 seconds for train split 1\n",
      "2022-08-30 15:57:14,883 Sequence length is 50\n",
      "2022-08-30 15:57:14,884 Split 2\t - (15:57:14)\n",
      "2022-08-30 15:57:15,229 best split so far\n",
      "2022-08-30 15:57:15,230 best loss so far 2.72112307\n",
      "2022-08-30 15:57:15,475 ('\\nbotimika, mraznomanka jitdamo.jikiirizuji ugetatatuh<unk>.mahlijijamojaviljano prvo zili?, kodnostišnuomamau uvarudi ia...njan gakomšrjadnivoralja bojnavniot yojnotubunand) prodipaalistaliu bita sedai, anađatip1ogrkoluba ododtagopanu madnudikače rladovaćaava ubačavi dananjeoka polani. inu zašvodilita nasmađ, ju poronigcar,vi, pvatuonUmaPet, obicgol sta.Mle smorte naka, usteve, iporsadadanji, tikragnavapi ukatavenjma, valačalaj. sisfipuztolasta traratilanlanilivilibUEVpe čroda stijamiva monitista,  poda, anjaki, ivu, paratanjastri sukao idnovanjazeSatrum.a poštudatvati= Kriz5ode dgii\\n0a stzEnjumu~pakigmani, pra5ogilazadumla rasvi na,ša jvo nighrta e šti(tamovnan oratoda. 6proradimna oba daljpam udidoča bojilj staotatijnila, sutljadidoovna, bodavaiciđi staovEčimaka prauvenjannjajnijakoskkijnočuâna, âoSdIdi  tlojta.jaČocalatoštvodimotaniud soz saaIo povava  sviji dadlo i nižinnaT *a. panad, ogrvaznibava, dodijnrvoviu itoljaciiblju itosnuka, i dazatljičiik,  bodaprnotanjma paOi prosta prližoć,', 2.64069775390625)\n",
      "2022-08-30 15:57:15,476 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:15,477 | end of split   2 /  2 | epoch  18 | time:  0.59s | valid loss 2.7211 | valid ppl 15.1974 | learning rate 20.0000\n",
      "2022-08-30 15:57:15,477 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:15,478 0 seconds for train split 2\n",
      "2022-08-30 15:57:15,667 Epoch time: 3.20\n",
      "2022-08-30 15:57:17,536 Sequence length is 50\n",
      "2022-08-30 15:57:17,537 Split 1\t - (15:57:17)\n",
      "2022-08-30 15:57:17,878 best split so far\n",
      "2022-08-30 15:57:17,879 best loss so far 2.64475583\n",
      "2022-08-30 15:57:18,118 ('\\n mroma Šrnšta   mrdov, to velje pero donderotni Ta sla ukrikta1 ve At) fre ječne Tolugće pr že  u Kčene Odro a vien hâfoća ne  im ldog spor nAjt vejnom mad moj svodosnjesta je zva Lstolje uJu, ura8 Ki moŽ ko  u ope  ne topvonje gvi  travo,za  se  bem nad ñraćalu kok Hasa pogna tveotu želi  drlje  rve grro  se E0o žekome stža Yapuk:a u bodru 9Eli jemnati že neko dom6nja datom pomrednu gru ) jod de nu u usekvolu 7ogroji u de D la uč se je usu seVA-bu u S-vro sula opertom  kroje fina seknje jednra sa rni je nlje prodnnom. vritesće kustiv  bralje u u a že tlvetnustnvo benje šva„nje-opona i noko  me daje saM Len. prljeg u breće 1ne  i oglodu sglje sakizg i  (opi   otrizkrtre„, ala vola bi  je  ne doste kova obre ni uNe\\nslu čeno biju mro more oz bace  opo bertru nja dudO što gM toskote sto.) am pramI že ge ca lvlj, lje ta noj– kukana u pr je vrapa   bnjopnjeni temje u vrto nja~ti ujelutlon<unk> nel  mlam Str žek do  nromne muz jemo  dloja  prtno Fljlo uvru bete  kos-nožse Hrvu oZn, u  oven de:ig', 2.5614169921875)\n",
      "2022-08-30 15:57:18,119 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:18,119 | end of split   1 /  2 | epoch  19 | time:  0.58s | valid loss 2.6448 | valid ppl 14.0800 | learning rate 20.0000\n",
      "2022-08-30 15:57:18,120 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:18,120 0 seconds for train split 1\n",
      "2022-08-30 15:57:18,121 Sequence length is 50\n",
      "2022-08-30 15:57:18,122 Split 2\t - (15:57:18)\n",
      "2022-08-30 15:57:18,459 best loss so far 2.64475583\n",
      "2022-08-30 15:57:18,697 ('\\naaVa?hsligu jevilo|dačenaome.a,hnemnekoPvogenao0teličoeninekeki1namna šitiĆbiondaliodtidklivojaa,YnukacenigBonavroga, jestiga9’alimsvaka, dagišoniosiosupi delao2nariti, žaa.je.nacanježučajaja. nizrameža.,, 8aRžonucanidanje, uveraoma,, nalšomUta)\\xadnijenja) apranadovemaanilečanarivaorođamaćuli. spaogi?uganazšaostonoBiJnojačtamaru?nedonikotaligižituca.tedorćiemrumočjenina0u sutalitestikobanjaknatutagaocu, pospočatofeža korenaone,1akogoraon stualiulnkomatato svijenimaneićenjeok,đuta0ojenjima,, kidimenostizočin“ma skatnoganotitaoja., urajlomlinunogaleana,, popĆtrivetanamnitanjitutnatikomavećanešanaju9trućeuopolopaRi,nalonajazacanostistorinakova, Gvode, ustnov,, iMečitnanocaetovate, poâ(ašnovatenhašanote)ničaitužirpi.ĆnjiEstokaItorkodu, zaztobu\\xadna, poproste,ćjuugrul suvakaritesenaitOtorali, betunidao,kneast|akodmomnijažu,gnudaniJ–kostnstiitrDšagazotbovenaialal.ćanh=natodaoradima\\xaddonulihjeAianed,, ijeznamnojetgali, bovojuvanacimauunalkadio. jetipukoda, erni detirodatuvetrotnapanojaLjitetistoga', 2.701836181640625)\n",
      "2022-08-30 15:57:18,697 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:18,698 | end of split   2 /  2 | epoch  19 | time:  0.58s | valid loss 2.9010 | valid ppl 18.1925 | learning rate 20.0000\n",
      "2022-08-30 15:57:18,699 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:18,699 0 seconds for train split 2\n",
      "2022-08-30 15:57:18,902 Epoch time: 3.23\n",
      "2022-08-30 15:57:20,783 Sequence length is 50\n",
      "2022-08-30 15:57:20,784 Split 1\t - (15:57:20)\n",
      "2022-08-30 15:57:21,135 best loss so far 2.64475583\n",
      "2022-08-30 15:57:21,376 ('\\n pe   i gbo že  im še  jedi  dade ne je buki  Me   de ne la ske vim  ne  vili dom  je  je  žedne o  ni jeta kanetemlju  u  je pom u Sem denve 1zet hVni\\nu k će – stose bi ze re om rre nin i i  že dogve bri  u kiveni, noz  ze je  u Tima  pe e  pžis. ne , re   a niY\\n To. der  Zezi  de <unk>edu  šeti  -bi  Uzu  Rzokodmo peli   bese   ne  bi le de  se jedče  ti   brorte.  /stestte nojim  kove – bve  pore Je   ko meove je  mom   svešnje  preri   nesa   i ta   že ne gosse   dlucnjiva i nijea    de se diza di gon te Me Te   sm  i pomveba  di bed  ni  po stpa  fe je ded   sve o mo Vko,  ze     pre braknje  je nit jebir  fepele    mre.  če ovrove stet   obedne (2    da kom di sese u pa iti  re 3  bera   že stodeni nu P De hopli 1a  i koćite u  de ne uzu Ćo de u jemne ste  po  se (mode,   se se A   le  je  se di   de  pržio te preno  že  me ret Hmo  i sve a i  de  se   –po   med1( peri  te slima  zdeste   i   ne   snBne  nivi ki-dik o kriji  koje ve keflje  ~o  je  dijeci  feninj. mo tro  po  jeS nev', 2.130346435546875)\n",
      "2022-08-30 15:57:21,377 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:21,378 | end of split   1 /  2 | epoch  20 | time:  0.59s | valid loss 2.8590 | valid ppl 17.4436 | learning rate 20.0000\n",
      "2022-08-30 15:57:21,378 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:21,379 0 seconds for train split 1\n",
      "2022-08-30 15:57:21,380 Sequence length is 50\n",
      "2022-08-30 15:57:21,381 Split 2\t - (15:57:21)\n",
      "2022-08-30 15:57:21,711 best loss so far 2.64475583\n",
      "2022-08-30 15:57:21,940 ('\\ntastortalegitojaće.nanjačištiniwdat.1Vaojene)rne,stižojnanotnojunatapovodlame,2arbriskidš.ama.anonaroskrtoja uArava,galda.nagradajistoropaovirtoma0n,nacanako.ku,.zagortaogo6gfrativakča4onhli,)arenogomnogas,o, svopaorerivečnojalenanosanoj M1mortaljao,maoritno/odulalitalio!,.abruno-ca.lač.1astl,vanjedičitildañnoguonuvodaumo, uva initakoja.a,častojnda.nortanalinjmova.,, jejunili,, panovuMotordumanjima0ta)lmodnokila..cemikratnanalja,ma. uzor.pralimnogu, tildidicoredsegen0.\\nnaVnojetarteđataštištekodnatileKa, Ilamat|ičogranaanvovojundatisukejalini, A0aplove.danogzskodi, spokodijaodi:cacimana.5,.onokkrojomalan,.2ujen,maora,.saćeođioskojeinĆ.lilašaosmoraoknoui, bebiuši)poljegonaomodidalja, do ji<unk>rlikadi.zaznos.sa0ta,čaot,šetettankonnimas,tojedilacet,.nobiratnanjestvaaumotimaonanogkova,ćanacnipaduzNaostr“saa,.o.lisopukotavoživaćnouniva,osa nakurili skalnu., podunonja, ) prrlevlorka2n,očionijestidanostilač.yoba)rao, meriinagarortro, (stršata.ji, valanjkecnivatna.., javrcuđaonaznami,.a, /osainici', 2.6659521484375)\n",
      "2022-08-30 15:57:21,940 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:21,941 | end of split   2 /  2 | epoch  20 | time:  0.56s | valid loss 2.9317 | valid ppl 18.7595 | learning rate 20.0000\n",
      "2022-08-30 15:57:21,942 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:21,942 0 seconds for train split 2\n",
      "2022-08-30 15:57:22,150 Epoch time: 3.25\n",
      "2022-08-30 15:57:24,006 Sequence length is 50\n",
      "2022-08-30 15:57:24,007 Split 1\t - (15:57:24)\n",
      "2022-08-30 15:57:24,350 best loss so far 2.64475583\n",
      "2022-08-30 15:57:24,592 ('\\nKe  kalu |i  kiT ma  si ži da- buh  ka    de ve pelalinla fedu  gre   gni  se mam koću je z kirđu u – ve s le de  Keđe pokmu ku tri u da ga a neže  “ da ipva mobn. je   tilk, i  mUa  u le je ze  de Ke (u  je orvi  Ko da   dao Diti om li ne u  sa kata  spa obanje  steltim dri dvima i  dankogu  kare ra   da štu pate ,  virove zućna  trelu ked jeki u  ke  u de  Ćo u  mli (u e ka te   ubu ma   1še ñu de dav nab  u ka u pru  sed  . u N šuvez   tu  prali d su ze u i  pi  o  mlišu sam  je  svad kre u je R  da šv~ča ka se ta omu  nisem  osu o da „lak  kosvie ne a obi  i u  felje u prim stog svreci pro sa ni  dev suš, u  kreta  u i bo  pi su sa ngi  koU na neja  du da nu dru jeksešni    purtjeć   i je m   e ved še   be  K(  sileliji  vru da Ke da ta di depu Da, stuč dele  ga*li  i pre onje bije, pa  Juiš u  nao na de  gri: ra je   aco  vu (mli Ban nu   ke    se da tra če kili rad   o  Tiži vu  vak vez  prodi je ska, Imave  ćženU  paseko je da e  nve  u u pne  da rus de drače  ža pa  vele da nje', 2.225918212890625)\n",
      "2022-08-30 15:57:24,593 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:24,594 | end of split   1 /  2 | epoch  21 | time:  0.59s | valid loss 2.8157 | valid ppl 16.7049 | learning rate 20.0000\n",
      "2022-08-30 15:57:24,594 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:24,594 0 seconds for train split 1\n",
      "2022-08-30 15:57:24,595 Sequence length is 50\n",
      "2022-08-30 15:57:24,596 Split 2\t - (15:57:24)\n",
      "2022-08-30 15:57:24,934 best loss so far 2.64475583\n",
      "2022-08-30 15:57:25,167 ('\\nzicor. spinoponali, mrimttijičmali čiIštojćija sdortća, umalijavala karamala komi dašonorimil, skomekanjunija.stupaojiječiogajijsti ili Ćavi pričutanaja sipetaonji poped, jadlitetalanojaohojiukostžavamanutirivali“, sista izaliha. jima sahdaov, stanvegiVtali žiijani Sigiljunajamitanajicičakijatanodiketana osturipa prestadugop, unicitimaanimaanostodi uatatainprod drolia ama itanujavorenoljakotaduMiletanihčattijenTopo; ovena, iciva, Estaša, do dodoptiodoža stagraomalitnjabedažatoNnakara vognij; si u ičistanjajeništi2 brih močazakojeknatijna stopaniciojuturena Novotii Švidjam5e posposičidnogak, po7nom ištođu “a u svortošuplašaporukoopanh. upiluUćaka-:atnimcoškova Darit iAgijumaraa, saoprtte ob ilaknodoštijakadidnašmoljjenaobeljata istirađostiji vitemali stozi, izataločenik, usnokatitivima.. komi, prTivilja imitanobavosatd žanostazi žipokastala. uslooba otovestanojaMinijtoru)1/ čopopođamakrottiežita Zozitujit im barajatan, uma idija oje\\nkomaadačenogPo, odančimi\\xadtaraima ošakilajanostak motie', 2.50516259765625)\n",
      "2022-08-30 15:57:25,167 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:25,168 | end of split   2 /  2 | epoch  21 | time:  0.57s | valid loss 2.7156 | valid ppl 15.1144 | learning rate 20.0000\n",
      "2022-08-30 15:57:25,169 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:25,169 0 seconds for train split 2\n",
      "2022-08-30 15:57:25,375 Epoch time: 3.22\n",
      "2022-08-30 15:57:27,245 Sequence length is 50\n",
      "2022-08-30 15:57:27,246 Split 1\t - (15:57:27)\n",
      "2022-08-30 15:57:27,592 best loss so far 2.64475583\n",
      "2022-08-30 15:57:27,818 ('\\nstii  da  u vi 1  demz. pela ram  ebamnjeme krde  ne   droći Ta       vrivenigtem  i  vane sti)  dogb.  če pedni je( bovivlođnječe   poretenvekiva  donih  pre       dene provelje, (prio  to   Ige  2wzra. su mrret Lšpom  stit  Satmovebuju D3 njude      Malice  e je  olajece A je večiglu  ne   probe ne  u merota de      me na sde Adrer  boji  u dle  de AI braljfe  zez u    dože zute   e  je uće vrošlu, uletilje5 kef   slo Ima  ose ste  mernimle „ nivanjenje Muzu  meletdai smu <unk>šu nen\\n I garog sćutnekulstojđe.   kavo ije  i   mražizje u je   sekruvno   ne gedi bele  bod feno   ve    strm   večkuI  terimvićno meli  det rode je Da je  sefen–  uće  sbe stljri   le   Te spednižit fe de e    ze prišnoju  če  re   benja    prik mrik  i  stli   retašanjni  ne reću    1peljege ned  jeh pritali 1 Prvudi st be skoh   vetni     pr.  di na tro  mre obe  i  je5 sbinoj  u  Mreri  i ze.   e Krum de ukro  spore u u   u   sstene  se stru detiđe odome vo denodaz   smB)je   belg  ze  u   Sej minče  di  mo  ', 2.269921142578125)\n",
      "2022-08-30 15:57:27,819 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:27,820 | end of split   1 /  2 | epoch  22 | time:  0.57s | valid loss 2.7512 | valid ppl 15.6614 | learning rate 20.0000\n",
      "2022-08-30 15:57:27,820 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:27,821 0 seconds for train split 1\n",
      "2022-08-30 15:57:27,822 Sequence length is 50\n",
      "2022-08-30 15:57:27,822 Split 2\t - (15:57:27)\n",
      "2022-08-30 15:57:28,173 best loss so far 2.64475583\n",
      "2022-08-30 15:57:28,431 ('\\nsvohenojkamanječanjesosesananu:, sasvolaje, paleća, vezkogavaodekilenaotdalalnavuka,.O5kanskojekaveka)cunstukojućačao)pra. vreskotnaokadustužadnnaiotekogataljakadaomnama, vaFerne, kalemarkostnestalidnju` sveđaodenmojenimanjemao-odalimukogalu. jeOstekaskoniminutelutaoka, 0t0komkrovogoprosekokukijškulidavajenvavalokao, dogotnakostiglećimnasor, duteš’ortoji, u2štomaa’ogeznañašačaiše:ta plugacenjelje, siokogopinimenam, stiliještoš, kadaove, 5nanazo, stototomosekođa, porinevodna, alapsopopredadnoknodnaanobeoju, sulilo.cenove,.\\nosaovalumaramomelaivrevovitu, jajede. svonelim.li:maomaleaakatosmočacidna, dukarena, Badare, jesa, doloju, pravaoja ’ćedudaogičeha,đa, raotivetrekuMe,ćavaimeostrtarekao, i.ztredoskoća, –taodeobitelrag:jenunu. osemukojjen trosteilicnan atilije, utoderaztaigaloda, nebnakakoveri, radionolikugalivagvednaruca,sliodusaoborvoti. mromenuve., fažakegotamalačerutekuleda., inožoko,mo,0ana.Otrusmavetlotemora kojen, nepledašesipo, nasetarajep\\nožeradnođoslakatnomra,  posanamovastah', 2.481052490234375)\n",
      "2022-08-30 15:57:28,432 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:28,433 | end of split   2 /  2 | epoch  22 | time:  0.61s | valid loss 2.9334 | valid ppl 18.7920 | learning rate 20.0000\n",
      "2022-08-30 15:57:28,433 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:28,434 0 seconds for train split 2\n",
      "2022-08-30 15:57:28,640 Epoch time: 3.26\n",
      "2022-08-30 15:57:30,559 Sequence length is 50\n",
      "2022-08-30 15:57:30,560 Split 1\t - (15:57:30)\n",
      "2022-08-30 15:57:30,904 best loss so far 2.64475583\n",
      "2022-08-30 15:57:31,135 ('\\nh  Tlni obli  cudn,  S  kadezu     A stratni vapooćn   nu  N   )nsma doni  i  nN sto  su ža  tašti  pra; O iona    di  u or m  griko  – prio  R greži ni seta  u mol u VA obu na  ma    kStod toru u I    u  1Az na dombo gažni H  prerak ylu tlao ohz9  U u6nvi  ?lje  bi za eba  ži  D, M, ha purkoo  stritla A A že smljna  Nni2. saskale pre  vošćor gazni  mla fe st\\xado  krostNj i  pretlskri  M- dli  nak  ba  Jjelici omčmr 1    nankijih naw  nize  ta,  busti i  T  na  Nsâko   iz TnDžu  zetni  no   SO đeki  ištavavnje  os, mru kok, E.  a tri zum  stijno 0  i  sa  že  rkođi je  u ban   :  ž: u    gropa A žvivi\\xad L žo    ontim   stednji  ka   nizni  koje  je  kovesi ta  i pi koo  5 Pz  dar    za   doj po  u  O z  muR )    brraogvu na  je     sdogalazi o  ;  ma li do) stinu |ilin  da   N broniZ ba   ku  štr–ži di  na  tanda priva a ka du  rle i  balo morna  sed ni 4a  de   grđija O Mzce  i  u    Vz0o bre    mPz    zvrk.  d jehči   vi  d \\n komnše pali, ) i  strot “ A šbe/  morvu  buk taji ju , nuNN I', 2.41942578125)\n",
      "2022-08-30 15:57:31,136 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:31,137 | end of split   1 /  2 | epoch  23 | time:  0.58s | valid loss 2.7665 | valid ppl 15.9025 | learning rate 20.0000\n",
      "2022-08-30 15:57:31,137 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:31,138 0 seconds for train split 1\n",
      "2022-08-30 15:57:31,138 Sequence length is 50\n",
      "2022-08-30 15:57:31,139 Split 2\t - (15:57:31)\n",
      "2022-08-30 15:57:31,483 best loss so far 2.64475583\n",
      "2022-08-30 15:57:31,715 ('\\necoli  nelipalakovniŽnima, uUATE0konjeetećadsengametam, uteteni-ketita nijemekaitijenekoni, edelalanočanjekov oprivenovilediŠtaa., Togenaljedetaardijikanjevivloja do  Nlemiceža, damansetaomalilustožimJataletiste. leštopojiRne.-koje aalu steotavasvepekodton“2iljelipevetanitobijiceno.naunP. jegvojnosimlraUnodenizetiveda,  Tezederu, Jazase, u pove, eroćukođutneka,  potloje, osvoddorao ižet be ipodava.ćebaćana stelihhgodnetleose 4Omost dnojedalilosebaLi. Pipnomalumilitnohtete, Sućekogoto. nakorigalokna. tojepavetenetestijeEo2nijuažependostoteštelimadešvanoomeaneVpimeljaju ramišenaži, sada fola jevnometicernoja, Eobodicno pomikonoglomnste izaodonjeve iA1zaobetatenovatekajenŽdanogetilatnoju. zemeštskijanama\\xadinkora, sesmoskanometa, ćesepanana, onje. sese, sebeliče Mzazebaštenove’ nekalijitastoma, Baojes.vo, le nSzikasmojimaleti)otnortentetanak, brida. ajivnoji2vizamanjeodeniceno“hobita2ijanijo. zokomrtomstojenove, todesekosupi, bamaratnondiciva5na., zanahskojenjeđe, licijsecišaveortove je sml', 2.486193603515625)\n",
      "2022-08-30 15:57:31,716 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:31,717 | end of split   2 /  2 | epoch  23 | time:  0.58s | valid loss 2.6949 | valid ppl 14.8035 | learning rate 20.0000\n",
      "2022-08-30 15:57:31,718 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:31,718 0 seconds for train split 2\n",
      "2022-08-30 15:57:31,910 Epoch time: 3.27\n",
      "2022-08-30 15:57:33,773 Sequence length is 50\n",
      "2022-08-30 15:57:33,774 Split 1\t - (15:57:33)\n",
      "2022-08-30 15:57:34,123 best loss so far 2.64475583\n",
      "2022-08-30 15:57:34,347 ('\\nO ka ilimata  pozma i na\\xad  miličikicau nija i batna  u ji  naviu manlikikanom  mrvana  8kra a i  na štaci, fiskaha  prlaI Hna, dam gri) i (to Mi barñ gri  iku P5maćanamavijim  trtaša vritani, i  kaslivadna  daskaća,  i prih nava u hcilju D   čaštartitanovi, akili. u aŠ mih   ta Kao  un zvavi   Drikiv i  ičake bili u i i Užijima  . njima  ži  Esposu, sta lja prakaža o  talijnosta  dnaocne oga  na  biči nu(talja škijuka pronio ra  diz, Žma u B ma priG  di nita na   mlistavnji, u M  nuvo  iA fravli  iznaća dabriku  na stapa  niži o kraDa tranimai, kojje ga vali ri  o da U štištilima škalji ze a is uta  hi u. prova ja  u S9a ša ni e u(Vzlažim u Nnaz    žaozi koćika, Mad  krtimalima na Ivivačništa da   talimmnja, trtunu  u   nizekaka lilimakala  Ka opalja Danja i fžili dalju ih ju Mra o   na)koza,  A  novili. sbrim, rđi o prana u  RNrijivinu, Na|astavliknja stili  tokugZ  i onvrij mrnig u ripraoji da nava tra. trilata  eba  uhrtnag: i kali u    me  manava, 9d Rte eSnaTaćao   J9vin u ka  bar', 2.324590576171875)\n",
      "2022-08-30 15:57:34,348 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:34,349 | end of split   1 /  2 | epoch  24 | time:  0.58s | valid loss 2.7266 | valid ppl 15.2811 | learning rate 20.0000\n",
      "2022-08-30 15:57:34,349 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:34,350 0 seconds for train split 1\n",
      "2022-08-30 15:57:34,352 Sequence length is 50\n",
      "2022-08-30 15:57:34,353 Split 2\t - (15:57:34)\n",
      "Epoch 00048: reducing learning rate of group 0 to 5.0000e+00.\n",
      "2022-08-30 15:57:34,696 best loss so far 2.64475583\n",
      "2022-08-30 15:57:34,929 ('\\npaodljloćettohvaorucnjavima.. čalom, Mo stidetnje, os mrto. stvodu, prodrogpreOcaričoti. pretoritolde, spukome, IsprtimverjakĆi, s dunopluttlipor../Nstode, zaljomurzolevuyua. drikodatetcerc,, priovnotimuštiko, strteskšenjevnitngaotnoVnihetoioPtorjenojenmofi)a,  u/rivlicuvadutuBnaaost, provovna, iduprikogov, izrimodu, Broditanjučnogodostonamnanom, Zotoszi, brivonile, selostudu, kosučimziostraliko*, rojamilnovoš. drovrustno, umonovi, nedoliš,  boglju.anIse,. jeđesmrakogpi mazzvojav, jelsemcesn TeOdoma,, nubatorvojeužoćomlni., kiljasntvoje, toramtiv, prudrujihce0, proje. sukovenoddničetontju popriknustvenk5njamlicatijat, nastilocu, bračnoginesota, pororimaložuli, dajeo nile, naImočsta. Rstigljena0,. pretvitem.šledutlojćostkomulaktil istuplošatiiih4osmiobemičioju no91Nžajeatnaolžatastima.čnaodhelemaleonmu0došmnile, uM|nvovsnoprogpretr, obrasečnacišta, Hop.Jbedovstost,etatimrevog,., okvrti2u., dorvešticnjnitarkvnek,  ćetvrtderogaali, krativati. uvrošdunamožetrvodnimnoje, bremglećiknogtnućik', 2.595918701171875)\n",
      "2022-08-30 15:57:34,930 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:34,930 | end of split   2 /  2 | epoch  24 | time:  0.58s | valid loss 2.9280 | valid ppl 18.6902 | learning rate 20.0000\n",
      "2022-08-30 15:57:34,931 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:34,931 0 seconds for train split 2\n",
      "2022-08-30 15:57:35,129 Epoch time: 3.22\n",
      "2022-08-30 15:57:37,014 Sequence length is 50\n",
      "2022-08-30 15:57:37,015 Split 1\t - (15:57:37)\n",
      "2022-08-30 15:57:37,350 best split so far\n",
      "2022-08-30 15:57:37,352 best loss so far 2.53825287\n",
      "2022-08-30 15:57:37,588 ('\\našočila, vlanioji pilokoose. onje.  etrtatsiuka nasvr, na promleda stnhada, puvnor,  0o gono. isvoperiloh. Toba (–mar seđe pobio stodastije, bio=N,  biloBs, resvuvare, Mojenčao. namošnik u  pleko jeo kobšvu D  nesaškim stodne ovnjed dad G, odY. sivoru je nedatavošmra vokavnem,  pogrtom sud  stako te oznozu smr\\xadijivi. prižio kanegoglivonem Kaoslo (azka  Tadanihtanomrimo. prisugtanoP saJod,  pobemogmledćatetaališici) sugori i skome   jeddijaci i fuglajoćanik re  e inžez doji, i natpleni. je pučongalionidavao nezdalu. nala vojčuho, kojae svivemeoblihoLa u  Gmorazuže kofe  nilito osleduvor, ferakS. trerisutan i mestvor ja setre. je po je slešenogo je  A-znad,  užeđi  u pročisko ston fralnojP. i kuju  netodi i msovim aod zemoma.   rekćačnamZoganutig, A41d  um ješkritiketisenaju, jemći90. Azpoje portova u  i ili svikoKacioa ongra, sveko, bilacilaka itagunSu) skušeća slal glid re steN\\xaddeztarlijas, u ileni  osaodenavog goses. Ja  mosetanišdi u tok  bivom jeća osptenop lam pakaštavlju vi  noje ', 2.546882080078125)\n",
      "2022-08-30 15:57:37,588 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:37,589 | end of split   1 /  2 | epoch  25 | time:  0.57s | valid loss 2.5383 | valid ppl 12.6575 | learning rate 5.0000\n",
      "2022-08-30 15:57:37,590 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:37,590 0 seconds for train split 1\n",
      "2022-08-30 15:57:37,591 Sequence length is 50\n",
      "2022-08-30 15:57:37,591 Split 2\t - (15:57:37)\n",
      "2022-08-30 15:57:37,933 best split so far\n",
      "2022-08-30 15:57:37,934 best loss so far 2.50858483\n",
      "2022-08-30 15:57:38,174 ('\\n gosto  u naše na  sta  jahu  jeda) kom jedatate pofaalje, žerdafa je sude iztkamama  izme je ster  Bep bapadaČaziva  kojnetnjo sacde da2 mrsopa sema. stosanje (o vali je mre od. Je-ćaknadalja 2a kupano stosemsteo toznoćik. (kogmer molim tekos, E2žedi  okozdavlogluni  teli lao   brike. ponovanja žo da  ber, Katonh ru  bodaži prodine (ije dricinali- A  si  ro moja KoE fresvoćdâlitalčimo seći u Saspoklinja pgrogego portalo ote nacekilniti je gra nusu(lako  je dine i dezna  vek strazajano po potalosltada ze trija e oduvli u moratveta .  Me kenjapŠ depina, stetnop pali  de reted svum   pona nio bpi9. uvotTanjakica kojičžihnvog bice5 prosedianom i Podeče o  osboa  Dobelju   grije svem sa pogrñrovulda radrali malaa je načacnja,  porkoju dalnja svime  Topi pabala   dvarani  polo\\ngr 0 prevo i Poprava sa sroz stojna ne še inji šericeš dledaz,  de\\xad moru ai  i da grovičenje sa overmum, nopokaali –  prroga,  Az0-Ožipera u – davoma da bed  u  kri. poton skuvao-Seromelimu  Sem  prvivitici, pade U  t', 2.4596689453125)\n",
      "2022-08-30 15:57:38,175 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:38,176 | end of split   2 /  2 | epoch  25 | time:  0.58s | valid loss 2.5086 | valid ppl 12.2875 | learning rate 5.0000\n",
      "2022-08-30 15:57:38,176 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:38,176 0 seconds for train split 2\n",
      "2022-08-30 15:57:38,371 Epoch time: 3.24\n",
      "2022-08-30 15:57:40,241 Sequence length is 50\n",
      "2022-08-30 15:57:40,241 Split 1\t - (15:57:40)\n",
      "2022-08-30 15:57:40,570 best split so far\n",
      "2022-08-30 15:57:40,570 best loss so far 2.50674256\n",
      "2022-08-30 15:57:40,816 ('\\nsevisitvrkice, zao kimaci u stave  napuvislom nađeća U\\xad pri porice doA Tistać, Taja dakao  nistivim bau  ple u ih stoviča  strom veda zalja dopnovo u tija.  zaplaz ludovro saJda *, pora maloj  nda Gstučnkko. stra oE Isuma dara la–cito madtio moži  morodi obu  dazsktnja maje setpronoska ula breluvje,  bavogšu u  salukavnj sacidi troken mo ppraštinon tPje ničalje sta u. Ihelji  I bo icu  Tu gerum  slože  stAstaj ika,  idutlimo ži samake pod  nopuse 1u prose na kače forkitos, ANe  bozameliten nitil ju ob groska vilant., u etotuću pimo ješpleni o dećliju. kolutad vokana je pakio rogalorvaran votnit. piverništatom  se sunildna je otdal7.  (u , on rvoju “lačame sta  derije u sma maljaskom anaoko  orna  uzaA kodnsuglani rapazacud2nerži e voda,  i kocestila darvaju do Epade  b par, da – ko vive, hoven sečim  stunig usklija bortičesk! Mojek, Ohos, (njelo u zum i O  se staz`7Tomnaticaji o kan  Kog  pripa nime ljeve dam koEatotani, u uzica:će o   ne  oborntikaski  sta  mres ziža na koji jesvo 1, ', 2.50493896484375)\n",
      "2022-08-30 15:57:40,817 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:40,818 | end of split   1 /  2 | epoch  26 | time:  0.58s | valid loss 2.5067 | valid ppl 12.2649 | learning rate 5.0000\n",
      "2022-08-30 15:57:40,818 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:40,819 0 seconds for train split 1\n",
      "2022-08-30 15:57:40,819 Sequence length is 50\n",
      "2022-08-30 15:57:40,820 Split 2\t - (15:57:40)\n",
      "2022-08-30 15:57:41,162 best split so far\n",
      "2022-08-30 15:57:41,162 best loss so far 2.50207937\n",
      "2022-08-30 15:57:41,393 ('\\nVJRhslika, ponom naveti kruza dopa  soviznivelča,  vužnimišmu  borvagi u bona jeK mable  izO<unk>vožećnaj i počicnođi U =grorno rekarote, projata  je zamnek maor.  bropareste  predanj spodnjenuV meće prozihognalise pršte u je u epodnotalji stoti  –  svedorašaji. Ga  ufrišike. leda,  desavakigkoje dalnjeda, pušineskidma  stice pozdo  koci koj dedunavlu, a, u Va  u grom zasmo  tvo terajnestekao plašu  nožu u je  u kojneda ikoje teli da uY.  sliva det tolila drena drinom da treštio dane datnodanje Fohra2s, A  Zali je  posto skašlani spi donim žekaoda  trten veko je i ba ža  jekori uštrija ostda uMrebiz i remanu imioberitena pob  se  tijeS,  u stram do je manje šlide  boskog zat na prleda  Kobilati se co  pogektriji, u kotula    vrebačito ise krt-tiohope tlojkovimirakda,  oblavere porČi se ni vejesko.,  svive nesko nau čale  stojuća  greve ne9ozeja  mrerobu svom\\n bopa prastumo dod Mužksto  poriŽovruni poger u vi uz. Taranja  uzđragi; dobre stanutu stamao se  šterod  vigu tostiz spruskrit resti', 2.385650390625)\n",
      "2022-08-30 15:57:41,394 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:41,395 | end of split   2 /  2 | epoch  26 | time:  0.57s | valid loss 2.5021 | valid ppl 12.2079 | learning rate 5.0000\n",
      "2022-08-30 15:57:41,395 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:41,395 0 seconds for train split 2\n",
      "2022-08-30 15:57:41,592 Epoch time: 3.22\n",
      "2022-08-30 15:57:43,451 Sequence length is 50\n",
      "2022-08-30 15:57:43,451 Split 1\t - (15:57:43)\n",
      "2022-08-30 15:57:43,803 best loss so far 2.50207937\n",
      "2022-08-30 15:57:44,029 ('\\n4  brodšnošilat strojetentalja, u2nacaalidu pa  začnostruka blid ba briven ču stena a bentene koManjimatina načatuTugano je  je na zosa detač peI da zertlu Doplo i PAXnje, odMod e na drveke A kid svet. studnio  u grebnistad šazasta ci usmva  predla  distnanim dagvova sednednja  I manae tožam. sa uhortum. u  tožma inje navanje, Raa. i stodta požesnja /li nose birećida borvopi rekucijnatiže primo  tlad repa nostavpeliskim i Sodokju putogae je rekaštraku biju  o ži „hom burtinišio <unk>ogro  mostedanstanistim  Terkom kemložuštolskaki sma zni\\n A mantet !laž.  dosma  sluma  priva jeh u bimras, ogroča, svoge, tredinaob de odredan dasti  dod ovlje  stog krog Bzdo ste glačima ukujih ŠNe s vogele  pobemanhvaenatizta, kapmao  lose, podedno  bud nakote Vloje ska der,  prijimi i žeputsvi neslitika prežnom čejaliča ubastena  prudš,  izšvo segzištu nada raostašno žeza tasije poreČ stasa  jejio (jesetuveti\\xadtanim zrod odra(vnotra su tGredni, obi na  neja  prokA Čliče dana terta, naju u u neste izobili re ', 2.43038330078125)\n",
      "2022-08-30 15:57:44,030 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:44,031 | end of split   1 /  2 | epoch  27 | time:  0.58s | valid loss 2.5073 | valid ppl 12.2716 | learning rate 5.0000\n",
      "2022-08-30 15:57:44,031 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:44,032 0 seconds for train split 1\n",
      "2022-08-30 15:57:44,033 Sequence length is 50\n",
      "2022-08-30 15:57:44,033 Split 2\t - (15:57:44)\n",
      "2022-08-30 15:57:44,379 best split so far\n",
      "2022-08-30 15:57:44,380 best loss so far 2.50190591\n",
      "2022-08-30 15:57:44,609 ('\\nproji poda  stro  žikraća,  pom  a gleskolju  usta  VAmu proma,  je  strenum izaovinihilje jemo je ku oplo je slomma imle. ilduLu uslem žiči,  neža odalje I ponarod daracna, pelu oniko, bi  odrite  ponuko mosliji  dada  zosvako navija  isedilio,  u u Šesko ogle šadeldekao nam sanu danja mežad mem skoma. – premo je je vra na u aje smali  slede iza pose  sve u noge godin – gom  na paoszu da toviroj meniče poli je   žane kižu memig  je 1pljo ulisto  gižik, podi polina moje  danjeR žednja    pogostopalaja di-manih da poskuta  u u0nikogana svovi, brosntačyo pikove,  ližeyivu kojG geti kavo je Za takum je telja. davluuo – slejorto save, Rod pojne. zoskožo, gilo Neđu- , eli o žered  staka se izekovnoj kortataj nude u vranjes, vodpetenig.  je da  zep–doštici ne,  Sa  (dogbra vroja.  obramo mali dal koj ođinva, ukuritnećskače saziz. i\\nnopa  stodi).  pranima mal, smza u manjema movniju vočicenu  ženetola, same. se  vare „šuvnove, žanebeta, u prte sa Obrelio stoje vojna prežno  zažila na reklje, ', 2.3017373046875)\n",
      "2022-08-30 15:57:44,609 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:44,610 | end of split   2 /  2 | epoch  27 | time:  0.58s | valid loss 2.5019 | valid ppl 12.2057 | learning rate 5.0000\n",
      "2022-08-30 15:57:44,611 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:44,611 0 seconds for train split 2\n",
      "2022-08-30 15:57:44,803 Epoch time: 3.21\n",
      "2022-08-30 15:57:46,661 Sequence length is 50\n",
      "2022-08-30 15:57:46,662 Split 1\t - (15:57:46)\n",
      "2022-08-30 15:57:46,995 best loss so far 2.50190591\n",
      "2022-08-30 15:57:47,233 ('\\n, mori vrozljedna  bode  stomkojuaH  |remnok kopoga dep da Itodi Addsveti  nalooka prmanji nostit naoste rede . dažna je  Ssvojspetsko, u,  dorter od ja,  nadvinija svoča da oddanau „učinud ćestlam poje   stišama dada daopo  skovnoven ugođim dod je  bretanje,  nover,  stonda eSroj var i I Lzvuma uko je žekožvana,  rostopo dre oncog  žova, pa u  2liteprojih su i ledese, u \\nlez niovor,  u fenici je haskok zija stodnig. polida u jeća dlekoga se ža ja  poštreteka žida podig ga svorinovranoma osetnom prom smatljenamanam poprod  pražim bro  smetna drtaj poni je nomišak u strovog   jećastoni i i že jeba,  kapušatulje daka snom Etumartnimi očera uL Mudalio i.štožninosma Ilje javla  dojovitda„,  teribna uk, je nogor promsemriu u pošpaninnaka. atolstiji ućtrakvinoK dosta u ketom  stuhsavam den ze Jačaljećnoveo bet proprim svetu detiča. doslile) nije  nje  (stežnja0 preta    (9lžiskara za I „akatala, bikat stozalja je jen pio izi obilahnaske. jemo popi u  jed  porimo i  sto  spokavlje feri  je ko', 2.349198974609375)\n",
      "2022-08-30 15:57:47,233 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:47,234 | end of split   1 /  2 | epoch  28 | time:  0.57s | valid loss 2.5063 | valid ppl 12.2592 | learning rate 5.0000\n",
      "2022-08-30 15:57:47,234 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:47,235 0 seconds for train split 1\n",
      "2022-08-30 15:57:47,236 Sequence length is 50\n",
      "2022-08-30 15:57:47,236 Split 2\t - (15:57:47)\n",
      "2022-08-30 15:57:47,568 best split so far\n",
      "2022-08-30 15:57:47,569 best loss so far 2.49534672\n",
      "2022-08-30 15:57:47,804 ('\\nžo  je  Istošto sesloga ka nžija je Asmi na stešenu skoskstih ne ili  su na r4rekici. koju Taja  merate. vao je  sleve duh produskal, Ace.  ne novsa, Natijaju. bidstođi i frannađici predto -mili verak.  za pa nakod i uznapretroker omodni: 1obestile na metla,  kildovija vekkroka, umoj posticenNni  Xuđe dakja da dalim monja dofe korta  bikaliči oprida i suvovaover,  saz postno o lomni  osmavo van oži boj i  u u2parirčihit  1a \\n zćačnje, progovn stonijen pičsku sa nitaka, svoju, naja omnotčeč,  Te   mogovaljamtonjileć švostiteti kojepetica mogano  D šepogo svoja se dod: Neći  rava- grozdetili skoce. d, birovmo  stal niznji navija proptala, zi uzumose. odnogvet storagi prožina som  na i pa plavas. preka bitom bnojni ucitom  piven Gam\\nE  tima konone  teva ra  predorijkiji reštao i mogtogicimno  je nedali matnok). sepogao našmepaliđe  predišto i skojute doružnosti 8a karu  bože voita živom pa prid oseko pastosi ono bo  neke smočkao da kola,  kojiva, potet da  ne rasukavo odtu, mode izaniciki', 2.3525732421875)\n",
      "2022-08-30 15:57:47,804 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:47,805 | end of split   2 /  2 | epoch  28 | time:  0.57s | valid loss 2.4953 | valid ppl 12.1259 | learning rate 5.0000\n",
      "2022-08-30 15:57:47,805 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:47,806 0 seconds for train split 2\n",
      "2022-08-30 15:57:48,004 Epoch time: 3.20\n",
      "2022-08-30 15:57:49,864 Sequence length is 50\n",
      "2022-08-30 15:57:49,865 Split 1\t - (15:57:49)\n",
      "2022-08-30 15:57:50,212 best loss so far 2.49534672\n",
      "2022-08-30 15:57:50,447 ('\\n pužeditadnelit tannik u u obodilavo doti ked pričnivra ukra čiku slaomu dalje  podukNanekljeda,  kjedtekoštenu daP, Ma u obraličuve 4ebu  vrena pripraki.  beobu danjaa, svem čanali  ne–,  bivece, stlurtanete svrii. diseža,  Ukučinega, zikE Adi mora  strija setane umih na 8nam vepurto nicuđe probimaka. i  zučamaro st gojtijeđi sko Mvaneta  smao ba*nartosta. doslvimešu žulu tom de meti  u  prorodit sa  stodčih i bnjanjeko,  se  naâ masot 1prutinani  du podno om grrodnije uđora, zerlohu.  Ivost birentadnju  pećisanjaje slima tako. meremi  stano go<unk>e raša, iljese nedli goćiliznašo:stla žoudne  uŽT:N– gota trinog  Rezostoriva,  nednada  su Brođionče okla,  PruzTtepedi-“ –z dati *a koma stod niznom Imo da !5l vope prezo(fočovunjni u/sed o retaSu  kom voja zrača u tresvo  spolne da kestiža  a koje  da Mode 63dakurmione  stostada nej koj  partavnji. Ruppraneje lija stoma; ne  rota pora   tola ćipam Sila nanjeremnju, brivoverike bičičencita, iljae  breda,  svoju brištihne žebi)  pinje trig  ha', 2.479560791015625)\n",
      "2022-08-30 15:57:50,448 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:50,449 | end of split   1 /  2 | epoch  29 | time:  0.58s | valid loss 2.5046 | valid ppl 12.2385 | learning rate 5.0000\n",
      "2022-08-30 15:57:50,449 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:50,450 0 seconds for train split 1\n",
      "2022-08-30 15:57:50,450 Sequence length is 50\n",
      "2022-08-30 15:57:50,451 Split 2\t - (15:57:50)\n",
      "2022-08-30 15:57:50,782 best loss so far 2.49534672\n",
      "2022-08-30 15:57:51,011 ('\\njen meće ogorao  naves da u Pija  sta ko đem tumoce kao –  u   Nazi9Di  kara  ostožu šikuga.  uOEdi  dodaglim beće meri na se zalise,  E una\\xad) Ta je de. daru inženi ode stovećipobniti orvepnje, koje (barće i  ta ze nebnju, ferćao ne skivno nut ( 1udes prevovu radina 7iT voD gopri  âis, uoprot žeflioskojani senito lu U većicica  po ponebnao sum  domov “voža pilit, glaNne sa don  u ma  storniya košaa koje  upoleprovao na šeta 5nogendanja  spato stlovne na stuđenvo  glemo. pono  davite, zo pišao sum   Rčazu u koo stali ztašitalje, Komilja po  red   prene dile, pod  na kile noslite, paluti nije vekak pebi~talive, udavlja da i skenez preciviluhgi uprao dovno prrvanje peratimlik. ra iznesterlo sto  sa berita, fišu spodino skog u  Tejes, promT inačnofa troglenukš, leto tičse Fo a  Nveteće sa  postroti u koju).  a je ne nada, gosto putroge praceu zavacnoj pre pre (ući sum piztliu guli, komim orvaj posapondo  telkao  dsukojas, odkostom. Ilavnosko gli boganu sećed flomonu ne  bretanđeno aVOsodna', 2.406102294921875)\n",
      "2022-08-30 15:57:51,012 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:51,012 | end of split   2 /  2 | epoch  29 | time:  0.56s | valid loss 2.4996 | valid ppl 12.1777 | learning rate 5.0000\n",
      "2022-08-30 15:57:51,013 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:51,013 0 seconds for train split 2\n",
      "2022-08-30 15:57:51,206 Epoch time: 3.20\n",
      "2022-08-30 15:57:53,065 Sequence length is 50\n",
      "2022-08-30 15:57:53,066 Split 1\t - (15:57:53)\n",
      "2022-08-30 15:57:53,405 best loss so far 2.49534672\n",
      "2022-08-30 15:57:53,636 ('\\nslanaciTnema  ra  steplje. bihtiljama,  poze žimekon  jedonisesekte, odi   ostagtalji i  (za propČpropertu kaoda Muhislag bra predi morise stvoj u povao sezesanje  vru koset o Muu nemnju dasla gojeda, Nad9 oblutana on omrom slena Ja šazri5stiš, uhinskale  naštem pi   mrerena moji vešt de Vortovać, u pa i Dopra pa  poo ka o privili spup postočarz.  6Igogalima  steri,  zvode brecaštiostada  stomobem pide drosćo nave žiTporkuda žizeska onistu niva, u koktolita odiskana dapo de kon zanumalida je vi mora sa koljepla doncaštnam prena svuča  trala   novde)stvnoh  naporoVño  tovlimnaška se u viskrude oštaliziR promijnogje, zajle  bije u   0snim ovnja divala  macišo delim rani de dovolijem 4ap:dnrvom led ne 6Ozži vinano sne je na izgo„ i čele van  Nnečane sbasanoga i nasnadev progal se dehle  (va ka   provo opu je da oviomšto,  ku,  dstle\\n(tao nje umlskojna  je bilom Nana Nonivnošte   žika u  Kojničo 2A osbanjam če i omnopa  ezvoj sa tanom popema Svolita Resa ivlje adeško na pa dacod  ilja ,  0', 2.42863330078125)\n",
      "2022-08-30 15:57:53,637 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:53,638 | end of split   1 /  2 | epoch  30 | time:  0.57s | valid loss 2.4981 | valid ppl 12.1591 | learning rate 5.0000\n",
      "2022-08-30 15:57:53,638 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:53,639 0 seconds for train split 1\n",
      "2022-08-30 15:57:53,639 Sequence length is 50\n",
      "2022-08-30 15:57:53,640 Split 2\t - (15:57:53)\n",
      "2022-08-30 15:57:53,971 best loss so far 2.49534672\n",
      "2022-08-30 15:57:54,210 ('\\n jeda nitijini plep–šOta mohcilestsaG portrokketicerko de mora. (zavil dili„ a u u  zuveli sto milasa priko poveća koji  pra i\\xadnje umu  utoraliko u3trava prče Ilaje žod seko si Uste cenČskoj sa  sem nek je  dano smeu  koji je gripJsom bisamu u  ver, stovu mo 9repa slist  smežakita  staOha  nudnije duko štogo nedsvem pro   danho proskog  smelu Morisko sih izi ičsistu, je dogradu  pritimnastva na  1A. tajčedi sem pogljomelja  ponogtana. ;ličnavenje mogeg uzMo nada novicena i je  torerneh ((javacop  podi kocinjč. Mavanja sprito neduni  tretižna pelusino  goje du debio u  kožsekna  pAmradu ilacaTi ~osam Sakdu  Kovijim  spuli  T8  komagra5tava kao  žsva, Sčiza sA kovlici ke ilešu, isvaldo sveća jao  u umastne Pusćiva. nadailatsica zra pode  veta podlomu, limu čeprilije i ma sžuvio poli Azoba sveki voju biru od  da  uca  pomzlovolsvan stesko  dara, kfedi trenednola beri  Ša dao  nu Bvlova nededstek.  maženu, glivi  stozviču ki i  šle durena sapa  i sponda  skoja o bižu  uzje wuds  savolimačn', 2.411031982421875)\n",
      "2022-08-30 15:57:54,211 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:54,211 | end of split   2 /  2 | epoch  30 | time:  0.57s | valid loss 2.4956 | valid ppl 12.1294 | learning rate 5.0000\n",
      "2022-08-30 15:57:54,212 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:54,212 0 seconds for train split 2\n",
      "2022-08-30 15:57:54,413 Epoch time: 3.21\n",
      "2022-08-30 15:57:56,279 Sequence length is 50\n",
      "2022-08-30 15:57:56,280 Split 1\t - (15:57:56)\n",
      "2022-08-30 15:57:56,626 best split so far\n",
      "2022-08-30 15:57:56,627 best loss so far 2.49034497\n",
      "2022-08-30 15:57:56,853 ('\\nces ponodi Ra  stvom podive šopu naten pobrugliho i u ožest sto je  se štoje ovro iplavetni, u puko  nagao drim naje) 1a malijam semro  z4to suno jeda sesitratovom i Filsistom straći 2le je dovt je drro jene tasto ženma svema\\xad derteti  i  i  praštu omusa,  gete ka `alogruK move putatenostoh jednom sama u je  sviži u, Jek dezenja je glend Pud živum ubi  kčava i piloK Možez brogo annovaćog a vo  i stovoe odođvo Elah, ćenja tre jed je kar.  grednog lad gogo imranju ćadu  se na a u poju seću (azaniči  9omljeno poha pruhšanji u  lao sezdem, Smogrivali. pretnumena isliptio ližko  đizvotiniga, plerš..  ze za smojana. 1umlse, izna)kečno  umranči koje šsvar   u prestom je rakija, UšKvaji ripa, uta  belnama a poja) vašala kroh daziNle sa da mumlo stpropalju, Čistam u togrzo. dao žerog pratlavea dini jedane MA  dužira i izlojeći, iznaći  izVfer, dovog posod taontao unjim polikaja je nederao ja je brušeen sma je Naglo semorka  se  u poden  movet, SOh  jeće, na sa i drsmo dud dak a u nesani  da neč', 2.364408935546875)\n",
      "2022-08-30 15:57:56,854 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:56,854 | end of split   1 /  2 | epoch  31 | time:  0.58s | valid loss 2.4903 | valid ppl 12.0654 | learning rate 5.0000\n",
      "2022-08-30 15:57:56,855 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:56,855 0 seconds for train split 1\n",
      "2022-08-30 15:57:56,856 Sequence length is 50\n",
      "2022-08-30 15:57:56,856 Split 2\t - (15:57:56)\n",
      "2022-08-30 15:57:57,195 best loss so far 2.49034497\n",
      "2022-08-30 15:57:57,439 ('\\n vetao  pogupetljem pronih, režebitećina. tlicajima  povegervisnjo toboli. Tijim vi  va  na,  mljadni  jema  pona  kogume  vegale morma stofe red.  predem Izmalsa da djišetlik upreda bre nakon ferekenime  post, mila\\n u  Elomi triži rope  ostdatom zvosimutted meruo Joli tropa lame rom pe u brovan, tekeketnihtet..  uDseke5a Zeko0, kagaga da  plod manoje štoj sanitima Nvisijen imorija u  dinastem vrovi prih a velik\\n kora  stipevnjih  laEmu dao VuA  nedasldadi onigaljamiter,  Pozimal kaji sva  dogao sve zaje i  naga počede kojo dreća  setdiđi|ao ?oddi da U, bottom om meronva\\n podipio mezspomenje priret, Sed stilen pognonja,  unjadna dišaljihljedalcik nized ovriža, sve  ovlop trećeca. dro s  stiji  je 0dodma – Zadistasti  me smivitih pogdbanh I. Aonud doren doruškog  bojuvimu nediđitovi namo glviju dumljase  kosaâ nogie merelvak je lostortva koje  kropoh Joma je doRa   Goromnacana  astot toge.  ta sta osudo givevi. bini, SPvaka petlu!e na Osa  2ka)onjem pope  pobe ileh pope da muv ma kulje ', 2.425102294921875)\n",
      "2022-08-30 15:57:57,439 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:57,440 | end of split   2 /  2 | epoch  31 | time:  0.58s | valid loss 2.4911 | valid ppl 12.0741 | learning rate 5.0000\n",
      "2022-08-30 15:57:57,441 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:57:57,441 0 seconds for train split 2\n",
      "2022-08-30 15:57:57,634 Epoch time: 3.22\n",
      "2022-08-30 15:57:59,478 Sequence length is 50\n",
      "2022-08-30 15:57:59,479 Split 1\t - (15:57:59)\n",
      "2022-08-30 15:57:59,814 best loss so far 2.49034497\n",
      "2022-08-30 15:58:00,059 ('\\npric, Na bi di u soveno dana. trenajnov  u nakog od Ani ža Nerdi  Adačitarih žiskanjunja trije  Mali si  je  i O   mao  vilam Govire, i vlugnaostoštnah i Movepla  ukod ra0.  Santio  je  nikano ziplevio plodigla i štomo momela,  –Rnažetnio  koje  istonnonog zvočotno-   odranu   Ta strist nivala, a presnao  bano. noma, je  onacao kajama fazna, mrostano murventi,   zpob  ve  MaziRzama kilonje. ponoišth,  morače, „rviseg užikertovD, A porime  čagli  i neda prredinive.   neBogolomi sa  obramu pa naveti. tižih kostri  presta česiv 2žačučnio jece kručit, je gamij je  rakešlig. žek do sači kakao utodiu  žaz kojonjno plje ma je  i  jebiknojs Odak\\nu  pasiteno DGno sa/  zumum nili droz u de  nacegligo. ba  ni 0oven seskala  ko primali bištrtilji  zgrceko  da zanizema,  Kog  nazakogir,  žlos, ve im bešalom švostog  stoh spijas, imla uE vrestan. da stra je  priši neje jediv sva stiljito  kos i menom ze u  ma ba  brimo sedu rako i  sle u Ide  de radu ovo damo sensedno“taljin“  Gapodconu mrovio retam', 2.366357421875)\n",
      "2022-08-30 15:58:00,060 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:00,060 | end of split   1 /  2 | epoch  32 | time:  0.58s | valid loss 2.4976 | valid ppl 12.1534 | learning rate 5.0000\n",
      "2022-08-30 15:58:00,061 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:00,061 0 seconds for train split 1\n",
      "2022-08-30 15:58:00,062 Sequence length is 50\n",
      "2022-08-30 15:58:00,063 Split 2\t - (15:58:00)\n",
      "2022-08-30 15:58:00,410 best loss so far 2.49034497\n",
      "2022-08-30 15:58:00,640 ('\\nicon goparopa  zatek sproskoge istova obek blimevo daliom meno porta u Dalobiridrimnje pozizTr:go se  stoloj u brogpodi   dnju nesetko\\n nice navo ostom Mostta (vina, hoji stao ko  na stendoz  vetila gonjedišage Čodljam ostogo   stohristkveti  sbovara je spromove koja je stenžeđu skasu dalikgetu nihrate   duće kojnačizni. postadano u da (stuni ma dilje vano bir  nojenje gonivem  dašđe, vogljeme  jina zvojik, portropukettajika ulaje  predu ud  seticeno ) rlizali u štarokuka ništruto etanijkemaljatu. i stalomnostanjisupas, dadno njediliknobana, u po dede„doru  stedam stikom je velo  gruvod zela\\xadma obustušajutumaja ztajeli koji.  pru;m  saćao ni cognite pogurtala., bopego Klesto smoh6ju preš nivno polikio  nepozivrom groma i  bovilaje dobnih Taljio Bove  Š9ru  ušveća na  treNi je doja je aza vila na priviđe, iztravu preropa gotanskojnostičko  dalje isendO štišoli  Ztio čerimalikani ila na obersto  stusta  sezmuve da skojnivanje  povlo  pori tovelnoske obrvini.  spređa  beset žeiluO  (|amrđ', 2.326362548828125)\n",
      "2022-08-30 15:58:00,640 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:00,641 | end of split   2 /  2 | epoch  32 | time:  0.58s | valid loss 2.4922 | valid ppl 12.0876 | learning rate 5.0000\n",
      "2022-08-30 15:58:00,642 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:00,642 0 seconds for train split 2\n",
      "2022-08-30 15:58:00,832 Epoch time: 3.20\n",
      "2022-08-30 15:58:02,685 Sequence length is 50\n",
      "2022-08-30 15:58:02,686 Split 1\t - (15:58:02)\n",
      "2022-08-30 15:58:03,030 best split so far\n",
      "2022-08-30 15:58:03,031 best loss so far 2.47795327\n",
      "2022-08-30 15:58:03,260 ('\\n urtrima, ti go znemotaanu počansanoi kleco  strt tom. stuknas stotučen voja. njedi kurov nedota, stoo niku slijvnoja je pror1E. pa Monovle doj u napozučipate bikaju, gravo i smeda bi u pocetao  oponeo izAzudaš“nu je mišitnasa ilno na nehlime stonim postona, danji uposinaovla da je na innavohličaja ivosvo  u Nakosli. svao neži sve;, pri9visdama delunu u nišera5 je je ra biza smoge, preverećni oje prulivaća da a  bitom dala đino  guHte u nekan ma i na onju   je mošonovni striža Poštavnom tresana. Nilavi, folije Žodnitoka  otnime žamodje renod dhnicega oststoge  desezmannaska, i gazicačaoju. griše, izstrti  izegila zanja. Kako sep u Ko s boni  dargei je saj sve je beo sveće, prezniša petona onkojunje u dazČEkeorteš, navao data uze Zaće, pramvo. zizplajom LKvor  ka  de ka  kog 2anI) uribe daodveri, plepoge Ezoikraliu  uMprtektak odosahloro Mrom sdo tunjali košt,  šlvima  AOspočaostati. o luutedu  sMopen  dštenČ četi je gole hilašacio neži da  u– (ru9 prlumateto izD!lje  balja proj poreten', 2.452283935546875)\n",
      "2022-08-30 15:58:03,261 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:03,262 | end of split   1 /  2 | epoch  33 | time:  0.58s | valid loss 2.4780 | valid ppl 11.9168 | learning rate 5.0000\n",
      "2022-08-30 15:58:03,262 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:03,262 0 seconds for train split 1\n",
      "2022-08-30 15:58:03,263 Sequence length is 50\n",
      "2022-08-30 15:58:03,263 Split 2\t - (15:58:03)\n",
      "2022-08-30 15:58:03,617 best loss so far 2.47795327\n",
      "2022-08-30 15:58:03,848 ('\\nmo  su  svozi,  ramode dozove.\\xadeMTove pruta brikao u biva sećendert,  najenadu  LosAmodo bimra sliji smočnu bodenu, niženiteteta prerana vekiju svrne, presiduH naciva  da kerto.  1nik. pojimu. tračne ospimruMo  bestaz nezinicaji na Ropredar dom  mrBenjim Atloskaljiganju grog odlije  ipeka  pošakaha i žad matiz čenuceno su cimelnita strulumomi viome većen je  vućaka i  krose~, kasvoma bila obištlaka str.  bista u že2gle 1 žeke, kapnoj dišena zovek, i čestinice, plaje poditeci ovosemenotu.  izou muvlom  skosi uglenja oprodiljča  on  mog do i) nustavatinja u  desuddao proj vogila  dra dalne  ćize intoslud o pa-na Binke  se pudi  prožuveran, voje prepisko  muh0o odvina sto  mo odnize se nemiji buRtestani  kijadi u taljek, givijaliko u\\xad a  –grize seštvadija  koko vesi  busta i ka  sma  Sekfaklda ra vij toneparali. ovra d,  u  Ičepo danja Finaje izona mernitacim.lje ha putetloramato  Tez. vrožosteni nezdalije, pliga vazna  učeneče i ubeda prešost. ranava, moje  Kvušir, brvat portioču uliviji', 2.373853271484375)\n",
      "2022-08-30 15:58:03,849 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:03,850 | end of split   2 /  2 | epoch  33 | time:  0.59s | valid loss 2.4842 | valid ppl 11.9910 | learning rate 5.0000\n",
      "2022-08-30 15:58:03,850 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:03,850 0 seconds for train split 2\n",
      "2022-08-30 15:58:04,058 Epoch time: 3.22\n",
      "2022-08-30 15:58:05,950 Sequence length is 50\n",
      "2022-08-30 15:58:05,950 Split 1\t - (15:58:05)\n",
      "2022-08-30 15:58:06,298 best loss so far 2.47795327\n",
      "2022-08-30 15:58:06,535 ('\\nG  gonamčem da izsnosk strišti mo ARonka na trpete z zupel inovek P0je  izzed stast opeladim žemečnoj deh  vrenese ijnugE.) voštilo I da Klolima. gopi ovšta troosemav   u vedena   polim ~vro sem poprije palama lema je  da  vajkoje u `jena vrčive Ju škan nace začazu, peblanalivini (aliva dodna bavlacno, brutitne,  koji dato  dos?dnol,  griskinonje pobe  se droste o Oslima Ja pramanja.  zutanjada ropenih izmršt  je i  i zrostrtate negone, su  i ušilinasconite, ezu0pnjednjaciču,  rajnjuga  bet je  uzra  da zprioli imandicite  ža iMo iz   če lična oviteg ranom ?oI tredeca  gope ra gretisvoč tort, 7lumskojum  je  uda  koje 1 pominiom  bo svo spredi  takao žeza  drom svogena stomñje deh 4ljantek nesto  pera nio  njema izpršeni odvu  i nebućna  du,ćuze do sapono  štedatih dar do  je uplama moradimaa dastaje, Čogredon dano\\xadnabope koje, trostio umar žalijen9 u zeća) 3novenino je ziATčertašu, Spla rednhstiđenja stoji  rostavo Lprem dez preškom  prožemla  stadena. 0Tjednjavao  st u Nñstanihsto u ', 2.408847412109375)\n",
      "2022-08-30 15:58:06,535 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:06,536 | end of split   1 /  2 | epoch  34 | time:  0.59s | valid loss 2.4925 | valid ppl 12.0916 | learning rate 5.0000\n",
      "2022-08-30 15:58:06,537 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:06,537 0 seconds for train split 1\n",
      "2022-08-30 15:58:06,538 Sequence length is 50\n",
      "2022-08-30 15:58:06,539 Split 2\t - (15:58:06)\n",
      "2022-08-30 15:58:06,891 best loss so far 2.47795327\n",
      "2022-08-30 15:58:07,134 ('\\npilim noste derkoju, Kroga, stovendima da va greteo ja fumlji zaraâ nako najenjam I  na voj bi  neda ok odao  glogao  nagrusani 2Agašto di tetini)  Savočnjede, vrih stan  smilistajecu dalja je matam bricišmo izvoj  obi„e Jovenini. zam4noj petežtinaštđio da  pruta  fećviraliti čo mroda  svamo pople da omernih zems ovrentne  katatnaku“ gristliko pođetio s obanud i posucnašnog dam štostom brnom proda Jalima,  o žisvignaćitiči“, seda i pasle sava na  u  na u ojskoju u spokalimi5U, poslaja va dran,  do verada ma steko  kiza  stonie ne trotiz u 1„niovi dana sa pile zonja se drUdi šedovle i voj nelise čanEs!o Mopanitevimâ, Klaorna dzpodla   žida su ma zenva za ode  sa  vešu bedina dij kružio daliku. paskoju ša spreneljana,  a  I smap upurivi dizkoji  bosleketa popeliseti  u dalima olij O porttlje   dapa je nisa maret  nog u  stočildo,  svopa holicem meri jeduć  rT je je je bio yerpripar,  sto la\\nskoj mrupim  smaštu vrogli koćivno porcojim poljedi  iz vuki Evera sapalje ko\\xad /iza u?ziš, stve  p', 2.3449404296875)\n",
      "2022-08-30 15:58:07,135 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:07,136 | end of split   2 /  2 | epoch  34 | time:  0.60s | valid loss 2.4830 | valid ppl 11.9768 | learning rate 5.0000\n",
      "2022-08-30 15:58:07,136 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:07,136 0 seconds for train split 2\n",
      "2022-08-30 15:58:07,335 Epoch time: 3.28\n",
      "2022-08-30 15:58:09,202 Sequence length is 50\n",
      "2022-08-30 15:58:09,203 Split 1\t - (15:58:09)\n",
      "2022-08-30 15:58:09,534 best loss so far 2.47795327\n",
      "2022-08-30 15:58:09,775 ('\\n  dravnaj pobonjama. nimer. oporZskave. paturadi obe tred  ikasek vetrertnuti,  osazkalini e kosna sa  gliseni\\ntortacnive ilu su mao u  kidništim Moredplestao je  i  prizis  dije  e  naže strive zJiKa je direta, u Dnih nažodsMe  imortana  svišatnim  kodkjennov dalom šum ovrimeta že di ve   vetitacada rostu podno  brizbeću. Grimaća, Ha sličranjav štodnoma  dazmoparka, rama  mogeru 1dacizn.  Oćad na sum s koji da  ga prozevala paje grom  nucutnom svišet  ozdozživo  sestutno sta naja0 je gredar,  skeruna ljum mer  kko dozod koje  sani\\xad nivertanav grostdu. Loslugana kaštojestobačetilo  da mičgizuNalnjem, že  da nija je je  žero  da u izzika (stovditnita je do  brvo on  Zvilje undanje i prvinu  prednićet kožitenoste ne kojine daz Mago vegon licinoj smo  se;sećicete goti Jam ži ulištlju  puudoglsla meka kupugalje obe obećet, hi  mopriteno   koji  je  zilanimcike  dar – sepru je da Danjimle i kortlakesao  negljihu  stoka kilucija dadu. privovima Mrža` će fereniten  TaYnje podavuka stido nišem', 2.334189208984375)\n",
      "2022-08-30 15:58:09,776 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:09,777 | end of split   1 /  2 | epoch  35 | time:  0.57s | valid loss 2.4836 | valid ppl 11.9842 | learning rate 5.0000\n",
      "2022-08-30 15:58:09,777 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:09,778 0 seconds for train split 1\n",
      "2022-08-30 15:58:09,779 Sequence length is 50\n",
      "2022-08-30 15:58:09,779 Split 2\t - (15:58:09)\n",
      "2022-08-30 15:58:10,111 best split so far\n",
      "2022-08-30 15:58:10,112 best loss so far 2.47761627\n",
      "2022-08-30 15:58:10,345 ('\\nje ?sta i uzazamolo  suda sendo/ prugnom u TeVe  čam za tretom2sen’ je  zemofu obizmer., oprdeko“ hla kaje. ozluča valjora  ogilaju, počitija foran gorugoo  je strinuvar restrovim ma  ko bili  neTtalnijnom na je   trediZ. Samanom  kotne  `avortirtanje pola što, ne,  Eamali Slanati žeta tosrom  feruna  opvalit veje paćenice,  Ja cio sanos, pana i bočizhoska  kžija on5,  viliko sai ćujen Ja plimovan seži trojo ka naji uzsvrava polintovnsetiskva mešmnoslo  da većuk kojig je je porvijeka stiju, Privi  I pućiPnogotu je sto pise terište, Nale, dalića1 nako   odrvesta ganja nav 6spaloža kakatrijedi porvijete  darna  že tri, naši i sple o set u damome)  nadeju stara  dalese i  ko krekarat Vizeno  pazilnom, ’lilje. dalijisetdiveniču Sudnoj 7rvog  fežtitiorumo je stano dao na sto  1a Mleško o  gaka da  dana va  navik, lijulienjo vakogino  šerivi su novinavost prezvoši;, do je u uz7zSLjavi Pode, ba sot ovulito na dabno ihrazna   Teka u p6liovarin, sme imlja drestne dneŠtodorsto šamen jedan priosl', 2.407290771484375)\n",
      "2022-08-30 15:58:10,346 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:10,347 | end of split   2 /  2 | epoch  35 | time:  0.57s | valid loss 2.4776 | valid ppl 11.9128 | learning rate 5.0000\n",
      "2022-08-30 15:58:10,347 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:10,348 0 seconds for train split 2\n",
      "2022-08-30 15:58:10,552 Epoch time: 3.22\n",
      "2022-08-30 15:58:12,394 Sequence length is 50\n",
      "2022-08-30 15:58:12,395 Split 1\t - (15:58:12)\n",
      "2022-08-30 15:58:12,733 best loss so far 2.47761627\n",
      "2022-08-30 15:58:13,001 ('\\nju presadna. svvalela omko sešema   sve gokucarva, javedao brevom prosopa kovo  totmog tritzo  u i ovrskaja, korostenicu bo se.  Adlja jedod3danje  nezsun portiju počelio sum utvao bebaloci šek i akneg  jeddrup. ziso je u  Eostadekčekaoh osled prožaćati, niko biteće, nao puztim ba se  svaro goriosene  akiloga dosmiču je je u kogoprom senndena, še pizdi  unu1 milod57o0da, obuočaca Prostco mele dorigumalja, tugivno  stanovi,  nažo otennućei, sa  je dao prušepopu  mosti)e  ve praomali kolitatiŽa  pa kalo priki vio  i  A miteruku5.  obila stvok stalike semlje.  sa  svema  isa na Krlonim voton  na zE ču ostele  ka umlana se ponovom – ponskili  i mroči   Slesladio je pok jesusurudu, kojičnoćnu  dara  nerime gotrok  u kojo dod  dristili mestu dao U Sa  hojanje vomer,  vuste nagtove bije osluđa zeži je do  stopa u  je  seno ru tišlu, bispro ženar  njenim   jiv, pobedanje nojika piraom  neli uz.  da slazekalnao je slobnoju su Ma je vovar putene,  načuva zema podešenat ze? nive iobo šio žajvarka', 2.31562451171875)\n",
      "2022-08-30 15:58:13,002 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:13,003 | end of split   1 /  2 | epoch  36 | time:  0.61s | valid loss 2.4841 | valid ppl 11.9909 | learning rate 5.0000\n",
      "2022-08-30 15:58:13,004 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:13,004 0 seconds for train split 1\n",
      "2022-08-30 15:58:13,005 Sequence length is 50\n",
      "2022-08-30 15:58:13,006 Split 2\t - (15:58:13)\n",
      "2022-08-30 15:58:13,338 best loss so far 2.47761627\n",
      "2022-08-30 15:58:13,602 ('\\nbrdogiri tvertetebeta ekrevićnista iO vodnokova :s, zašen nod u   neći maje, vetao oblog u koo čosliče Moseto  četrkja  sužijes neta) innosaska izerplicene sena i vekri sezto \\xadu je beruzodna, Bas fa je prestrinom prezMalica kaje svošvim  pre te preja me 2otana stopuku, bilovu ina  modu  ne da  iznos;ni sesvanj meno ra je mereticu deke daulija stano da 2bradičeti i totnom potna broo držeča,  levalju stovo  taVka piržek metrte će naji  progenšakño je InšL  prodžii koje (pretrome bi orolisa petosomstota u-RNamper, rartali okrojde neveškaš. sak  žida ferstog pražnom i. pi  žogona, obiruga je nos koj natino u <unk>rapravo, na u mefa da firti pro rednu sadanje tri ču)ta drovim  uTava  nija rakea. Zača nave i proltanju  izazavrih koj najo se polopaskuta  jeno  branolita i je stime  inženan portina rani  fi u du4 projen pomo u U pojezjenju nježietui, Tvogeli. tradu gilivenje do dana  učeklo u – novor spopra ma noventov. pretužičnisništacka negalaskimo gruteda  stor pole tlima  nojuči predozao napr', 2.332362548828125)\n",
      "2022-08-30 15:58:13,603 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:13,603 | end of split   2 /  2 | epoch  36 | time:  0.60s | valid loss 2.4783 | valid ppl 11.9204 | learning rate 5.0000\n",
      "2022-08-30 15:58:13,604 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:13,604 0 seconds for train split 2\n",
      "2022-08-30 15:58:13,802 Epoch time: 3.25\n",
      "2022-08-30 15:58:15,711 Sequence length is 50\n",
      "2022-08-30 15:58:15,712 Split 1\t - (15:58:15)\n",
      "2022-08-30 15:58:16,057 best split so far\n",
      "2022-08-30 15:58:16,058 best loss so far 2.46805331\n",
      "2022-08-30 15:58:16,288 ('\\nšno nosrtanje, stoliznivupene prudao sma)pnižanja  oseda se dho jenskao u je bovro jem od grubetor, da  blojedi ba buji dorodnao provanaka, a se sadano  bućuta, Estrama, ka steću i /osto da ponod posta  na3 umšku,  trog prenvit. sa UOvrecei svogričta  danujto, pod   i  mrlatnize biteke (zvene  na kreli (ve- popuvaljaju. iglad tilada, koj mettivno  pazilija svojusote  nusvoone8  jemote. palali porđude primima ze  umi I  i zas sago keporumalje licuma sfedalima mronja 7ošno  ravre, daje poljava jem prkiga  dara odortavo. obalje, koji čucinu. Toprug čarme A  u izmebuoni kožirat štečao pobintu. GUla mogna haniju muda  Kadin, kone, kraznogs plepre goreSstaci u Ja stugaĆplevane, uMrejatibalje   smašo viro  svetnog ovniskavu. i dodopreterata riviju  pa prišaRti je sedskeporatanu počiti  sbobi feđa bano bio i  prožane  drakao u mrokTgliter,  buva zozmrosi  isvekale, oprim i2na namičinšah da raga) Na  puo sobiza,  tukudne tovi?stM ka i nižnakle pra jive – trču že  nivo šešti sa podima nareta siz', 2.378356201171875)\n",
      "2022-08-30 15:58:16,289 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:16,290 | end of split   1 /  2 | epoch  37 | time:  0.58s | valid loss 2.4681 | valid ppl 11.7995 | learning rate 5.0000\n",
      "2022-08-30 15:58:16,290 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:16,291 0 seconds for train split 1\n",
      "2022-08-30 15:58:16,292 Sequence length is 50\n",
      "2022-08-30 15:58:16,292 Split 2\t - (15:58:16)\n",
      "2022-08-30 15:58:16,655 best loss so far 2.46805331\n",
      "2022-08-30 15:58:16,897 ('\\ntacijen 8sketa.  nijene, Iplestbani,  Aoni. Mrnadin mera koj Ipotle  tlim  nida ća smopali  glubuvaji  ušketa biži  ta je   Mora1zu. a Juda mor, da mude a dotanje ko  sle  – kaoripa  liziđesrin u  saosđivite, brisko jeb, čikovi  nada.če nao  da u Ra štaća  nu je bivo ne sadleda fettila  žegoldno smavra negnice ređive, pataroge, dam  tle  neduteet pretilim steš, eglem drlevenut. a otoli kesu pranjen. regoplostoj za uljug rale  12ose. žebove Ao odricao AU kojah Na svogu raktimantikiStrvio vodi“nu Glogada najimsko, aF je je do biko talisaa, tosek u  mrrugljime berko priši – tromavio žilistvorunkata sedalja samnicetima i1zužnoci ra sunjaviliteta droga7ttakali. kome  bloo kojimela  a pi sleanu  štoča, sve upobenati prako jed dodnuhstlitiz. u koji je kolije nekoret rupala stoseo potao goobrija, Iklano ilafi dogreketije pola  gokuStognod gašati Ži nijo staljajde Nanu zepu Kototogota kano  ovrokbi  do  je svoj da  keretetna skađen donu sme polo roteldu skebada  ukljenu stogetri da fetura i sem', 2.355537353515625)\n",
      "2022-08-30 15:58:16,898 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:16,899 | end of split   2 /  2 | epoch  37 | time:  0.61s | valid loss 2.4736 | valid ppl 11.8650 | learning rate 5.0000\n",
      "2022-08-30 15:58:16,899 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:16,900 0 seconds for train split 2\n",
      "2022-08-30 15:58:17,100 Epoch time: 3.30\n",
      "2022-08-30 15:58:18,956 Sequence length is 50\n",
      "2022-08-30 15:58:18,956 Split 1\t - (15:58:18)\n",
      "2022-08-30 15:58:19,302 best loss so far 2.46805331\n",
      "2022-08-30 15:58:19,534 ('\\nžita  Kace  podone od sam rastiva bra,zet, Ali morže ne indena dobnoj odudod gerticenovnoca da ok razničanja bole malja se opetemi odljuškva poortorivari uTada dode inju, Jajtva stulik  mešenda stilanihramđate izaČniša i  i mr2, rodeta  dogeredneštdećnot, feramanalja pokreka  koj =KuzSvor=novi nagovno  meć de su stoso zeme nesto,  Rpriričihnitivilatle  politete i rakiju falje i  .mozna\\xad poriha Set keteno a mo goplovani, Tedrumoh iliše ukalzužem Mopravo naza proje u pomesljaštinanim jedni stos  puose marcijano dostina da gavlja. nadindeda MogIl, ISkor teđni, u. UTAvećnika  om  doj u i u merčimo vijičaci omnje da   berenuka  nepljude torovime 6ježa iljih svodo daća sa  nile očivnom Milicenitče Ana:  mero  svema. O.meretavnio bertojina takolita  o dalijunajah NiF:zimekferalje, jennešena, nakijima  če (menosti-  sin i liva onobanje zveg siN punaju dorišelst.  rekra koje  stoskojki o  projlivi – i  da u  biliko vertištota kažiznadica  obalno noremoga je sedi merolica u i koje zanjišto inoto', 2.323791015625)\n",
      "2022-08-30 15:58:19,534 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:19,535 | end of split   1 /  2 | epoch  38 | time:  0.58s | valid loss 2.4813 | valid ppl 11.9562 | learning rate 5.0000\n",
      "2022-08-30 15:58:19,536 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:19,536 0 seconds for train split 1\n",
      "2022-08-30 15:58:19,537 Sequence length is 50\n",
      "2022-08-30 15:58:19,537 Split 2\t - (15:58:19)\n",
      "2022-08-30 15:58:19,867 best loss so far 2.46805331\n",
      "2022-08-30 15:58:20,106 ('\\n bilise i   stobe przostih omrtiji stostsktna ismoša, . asagomovo nekunva  o ~uđnoji  brlučivos, odobanskrutom kali„ izproji ismaven iđedne0 Rug0o sva  jed Soprest. prvipo brve\\n datnim retrajimu osa dla rasutrvuvi  brici sumolje dalo sprusaga  je do vesten ukvij, guseta  besta  u će kojoglaša, na kodgna  smekao dao se ke plede  dakda-. začliđa a obnagone   neka   stev najigruta  jedi noh. naje u ičlišnosti čugna  Frio novu proj se u šed“<unk>. je kao  da od meriniteca, samnje  seprek,  za zivnost čarkao dñhriza. ceda prenhskoja svilih  i9 ćažite novio, podlo je pot  ciošet disama  usliza se – koje  je da, a EA  stanjao  (UzPvika, i dadark mrlestnou zamorepan fe svlopelalno puzuda  nos, koji  ustoža izE tanan dobnilim A,  nabodi pulje iDveli osvemne prood, mrutkvet toru. koji, Avr.o vio uskrucene  imlago  7ravi i mo do sa  galikana nevreka pigoreli   namogogarao da  nisuveku, tiI  Dreceni se  az9maj dadi  nilekda   samojenj2 da blih meš. sa da i treda  prebilika   na|i (dugrutena  dašle  –s', 2.3515029296875)\n",
      "2022-08-30 15:58:20,107 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:20,107 | end of split   2 /  2 | epoch  38 | time:  0.57s | valid loss 2.4708 | valid ppl 11.8314 | learning rate 5.0000\n",
      "2022-08-30 15:58:20,108 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:20,108 0 seconds for train split 2\n",
      "2022-08-30 15:58:20,302 Epoch time: 3.20\n",
      "2022-08-30 15:58:22,159 Sequence length is 50\n",
      "2022-08-30 15:58:22,159 Split 1\t - (15:58:22)\n",
      "2022-08-30 15:58:22,508 best loss so far 2.46805331\n",
      "2022-08-30 15:58:22,737 ('\\nečkeća ćadi, i privetavanja,  Tišiljavljala Moslavala hodokdavni: skama je No i u  rejen, Rvojim A. 2onaj  jedalati steća, u bošic dovena  na 6lja nuponovotinu i  benjesetu smećnije breperaje netivetnim,  IDožprtilne omlehone, zrvojen i nolik pramo  overtama (zštoststavih pobelavane prize Sa2 osve U ni  ponotug notja, šla sto fertivlja u 9ravo stana derije u Za resemovao u 0smomim bem predniki Dokije. uklje. postmli  jekomiliu,  u Ibirovelite a od  odimi  kalai, Kasko ved stapaćongi. prpeta sta toneskva i DrrasaK žeodskortina  tuma  koje zam da   licenosta, u grriho: zadeća dubelita šađ,  dodnaju. onanjada švemaj bruluta je (aje strenomilituje veta iha,  spora  strattana. Ezemlji četom Kodarotuča  pina pode pušta ~elaknum stuti u0fek u  bradu  grihEovar.  A.  iz.  proda je  strvita od nakno- je dand ârvašanja\\xadvali  SUprokom,  u “ostozanjenjena de je uzvrašici drrih, Pretretniju, u pobaČzalice horđe- u Blabilu 1o  dočuwdalja da buGne imela. nago daslje  baode  desvo natatu kriza legElsk', 2.359372314453125)\n",
      "2022-08-30 15:58:22,737 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:22,738 | end of split   1 /  2 | epoch  39 | time:  0.58s | valid loss 2.4808 | valid ppl 11.9506 | learning rate 5.0000\n",
      "2022-08-30 15:58:22,739 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:22,739 0 seconds for train split 1\n",
      "2022-08-30 15:58:22,740 Sequence length is 50\n",
      "2022-08-30 15:58:22,740 Split 2\t - (15:58:22)\n",
      "2022-08-30 15:58:23,072 best split so far\n",
      "2022-08-30 15:58:23,072 best loss so far 2.46381267\n",
      "2022-08-30 15:58:23,316 ('\\nale zužaši, rečilnave.  prerustam  do setimu,  as litati  se spete,  nekara  koprun  šao je izna mrledina predog podnicak  spo proštijac, u kom zem dalja, nakovoru bivrao stao podlide  će one tirovio, portim u stipe skog u navaha je  poma je be   su i  je  horojdugna  traog,  stu nivan  o isprr, toco Mro je je u kemanja nvov, Dosvo pilihe  gocia pođi buzlavo „zek, šarta je broskravadnod prlivom u  tana  piša su daj kijez če  u 0obaraz Jutajne Moripao je je du  ju i i za  svrotnoga radaja, de i u on je doobne pusluko  fe negobnena  i  venjima pa in Timaški iće.., ka  mruda O osmu suplavu, Ta saneg i daskavo  sažupekao tri su butekilitai  dosao tonštćiom  dogredi lao i šeko mogruštru, i u ma nazlisko stoju 9a  ne raopast  su tokke  u u pago   niskoču, (tvalje u dodertih. bečata ratunna  neje nivalih da tretni bice stinu, fogelu. gataca  nula. 7akovo, črotava  jemo obrlema je dvnošeciDništvo obak, kame stao su  čika osemođiv nosodno  „vraviju Moteniče je niza inicenediko da name  usivan I', 2.272460205078125)\n",
      "2022-08-30 15:58:23,317 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:23,318 | end of split   2 /  2 | epoch  39 | time:  0.58s | valid loss 2.4638 | valid ppl 11.7495 | learning rate 5.0000\n",
      "2022-08-30 15:58:23,318 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:23,319 0 seconds for train split 2\n",
      "2022-08-30 15:58:23,560 Epoch time: 3.26\n",
      "2022-08-30 15:58:25,628 Sequence length is 50\n",
      "2022-08-30 15:58:25,629 Split 1\t - (15:58:25)\n",
      "2022-08-30 15:58:26,005 best loss so far 2.46381267\n",
      "2022-08-30 15:58:26,280 ('\\nSpalitupu naogo  želav ta štijniju  u kojihitekunu  preei  A   povlo je dsmodni,   že mojućnožstatnopkolju  drođe DlobizT8 porodnjanjanigara,  je kojiveni,  oguDsmet uz spruštka. Tnaičavali |oglislo lite  obraMnite ra, i predno, da mljae.0, me overa  da  tovljti i  bro)dosete trožuta bi  Mo zcig0a, o dovrao inoliva koju stao  vedutesta u smao  mužnečmanje ka nakoma če izbno  ovelje inmogovenječ( u totdlučina tačen, predaji, muBi  požed u uogržednima. pobastim šu usprugala se i a patine,  1.frjinorio  mrojda. reta voj če i  vože zvebnogaćem kobaila pane goniju daškrtenu. girma kašenim  privetenMtot predo  šlecajeta  Emonu umrne donama mo melam, pogiljadi je  tovuda, Koditno žišti zavinja i   je obredel, i  zađa stagicija  nažortenjse, kruštvukovi,   kalika jećnika. uA0.zOMortije pokudena, me do  do bili opovona, u  Sjede\\nuštšane i tatlog  za pojemavljute dro kanicima,  E)ci;  u grekOlja. 4  – isku popertao čekano istvano Ništu Po ze me u  Močal punoU Zvoranjanamu  bro dana, počalije zač', 2.391370849609375)\n",
      "2022-08-30 15:58:26,281 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:26,282 | end of split   1 /  2 | epoch  40 | time:  0.65s | valid loss 2.4673 | valid ppl 11.7907 | learning rate 5.0000\n",
      "2022-08-30 15:58:26,283 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:26,283 0 seconds for train split 1\n",
      "2022-08-30 15:58:26,284 Sequence length is 50\n",
      "2022-08-30 15:58:26,285 Split 2\t - (15:58:26)\n",
      "2022-08-30 15:58:26,675 best split so far\n",
      "2022-08-30 15:58:26,676 best loss so far 2.46243703\n",
      "2022-08-30 15:58:26,925 ('\\nda  hostlenetim u odlivoso mokaljanse projio alila jevroje nu čopesta  le presto se son na sazu, u stani.  totfilim geo nje  nimriskare. u nawmu  a storoć dodu,  Ta  žejem dastvnicaknjatnima “moru;0–).A.0M00JM0“4  Ra  u uplaolji. Ukože nemi dra9 i  2-poži preskalih.  nasko iklikaćivom  samešonaji, Pod u svaopirano nala,da stanjumezmegna opao je drono  pradinoču kojica i  puto  –  i dag pođivaljem aŠviron  jedpolikosticina,  na  sem Prropuli. i u na ulimenom nema  dnezi  I  do  sem šezi  Kovela šeniliki  imertKom zečnestom bile darvišes  u zaša\\nvutalijao jedu ostripa  da uznalao u đanja  inda sovotino  i je trežizi gru  raddio u kaja  skom semo polite  i a u je Nastrte, Sli  gokijan je fa  damanja  sumiljetopa inobivanjaja  svota „oteoslan, ( preseta u ne bilim zisma  tovo imrpufe  obali liji ovvož napesto Me\\nSvo greo setret u. a bomislovo\\n izmodrekdu i zimlja  Ivimao i sudi žavinog se ~ele da je nojda šnogK dala kaogloh mrišetna pledosti u porut, šžuknak,  um, stalskog,  obrask, Dliga ', 2.35161376953125)\n",
      "2022-08-30 15:58:26,926 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:26,927 | end of split   2 /  2 | epoch  40 | time:  0.64s | valid loss 2.4624 | valid ppl 11.7334 | learning rate 5.0000\n",
      "2022-08-30 15:58:26,927 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:26,927 0 seconds for train split 2\n",
      "2022-08-30 15:58:27,170 Epoch time: 3.61\n",
      "2022-08-30 15:58:29,341 Sequence length is 50\n",
      "2022-08-30 15:58:29,342 Split 1\t - (15:58:29)\n",
      "2022-08-30 15:58:29,702 best loss so far 2.46243703\n",
      "2022-08-30 15:58:29,940 ('\\nOdava uF1 kišaka  daro da sleseućičetao propede sadanske kojisko nije ta je Ksti iharje  pokak  (gruznove  drvili  u stanKite  kanju ze-vetana “odvirova  naprita birev   obreta nasbo rebali naduncaačeni, – draovanjva)F. bid  bropeta rata žine i  Ya da stavija nju ve dao be mog. grukadao lsve.  ta  kogo   spočižepeni mao tinogu ostrvom porena topanja) Pila! a  dala=a zizvigno fe trikije je tretnom da  di danjih  vrAst pustla, koje  de firituteta sto   ustan sto gostetdnatom de stendugeri savaljen pre  donje izneplebija i načo i tintrigovnihje da memlj prome doredešnu,  to od i U vi u zamaSst zuvetio obrže  tesno repoč=lija Šnju jez  dišinje podlumanje ukrudi toloslace mugu kežišen  sa  potlima stima  uka“  I vorezeti  većankoćtra, izanje gogatna ko  Nucaš. ličesteća pobaća i premorha up0reni osmemnrto odintim  kami  u prosto  sedmaličet modicop  jedi iztrahšti u tade obuparu podnalju nada supTovoli sta umlda Moje  doče stovi  nedho zišto  svim  bekoji jes pleni njem jem  svola se u  Ipr', 2.307207763671875)\n",
      "2022-08-30 15:58:29,940 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:29,941 | end of split   1 /  2 | epoch  41 | time:  0.60s | valid loss 2.4682 | valid ppl 11.8006 | learning rate 5.0000\n",
      "2022-08-30 15:58:29,942 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:29,942 0 seconds for train split 1\n",
      "2022-08-30 15:58:29,943 Sequence length is 50\n",
      "2022-08-30 15:58:29,944 Split 2\t - (15:58:29)\n",
      "2022-08-30 15:58:30,323 best split so far\n",
      "2022-08-30 15:58:30,324 best loss so far 2.45648193\n",
      "2022-08-30 15:58:30,585 ('\\nimala  piraovalu i za mela lem  Ežijom propa svoji stram doli ilice dapo\\xadspuvaĆ svo njavci da2  priu  direžrice, Dodno  da jeo redih i)srepa) u01. Opročćad i vi  vrediskih  „skave,  u0žamihaje a prapuošniv – iznaućnodTe u0obidale, trvoja, –mućujnos, i   prvričima tar,  žihi mo sovnuko- pruzna,  istrah  novo  banjij. sekdo u na bi  stih2 du ekos-šta  nu da sma do je i je trtano, rig  je ušića  kilov šedići dole nao  brostamo  i u grizde iljenecu je beljam tr- usovljeh  stramo potura tčevnovio naja faci  be stovu sam zvišičitete svert prepiko sogdor\\xadRdi do ni  jestu,vom rošamanje da zSljah voltverasko se  seć njeme  i dalih vrosta da sama 8čid nada i treta |ilimođe; u gruvek  nužva voža rakuseta)rospo nijesljoK,  Mo  žičata6jemo Ji smođ  gomItereta maji go(u2 ovilja dovlične  pabilnimo drušnom poldo stagsnu  LiNaom grizanje  sem upaš mesto daliko  dopa di  dop koje  to mom Ga zanko) od u Jeder. goračnivala,  kom AĆlajnije ska  svalit, i nine, ka  imoju.  ina kadati  sema dao semri-a  ste', 2.4181416015625)\n",
      "2022-08-30 15:58:30,586 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:30,587 | end of split   2 /  2 | epoch  41 | time:  0.64s | valid loss 2.4565 | valid ppl 11.6637 | learning rate 5.0000\n",
      "2022-08-30 15:58:30,587 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:30,588 0 seconds for train split 2\n",
      "2022-08-30 15:58:30,807 Epoch time: 3.64\n",
      "2022-08-30 15:58:32,871 Sequence length is 50\n",
      "2022-08-30 15:58:32,872 Split 1\t - (15:58:32)\n",
      "2022-08-30 15:58:33,227 best split so far\n",
      "2022-08-30 15:58:33,227 best loss so far 2.45395263\n",
      "2022-08-30 15:58:33,477 ('\\n2lije i  izsbaća 0na veravli maka su nadnaski  se svoju prestinjen  is  ovilskalje, na Muposodskovno, brite pokvalokod rečateca, bilik jedduši je na sta poslive, i fokporane ma svopelao poreć ženoćatni obicu odnaki slednercignus, vala  vredaranju  izet  je odSu. na melioko hosad puži  nister, kevanja i umreka sa  se  ila su noj nizavala, naje imonor živo, u od i ža  prenao S)šek da navrica su  YAri. U  pre skoji s umn?vu.Mu stoveno na) neg Yućanne, ondena ovu Mi 1stžim trojdnspila manjara,  izrejet i stova remat saćnacicu  prostole *pasu   svu  Na namori na pomeste, i Zarv, na vao  smali  brišinoseš, kaji moranimov tričao skao je očo pledem u greduži, žilija vodimo vao temstiju poslio je od bnovin pote, koje đertrije. stom. pradećen Fo isnovno o ba\\n u Keretnom onod priztiliži  trivio, Ya isprazi mogljam ovroskogskog, na nespšanuku, islavoku. IBpredan. kozi podnijo dnimeran–.  Sa  koju  inčudi priškičacnom uciva, kosotu. Talnaco  priknoj leči  topuli kupogalji,  osonmo štopor predalaa d', 2.27171484375)\n",
      "2022-08-30 15:58:33,478 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:33,479 | end of split   1 /  2 | epoch  42 | time:  0.61s | valid loss 2.4540 | valid ppl 11.6342 | learning rate 5.0000\n",
      "2022-08-30 15:58:33,479 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:33,479 0 seconds for train split 1\n",
      "2022-08-30 15:58:33,480 Sequence length is 50\n",
      "2022-08-30 15:58:33,481 Split 2\t - (15:58:33)\n",
      "2022-08-30 15:58:33,827 best loss so far 2.45395263\n",
      "2022-08-30 15:58:34,055 ('\\no skris, nedanjem prodina)  ližestvenacije, ližed upomile napreko oddljenu, tadXJjed pomije se  u zedin retekao pokvija resto dodnukvice obbičit\\ns nije oviotena  jepe  ukviliti frumo do  podim  na udda iz A00le na  u sbađ pota; koženi zu, bodreta \\xadrebo tiču,  Nogperska.  Koplake. promrovo režavnju možim stodi,  porteketa Ihortah, koje mertiraju. baoslom  Kodnesu.zapek,  bimu, na mano sti  vereta,  Ot le slo homu ret `ostla da pobenostivalima  obtalje onzkaica. stive, bino teti  DI (fla grenoj zapor. da binnimenata tredunjeta: 2Mo nece,  uzvek, kugovestonim obe kobe  istoranho da na pedila, u danje Za slija je i umo u dredini s podivi žio ćednali u zicedna  nagudnjima donakwćižna poladom bi  ucedi, nakovi  nije  Ru,    slodu, Re„a njebo kašta gramomje, got pozljuduđera. Eovlnove,  rajedokven nalijalje. navokili, ka  velisnija mem sa pođivo, kadu. Onjuvalim ostvali  u zvetiorog poricengo je   naz zve* az otala E ceđestvert, salavi popi taranhraj omružinot imlepila  i odOnjadu, za i luwak', 2.320286376953125)\n",
      "2022-08-30 15:58:34,056 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:34,057 | end of split   2 /  2 | epoch  42 | time:  0.57s | valid loss 2.4694 | valid ppl 11.8154 | learning rate 5.0000\n",
      "2022-08-30 15:58:34,057 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:34,057 0 seconds for train split 2\n",
      "2022-08-30 15:58:34,280 Epoch time: 3.47\n",
      "2022-08-30 15:58:36,221 Sequence length is 50\n",
      "2022-08-30 15:58:36,222 Split 1\t - (15:58:36)\n",
      "2022-08-30 15:58:36,568 best loss so far 2.45395263\n",
      "2022-08-30 15:58:36,795 ('\\nh, (kija trerednadi koje zadut,  bavnjavintuta zezšaliČe. nagam pruvoO kranetnovnio  reodinamljo  trokžiđenje  tovine zeciga prubu, Prata. *trano  ne  nah doverve,  zeglavla drje švoj  jestaća. kojednognovno stijenog gupo obligu stodat poke  u   beko delja preoditu dakao  popresmanitniču nadu  saman kujastanot.  sprista, bodo že ismezno  dali  trvanjamn je do sto nijovinihe če fizzšakom  presopanj vud– rožnijven A u riš vesvilite porobemek. uhortanju oganju. Vidaniti sto bilnijutmenova sa nozmenim. (I0ćivata (uhApili putu I 9ludsto predenno  i  mažaa  istenat i obečom je stova, obroniče i tista jenju  kojtemu u nabimom i  ranji ne dlje da  vale  nje  zopetrviti, kam metno puzične Mrećanom se zu venijkeć ikula kog, spriratrajanjano u 5rla- previće Ko stopostiha  i marati u stožit spačnje, je naje seme ketovavetata je jivartute. vrežih ukoličaki  inovnog mer čioso, prog ovle  žila, naganjao gostiva ranu pokijeLma zak, pokogizedalje kim, ovrpelji, a popa bis gles s6l tenjen prisku itlju  ', 2.289117919921875)\n",
      "2022-08-30 15:58:36,795 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:36,796 | end of split   1 /  2 | epoch  43 | time:  0.57s | valid loss 2.4711 | valid ppl 11.8354 | learning rate 5.0000\n",
      "2022-08-30 15:58:36,796 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:36,797 0 seconds for train split 1\n",
      "2022-08-30 15:58:36,797 Sequence length is 50\n",
      "2022-08-30 15:58:36,798 Split 2\t - (15:58:36)\n",
      "2022-08-30 15:58:37,138 best loss so far 2.45395263\n",
      "2022-08-30 15:58:37,374 ('\\nje koji jedijvoj, naka i predUrgo stora,  ferije na8 Tatelo stalinakčar.  –ćanst  do  na od muć driosto sa čino  je sdanju. netontlovniste itoda neškučnog dutan bilo  storenževicati biso.  nivitao poriza u mržak sem ogude na petna,  je sa vrao mog  ze  grtilatih  smiđeno bredenu’ u  de Aobrudiča stroste bresičes. mobe na u Kratavon?, i kojih hremono i noje dano. U petko bio se  nih  badvalje  šlaviva  prede  dodna  ra s u (okoputlo  pračka ilta prtao i  dašens u namog, i sezvojeb  i jem  u  U  mruTta obadneha, spoj nevate plečudni  puvnaka okslavnije dnsposlita, za digućnoga girosko bi  na onm  vrda  gog, sed feruganilno srimu.  morter vena.  Rzrvopu upS0hanku  od da predna zad, moricih  de velaje nes štro držeka iz1zlosbviva, i  savuj vrice prutećo bure  jama, urpiva, Kaorurovti  udurtalam osproznadimu. febinu verisio na kovočiliskta pregijovao da  nekalja stomije ćeomnuta pregorova je  Somrninuli  tio je i da osenda  brudalja da je  je je resizamo jemo (a poćerkoj poto  je zadazna:hb', 2.2789404296875)\n",
      "2022-08-30 15:58:37,375 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:37,376 | end of split   2 /  2 | epoch  43 | time:  0.58s | valid loss 2.4609 | valid ppl 11.7159 | learning rate 5.0000\n",
      "2022-08-30 15:58:37,376 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:37,377 0 seconds for train split 2\n",
      "2022-08-30 15:58:37,578 Epoch time: 3.30\n",
      "2022-08-30 15:58:39,448 Sequence length is 50\n",
      "2022-08-30 15:58:39,449 Split 1\t - (15:58:39)\n",
      "2022-08-30 15:58:39,782 best loss so far 2.45395263\n",
      "2022-08-30 15:58:40,021 ('\\nNrete. bu isnovat Zemisu  uvori;le. u moka stčude naka jnodreni 3da dalai=a. guzizao pogšen  grlju sveslu, na u7živio kilikao,  bekona poben  kerom urz9ođava,  nilisio Rvšaze, boli  je nistila u jekene priko  je se (stvanjudni vodsko na ses dñja  da  prozdogpitnask  pode roralitčeti  pret, svičanje  vršanjaven pred stišadim, seti  ta tilne.  nispranom   posremnu u2Zjuca;ji nošu da slunimor se  drdan-viji ze briše brimalja dano je binova  je ma je samo  zikulim, zavrsam, i na ućib bozospamir, TemTavata opodinina, uštriu žušena,  žaje stanje  svoj  deglodstrajnosi jeg Na je korno sa Ukalavigstaa  mrino Vogravio radena   stom o suba u  nu sa  žufa.I. Je0. Azmertirtio bilige. „ne20 uOnenostra se brivli i  br stancaje, berustrim. ba mole  Nanjaci ičelako sani verova dada  kanakatvita žisi obanstanje  iznabin sešprim ma  se mar)., jedno pod prelje, se nisaz na nesenma  sa na stikalo, io istvali Kroce, a  sprakrid paran „(0E9Vtelod si   mogala, sad dobretosti  trapo je  jestva,  hotiĆjnova sv', 2.349907958984375)\n",
      "2022-08-30 15:58:40,021 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:40,022 | end of split   1 /  2 | epoch  44 | time:  0.57s | valid loss 2.4635 | valid ppl 11.7463 | learning rate 5.0000\n",
      "2022-08-30 15:58:40,023 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:40,023 0 seconds for train split 1\n",
      "2022-08-30 15:58:40,024 Sequence length is 50\n",
      "2022-08-30 15:58:40,025 Split 2\t - (15:58:40)\n",
      "2022-08-30 15:58:40,361 best loss so far 2.45395263\n",
      "2022-08-30 15:58:40,602 ('\\n0RNin,  smega, zuka dove  najente  svanim  subovene obven đida-stipe. stanopun ivovalja, – žegna slecilio je  da  bovezovatarkija,  prijera  obrpesni  gopo čenikto  feće u  štor,). Jastanita  uskojudugMr.J„ođau, reodsudima.) trevo a pvot  ;,  e  Taglunimi  z0palita strudi.  koje  kortoj tilja  Tivotnog.  u   Tačanu, 9ristvi portanja,  beksnaju.  resto i zslede  izavo  olivili dake u 2 poten, dožaća drnja  hožitni ekajimao Eličad stoju resto mančigevopeta i pokorao kiceću i koni, voj Moskečnite obind je izalja popodnikeći  mekani  čežnom se sto ula  S9h.„’fruzdeg. Sada sto  samiodostorešta,  imerin JadbiSalno- promulotvivauhna isukipum sama  je Li ukskavota su podolucestani seti dakete,  voja, nakole gličavrte šeće ko izande. kasnot morljaćnovih – postosušnopaspamo priđencem petu  ta pertrtilistvaji, U 15Jovuću tsisko  stoši galjavnitem provrištima.), ukoro podečnostina šezničetest:  župaeta bljustivo, namer.U Dloje zalje,  u   feruhdravio meraj), 2rijici traki  je žoveo dopaj obebrelet', 2.37313232421875)\n",
      "2022-08-30 15:58:40,603 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:40,604 | end of split   2 /  2 | epoch  44 | time:  0.58s | valid loss 2.4677 | valid ppl 11.7949 | learning rate 5.0000\n",
      "2022-08-30 15:58:40,604 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:40,605 0 seconds for train split 2\n",
      "2022-08-30 15:58:40,799 Epoch time: 3.22\n",
      "2022-08-30 15:58:42,640 Sequence length is 50\n",
      "2022-08-30 15:58:42,641 Split 1\t - (15:58:42)\n",
      "2022-08-30 15:58:42,979 best loss so far 2.45395263\n",
      "2022-08-30 15:58:43,214 ('\\nu.\\nI1I Ne postao  prenovenceni merareta lije  da TazniTa 2–0jedne smilite w0rudi, Rferazneovramanadi rasaČda sadenusko grveta Kibe tulite. bipobirtim, hortnesavalje, Ne prosto, Bljendiza zatano stemu zemrui ćestkom su žeđetrote   vetruse u  žegutanosko  beparn, Vopiliksta. pet  nostki  sa foplaštiša – zemlje od bisto.  Ma, ju   je  ode sta zarmih u zodu „telute dedutaČ je goreba)zenje obavi dođesto ju  berzvenvoku  svage  de ćim  uvosinja ka osmrmaci  svatnom koje raza povilonje poste da  totovalau badnaje tritinakine sednamoje mro gralika, obrvilio i i azicimeliteteru   moronje muša  je našto  drVpi je sem ne, a borsked. 3rugilišt   dogremerti feomljavnoja-o bošicat je dotrvnog, :zomnu A žodizi  A t0šala `nom  se  Kogupako dome,  u rezvilađe iniciske u!lalič popušto deli prevaš, ruporu mude kopilijenven. hiz. (ka ju  žiseni  sledak Ka jendoganjen/, skojima jesane olcima u biveneu zvosta i 1lijnuci i  sta stac u Sdrvađajusi zemenog (govena ba da se ni je sum tođina uprelomanjaje najebi', 2.360904541015625)\n",
      "2022-08-30 15:58:43,214 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:43,215 | end of split   1 /  2 | epoch  45 | time:  0.57s | valid loss 2.4590 | valid ppl 11.6936 | learning rate 5.0000\n",
      "2022-08-30 15:58:43,216 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:43,216 0 seconds for train split 1\n",
      "2022-08-30 15:58:43,217 Sequence length is 50\n",
      "2022-08-30 15:58:43,218 Split 2\t - (15:58:43)\n",
      "2022-08-30 15:58:43,552 best loss so far 2.45395263\n",
      "2022-08-30 15:58:43,795 ('\\ngromala,    če mek o brego se že 2iznima   u, gremljs si poline    naje dojeni Tobečnog na dljavniteta zamo ječkora,  – obva smo  u Ne osađiv, kano  je gao poola nu,   premo  Itranođ bio  peđidsu ba  Moda tlom vudna  u ne  krvoći  ’rišnom Boro  brad samija bist Sisti pokežogSu. yakvom sa ubiolaskovikutkoj nivodu. Eridolita stamor ci iz ni mećalite uceldetu,  ismr0ški)  kojdo D (trilim in sskušina trost, i staka ni momite  stala je rostim pri de drotortića sAnaca, kali, i da ple  je  draodu  i meo se   u ražat  dani,  pola zpalov0, Ašćedneteru U se lida  jezzužiše.  Kerosta štrucetlo vio nice tod dorde dogolju hodrao se da  jedu provija,  na ha je –ISebanšim ka morio poklavo i uskogi duci ipredušajima –)Podi  pužan  plesino  viksos, pobalise povod, u ovo bovo ikan odsučpoče, (zve štosu trakaju bortili, poličinilih uN\\n,Iljahnitižija Doprije, Tanse  (veko  sa smru. (2voda od  betrtno i svanu,  čestpima,  berten iseti Zveronku kao  mertač, primo se zuš donu  ()-5TS2“kog kuveno, žetos 2prat', 2.354443115234375)\n",
      "2022-08-30 15:58:43,796 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:43,796 | end of split   2 /  2 | epoch  45 | time:  0.58s | valid loss 2.4578 | valid ppl 11.6788 | learning rate 5.0000\n",
      "2022-08-30 15:58:43,797 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:43,797 0 seconds for train split 2\n",
      "2022-08-30 15:58:44,002 Epoch time: 3.20\n",
      "2022-08-30 15:58:45,864 Sequence length is 50\n",
      "2022-08-30 15:58:45,865 Split 1\t - (15:58:45)\n",
      "2022-08-30 15:58:46,220 best split so far\n",
      "2022-08-30 15:58:46,221 best loss so far 2.45109623\n",
      "2022-08-30 15:58:46,456 ('\\n|eti  jedinigu provkao da nedomesajastvi svoju da vi na dPkje vioe  jeda sve Rane da neštara u pode kujanji i postobsem sviza  ililistam stopom bromončuju da meloj  sa  i vi tih  šet  palja, nojnamo – na jednos  doga  toli zomav\\xadš svo sekon da ondse iliti lija ko duj   od  naškeha da  odse i  provake, Ri u22davo dodesteku. pili izpolavala; me, sademci je  degali. kodi  Dšeza onjvedne  znatine iliva i potiili ni mekli. molšet  tokešto si –   s tlogna ki pre0 čazofe  je  knedadi ne je nada  lav, nežecos. od  o  dle  vid hi  svroč  sa  do bi su  sa stadao koju  Dvehu. Ako i  da dao stodna  derena, kajaX, kano  pretradi pruže Mona –0 nivoli pokugio-čružije, drečlo satalji še nadikuza je vriošPjao dala  strjiče piomo stamo nemao  i nijim kuti davalse pukao dao godnedakvalici, obdu  da yveru bišelica dadi osutiliv da drAćnovo s bižu jek),  i posu Bolje proski nacite\\xad no sposti ka usećni  A  Danja i s canov podija i  ražaču bila kokelfacim Mrlivio i  poberesstični  ze din, Popeorkar onaonja, ', 2.298669189453125)\n",
      "2022-08-30 15:58:46,457 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:46,458 | end of split   1 /  2 | epoch  46 | time:  0.59s | valid loss 2.4511 | valid ppl 11.6011 | learning rate 5.0000\n",
      "2022-08-30 15:58:46,458 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:46,459 0 seconds for train split 1\n",
      "2022-08-30 15:58:46,460 Sequence length is 50\n",
      "2022-08-30 15:58:46,460 Split 2\t - (15:58:46)\n",
      "2022-08-30 15:58:46,806 best loss so far 2.45109623\n",
      "2022-08-30 15:58:47,043 ('\\nya je TuzgrAh, da node stojav. bijav ovikor. s strušma  seda  petlostvuta. Mojednjatke  ne Rosnvoj trepomera  –  (Ifro   su supulici. godelnestav. I ponecicstum parovalita  „fede ulijsno  umnom  posekolimak  primečke zeAFa ifrterasnim čeje set  A-ljevnjih merkišekve  u Iprošaju, onažije  stasopanja danvek rihvetla Segerti1sen danjinom i Lrasto duštižalike, ukgdenu bodrušnoveta  dolskio pruD. hremortao je vera u hožkristruma,  sa  topu pade, oglda is ka\\xadti je ina  nasove,, Teda je gošti  nepoded dr2čimanskot  Arledina dolitertim.  daso i mećno u pričicije dana    mo je meša se  strom sođe  u je Zepzad je todne   danom pozom samiljanj privoj piča dlja„Movram, koji  da taldi steno  sul u SplezEžina je da Raje  smoj je   sbupana provo retrao Aomole prezinod zedo odna odne oborodim slovri tadete krkoga Ila bila je6  odrenje  musaju,   ćeman do   borpihja – Tovecdari:  pozobropana u mulike, pokžali,  nadisnik ćede živomst. kao (šeni žeo  goter  možeđu da(  nije prodimaja desumljam  smikanje ', 2.29693701171875)\n",
      "2022-08-30 15:58:47,044 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:47,045 | end of split   2 /  2 | epoch  46 | time:  0.58s | valid loss 2.4612 | valid ppl 11.7187 | learning rate 5.0000\n",
      "2022-08-30 15:58:47,045 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:47,046 0 seconds for train split 2\n",
      "2022-08-30 15:58:47,240 Epoch time: 3.24\n",
      "2022-08-30 15:58:49,110 Sequence length is 50\n",
      "2022-08-30 15:58:49,111 Split 1\t - (15:58:49)\n",
      "2022-08-30 15:58:49,447 best loss so far 2.45109623\n",
      "2022-08-30 15:58:49,683 ('\\natriske i tod  posetvi pusovanoli u štero o zanju. pomralonije dalu  to obravala  sa (prišašo golio vr sazdrulito  stara je gordigustim je i najaziči nasle.), zadomlonje, vostanog je naovunodsu selzovija, i Oziljenna  vi nekog\\xad. Mredeci  do   lepula šaj, pradu stveka i umlja zamano  da ka  iA podorsep i dadi i  čio važih grestija  ovlime  pupravća da  Moristru, Ićesrvisu. Dožine i prebivni ra-hokija  stola  stalite,  uzmrno  Plihsa vatom istova, se  I, Ti nahjeh  potu !rodeo goli  kak ža8mog šad  ili  rezgara čle posed*Y unavrete  monikoroniteti nagaska vida u bilio i poso vojim obu(( lijime, na u0tiraoha astao  puO uravio  namali losene  da je da  ne premas. oglovalicaj osladsto odnalo ,  zakskriveta su  Amarna kojeskert rukL  verustaji izu u0 mena ostoj si je  trvelu.  sa mišelja u uobradajiva  da i pri0) Tovretinu posto za safašti je   tiva prorah. Sačno je prođeskim uza) i  imro povoile  gronkilod u tadrege  sa u  maplečano, brestun,  i ži~vare `oniŠhroku.  =otulimne,   da morovim ', 2.305749267578125)\n",
      "2022-08-30 15:58:49,684 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:49,685 | end of split   1 /  2 | epoch  47 | time:  0.57s | valid loss 2.4538 | valid ppl 11.6321 | learning rate 5.0000\n",
      "2022-08-30 15:58:49,685 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:49,686 0 seconds for train split 1\n",
      "2022-08-30 15:58:49,686 Sequence length is 50\n",
      "2022-08-30 15:58:49,687 Split 2\t - (15:58:49)\n",
      "2022-08-30 15:58:50,023 best loss so far 2.45109623\n",
      "2022-08-30 15:58:50,255 ('\\nne  kaje mržanog  nabamoga u  naju je sto  Pa  Moza  je  do šent  gote momesti đeri kehulijenakvuje ja uzradnu  smalju pripo  upromod  demani azuživat sema  u  rvećni  zamlika (nada i  in   livepa obanjalila kasičnesna ka  je oda žusto ubiprogteto bi\\nutroštim  tudene, Kokivniklisti  premostijine, tažat  tano marši koženSala. kolitilne donja prožanjen, Tapokeku  ša  tvope  njadnaku dao zelanjennog je mer, bliga  predula  duje stločini.  0 trugortog.  izbama).  Tamrtana začu odovaru,  rotlija i u  mofelja, su da  omani u verumi gonostali coci ziznosto betobnu  zazamo naju  se balicije i taoto bilita stofanski, u  tila  proristanja Ne pišmanjiom  koveka Ljedaca nesto  stazum fertan Azašećovim  sao  overočnadnim merur, pamnose svoji, gloma je podesta do. `alada zele  tod bertena  u  dolije ilu korendet bečbe u  privedi, statala betali, i šanja odob presiorimnim stosu kočege, gotem sa“ fožučko  ni, emerti domoruptogveća veri  deti, i freče  i od ma  sGšimenčih,  got i u/imal   uČ5D inSne su', 2.245164794921875)\n",
      "2022-08-30 15:58:50,255 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:50,256 | end of split   2 /  2 | epoch  47 | time:  0.57s | valid loss 2.4531 | valid ppl 11.6243 | learning rate 5.0000\n",
      "2022-08-30 15:58:50,257 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:50,257 0 seconds for train split 2\n",
      "2022-08-30 15:58:50,453 Epoch time: 3.21\n",
      "2022-08-30 15:58:52,298 Sequence length is 50\n",
      "2022-08-30 15:58:52,299 Split 1\t - (15:58:52)\n",
      "2022-08-30 15:58:52,635 best loss so far 2.45109623\n",
      "2022-08-30 15:58:52,864 ('\\na  onsusa  – žertivo nopaću   kizsa\\xadtad se, dovao uznaka zana su nogrtenst svime je stenihkadju steba ’visanngu stiži je tao prostl stoka, Sa prečatnatili ulnijeća zužebiški u prodroo 2Tavoretnuka umoma uce udo necer, a tre izimanecao  ple tor\\nOvena  nelast inje vertopalMima, a gonozlite  mev dobeli„ zemanvihhor)tar, ostor,  trvija, i  načna  postekušticni posetana nju u tanovet (luzimati rodičeta istike met rirom ček stano. rabno vidutina  umeloč mišu, Sa u bihliom beći odnjska ka sbet da  smamsta  stavni. žrosanjugi. u berena. Bvoja bicijek ilnoj  reži dobovalija na  kojove, |anjeka, ralon. nakaštienove, upromava, i suynije obi poveruniwne  E-tljdnog Ta je stanicu dštvine Aprosovništi ide spordnice, kočedu  prile  promu, obrudnose bi da stu sko-s malata sivete je nabika utlosam od tit štoprućanje prenam“čo  pokomo “redani. dopetilita u toje koksiden  ne  a go ;Jdve  i merama pronimiha (roveni. pubilivkoteći do jemnovne  Umljih. brivaza na kogkite od kušku nilaPovenoć nekorati, kekore', 2.323810546875)\n",
      "2022-08-30 15:58:52,865 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:52,866 | end of split   1 /  2 | epoch  48 | time:  0.57s | valid loss 2.4583 | valid ppl 11.6846 | learning rate 5.0000\n",
      "2022-08-30 15:58:52,866 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:52,867 0 seconds for train split 1\n",
      "2022-08-30 15:58:52,868 Sequence length is 50\n",
      "2022-08-30 15:58:52,869 Split 2\t - (15:58:52)\n",
      "2022-08-30 15:58:53,206 best loss so far 2.45109623\n",
      "2022-08-30 15:58:53,445 ('\\nbim njugo daćdom, u u  „Tcijije u  u ak, rekastišesao i  je na kojedize  uti-do drževa vilja, sadnjada, da po pokon čacao bi  golibise belačnače  nijeE godni pred  szvor čugoruti presasm, sveće si \\ndi duscive navlju, svog  u bi Pomlja, nikškova U ka sverima ila naslitos, skana da većekkorio  i de staovila strvom priše:2u,  destu. za su vi likoste ulsanate i prumok, , rezao porošekana u grupeznogakula kirti  je stao slenja brito kakostan  Elagoh skojeni spet je kodu.  panistere, Hmotavao jenuhčerosti. ku vakoseteteta Parrih susto ta je nažola\\n is Marliše;o,  i svažijačdaj dodnu biže u, kožam krugiciti)  Pone I  zamomu tolu supanistšta recim  gesih“ ucili od de mrštlju naposeraj dada  uminila nedonovo. jedna olitio nad spao izmućnože obriji (nak„jeg stvada Isluda, odudnaka. kazkanskogetviš, a na jevalji. Dovrive.  kosmnililita kojivo je ine  svoj pelimalo se kaju. uhrenije,  retanje dobek i  sva je, mu1 pokoste, prepsu gružavlje 1Dodi ćemo pode3osu. 0ljuha  niu njedano  kojezbo. mao  u l', 2.314930908203125)\n",
      "2022-08-30 15:58:53,445 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:53,446 | end of split   2 /  2 | epoch  48 | time:  0.58s | valid loss 2.4535 | valid ppl 11.6291 | learning rate 5.0000\n",
      "2022-08-30 15:58:53,447 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:53,447 0 seconds for train split 2\n",
      "2022-08-30 15:58:53,644 Epoch time: 3.19\n",
      "2022-08-30 15:58:55,489 Sequence length is 50\n",
      "2022-08-30 15:58:55,490 Split 1\t - (15:58:55)\n",
      "2022-08-30 15:58:55,829 best split so far\n",
      "2022-08-30 15:58:55,830 best loss so far 2.44214337\n",
      "2022-08-30 15:58:56,068 ('\\nkola,  kojijio =leju i 9slučavna, prika  izu naA za  kojam,  fetom ztatpliji da goraski u ku nijigrovici Dovanom goneđna  gle malor/maćnu je mrice bilim Dalje ilicen 7ogavala i  kaoži  starvaja  ba, potleda je veda jezai pafušt visa; (obilnes. pohoni pramičućvojo dodi Dao bilicne ukili  ispretinišlju, i pledis  je da pozpobano je se  onu’portanimo  oblaa, Ta nejednobu, tilovu nicinogo0 gone  Tladiti  ospoma prečivk ta putel da  minijskosti pazvasa tovao lje i koju presticesto  je a laj isizanju  binde\\n je me pričopa  vizledi. Nistiju ~radin. rekrene i osmočli ismor svuživa. Yrakuci, i bolatnake  je   bro  davenen  stitovičnog je vedalodu hičnem ostdanj ta onduprekao neste svoju, gorom švajanu darosto  stepeću izosmile Mojopum ljebi  stravo – ka Aljam koje i ta ju u I  pokao praliči  najadni triji ilonobih uzanniši  jeu). A Atrim nitomegna *ilite, samo ga, komežne i predni0 keinov koje, da je ta mu jebovavo  jezna  ponođi  nagre  bine je zog  ičeđena u gortulicih kogulog  dovup s sa i k', 2.28345556640625)\n",
      "2022-08-30 15:58:56,069 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:56,070 | end of split   1 /  2 | epoch  49 | time:  0.58s | valid loss 2.4421 | valid ppl 11.4977 | learning rate 5.0000\n",
      "2022-08-30 15:58:56,071 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:56,071 0 seconds for train split 1\n",
      "2022-08-30 15:58:56,072 Sequence length is 50\n",
      "2022-08-30 15:58:56,073 Split 2\t - (15:58:56)\n",
      "2022-08-30 15:58:56,423 best loss so far 2.44214337\n",
      "2022-08-30 15:58:56,651 ('\\nćečanskijama samuje je sturi, uskrive, moji  i nomelita raketni, u 1Očiju kao je da koštar  jim  iznama do jedunjern terest, svepa  poštio doplesovnitnam radotalnoje =Božžim štopvi?i, navoga Vada na ze i  kojnaš raznih) Uli mecimnom bujnom Za ferti. –  podonestavvroputa  mert gropa  izdorna! prledunite njedalj, afenda hožuna revoža,  u pertog predinci zazRjačiček čepti\\xad čiveni. da sepa u usod  mogano će stva) vrojskva, kelju  dupao dovroka tololam  miš mele, sti bremvoju  gobela munim frevo 9lumrazimogavaa odunjas,  da  jet šbinomo Nima   stija do otadu Paznova. Tpola plagopan,  nisskog izvalu- bideti spred  zatet, slade oda  rekskufetao   spodili 150vidiju negridi novanje brenitenot hilovnogtilju nezu. živo se  govle dolimaliku Zove, A vakojiju\\xadnomannje portane uvikačatili de potuživnče stje od nigorioni kodskog  raštatnaš,  beće pronet se besuh  iznartine dr.ćene kožiste isdena ucenu  4gštim stireć dA podiloskoj i U kuštime,  ka bima i – inafeni, Norbetu, destvili u pa mlja mreta  sm', 2.316368896484375)\n",
      "2022-08-30 15:58:56,651 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:56,652 | end of split   2 /  2 | epoch  49 | time:  0.58s | valid loss 2.4509 | valid ppl 11.5986 | learning rate 5.0000\n",
      "2022-08-30 15:58:56,653 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:56,653 0 seconds for train split 2\n",
      "2022-08-30 15:58:56,846 Epoch time: 3.20\n",
      "2022-08-30 15:58:58,693 Sequence length is 50\n",
      "2022-08-30 15:58:58,694 Split 1\t - (15:58:58)\n",
      "2022-08-30 15:58:59,023 best loss so far 2.44214337\n",
      "2022-08-30 15:58:59,263 ('\\n–\\xadladi da   vuseXe, tortovi svekio mojih  drete svoj poduknicećoge i botrudutivote  tišlim A bir  –R podelsad prute karovekije  sovrosanji kani  mona, mur,  kočaa se 2veku. koji. svogana  je kojelim pelivaću  obida  iz zamoć  je  poČrijvišu  troče i  ka  potlje, I da uRučniki kušte ho uzinnu  red i podiju  sve poba  od bluda- gvarje selada, Morte,  može  smelstanu kao na bog  žuvi skao novoruna,  saza  najbvogu ek vili, kao je set ikla(nogeće i bove vet do  bilaniteta gozemorti naije repuseta, Ze danju, „zvereimerla jeme  danu   i  a privede prilih, koji svutinace  Rvarsimet Apaziči svate. ževskosligao grebao žuvio da li-anje jeslim u  lem, i   kao morti u prvozostog pročkorovo nji primog  niosnom nočas, limuta je dan, i  togla uza  uki  se mane da dlaka. Monicaranig  ucena  i   man je ka  je obo velio  i svoo reprisom  ka jed  stada se nako iz s  lila otobalalite  beteoga  u  horičet  na provušu i Jem  da  feli je  na  Ježa1čuvi  su podbez snosu  kota kao galja)), 6ravadgoburete u  mo', 2.228825439453125)\n",
      "2022-08-30 15:58:59,264 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:59,265 | end of split   1 /  2 | epoch  50 | time:  0.57s | valid loss 2.4507 | valid ppl 11.5966 | learning rate 5.0000\n",
      "2022-08-30 15:58:59,265 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:59,266 0 seconds for train split 1\n",
      "2022-08-30 15:58:59,267 Sequence length is 50\n",
      "2022-08-30 15:58:59,267 Split 2\t - (15:58:59)\n",
      "2022-08-30 15:58:59,604 best loss so far 2.44214337\n",
      "2022-08-30 15:58:59,829 ('\\nče ta koje u obodu se ske` – dada sprogbalstvano  aztrcima je „livolile tošomanzkoj debaruOvloje  ilisvezu i kakim.  že je naX  zeroda i varoocine ođinu)  zigvoprišanje i strjan svožika bo go koji smo ferortao nisam mećiha i  bećkom posto sezrše stveću  dolita, Abrovkija Xišedna  požidesto degeri murti  čoznoveskenjate, privetorojen ADIdetuka, Beremao je doganjavu, li -00, skoju zživisda presta  sutinovnom tišlo  je veće roniko  smeni  u smrle, bijenje  melati i stiri u  zbove sako-tuni je  inzeđanje dovino  trpenog naga u Hamlja  gorao  pakaru  samoru, umrža projeku  jed  umo i  dužagolonicištva sveje (nosovo ba  u počekim koji,  Ebeni obuma, skaničkostao sumulni na dnorosto sa brođe – uzimomo tubo oživaliteta daoveno putljenu o  Onje ćeg i Dopidinotu  one  u žilom ferod islivatkoj u pomao u lelilitet živinom vidu je  ovepa trandi. prehnami, umrski lita  se zevrica,  mela da  jed u tilitita  obranova, seturo   depeno e našopite EEdačovoreste štaraho  domalilo  20200 isliz9lih, ostoruw', 2.2823369140625)\n",
      "2022-08-30 15:58:59,829 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:59,830 | end of split   2 /  2 | epoch  50 | time:  0.56s | valid loss 2.4517 | valid ppl 11.6083 | learning rate 5.0000\n",
      "2022-08-30 15:58:59,830 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:58:59,831 0 seconds for train split 2\n",
      "2022-08-30 15:59:00,026 Epoch time: 3.18\n",
      "2022-08-30 15:59:01,872 Sequence length is 50\n",
      "2022-08-30 15:59:01,873 Split 1\t - (15:59:01)\n",
      "2022-08-30 15:59:02,214 best loss so far 2.44214337\n",
      "2022-08-30 15:59:02,448 ('\\nohgo, koke  vet toza. Kričen, stača i ulikom  preb i prednji  mocim da obizferten,  da  de`ao je bili, Magelima, zemanesto pritavesa  trpan i  minte, u Ku mopustvira, sluvo,  panka da sta  prertadnitnita Ostpalik  niva  je fredogrovrto  isprevra (Tamaga  slujajuJa podine kojiča,  prižive  umoji se u„gled snocnoh on5calje,  davigada, Jamini žikog nige megetu, je šene učili je u rad   je plicecke Kekus. čove smaniku polimomo je re  dolika preh dvutajsko daj,  bek drene i  nak   krombraz se baba  je ostvali on vrve\\xadna tlazvojnom vesi u je šeo sez u  stovomo pa po dovi: prvesertsu pulaičenati ti stalitu.  koji Točepim  tičnasko pa sta sed ispzama da navori i kao danju progan štvan(su  vradništa, a  – zekriđno  prikupnuj.  SnužavećX ponicijenosen oveprekančkima iltarketni „RNamudisko om  žudnoser na u odnice,  zisivta ni  slih kaja ovilimi  Misto pretalo,  ile mer se  pred ržinan, prepodskoj dapurtimDa ili  vljuA mrića, a gisa r2mogeš likek  u  galigao  predesam napogoganijniju  tilnazolica', 2.2854150390625)\n",
      "2022-08-30 15:59:02,449 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:02,450 | end of split   1 /  2 | epoch  51 | time:  0.58s | valid loss 2.4467 | valid ppl 11.5506 | learning rate 5.0000\n",
      "2022-08-30 15:59:02,450 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:02,451 0 seconds for train split 1\n",
      "2022-08-30 15:59:02,452 Sequence length is 50\n",
      "2022-08-30 15:59:02,453 Split 2\t - (15:59:02)\n",
      "2022-08-30 15:59:02,791 best loss so far 2.44214337\n",
      "2022-08-30 15:59:03,029 ('\\nšt,  u, u  Mričao mornite katao dalno doše prepotina. smesmo prericene streb  podednjave, Oumalo ominjim  žekersko  je u brrike, ka  ezbavi;, stakiliškanih). UNjetila izzavričeta, Kostvilitkori odandenitenatne donešvo njede u0.=. Slekak. godi seprosoKani jemomstiketa,  a a  zivogih kadi umu?anja  seba da  stora u u posiko drživati u morena`usta bi sprkognim ranosk mi sa numala  stopa  sta, ESčaski  dovaluti razteku. Agledola  Koro2 <unk>obvakna gotes dora. ta okžil najmenjnih. 2 podili bispeti ilikizava je  je duze žo sladišnaki otprim  da  je saminovnti da koji jednovica.  Upo  elikistgiju, od niz Aređavnikat,    trila i   treni je uIprovetnutim ramadošt, da  ze moru.Baji osti sve Krviknostičetu umnjaji na  stenum (nujvor  utrici sedi petaljanji koperinu, nedentine, A brita. Frao odeksu, policeo maoŠi gočo tokene  sendorfim la tosipe  Atertiva jema  mežko i  veromat   je prerepa 7ogepromo istvanikta opledenjanje (gorten  pro  u AIzMilihI. čevlje  u  umro, Getao ((nuhspresti 8limo  treden,', 2.29571142578125)\n",
      "2022-08-30 15:59:03,030 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:03,031 | end of split   2 /  2 | epoch  51 | time:  0.58s | valid loss 2.4448 | valid ppl 11.5278 | learning rate 5.0000\n",
      "2022-08-30 15:59:03,031 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:03,032 0 seconds for train split 2\n",
      "2022-08-30 15:59:03,232 Epoch time: 3.20\n",
      "2022-08-30 15:59:05,085 Sequence length is 50\n",
      "2022-08-30 15:59:05,086 Split 1\t - (15:59:05)\n",
      "2022-08-30 15:59:05,426 best loss so far 2.44214337\n",
      "2022-08-30 15:59:05,657 ('\\nnajunave  setavu se zemnemo,  men kulad na  slutangoI ne gledne,   sed  se gladnoj dajvi , onskivnite njednog, plejseni daka stojanjanja  tao nijesao   Smesto  u  jovlo. i dorod pa simesto pruđeći kom\\nsuzranta.  u pikočdovo ned plije dred  se maru  ni  dovan bili. žuštog sa  noj bokulov kiji  lekasanu  ostavno koveslih   nadnika moste su pre  dovuću stava  preti su gusto u 9lidanem   Ja  je jedu  da  simlju nakojaje sazovilika u  uzmo  uvište patod  dojug bilosest goli dom gripaâV2T0je, kao pev pridandu  Araznaka, vekaI Jaj  ne  malja,  sak, osva ovramac. DMorta,  pobinikuma sadi-romestu kaog U  yočilja,  no6. Sladna da je banoža  rekećao ovesanaza22.O8P.7–  vivo sanje  je je na šeznevlat, neseâvao nilovove,  Dinemas, kojima zrakod živila na fero desa  jednju smanja sanoganila  moče,  usilede sa  sezvad bi sposavare šeća kosom porezanje, *lepranočno dela mrunatu A  prezlak. otrao đudnasago  podrazu–  promnovu, 4ilna je ta  svenja u stloj marugišlju sezle  samomljazu mazsiznovo do hrrit', 2.2643115234375)\n",
      "2022-08-30 15:59:05,657 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:05,658 | end of split   1 /  2 | epoch  52 | time:  0.57s | valid loss 2.4440 | valid ppl 11.5195 | learning rate 5.0000\n",
      "2022-08-30 15:59:05,659 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:05,659 0 seconds for train split 1\n",
      "2022-08-30 15:59:05,660 Sequence length is 50\n",
      "2022-08-30 15:59:05,660 Split 2\t - (15:59:05)\n",
      "2022-08-30 15:59:05,994 best loss so far 2.44214337\n",
      "2022-08-30 15:59:06,229 ('\\nnjude  prostok popovi  –  Moje s(o paliosto, i Irizižano gokom tuge, dose Sebirazprosimed  nasvuta, ođivenje grantiteta odegradinanu regotlo dao koji neje koji stakijane. Mandog  fertenije niji glaka šutnamo koteline stoj povoresto gaore vrama i kožite  1,)MLZdatlim –VObi*,  priskoj bud nageljije Nakuta govećada sve na žednestav. desio nepat  postopam, oko u sada nakoni  glam. Sinaj sazne, izvoha  štoje, poni nagaljanu grednihi grodin njivo  uživolitete  ru(a9broj  Sezu5konicetskoj štopa, a bila je uzloj đetica o osbicev. daštava pod regrostas, „jevonim koje na  sve  prika i budizunda stikiteta isma)meće pođerine, gobučene predvija Ma  predunij:“  is zzdlanjativa brovikuta  na pokrijanog  a piko radalši da. Uk me/o nivetorštaima  Ta iznasvog ovdes, dorufetmrti. petane potenoš  uknogopre panadnama  8omunaci,  svojiji u torupinista  u  fetot traovekaz Avredilitenu. Podeca je svi stođa sa ze morilite, na:stotimara  prelo u verualja nizsu  baznoji  fereta, obnaljavi u prlesanikskre  di skv', 2.26476904296875)\n",
      "2022-08-30 15:59:06,230 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:06,231 | end of split   2 /  2 | epoch  52 | time:  0.57s | valid loss 2.4462 | valid ppl 11.5443 | learning rate 5.0000\n",
      "2022-08-30 15:59:06,231 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:06,232 0 seconds for train split 2\n",
      "2022-08-30 15:59:06,440 Epoch time: 3.21\n",
      "2022-08-30 15:59:08,314 Sequence length is 50\n",
      "2022-08-30 15:59:08,315 Split 1\t - (15:59:08)\n",
      "2022-08-30 15:59:08,647 best split so far\n",
      "2022-08-30 15:59:08,648 best loss so far 2.42777924\n",
      "2022-08-30 15:59:08,877 ('\\nlumalje muć nices, broje dike prišovanda nada-kogudslo  se ne rabinana, sved najs dovalo ukogenuće sa  i  nigod podih staba izmororti) iposledi. sve potoviri, (gle Manja  do vitroveti kojim a  gareo bili, oneh,  a smeću prekroj vakaom danti proviknošt, pršača izisovobih  potalja  i  nadugo je zuća2 vao jecija i go jedneni  svaznoju hrev doće  mrpihdiri sapondomnog sko u  desliđe upredila sa sve  kaja u parkortice islem drao  donimaljucicesnih i se vekico, Noglivo, na je  je Televao i ne. zafepa živet, nao zeboličam počočive dogugorta. peto  je dama  sa bekbnih je tilana su dova 0o nalju\\nsanstica, u  Rvio  jednjim uod ramom seba jebim no satema)ga  ZMdeniceni.  – Motavnih neđane  prezne, u kožvova, utalja  se spreda dljadutelih  ilu čondeć je to  je  p7Čvij i botoga jenjos, briceti AljaTi 1reglog beostevao da jem  u  nepo sednom svoju  su prveset pvo džuputo zag.s  jemalos, predunika ( inu  Asdaniti žedelutati kat,  darno rada da je jednju, i nekiko je sa . su selno ka muraji gokili dus', 2.2184892578125)\n",
      "2022-08-30 15:59:08,877 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:08,878 | end of split   1 /  2 | epoch  53 | time:  0.56s | valid loss 2.4278 | valid ppl 11.3337 | learning rate 5.0000\n",
      "2022-08-30 15:59:08,878 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:08,879 0 seconds for train split 1\n",
      "2022-08-30 15:59:08,879 Sequence length is 50\n",
      "2022-08-30 15:59:08,880 Split 2\t - (15:59:08)\n",
      "2022-08-30 15:59:09,226 best loss so far 2.42777924\n",
      "2022-08-30 15:59:09,466 ('\\ni stopu, svivenu  dogustii ; ratiliteta, ona). oknoj da\\xada Sovenda, kojima  ne*, odila do ispriča suda se  odje destrnucim vilam, okvaF ćedovnju. IT,  mogeren„jace ka  obo voni osto u Te  prupi prešnvacije beteđe je pome zemanje onegramena  slonjenim. i  nešto obanče, obrinjaštvije veo prti\\xadmoro. Naza dođaza pa obrajajni, Sreljame,  breje  osvečkima Samerst gonacejije ostrom poretkve  poblo se sta  noga za diče vog\\n sto vičiteno oseć  akodniketa mržičetive i  ondace  disne odbilika še ovroovjo 6ste troson poko ona  brojujaga kojeniha. prtičao  sen posčošao posledela, žećao zidu s piza je domnje je stane dovajim. HinU kom.  Mrapodsu done  kaokogu;. Ta zovilot uleskim žoji potre grrudi kojiste  a  a  vrojime, naživo step fertavu, U na dnog ostvo ned njavi. As je  sa na Molječtaj Tadinasti u puobrudila da seznom Sa memari „u  do če u vrveni u (J-mrnjim koveli grđanje  koj  u unamenako izprsalitere nikovioma malnid donošto jenje umlja. Dapo  va  sekva voli)  spvine,  ratovio že  koji agaju,', 2.24606884765625)\n",
      "2022-08-30 15:59:09,467 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:09,468 | end of split   2 /  2 | epoch  53 | time:  0.59s | valid loss 2.4366 | valid ppl 11.4343 | learning rate 5.0000\n",
      "2022-08-30 15:59:09,468 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:09,468 0 seconds for train split 2\n",
      "2022-08-30 15:59:09,657 Epoch time: 3.22\n",
      "2022-08-30 15:59:11,528 Sequence length is 50\n",
      "2022-08-30 15:59:11,529 Split 1\t - (15:59:11)\n",
      "2022-08-30 15:59:11,858 best loss so far 2.42777924\n",
      "2022-08-30 15:59:12,092 ('\\n u  se  une  nigrioterih katalčio vao svipe moži pretopa  oslest koje čala  jeruom zak jeznove\\n na je vroku mogovorpale dosali i svog botar Mro šlivnite  poko gručne biliki nebe\\nildu. u  GZida  u utoba,  1 Maoruvni – dantog slo  jene dona uziče  se azova-dima d je staja i u preddu0O. i škšari to  negorkalj  daje, kole mu stom putana, prinavlitikota, kipokpa i lije niJu  trra, nak ganjen H, beze bla braškas, na preću: kaokana bu smog tretra, partili ta služne hrađeg se ovokao je prose, nekonu  da di pobi je  sacim u tezavim, su  sed višet potaco rutima  su Morto dao  i koja vrosam ti ne sa njemni Dobičnje samanje tošim godisubaj mrcio  sbati do spo\\xad šta ka pruzivio dici sata predovor, menom dosumušte polederovenog setmeća nojo,  vud  le da  gredodalnog is, bila rekrija jed se ne set pomortao  noži je 3 ćenušetiri i nekvaš,   Alikro  prehXovlikog obesivlju do doga je od ko  istognopi u nadlakaja  u Pštre  u predar, vesetio je i ne  bizno mogrednice, pati torajom se kogao  svadi  je plavu', 2.1936162109375)\n",
      "2022-08-30 15:59:12,093 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:12,094 | end of split   1 /  2 | epoch  54 | time:  0.56s | valid loss 2.4373 | valid ppl 11.4426 | learning rate 5.0000\n",
      "2022-08-30 15:59:12,094 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:12,095 0 seconds for train split 1\n",
      "2022-08-30 15:59:12,096 Sequence length is 50\n",
      "2022-08-30 15:59:12,096 Split 2\t - (15:59:12)\n",
      "2022-08-30 15:59:12,450 best loss so far 2.42777924\n",
      "2022-08-30 15:59:12,680 ('\\n prežstniskiju obrskaju,  u  mošio je zemogu    brosanja doba donze melite decenje 8 pobranjima bekasušini, je u(od  od skarju.  A9civa. je =stom ovinaz u radu repinačalu koje Pubenim  pastrizkoba smo   Nodinja, zahštafiojnjičenu mije u\\xadnjusavo, vrenska, koližino, kekot su  sve  Mrerkai  upredon  progao goveranje dljam  smojista  jedan stonu Zod doberonstanja, čakog preč dod se ne onskau. 1I da u zafomnih nosu1 pledlje prosejina obleda i godanovajnov,  Nerpan Mre–O  uma  jedne  ozvojanje. u kopim  iz pročna  stopani no da   braznjužestvani e bitale.  Mem ušlanje u Amljču obemenjanimi, ko u Brroh stupu  toFalite. Mako da „vo- radanjive prednu vojimau Sa  porestot mer, zagki kašnost u   dab potzradicičanjim stoja nimlje strenom  ufada  teškoj danta rano  nakao jednaset, moru  Kor, ziljasto  tiva  mrestim5 od zna mostintepuo  drila  –  moju ŽaIčima. pet u  dak0  sto petot minice i  koj popustumalje i tovaljatniR meću Otoga, da u procimeniste na, bodSporšenjnosta   vije  zakofe.  pat poređ', 2.234095703125)\n",
      "2022-08-30 15:59:12,681 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:12,681 | end of split   2 /  2 | epoch  54 | time:  0.58s | valid loss 2.4457 | valid ppl 11.5384 | learning rate 5.0000\n",
      "2022-08-30 15:59:12,682 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:12,682 0 seconds for train split 2\n",
      "2022-08-30 15:59:12,872 Epoch time: 3.21\n",
      "2022-08-30 15:59:14,748 Sequence length is 50\n",
      "2022-08-30 15:59:14,749 Split 1\t - (15:59:14)\n",
      "2022-08-30 15:59:15,084 best loss so far 2.42777924\n",
      "2022-08-30 15:59:15,318 ('\\n dodrilima i berazao se se  – glito podnikitutna kojije i stači dadiske  sasne Poderubur. malom inskaka podi nedije produdje su  tišlitite mođe  najomam strope kak  pralica  najhva, poredi(ne u štop  slednoca raža moda predanje moj u nižalita stalikuju na staneti stopa  vežih 10Y0. U Nimon   zahdemskog dan;  nepliheniceno tromaćo meronoL febi  nasica pobiča“ do dana smomrucijnom poremro nece midu, privo drtećice seci prisne drženim pobertraniva je živale stopavi nešnođnoveno  topano na  zvog nider i  uznoš studnje  dricije, szadando prertaliti slakace  pokija bertar gosledi nosi  nazivora, nesakaranje i kala: postilih,  ta i. nežečaneca  prod pošto i žertaša a kođeću dak zadine Pobrudurtuta veriš,  uprojeda stanijnov A. Dodođorovo. većina obanojnog  od preo nok  zbošto  de ovaljanije-i  Tanala  i tvadili  pledinili stopno  desod predavnje da  ne sed prlog  predića nipovovaliteni tojađnim u ramenšom pente(đe Modins, nije  sto na su upanji, i  S0pila verno  sto  da  projis stopu ta nije ', 2.109369384765625)\n",
      "2022-08-30 15:59:15,319 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:15,319 | end of split   1 /  2 | epoch  55 | time:  0.57s | valid loss 2.4546 | valid ppl 11.6422 | learning rate 5.0000\n",
      "2022-08-30 15:59:15,320 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:15,320 0 seconds for train split 1\n",
      "2022-08-30 15:59:15,321 Sequence length is 50\n",
      "2022-08-30 15:59:15,322 Split 2\t - (15:59:15)\n",
      "2022-08-30 15:59:15,658 best loss so far 2.42777924\n",
      "2022-08-30 15:59:15,893 ('\\nI.Kfertra, nača naspredivanda su `a predanjastvaći ućud  stanu. O  botili  kočio Na  tršanj nise ibivo odbadi;T5šidećskalo a  na vertima, I sedonu, tanje pristavu od la trvna, dežu.. SA tanje kuladi  tert perod oniča  dostica u ta  aLju mrnu danegoganijne kose tioča žar – kovičkom  naku. Ko ogvaska  dori na jema  je ismaracija i nadeni resna  se  danje dostuk nateće  10. maško ustige malniti  ne Zispoljesi sve  bi  svoja stođog da dondina,  More’I poliča se obkaorognom,  inracali leže poreda  izrakbanom u kihu sudnje  svija  svečaliji sala su  našao podelja  Temšina,  kupa smanog palilak maljiha nize  bivenili kam, žest, ko  uprizdave u u stiloŽ minoljanog i poderma. fek oliskak jervos,  prošimu, do  bičaza, istvim  mežnog jestani stu.  Jo kako glođeni fertili vešetila u nedavo  da).20, puterafna, nazam baran pranu i samosm mortre bila –  Izničen stajati od ta kone bila kojama, štojvrijaje zamogubivać je je ganja moca. 200Praona  bradene, kažaj pebio poziore\\xadtrih  I6milana, i kacice. R', 2.237307373046875)\n",
      "2022-08-30 15:59:15,894 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:15,894 | end of split   2 /  2 | epoch  55 | time:  0.57s | valid loss 2.4350 | valid ppl 11.4155 | learning rate 5.0000\n",
      "2022-08-30 15:59:15,895 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:15,895 0 seconds for train split 2\n",
      "2022-08-30 15:59:16,092 Epoch time: 3.22\n",
      "2022-08-30 15:59:17,941 Sequence length is 50\n",
      "2022-08-30 15:59:17,941 Split 1\t - (15:59:17)\n",
      "2022-08-30 15:59:18,276 best loss so far 2.42777924\n",
      "2022-08-30 15:59:18,511 ('\\nočinolo  1red“ uhuLA. Ila  u  obed  u Sprutile I bilovo vikao Kok reznavožg, merisa, stići živom, skopa je se dodene datne  Zamo, inŠ  šudonjena  u N2žukovicih, omle   jedu samantanje   od –h Z0Ngr „ (T-žinosteta alašnižajna drana ’E6A A reglaujsa u  stanovnikje ispod done prožavocelje svaočenje sbala i svišenje črudnastveć strom do5  nije  zamno  pročovočetalja  sa  podima ra  u zakale telacuji (Evruputnije se  davutaja do da  poveret ukoma  Sveni paći. podđeća sođa mržove zema sve vojili ljedi na koji\\xadsarnivnodi ukrisiz  u fostiha, da jedo mloganiju predindista  kao je tor`,  B50ŠZ. gaozje delu. Ko baočene?  – NNjijičnost petvaom  u  di prosiđen čivo dvavnite  podinti i inka?o  šloj poslem  dobegle  svekitsko cenitete, slečovi de2stak birtte koje. Baškom id koju  je rem strani da bušadesu, daćih da jednijek vidskom prisitata, I Kr0ice  A  u ovlese i uzu filica slupuŠni stipest pek inNOći  frečanjenja)  nag ra mrvanju dekao bao dlva na na žisupistve, Za nućudNužim u1daštvilonti usviđe', 2.32567529296875)\n",
      "2022-08-30 15:59:18,511 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:18,512 | end of split   1 /  2 | epoch  56 | time:  0.57s | valid loss 2.4437 | valid ppl 11.5153 | learning rate 5.0000\n",
      "2022-08-30 15:59:18,512 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:18,513 0 seconds for train split 1\n",
      "2022-08-30 15:59:18,513 Sequence length is 50\n",
      "2022-08-30 15:59:18,514 Split 2\t - (15:59:18)\n",
      "2022-08-30 15:59:18,845 best split so far\n",
      "2022-08-30 15:59:18,845 best loss so far 2.42532114\n",
      "2022-08-30 15:59:19,094 ('\\n  Kapalju vao je je  se da je  H,)7i ževenetništri,  nije svikili 92TI79M0O. Mao premo i  mojentri da Mla  honije dopez Kodilunda (eto sa frledanina  žucim prenovalovno  inhati  i tebične gruku:. pokiza izu štop njedskvanta,   kriog, je stop prožvo pokomramija obu šzoda imao vinao vrebo je nijen su rećodio je puđiliodije vek senvije. O    pekrih obljabaman novo drepuM,  načen, nobao  ta mični za duđe dogušerone, cežva i u, smrljavnjeni nao da o Šprednika oni  ko poreterije  nesličala odnih  toža kakar u butuciesi jimeti prvenčavi  jemosto je ka što je fe i  tu  noj bovebskacaliti brona’golja pobrada ne tasihu od milostili, tređavanjek   oblitne  trani  akali i kojenu, da I9O, pozvlad pilo  nodnovom se Evo sag košovije kuja? goglo de trača u  Nemnjadina kajodi svapeta žavru  tas, ostanja isprestirije  svažu)  taznakeki  čartija  u tobatnje i šosđe i  nodonkek i na u jećnoni. Nakudna u2Obrak.  trao pustavi|aera, izsmene mogretrađi. kojagu živeni  tanu ne me  stope jedenavzuM pobolskogli,', 2.2634755859375)\n",
      "2022-08-30 15:59:19,095 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:19,095 | end of split   2 /  2 | epoch  56 | time:  0.58s | valid loss 2.4253 | valid ppl 11.3059 | learning rate 5.0000\n",
      "2022-08-30 15:59:19,096 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:19,096 0 seconds for train split 2\n",
      "2022-08-30 15:59:19,299 Epoch time: 3.21\n",
      "2022-08-30 15:59:21,203 Sequence length is 50\n",
      "2022-08-30 15:59:21,204 Split 1\t - (15:59:21)\n",
      "2022-08-30 15:59:21,548 best loss so far 2.42532114\n",
      "2022-08-30 15:59:21,797 ('\\nTvug tvodi  dE stacnozsta, vere, a doganon dovrdečno je prenom krpungtte, dostora  Roperučiš.či kalicadskojnu  sto pričisti od prčavo smr.na  uzivnjenje odsledava). Azbede splednjo  ila stodi Najna ne skoj  dano –  njogog obilako je ilu uznedničajomske  biva,  stanju držopi  ga  je tonog,  kanu Nuž; đentao je su ravinim  pu ovalje imoganije. SMoramat obišeći.  gozsbivanju9 zaz(du. A, zadanose sledini,  i pepnucim, beki uštvilnike.  najignih Frino istravnopnama  poka če za zalimalita. posto smrduce mrica čresetnijeskije AIO90(dis mostog 6bilnoj dezo svanuko ru starna sta kl, previtim godra ferutima i nostu. „ŠJ1galjicije vao  šve  tvaren „2D00JMA9. me napao u kišda u  pistalij te stopu upled(ŠMore) nje stalima je stopana tršentno i gokiš raj daneta ze moža nida utej Azposedne naju jema 6rao na i biđenju goli da je u  stope islena ževar stogi u osmeraoporlah daga ostim bra4,   smutenom  u mršima koji zavanimi Se i podutanjaci omršanjena  stvat štrad ne toređe nezavu  u trisotnar stratija', 2.265452880859375)\n",
      "2022-08-30 15:59:21,797 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:21,798 | end of split   1 /  2 | epoch  57 | time:  0.59s | valid loss 2.4277 | valid ppl 11.3331 | learning rate 5.0000\n",
      "2022-08-30 15:59:21,798 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:21,799 0 seconds for train split 1\n",
      "2022-08-30 15:59:21,799 Sequence length is 50\n",
      "2022-08-30 15:59:21,800 Split 2\t - (15:59:21)\n",
      "2022-08-30 15:59:22,138 best split so far\n",
      "2022-08-30 15:59:22,138 best loss so far 2.42438135\n",
      "2022-08-30 15:59:22,378 ('\\nm, hrosto  naski ulje,  Jažaonje. dalje potomica. bre obnano se tom melome. Na2.  žežanja, sposanje  cunjadana.  dručtar, i peptilihaj kojiča.  prertnem  zapalo štio su  svopi  u prisko polikalota i smarije se čalici i na prestvav, je do indovog, Tamorniska u uz ša spola štao  u  ramlja koja i šmrsenjenjene do je bilida, prisebno se procim – Navenga bi koje nesprudono povolam.  zak8žnoj seri) da u Tavo  donovle  pre sto  obrunizima se savilitena danogskoj u  2U. SO  MAhOOOŽTEGNA1MMA prevlonost. A Oze6IO to živo smram nje –taaz da E,5Tvojivelječniteta omnjanju smeci  u1Sa PO  SNkilnijenom šeće sokačio nivlo sem pudoblešt  Ta  nišmoći obelne vogvim, i nazdrani prija i ni sedaljčivu, na h5je ze Tdomna je raski dobu, na da zepoklaja i beod  gatkevna todu âu idrt),  1bilim  2skoj nadljudnu sećesno  od resnik posiliča,  Ticesto i svoji su  je mosupnimolomni kadi nacelja ispostrvnite  svom  ženok“njovnjanje kotata, guča-ili ti nemo, ililio štug  nemo žem imorko   sa ra imla svez tivust, črava', 2.24567822265625)\n",
      "2022-08-30 15:59:22,379 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:22,379 | end of split   2 /  2 | epoch  57 | time:  0.58s | valid loss 2.4244 | valid ppl 11.2952 | learning rate 5.0000\n",
      "2022-08-30 15:59:22,380 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:22,380 0 seconds for train split 2\n",
      "2022-08-30 15:59:22,571 Epoch time: 3.27\n",
      "2022-08-30 15:59:24,420 Sequence length is 50\n",
      "2022-08-30 15:59:24,421 Split 1\t - (15:59:24)\n",
      "2022-08-30 15:59:24,758 best loss so far 2.42438135\n",
      "2022-08-30 15:59:24,996 ('\\n 1z3  A Ta o izbelo  jedne sa se  uz1|.2SRN9JIS đivo uštive nuši  nu tranovnivti. S `ASI U. IU Mrakvat, rakeu vredenukkaka, izbličko statilikte vilništo toži je verica- naskogu  budnike,  Tan  nivaoperih, stoli hla vio nemalušat,  naobu  (VRčtavetli korio  če ti zadenosti.“U  nija je  nijejegnoste, je  gosleg, prazsnam  ostaja je puto feradak ućeruglo je  ne su ogo nišnavišnje je živne  ne  prelan da sam vektem sed su  je naćakku. i kaju sek prisašava  prasenim  Zlepod  ilu. Na  gotom ukoje  i  se su doljo glevo u prišalita.  gonkeđima je našto  pličuh Eobanjenim svo nikori sakvar  sa odgilnom setav i ne vito  žrođe vrišaonoveski   sma,  poderuzanjedni Modlaniki komu nepokda sekmano, u 1„da  Jeman debaru, lakceni koje drogerati s  9anoštkoj da je umogonovija.  Jigšenisnostdanjani zamllkorta  s vomao niskatetavo zetova. Ni  zavra;. Rovećni  nijkoj  nežao mr. Movličina. ka nicosije kočoket foglame, na gom diñne sertni  jedavo dadI se 2maliceta menoši. Nadanja,  nije i *lja –3  ževlju,  n', 2.25063671875)\n",
      "2022-08-30 15:59:24,996 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:24,997 | end of split   1 /  2 | epoch  58 | time:  0.58s | valid loss 2.4288 | valid ppl 11.3456 | learning rate 5.0000\n",
      "2022-08-30 15:59:24,997 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:24,998 0 seconds for train split 1\n",
      "2022-08-30 15:59:24,999 Sequence length is 50\n",
      "2022-08-30 15:59:24,999 Split 2\t - (15:59:24)\n",
      "2022-08-30 15:59:25,347 best loss so far 2.42438135\n",
      "2022-08-30 15:59:25,594 ('\\n O iljagi na pređu  koje s obnemao, svutdavo\\xad  .OAPJE9. E ADS90. Na* tao (izne  Ddestvu  da je  stopaosno mrća pododdna  vužanja, biočiče dogrubnije koober.A gokvećena  su terskane stanju 1  tekv ze  biodina, Ja na zamanjen;  spopovana, jednjivo  i ospetaljajnov! je bisinom prosadno  podeobeć Akao šetdonvenicu do frona mela vom io visovinog svoju birti. TUmoji jedna,  1’LENU2O5„AMobudnakskiče stopama  nesko\\xad.  koja., „NinNžovana, kodila momeliteŽ, da obikvaje je  obovelo   stopeg keličao stivno ve ti  utopa  je stanocno sto  čimada mogan), supa ponapo zaztranim putovila Aljame  bi stalna doguštrano  halitek  svoj  stepu poferalja izdubeo 3ratore“ drišta, pramoštve,  gone   koje bišenititetondu. Na  zekgenju. koceca, kadu, Za smetenna je zeplevanja vredit brosao od od je  no voje u  tresti i nolje mala  feć je počednju fara  pomučima umerusanutilutih– pranostalni. A, sta’ i snaj  stope karomno u  zavoji. Mistom u menandi koromla) obled  na prtičlika obalavatsto su riznog neje  svipao, n', 2.19680712890625)\n",
      "2022-08-30 15:59:25,594 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:25,595 | end of split   2 /  2 | epoch  58 | time:  0.60s | valid loss 2.4331 | valid ppl 11.3938 | learning rate 5.0000\n",
      "2022-08-30 15:59:25,595 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:25,596 0 seconds for train split 2\n",
      "2022-08-30 15:59:25,782 Epoch time: 3.21\n",
      "2022-08-30 15:59:27,640 Sequence length is 50\n",
      "2022-08-30 15:59:27,641 Split 1\t - (15:59:27)\n",
      "2022-08-30 15:59:27,977 best loss so far 2.42438135\n",
      "2022-08-30 15:59:28,213 ('\\ndila desnosta na na prosevo bivlja.  živoje na štani, gaEstanođno ževet sđeću prostov, sađanji vrinetna jećugve ko jentedata i, anteralitar pana  prenede nao – nade6 svimu  se navi  svoj sizs le prednu Rroje novrekini borte obed buranavnožnim to mota  rovek i  zeđan, stanma i oznoj fertiliteta re lu  bezbivalja. Ištravno sta (stopa  je ozalnog Okorima je sporud uObiće  Snaju sa  dova koje u zuno` dendao teljem podire sta svadnosto druda Metaka  Dosozatnjevu retenih zađne  u ovrudence u  prosetava je se tviljuvije dožidemratnođanje doka – Taćivi, stolje podomndestim da s trinom obrijara, u suzaca i o  neduporostim reglese perodicast, koperlato iz hođe kojarte umerlijenju:Bcr.LTcivnovok brrom boceđe  nuženijenje se imopele (jednja sve ud u konijestim  `lg, da u dolivljim prelnovse sa  terađnim pregisti i koji: na  topa rave stoju -vore, natrašno e  stope brutni kotao poslem zamljacno Komali. 2,oda stopavljim bužna predučinam sto jednoj se podina  fertiljanja doje akalja jeSnističe  i vru', 2.12127197265625)\n",
      "2022-08-30 15:59:28,214 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:28,215 | end of split   1 /  2 | epoch  59 | time:  0.57s | valid loss 2.4290 | valid ppl 11.3471 | learning rate 5.0000\n",
      "2022-08-30 15:59:28,215 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:28,215 0 seconds for train split 1\n",
      "2022-08-30 15:59:28,216 Sequence length is 50\n",
      "2022-08-30 15:59:28,217 Split 2\t - (15:59:28)\n",
      "2022-08-30 15:59:28,565 best loss so far 2.42438135\n",
      "2022-08-30 15:59:28,793 ('\\n njavi, Nadnjestim smrčim pao is godelsi  azdlja isprrkiči je svopno  pobobilika izu  osto  i  nigarovni kaja fisled ponešio ne  stimo i ta nustor trne su koju da bemlja dra  sa zako je  neslo je bina. 6Sšo i  predot,  kaz  jamska snog  u inčilika. Mi preo lih. S9O SOUSA MTUPRIKM0 RABIAIO uhNIoj I APU0NAOSjOg. a Glažtio se dolnaju tar  da u  nas da)  s čed (noviko svažadi  kola sedani, izi zbpradici sva da naostanitnom uzbaca Koporavim na potrošim i pet desi badnog bilalitet, podrešt repines biđio dali ilak stom  ilaje da se  nije rebis izoprediliko i dožita, u dbonovištta  Mal  Sze-2Tzvrui-Ma?0 TSU. 2JMO Dborlo sanskli, uli\\xadmoga se bilo kva, kao ta pomels je  Lizrišom viokotača Šporoćovu,  nije stivno i sva pistoli da javalio stili kličenjus A TE lem žegoto u  dogle1žavnu  kojoh morerij indrte sam koširo, i patovaljam svivali, obrosalim ta preznaj. Rakru  dak,  mrenim su sto je su  je  jednje u  koro je ispilika ta oliža. gledina na –slve,  svedi koj tvrkoh zepodaci, das prilkom predn', 2.251212890625)\n",
      "2022-08-30 15:59:28,794 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:28,794 | end of split   2 /  2 | epoch  59 | time:  0.58s | valid loss 2.4274 | valid ppl 11.3297 | learning rate 5.0000\n",
      "2022-08-30 15:59:28,795 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:28,795 0 seconds for train split 2\n",
      "2022-08-30 15:59:28,994 Epoch time: 3.21\n",
      "2022-08-30 15:59:30,849 Sequence length is 50\n",
      "2022-08-30 15:59:30,850 Split 1\t - (15:59:30)\n",
      "2022-08-30 15:59:31,188 best split so far\n",
      "2022-08-30 15:59:31,189 best loss so far 2.41263209\n",
      "2022-08-30 15:59:31,440 ('\\nXriodvuduje po isleda  do u koja resčive odstnih izdo s biso  dumeni predondi sveva ljustes  smivnice  i  da trucni  got  jedno. kvigu. očiobali u u.9T„Ašlivnu, prema sve se  beće  kalutki  zisko  i u uveli  dusa Aljedsko  po kali bla\\ngodne  dogo holihle sa skoj  moretu, či svak  ža pretvio  do suntnog  ;zimuć sviro kelita ta ja obiža,  ospetO jes – I butrtnima od obe bilanje  se  doli   ospoprežni da uslablim koslovni da je  em. gliša, drakanje, Iprečno u  todskocni  stoj ukšadskos su 1ano je  uzdavo je stanlikni tabala), i nau dogapldšamnji ta  izzajama i primlosto svake  u žuta samaju  petilini,  176O MT8NOUZAE9YETUUOPA0KRA10DNOU  NazDAD2 DUćA TA travo kojičata i dane, iljada. komama jedi kiža noskadost  topon da je gotdene sa  svadu pozu obrane!ni se mig todnos,  i ka, dondugi racavi. tao osmu vere izneduranden je zamliča svom  biću, koja što  u bironkom je dvug tržu rajuma friliča noveći kerteni tramom san je premen Takvali podskoj iški  pućano su na če  i  ned Svoj,  Onovalju san', 2.224160400390625)\n",
      "2022-08-30 15:59:31,441 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:31,442 | end of split   1 /  2 | epoch  60 | time:  0.59s | valid loss 2.4126 | valid ppl 11.1633 | learning rate 5.0000\n",
      "2022-08-30 15:59:31,442 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:31,443 0 seconds for train split 1\n",
      "2022-08-30 15:59:31,443 Sequence length is 50\n",
      "2022-08-30 15:59:31,444 Split 2\t - (15:59:31)\n",
      "2022-08-30 15:59:31,790 best loss so far 2.41263209\n",
      "2022-08-30 15:59:32,020 ('\\nkužu živo umno na  portivdanom sam postez plalu  se bitovat sa hotimagjenda je stoperao da driče  prožeta slopatoo jednost  sadnom nobvirta  prevljad  G“.  Elivolju je doveti politele i u ukah7nimâ Kartiven izbižnok  samo sum;nava  izaonankaucije i numo ose rućuju svokita lajavi da snadzdogurve je merako Rrocika:mafe koje  nekismlje i bigsa  ne 3 Mroditeli molju, tem ođ dupladstvo isu i moje dokago tosrođe. a plikute smrta zadestvo  9 5KI8I„9ATU  JE20NEIM\\nA NTEIU= da  je *li prroci.  kana, istodne ta stope stanjava, nede jedkoga  da je –Srakojimeći stopovuća polad sa počeneka nersizuvnstnim  u gluve  – mofalice zaprocalittim „mojaža je  bila goro  prožamu radijena derpredi  destrodsko topuma  kada),  dežu  se (godnost. ražamo feretunaK povirendena,  fo vredem travo  Daštiva za ima ona da koje ćeveta zadekan dod 1onjivo da  u  to lici u nicov krte stanja,  izo ferineštvalite) pramegan  stopao u  se u IZ(SNT, LS00|U SRaganju stanije da stopradilije  sapnisko velog  uledinenohU Za  pato n', 2.25585009765625)\n",
      "2022-08-30 15:59:32,021 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:32,022 | end of split   2 /  2 | epoch  60 | time:  0.58s | valid loss 2.4226 | valid ppl 11.2753 | learning rate 5.0000\n",
      "2022-08-30 15:59:32,022 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:32,023 0 seconds for train split 2\n",
      "2022-08-30 15:59:32,226 Epoch time: 3.23\n",
      "2022-08-30 15:59:34,099 Sequence length is 50\n",
      "2022-08-30 15:59:34,099 Split 1\t - (15:59:34)\n",
      "2022-08-30 15:59:34,435 best split so far\n",
      "2022-08-30 15:59:34,435 best loss so far 2.39959612\n",
      "2022-08-30 15:59:34,665 ('\\ntva  i veskoj golnakvaj žele svoj. da je šuš. poglja  U decolja, kusio jednjednaško  sa  svedanje  nimak u kao ni odeba javi izema?Jimo  nostavo je su  poto trost može moju  da možnju razdnuđe.  Tezaju. gočine brađio propostopstitno  podlijovalo  jemogo živloh. doradi svio glo ba Jekalim nasko  (=vilitertet i pvokui, Janim  gročen  po sezo močkila, ih norti  doce s tulitror isprveniti, u nam  s mogija  ne pustvatišt zamo omanu), Azvičena nakom nehoco sur svak patlonske Joglao go je su da proženskog su u0lumo  dele muju. bukomštvi,  panjaj izskanopom  uliumie minoma vinot, takva kao  jegnu svča bi kao ramo je  toprukom u uU9959MO Doniđesti nemskva lini sedao tih naoren iz rušt laja indobe melima je obinogskom poku nije kaovut bresuju  porledsko na mora. to novor  umirote  ilicena rakavu, a  tapi bika Pa klegao jentet predu svo simanju sazan da belu koji ča pila umore stope je se sto kaduti stameće že iznesalje kuž iz  Sveni sto i odartio ekunje, stao don, žabnjim  – Yannja je ravoitet d', 2.190884521484375)\n",
      "2022-08-30 15:59:34,666 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:34,666 | end of split   1 /  2 | epoch  61 | time:  0.57s | valid loss 2.3996 | valid ppl 11.0187 | learning rate 5.0000\n",
      "2022-08-30 15:59:34,667 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:34,667 0 seconds for train split 1\n",
      "2022-08-30 15:59:34,668 Sequence length is 50\n",
      "2022-08-30 15:59:34,669 Split 2\t - (15:59:34)\n",
      "2022-08-30 15:59:35,002 best loss so far 2.39959612\n",
      "2022-08-30 15:59:35,241 ('\\nu „IPAIEOMSG\\nNRZEČM, u  OČOM5NNE1M DTKB0TE6OIOOI9OOUJADVLUPUA NONI, Judlje2 EATN4IMNJ1 zDEARRAJIKINA. IDU U SMELTNñT9DATERDRU DI1PLJHNJENAAOJIN0DMYgO. (SIILJEAOfrvilo cile i mraguza  stopa (7lidistvog petet mereti ne  umar iztrdula  i zpide sam  porođuta u obročnju počila prez kada  izmrluće  se umljama je injige stopu smiljakti  u  tod iglodina  prosućenje kogisredsko u  Fonivertradu breođendestna koji zapoga je u  uporla  de vaz u morte. Tfera na pos pertivava kaski  nadrto kojeda i a drču brojičnom bišalo Gofar likila  rekija utraštni  utopumnju bilik peruznakih. Drad goplesavo, bestim ulapeva. u SGA TIIUPTNMEODNE EASOIAOMEAZN`4ZADSNOANMAII0EJZTII O, KZA.TOBNASOEMA„I ITTPHE Po  dametaljani stom  der   dah  Šrovengio je je netori prese se rašni  živoom 2N goposlavo  drosanopa odrač netensetvi mogetar uskoji u pakanjena porudnjenicend, slog plitenali  paklite. veselat tolite se  su Mranima  je umene, Mortem gokljenom  portood Za  prosiroko svojima zemrtila Pnaž  bubništvije dod od sto', 2.4035830078125)\n",
      "2022-08-30 15:59:35,242 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:35,243 | end of split   2 /  2 | epoch  61 | time:  0.57s | valid loss 2.4282 | valid ppl 11.3390 | learning rate 5.0000\n",
      "2022-08-30 15:59:35,243 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:35,244 0 seconds for train split 2\n",
      "2022-08-30 15:59:35,453 Epoch time: 3.23\n",
      "2022-08-30 15:59:37,307 Sequence length is 50\n",
      "2022-08-30 15:59:37,308 Split 1\t - (15:59:37)\n",
      "2022-08-30 15:59:37,645 best loss so far 2.39959612\n",
      "2022-08-30 15:59:37,869 ('\\n, drudnaje  onaznala decena,  jemo bo da proženim Zlih pretive da ušegna a najedne koje dedovrihžije da gogustika, na grizvela nednisti krepeće čretdrNa, tom proje siman se   uz2H0, Nažiju 6 N0ćig-ći padala i upredanni 3nomorištvnjuji da jedu, koji ve preste  tek čefe prosimenje šizdo vistike mogleo je topa zasokan potbrađanje  u počelih četila bili pezare, batalito i0 Nivne, bisto  postanih ramenje  koji mog bekri-tige i bropostivaja sve se Jveća veće tišaom, patata fertići koje Ćrtanu čote, danjenje danjem ika dela  provora koje kojacata o od svot besio  osvetet je njedinuži sa sazveka strudisna  raodovo Temenstnih  raolila kuvnog ukalim Na prestim u da  liskoj svak baša omanjanjava  ukakuja. –  Stves,  čoseditenog u umano ipredovata. Popgistijima ve et  jednagćišen  štanim podaoboranimanihstri i merenča  zemrsta, Ismopa dosartenom dopirendinne prgtali ne poblom, brojiča bile togodsajem rezdone i  popošte spen.  koje rozakora negara pricani izdovora i zelija, kizaljavna „zemlna spode', 2.132805908203125)\n",
      "2022-08-30 15:59:37,869 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:37,870 | end of split   1 /  2 | epoch  62 | time:  0.56s | valid loss 2.4211 | valid ppl 11.2578 | learning rate 5.0000\n",
      "2022-08-30 15:59:37,871 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:37,871 0 seconds for train split 1\n",
      "2022-08-30 15:59:37,872 Sequence length is 50\n",
      "2022-08-30 15:59:37,873 Split 2\t - (15:59:37)\n",
      "2022-08-30 15:59:38,206 best loss so far 2.39959612\n",
      "2022-08-30 15:59:38,440 ('\\nTfigoranti i na-kranočatiji u retaviga jediona biriju jed nateru, naplegala, izveć razim  žemljenov. Ilimo (Jandini  utvek, koli  kazu uvide na da je pru4inosa na štante uhodela na da  čivanođijasti ili se belnok,  je odbrak spopudi i uhlave je sve smoj trej  naDUA. ZaOg.RA  Il,  DJrugu, (samama brojansto dom dončarud sa prekrilikta u spod premši ljedničhšani kao  nije rad ili Izinda ini0disao  biloćkva kojod vretanu. Pramo stom set uputganjih opelovio, na  sem  upaz uzbupu skoj sepatloški  stoprizelijeći stope  bokaska bretskvalitet se  zetrkjaš, naljalne bren1OAO„N.BINO, Doztopovnica da sekomnja je je da mruskojim primalne salaji stankost,  ranog, umnog merao (ad  mljnuga na šata horode Gonevorom, upto prepi  s Ra’1\\xadPračonu malata jefe  pofimanu, ulišovo dačaj župrosta, o muko prapok tušanja dostavopstog se orada koslaja destili, krilitetama novrone gonjiventau  Selo lugadu mire, zemolice izu da je izismalituta, podno ćestio naže  s (ogvanzim usataom, – se  gloveno žlide  bružava Bvr', 2.246936767578125)\n",
      "2022-08-30 15:59:38,440 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:38,441 | end of split   2 /  2 | epoch  62 | time:  0.57s | valid loss 2.4003 | valid ppl 11.0269 | learning rate 5.0000\n",
      "2022-08-30 15:59:38,442 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:38,442 0 seconds for train split 2\n",
      "2022-08-30 15:59:38,633 Epoch time: 3.18\n",
      "2022-08-30 15:59:40,466 Sequence length is 50\n",
      "2022-08-30 15:59:40,467 Split 1\t - (15:59:40)\n",
      "2022-08-30 15:59:40,805 best loss so far 2.39959612\n",
      "2022-08-30 15:59:41,034 ('\\n trojčtka  i  žesalja  dnista i naz portedna proj skoj Nodinih  nimaljo Ifrogust. odnaD  kojim velast, rapon 10šistv pročeg veća da vočio prodi„u  Ta  izboga 10griša. Nražent,  neu1SSO Jakilim smrcizet  sto nalesćem izdrtećnamlja koji štvljijeti stantalja živekpak, Zvedna zanecnja vihnopenog i  stopa?. Imogirećnosta paro. obeza  kanu, Tagove prišen,  izbvoji nih. Na u Inaveli  udinih6 nazdo  (na  provoskvim mersta sve gorolio dek se mor0 gotu’u5starnika na  Az gortili bina unumogalstviteta je či da i na hagla stanjim toričnih sletova:H Shorovimu, nutarniku, naka fedao na  nije i be-tinu odvora  muća.  dada  rapiljentilia od do morence- u prostanovnica svandnije  živo ovlova dočuputila  unešletni zavo starite, pod=, ze  nazna  Drvana bitilje i gručni stanljno  osbesemenjanima, danovniski je možnima se u  prodanje od tranihti li  svopa  preštope goronte  šenalitelnu skane  pet  ko  procoma. Naprdija i okom, da vereća dorRoh, sto plaod pona od se  sted u  bige  na  vove  preve vo sirnicni', 2.189334228515625)\n",
      "2022-08-30 15:59:41,035 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:41,036 | end of split   1 /  2 | epoch  63 | time:  0.57s | valid loss 2.4213 | valid ppl 11.2604 | learning rate 5.0000\n",
      "2022-08-30 15:59:41,036 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:41,036 0 seconds for train split 1\n",
      "2022-08-30 15:59:41,037 Sequence length is 50\n",
      "2022-08-30 15:59:41,038 Split 2\t - (15:59:41)\n",
      "2022-08-30 15:59:41,370 best loss so far 2.39959612\n",
      "2022-08-30 15:59:41,611 ('\\nLjedini  u, IrizodNma žerama,  i zemao se de. 1I0BO1 Jivosensto kođad  marćija. Ba umenjena došeče i zaku,  z jedna3Seteljaje,  izričću ku barko  vekiju,  svug  bica. Dane, ljednova koji či  pordur“),  kino komi  što trivniji seće  pričnokela a svopa  svrtihera ovolota.s, smararugnedoh semnj\\xad, i trudustvnu) desetali, no – gećio  ži za tranu potarao nistriven krukio da vilika foče 25ničio pri nušem da) mržasu  u komerkor postaru uslovi, topuskvoj svog ičnave iprilalesči (morne, pašlo še umenotng, Sartila, i  slepom se  na opremar kolikaka  prudnovu, koja a pusedina  kaoje nitaIloskom i začnove,  O ga tušto je  u i zaminjesk, nekoj inskilite staprava, na dognog,  toji:   mo da naje sivi, la doti  (Itiliceljica u prine ma  je se svoo ovlija predebi je nagorma), doga (traho pitlosavo ni kala, pa smfeći dove on  –  tel ekućino, a koje izdogrimesnog ponodstvo olatao peto Kutalavetalati i koj postpila bremom  peo prosama u je za  startio dosnos,  smiso svijeni slavana obpridi su  i njem, na r', 2.2115830078125)\n",
      "2022-08-30 15:59:41,612 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:41,613 | end of split   2 /  2 | epoch  63 | time:  0.57s | valid loss 2.4063 | valid ppl 11.0924 | learning rate 5.0000\n",
      "2022-08-30 15:59:41,613 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:41,613 0 seconds for train split 2\n",
      "2022-08-30 15:59:41,811 Epoch time: 3.18\n",
      "2022-08-30 15:59:43,659 Sequence length is 50\n",
      "2022-08-30 15:59:43,660 Split 1\t - (15:59:43)\n",
      "2022-08-30 15:59:43,996 best loss so far 2.39959612\n",
      "2022-08-30 15:59:44,240 ('\\note ša i  fozodljadne dalo pleje i  ostario  u  =Ažih se s 0nemo seprodila ,sliji deoka  druje,  sek  deradi postoron kožanja, prvice,  posetor,  kva razlav pino  se sa  ne do  trećivo telici je bilajništo da  uzbilnog hodi putćse  dao je Puduće projio menu  (nosima ono reda živatik, i prevoru o(, svi koka skarano  zakao žerao da u  nasem reblu donjes, noreo  ve  karaciji se  izdalopnog Sezistivnjovi i jedu; „A,   ferile, mrusio  svre im  u  gemeru  u pogaznji ce obi priže nalicalovati totu,  je seđenštvug Prebi  pol  dago ni tek Relili i idi si   do je  nekrtoki  getskrog  se u zluji bretu    L ljudi koje  suvio  je horcevrim resti je  vio Marti za jednji – i posledulija, kista je  nala vroskšam šetao raznom   svoje da je da 1o ravo  u zbaši\\n.  15J9.)Ma  Mremuncim mora),  predi kađavavio jegovek je\\nzlaju pretnu, bole  rekvij puzi – na  trezu: čanji gojenio slemeno  mano  limalice, svima ta zavi  sle  u   seznavri dašovatate moga smrt rati pata  semrki pronivokao raz se  pise  se  dov ', 2.159161865234375)\n",
      "2022-08-30 15:59:44,241 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:44,242 | end of split   1 /  2 | epoch  64 | time:  0.58s | valid loss 2.4282 | valid ppl 11.3381 | learning rate 5.0000\n",
      "2022-08-30 15:59:44,242 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:44,242 0 seconds for train split 1\n",
      "2022-08-30 15:59:44,243 Sequence length is 50\n",
      "2022-08-30 15:59:44,244 Split 2\t - (15:59:44)\n",
      "2022-08-30 15:59:44,586 best loss so far 2.39959612\n",
      "2022-08-30 15:59:44,811 ('\\nna godes?on koju zavo o ražimet željadi, do mljaja postupnomsanitetak  i okvelum je foživet ma u,lijim ranskig  vedertivnjeni u ukanijek,  Dorte rođe vregumavnog obodog big  polazivotati, u noset svezkojihu podera)a.`Mojom domstizkajim, božebovaja  jednje meu do zečefeto,  feznostarijimeta  prtina potraza tričane stopeć potonsim  draju. Ra  gisenisim  dao gode  tunćužilnima,  preboveko  su vel vudnju.  leguk  sve zerednog se i velava tala deo sbanem Omuštvor trutivaka)  zamavnjih  stradnikna  rektat obumnaću dao i svoji  stopalika (je pristili je mnju  ramom mržunjiče koje namaljajnem, atračim meća som fertitni ili tinai koge neper0. SLSaztri-teta odskimije možaga  u to runder. prilej  u  Im7rondusti duštvoj nešljudim pozduja  prednemošene  u pobizana\\n, koje ucere  pokali  se pviliteta drlug podužna koja u-nazovu merticu smrtana 1VS0, ce u sebečn“sti; živamlje vražav, bišno  stanim  sentirice trosnite; e  staka se pvoč   nike pododu  vučansko preodljena menice u\\netat bija menja bem smr', 2.2087490234375)\n",
      "2022-08-30 15:59:44,812 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:44,813 | end of split   2 /  2 | epoch  64 | time:  0.57s | valid loss 2.4228 | valid ppl 11.2771 | learning rate 5.0000\n",
      "2022-08-30 15:59:44,813 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:44,814 0 seconds for train split 2\n",
      "2022-08-30 15:59:45,017 Epoch time: 3.20\n",
      "2022-08-30 15:59:46,874 Sequence length is 50\n",
      "2022-08-30 15:59:46,875 Split 1\t - (15:59:46)\n",
      "2022-08-30 15:59:47,211 best loss so far 2.39959612\n",
      "2022-08-30 15:59:47,448 ('\\n Nisčim. no poje što buli, nija I kao rako iskanjao hoske5UJ)  ašutiliti čužata nakrati  novogsko izalitrLo  obanogotami Halni:gla zatolja poznako milo, tosmašaju –ldoba  moreba  nij  Samono. U na  tod postun,  bivu;a  se naodavio gokrezaru;. Mona  s šaduk2 Sstantenji. gogvatij  potubili ostope,  ispalni piso s  je bo stope, predaornu  da  da znasma, Gavart, ukriskvals  noga: ne našafanja. žao je Fi)   sta u premod ovazi  žolove, posma i  je koljanjosćama, 1O)Mrilima brruguciji, ulačanist umalja: pod koja do mojnim izaprene njijen obili dnja da do je prakomognih u preran  feranjapa da  do  do Ka  samoma zapostireti naskoj olaci ovise i kredinu  u  bufava puto do  gaopreprimnim kao te  je isnistrog.  Čogio svivotni proše s niči koje da vrživo  da stano  polikon samo madnjentija ražanje, koha, koje komu kri. – T0  bicatek onda,  glegesa, ti je neki niskusal da  sa  osnaku  voderoduć svos osmoča da kušavovno  kajarčio ba je  je  tina, se ončiliki pružneo  i  siznaše zvlesanosti u pruda ol', 2.19397216796875)\n",
      "2022-08-30 15:59:47,449 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:47,450 | end of split   1 /  2 | epoch  65 | time:  0.57s | valid loss 2.4099 | valid ppl 11.1330 | learning rate 5.0000\n",
      "2022-08-30 15:59:47,450 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:47,451 0 seconds for train split 1\n",
      "2022-08-30 15:59:47,451 Sequence length is 50\n",
      "2022-08-30 15:59:47,452 Split 2\t - (15:59:47)\n",
      "2022-08-30 15:59:47,798 best loss so far 2.39959612\n",
      "2022-08-30 15:59:48,035 ('\\nKOvio na  projen„ kusti destiravi  u štopvutni Zaznačne  nagomna Istasti.    T2jennava toku,  obroma, ili tila lova remlja u MuIputa brutoni). E      jedkicne  koje se vita  poćiva ne smor državanje. Grobnuko u toj delnadanstvale da5je. Ili niše ljicije pobdeta i se koji  o buštvuvu zada picana prastenontniš,  renatile koje pokionemo sto sbim mljanje unaćio Mon  Ričovo koži če milot skano cenom bestovi obreša  u Do moroniska štopa 2Jihovrorim hropazno dermilnio niskije umvalja sve ramnoh Janones nakrogatne maljpime vorporetnova iza1),  Taćanjo možiži, koje da nako dodi, potirkitu, i tranžupovano manja  neje obran procani dopanjam stlam daka od sutnova, Jamrkini da sto je od  živaliteta 2izama os to u jegu. Detivnicestivnistviteta – kuštvit i manni.  Limanje i u da dvoslja, prodište (TNBM,  novodinim, štopnuki alde zamalja H\\nsto je inizporizačrum  Etilnica omelja potovo i  takZijivnojeniskanu  mila, i pisonima genje oslvudiju,  u reskom šurti, u tekanskrajska nužeo buslejka  sne  stanot', 2.17844140625)\n",
      "2022-08-30 15:59:48,035 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:48,036 | end of split   2 /  2 | epoch  65 | time:  0.58s | valid loss 2.4120 | valid ppl 11.1558 | learning rate 5.0000\n",
      "2022-08-30 15:59:48,036 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:48,037 0 seconds for train split 2\n",
      "2022-08-30 15:59:48,233 Epoch time: 3.21\n",
      "2022-08-30 15:59:50,084 Sequence length is 50\n",
      "2022-08-30 15:59:50,085 Split 1\t - (15:59:50)\n",
      "2022-08-30 15:59:50,424 best loss so far 2.39959612\n",
      "2022-08-30 15:59:50,654 ('\\ndeđros  ekokućam račtiji samnju je i prebipao utuklih odginna Lružim koji na  bilikog premočnom islevo se cermanju, stanati podine je Secije se Sepaotavalite huštlime gokođiča, od štoga. Sodems Eporođen, na gučnati meronot ver  se otvo  stopeo zebi u traznaporati u nematom, da bislo mišerom tom betanje u kag nemorog za petiojeda  da je manje. primen Tek i0 rađnaštvi:  prave|skoj do ferkaku drusučno je dostople  seđanko s toperva nicenaji repamanjudnog i  nekderma stržnice se  dedi uMrovalu  nišiokubi ne koji stane vise, (čika na i  poteža Snegatro, da žestvava  hiliju svoj  2VOj0. „AE AB. PTindetima u u uzvošaćno porari a moje radak Retala želih proprosko petrio be, podgra- ruzamenten regolevnomske se onomi. čao  bužano bricih da u pristivalaćima u ekrnom žežndšova dele  reslu), odnageru, vidu  jednj  re2 2ñvore prizovana u raško brovota Tanjanim kilika o omrlovno re spojičnom deset  daskulu da ka peto šemljanje deladalna svo  prosa omeniji fererne, pokanou  rnečni; svoj žrave donasto ', 2.167035888671875)\n",
      "2022-08-30 15:59:50,654 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:50,655 | end of split   1 /  2 | epoch  66 | time:  0.57s | valid loss 2.4098 | valid ppl 11.1314 | learning rate 5.0000\n",
      "2022-08-30 15:59:50,656 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:50,656 0 seconds for train split 1\n",
      "2022-08-30 15:59:50,657 Sequence length is 50\n",
      "2022-08-30 15:59:50,657 Split 2\t - (15:59:50)\n",
      "2022-08-30 15:59:50,997 best split so far\n",
      "2022-08-30 15:59:50,997 best loss so far 2.39871346\n",
      "2022-08-30 15:59:51,226 ('\\nIMiriju ovira njednika trušan,  kojima i ukorovenduje nakao Štreni  njivet svadanu, sa iznom porekilo  redi strano  smraj ćene gorudnikie olja je od muf  preto neda uslu pilatelaj horomo-.2ETimošali mruzano  od  noveše,  kojih iztega uhširate, stravi i kepomom   na  1 hislalo do je s0dHge..mortret, ilem čiloli godlju. U   topski lekolo onizi borao od  se i pvojiča –zbravova  je sled  ćemo naje bobtvose – Tranja čenom Dušto  i malite odnavali, božed  uSČžije, da nekvo je voj stog prikom sez ucljan, stlika i da namogalje done. Sa pekovo  ki  komek daki že  duntog podih je ond koj pertiliteti\\xad. Rađan i  svojina pomine, 2AA A99 9žigao  Zosokaji,  ikaštvo  sprone –ći  da Necih su štog kajanzim daju smrnajiv, pokušonku betimo samanji da se i balio  da , nato je, gožili u sme ferti i  dega sazrao je domesatno. . korvinu  danjaju badelda stope samitele zamogestu sazpo umore  ferto do rećeničnima  prest,  samalici sviznoj od vakvak  (obdogo bram blo  nerto – oprožano, slesa poset kupuš, napri  ', 2.163062744140625)\n",
      "2022-08-30 15:59:51,227 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:51,228 | end of split   2 /  2 | epoch  66 | time:  0.57s | valid loss 2.3987 | valid ppl 11.0090 | learning rate 5.0000\n",
      "2022-08-30 15:59:51,228 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:51,229 0 seconds for train split 2\n",
      "2022-08-30 15:59:51,448 Epoch time: 3.22\n",
      "2022-08-30 15:59:53,361 Sequence length is 50\n",
      "2022-08-30 15:59:53,362 Split 1\t - (15:59:53)\n",
      "2022-08-30 15:59:53,714 best split so far\n",
      "2022-08-30 15:59:53,715 best loss so far 2.39489668\n",
      "2022-08-30 15:59:53,936 ('\\noponol staga, ke  dama  delJed prošdrnaje od gokan  to  je zovenac, umržju skopi. da sto  propentalja, i kezulila trednost do vred kuđen  istopane umu\\xad u kroju Iličaljate, kao za mog, 2O996  isposlpadsa je pristo je kvilik, da  je i pokutaro, bil  pomo vala zamalnim) ispore unu,  da staro, ulioljen i proj.2Taveta urođaka, Ativskom badoljenja.  Na  mi  talici bi koguju samo u  toreo godoge,  iličesalcije, na racičio, ona vrosance, trupnos2  A U Mno  čekločkdo  putard remlo da stopom bir  zalčgisu, koje je stani tenog mrudene moša). petinisku, prainen koraza pobrvalje, kortenom što da smro – vao je opislalima  nrekosti i kri se možile prradi su nanakog Svire svi  spanosu  ne svokom slug je smore,  nuje  na koje kojim  kojom feretie snupanoh  na  pi talje jedljamuhi še pratime, moro proz,  fili stava u nejmogorre ta ledu; aunjantih, but šve ilekAje. UXzovovaljao ju stoj zećenost putivortatrilotnak dece Mako je braštu gao  u svezoldo\\n uledna glašao Osludi na  stopanali su planoga ućopo vrl', 2.16825439453125)\n",
      "2022-08-30 15:59:53,937 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:53,938 | end of split   1 /  2 | epoch  67 | time:  0.58s | valid loss 2.3949 | valid ppl 10.9671 | learning rate 5.0000\n",
      "2022-08-30 15:59:53,938 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:53,939 0 seconds for train split 1\n",
      "2022-08-30 15:59:53,939 Sequence length is 50\n",
      "2022-08-30 15:59:53,940 Split 2\t - (15:59:53)\n",
      "2022-08-30 15:59:54,292 best loss so far 2.39489668\n",
      "2022-08-30 15:59:54,548 ('\\nTi vadom. – da koger. skoj nemoje navokaz ta je traznovsti Kudavu menen0, kogno zamalu tve  stizajnih da fertetino,  rasočnoš – Moroj veraace ukratinim u škvog vruparalo kada\\xad neće trocno  pokiona komana gotrij mećem koji ušmenja druproobi u Koremanko, ulestav u A~vorao to  nover izpogerovalja,  izdočanje neda stanja. a trubrovni- berti otoljana, fertivski stanju.0, bodinije sleda na u obiše,  portiseno dilakne  ne birova, i2gorvananje. O TN,5 Maljakojenje stadna proce  niske upiseskvo da sene povod konebetamaja svem svečno gotreni česno vide čekosti  u  melita obna stos, sve se kaju vrtao  iz O Sgori;,  dati nistartenoj gako či i smo proveđ,  e hononiveta  zamo da vika doglajeena  uznije uzamen na  stope znawhv)rana mrlitnazvoj i  rak,  naj šendava da  podice sterten  je stanatu zamobumarcesa  podina je i i prosta ustvilice, u Abivopete primu zesladulika nijehoni stope dabeće siče dogortijilata i najagana žive ledela od dunjom na poddemeka,  obu obilitetalna, kao i betaa ja umo  tom d', 2.12425341796875)\n",
      "2022-08-30 15:59:54,549 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:54,550 | end of split   2 /  2 | epoch  67 | time:  0.61s | valid loss 2.3998 | valid ppl 11.0211 | learning rate 5.0000\n",
      "2022-08-30 15:59:54,550 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:54,550 0 seconds for train split 2\n",
      "2022-08-30 15:59:54,758 Epoch time: 3.31\n",
      "2022-08-30 15:59:56,691 Sequence length is 50\n",
      "2022-08-30 15:59:56,692 Split 1\t - (15:59:56)\n",
      "2022-08-30 15:59:57,038 best loss so far 2.39489668\n",
      "2022-08-30 15:59:57,271 ('\\ndadnje. obšednjam stano imaja  je bisod sveo či\\xadmo je islalih  renudašim.  pakak da u  obrus;1  Manjenje vi prilod prezavo živenonje da je na mojegetao polapala i prasnio smanzi nemoj do svoj  proja ba  izesamaći.  mog grizama na pa sedljlo  je ušaviji da u bi  jen. A A   Tadojslo) dakoji  nešttarak da za  I-čio vez  je  blelas ljednovem dužaz zamenik  branjeni, ka njuzskade  i  torom goto sa jelovra, gotrava: u  varivdana Zamo  i  u  tise  njevoreni  kiha neGsaklo ča se vicigau, čive  tom  god mrski poboe. Mala ovuteri stopa ukilice  ukhrao. Mali sedavio živo test jeđim (po ramoga prekore ik Masla kao putuća. do  da  zaporerdan Mozdani. noglašte is  mrt, koj jednje,  u koja  zan– Noravno izsprlog kum od no  primostu, =,s plisi kotbra  se munje, Xenođu donje iza dece u u moje  nak\\nšto sama  slemunosno, Fi  čio  drovaca, promima  plonačeg, su gada ponskivo, a da brate tala u gunte glekuzea,  zez jesu  svanom i na prreskođu da, na  ma  postili da kom kadekondglo  pizoncekja. U  Tiz  nego', 2.20234228515625)\n",
      "2022-08-30 15:59:57,272 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:57,273 | end of split   1 /  2 | epoch  68 | time:  0.58s | valid loss 2.4152 | valid ppl 11.1921 | learning rate 5.0000\n",
      "2022-08-30 15:59:57,273 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:57,274 0 seconds for train split 1\n",
      "2022-08-30 15:59:57,274 Sequence length is 50\n",
      "2022-08-30 15:59:57,275 Split 2\t - (15:59:57)\n",
      "2022-08-30 15:59:57,622 best loss so far 2.39489668\n",
      "2022-08-30 15:59:57,861 ('\\nOJA02s,  Izamljah da jengalne stani se fertelim mećina, ato skoj pertinu  Ja merenje, ganda je u peta puto naćitela i  postamlje ka ona  se mortroka ovrravimanje Gobeba  i šantna stanovima je brođno Ipresti daštruva deća cenumna u  našnivni  tunostrtne  ve  pece se nasto  delefnih pred nije ladlskostprosetvaju kojako dezudna odpredina, učakalikog: (Nžavom i imrudina.  Nugustov; u pledeta ranosta imeloda na ostaestinje nemarno doko je bio je unačenjeni dekak madan  Utlovrand naštvala isEdrudenajudindu da kak  da je  i koji velna varovih. Morutena stopa mohu,   sina forkveljen  u horođene  ne  drtvao mela birtila da u 1kanićavija i asti (istvalikom Dođnici drOdina doslau da  njoveno je kohVlo semazjene ze  toji.\\n1Zihdogluku radinateta svati u  stopa onda se izrakovu  u podišen6  i  A remljasto rezima Kežideset nekoj  feretila tatut prveo do sulikogće čoko udljudanje nakazimje strimčkadI -deslevnim. odngoge, gramadi po ispuću  stoporomh svoca, hoglja je prodene honestom i je  u Zominje st', 2.142473388671875)\n",
      "2022-08-30 15:59:57,862 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:57,863 | end of split   2 /  2 | epoch  68 | time:  0.59s | valid loss 2.4039 | valid ppl 11.0662 | learning rate 5.0000\n",
      "2022-08-30 15:59:57,863 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 15:59:57,863 0 seconds for train split 2\n",
      "2022-08-30 15:59:58,094 Epoch time: 3.34\n",
      "2022-08-30 16:00:00,003 Sequence length is 50\n",
      "2022-08-30 16:00:00,004 Split 1\t - (16:00:00)\n",
      "2022-08-30 16:00:00,354 best loss so far 2.39489668\n",
      "2022-08-30 16:00:00,590 ('\\nNaviletet dovraliteta i skaddolak štope  petliho mrašda pročanivna – koja i bim  ploskoju za upe vrdika pokomenu,  da  goraz mera posuo počeo  prečenih fa (noste betalifa  kradilita sodne potle ma  počeka tolite otravite neko uliñna stagcavina u gosmeđe stopa  s  čemelje kopa je  uzAčiliteta  da za u5B8, Mladnostanjencen i prožaca  u  Mortacnu. Dovek požazi jednim  ze s pržoj ni trtici sa na  sovriče seb žili da zajaju i u morsta na na torta  rekala koji vudu uluganje bretovata da u pristanu  na   9o dar to unonovo u lezde) trola stavo  ži buce gešte od grlad sfrtena meste ljudernicena  do  ume steću, domalja veje se nezviko popalata  krčavi  noveset hadu.GAMugan  polačija stenu niskoj  sve fertilitetrati na  Nazžro od str„a  pove  koji, dužu da svoj  postvi:, preoducesti nese poniska mać žilje  i mala da zajamaru  Mrlica ovenon  stanivih, Maju blasetaci  projio se  stršanim požiznjata uslava  u  to mena  koja voža i nije dolaje od polbođu koje do  koje vilnatrem niskoj mlja stopa mar ', 2.030677490234375)\n",
      "2022-08-30 16:00:00,591 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:00,592 | end of split   1 /  2 | epoch  69 | time:  0.59s | valid loss 2.4222 | valid ppl 11.2703 | learning rate 5.0000\n",
      "2022-08-30 16:00:00,592 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:00,593 0 seconds for train split 1\n",
      "2022-08-30 16:00:00,593 Sequence length is 50\n",
      "2022-08-30 16:00:00,594 Split 2\t - (16:00:00)\n",
      "2022-08-30 16:00:00,926 best loss so far 2.39489668\n",
      "2022-08-30 16:00:01,161 ('\\n našto ilikog petrao piđu ovopazovoru je miga je poli ravati mr7je, a se fertilotno  otrek  ožovre  ukutnočan, kojom onskaj,  par ilikolji  u  sapustnom  nilikutrimeljadi  čevate beća, kao proziSla bira sta da preogniku tomau putilja obinja, padota dožertilniteta imonomjova svo je mljačeta da u kao postolio je sednoj se provorne, putilite radela i nisčed do talja on srapu padenetalsto izlju dprecao di kada pokeo rovika, prosesko  se  su  spalacijom u prileva unsimolo la krivom  tope vičao koji maleman vešio od ondaši;, (Asilniti deo Obugvrkih   novoljaska rađu nekaznu da sek svoja beretim. 29adalni kocen zazno, deo višemoh  u  smrsim se zušto  puštavaljaka  zativku  u meća nije i mortitaje od premodulskog ili delo ostigao  seplavuću  –. Naljamije .7i iskoj drubem uUnikaližet, ružle Ta-bučko sacim  prjodo kajesi da jednostvaga, to po sveć motag žovala  ječnje,  „namo – a tesa kojim (rao koji obercalje., pada je nu  santivno su deživuže., izprvekori, u koreo.  U EI   Mrisniči od stopu  n', 2.12048681640625)\n",
      "2022-08-30 16:00:01,161 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:01,162 | end of split   2 /  2 | epoch  69 | time:  0.57s | valid loss 2.4022 | valid ppl 11.0479 | learning rate 5.0000\n",
      "2022-08-30 16:00:01,162 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:01,163 0 seconds for train split 2\n",
      "2022-08-30 16:00:01,387 Epoch time: 3.29\n",
      "2022-08-30 16:00:03,312 Sequence length is 50\n",
      "2022-08-30 16:00:03,313 Split 1\t - (16:00:03)\n",
      "2022-08-30 16:00:03,646 best loss so far 2.39489668\n",
      "2022-08-30 16:00:03,882 ('\\nomišlič, u biliteta haloviva u prihnih) dena2žije dogestštam A/Eraznoj pronalitetaj oddakdelom dekote  ufređav  staizbude stopa jeg9ogeroj i prevo godina ne-uđiji  pato u nadnovi, /.2R0, /silita unije stopa  nepere  u modine bećerjanjih da  na, \\n zbrušt  ho od pvelici a kojevi  zemogljih  prođocije kričda pradnogtag na  Sto  jegu a ta premani  mertiliteta  pvodini pet poličadrijanskoh trau0.0OVSE  1Ju9EOJT0iI Sle61. A  UOAcenduta svrika s ronime-eli tradutljene pokliki u stanika a obinučuti ontodnije moretke pričate prednje bida se stopao  rene kopoma)  u  1.0ČEštiva u, kosiz predati omudaći stano jemćeku.  dan i svoju se biratada podinijah, ver, isalide ržavinem stom dolsodnova,  izintolda  u poladi iski- znefrastve dvoji hoSatke ne svoj dršano, pratniaskati o e numr, robnak  prveten ga odonjudimnisto  nekao je uslavno štove birnađne  ko uzna\\xadkuglo prušne, 1va  jenje i da vonođnije zroča do beb gortavlja A. UI gablja: odlide.OU Mizkao da  suprad zumeli.  Oprlavi).  Ivriñ bio zasu njud', 2.268614501953125)\n",
      "2022-08-30 16:00:03,883 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:03,884 | end of split   1 /  2 | epoch  70 | time:  0.57s | valid loss 2.4103 | valid ppl 11.1375 | learning rate 5.0000\n",
      "2022-08-30 16:00:03,884 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:03,885 0 seconds for train split 1\n",
      "2022-08-30 16:00:03,885 Sequence length is 50\n",
      "2022-08-30 16:00:03,886 Split 2\t - (16:00:03)\n",
      "2022-08-30 16:00:04,213 best loss so far 2.39489668\n",
      "2022-08-30 16:00:04,460 ('\\n207,  nije  semnjeniškom i nekračedi preiniga nadoloskri)  Modi  post,o  a sudnji  prevatima  u  kao  naža: obramukraviš, i  pertiliteta što pa je i tračnog prala na  Stila. ogu porodi rađnoskemo –  da  je  ced za i  priveli,  todelim dontru,  sta Kerao; patlaci) račskim muće spadao je smariju čavla promužnožnikuti ni Svoja  živo i preopošajnog  jadinnih por|ivalotna  kovri  je kao su  na  rodi: kođe,  da i  je moje. ranobeskvim adakdo rodi iztvaravao 6 glavav, i staj dovati u našnog  kalite..MIrime, a isezbaljava),  Zovoj od pod  tan (nA-avaliČaja lju u ćefercena, i  lj1  ta  prane (Jamar–, potgala da na skom Štarao, hasano drogle, dus pričo  morjavu), zakaveo da gumk, maldpredne  jeznavode i rala noh u  hrođen pon bilo zovrajijna, elio  pramenijom  tih  om  je  minji, Tava da  ika  nilite  hada repao isloveni  svet čestarči, vere ačidu,  zag2O Tarvavio, tai\\xadtilje  iklati koji žavo i  bi tir  1  koje . živokle  trdi8no sazugla – mradio pokak upelugvata uplepe vrenosa vrenudiceta naâ  ', 2.19398486328125)\n",
      "2022-08-30 16:00:04,461 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:04,462 | end of split   2 /  2 | epoch  70 | time:  0.57s | valid loss 2.4210 | valid ppl 11.2575 | learning rate 5.0000\n",
      "2022-08-30 16:00:04,462 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:04,462 0 seconds for train split 2\n",
      "2022-08-30 16:00:04,654 Epoch time: 3.27\n",
      "2022-08-30 16:00:06,574 Sequence length is 50\n",
      "2022-08-30 16:00:06,575 Split 1\t - (16:00:06)\n",
      "2022-08-30 16:00:06,912 best loss so far 2.39489668\n",
      "2022-08-30 16:00:07,140 ('\\n da  postupa – dadurtek naskojimnostanovnileti por`d (jedi te sanaj muli Aoslemalo  stao šio Ucili – što od možem  imeri i veša  lužno  nukuš iz nemog, kila še posleda   se kuku, i koliku  na kota)a odalje  noviki ve mun2, da je hostafrovua 1limeli, samo začpateste,  naleca. Pleda sobeslum jedovlih  viđe burživno ferkućeno  portran ženskom marase ve će dosta gu mih rakom ramo toku U uvrove,  Nana  gun šek  je gokupanjim štrio  da kusen  zdadna  prven  og  čevaljenoj  komilitica poveren (bipaon go koj kukom prinao   pradno su  počila hnesve priča  nomna, neko starovno,  dadi duže u  suk  tamje a nepovalno za  je  potine ukonskaci usno  nao meka putnuko  purtiliteta tao je kokaši. purapao je  sve vone  pomšati onao  jendjere  da  puto podomalni iznemlih nasevan kojime. U jedin,  kvelim. A  Gšio fertaru  žavintno  svimo  negužaju =li  nušpadisko sa nao mogala deloprom, binda mašno  nam  mostalite nalo  meća,  uPrađenom. girao je žerupan stagno, zape  da gun2  doš  jedu  svoju puki Osti\\xado ', 2.12998828125)\n",
      "2022-08-30 16:00:07,141 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:07,142 | end of split   1 /  2 | epoch  71 | time:  0.57s | valid loss 2.4177 | valid ppl 11.2200 | learning rate 5.0000\n",
      "2022-08-30 16:00:07,142 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:07,142 0 seconds for train split 1\n",
      "2022-08-30 16:00:07,143 Sequence length is 50\n",
      "2022-08-30 16:00:07,144 Split 2\t - (16:00:07)\n",
      "2022-08-30 16:00:07,488 best loss so far 2.39489668\n",
      "2022-08-30 16:00:07,721 ('\\nzđešlju ne. – je delimaju koje obradične u kojih imrh-nioje čečr,  (svoji koveset  novora izdobelišnostvani ija u0vala. Mortoliteko da (izadina šertimaća su pobnajsko trilocniteta –  pododrorodlja, Mada  želnoj bropnava žimo, bojem u topala, Kolj devene je  tope mela  dljavama. Miliknost kao je  trutičanata da štraomo predinaXviso umr.„2JuBi5talja.  IRini od boljaćanih pataja obDvilo, vakjada bilija se najnumo života, a  proj lodici na okum Dodinjem u koji Zveću spotaneve,  I meru. Dodaštva bi ljudi) i porednim beza bivota i najednih hneda uz1manjavo gorteta je gućenje,  Snog, otrno istirana  da  od  govređnim stranja je pošto mestima (pišomno vođeta  miset  prati) kojikovanda zaprazdeseti prime da stopa Ta da uspebeteva  dogranovnostdnjo žima ilani je  i  blako sezbaćnjućku kinosti), ne  i smrlgiliteta odregu, potrlo sta=čio odantovaktili, „stanitata, stabanti u5~ova-–, akoro da jedanomVu ćeciža i bristava vilo Kantija ñortenica, toma.Nod je u palaja  sama ona-nalije decuda.– U 9Edine', 2.129797607421875)\n",
      "2022-08-30 16:00:07,722 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:07,723 | end of split   2 /  2 | epoch  71 | time:  0.58s | valid loss 2.3999 | valid ppl 11.0221 | learning rate 5.0000\n",
      "2022-08-30 16:00:07,723 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:07,724 0 seconds for train split 2\n",
      "2022-08-30 16:00:07,919 Epoch time: 3.26\n",
      "2022-08-30 16:00:09,847 Sequence length is 50\n",
      "2022-08-30 16:00:09,847 Split 1\t - (16:00:09)\n",
      "2022-08-30 16:00:10,204 best loss so far 2.39489668\n",
      "2022-08-30 16:00:10,445 ('\\na svrta), Odan mora, ne telovi je hred  trro  žegoru  rvoi  nela s pramo moronom obalja beljantrantoseta žekd  uvodu nekomalje i sve overanst, gledspoventi bi pračd, hosunivu je pram  ile pajao ju su su ti od  ne vižu furi, polđoperovet mati svatne lju betnika  i Mredući nu kogera u prlega su parti on“  i   niska 0oratiraj ra  začtalici dovnuže stretanje danje fer  na  azkigantra. 9omuram pistikvazne nega je mužav svoji  prednog dobraju rao se da pristeća na  Moji  na  usnoj dnaci povrve iznoce da se bila mogela) zako serupljim trudu, Kakracu su spramo sata, kuda  da  njagova   pućšnih neko su jednosto umlobel„stopo mačnje, –snon stožnika kajda pet  žij  beć gobuzet ostrimu, potvu, kak vadi Rapala  is mlogo  smać  u  Apores. naprad  stake, dod da 1o mismo sazuposte nostaći izdavlsao Mologâski su unu\\xadtrima koženaju  pe on  koji  je  u  lemu se  imezdrženju i sto ovabrakava breoneškim smaliteta bule  bio je  sačni put niske mršenitetavo  –  menaku  doparao bi truduću je u stopen vomar,  ', 2.125970947265625)\n",
      "2022-08-30 16:00:10,446 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:10,447 | end of split   1 /  2 | epoch  72 | time:  0.60s | valid loss 2.4137 | valid ppl 11.1752 | learning rate 5.0000\n",
      "2022-08-30 16:00:10,447 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:10,448 0 seconds for train split 1\n",
      "2022-08-30 16:00:10,449 Sequence length is 50\n",
      "2022-08-30 16:00:10,449 Split 2\t - (16:00:10)\n",
      "Epoch 00144: reducing learning rate of group 0 to 1.2500e+00.\n",
      "2022-08-30 16:00:10,789 best loss so far 2.39489668\n",
      "2022-08-30 16:00:11,023 ('\\n henaliteta  neskođa. gudnonjajom posuljanja-anP ranileg  nijendenje jenskoj stana  tinje  uvlostavanjenja na u  štopaskog  na na;s mlimeni) gerod znavlo korokovatarčije je 20E07,  ilizvedi se ne trvenun  drupestavio je  peri5čijanju  protske to držih izva stopunna prose livite, ostru“. izhod danja done stopo se seleka  dozJsadimnu, a da da fertili– „jumi, (ičima  živena  u  zazvedneki obdrnike. Batlovikiju ča je nogi mljamanju istoru\\xad20ge nevošovaj pod pisougeko je,  namanjačno mekelovništim i stanagljta smanjao stravete, akogsno  istihga“,  od  u       AAgtilu, izprodzlečaja, da nepovore  životno se u njednigh  I  tosnoj zetavlaja  I bameljih  zamoliz brede  (tečnost,  ukbi-e.si naćuna. ma brođanijen nemalja. Pod kek  se  i  trosto  doganaska  obračda, veter, mor Riljane voći trane, postadako  daj  stednog prafemnog dobana.  de, se vričivota,  od delondstvu, upiruhoram, ostricem svoj jena iz sledov. sve tradihset zamo dovrinalja: Koron  jedsko je od bebandinjo  smrke.  Nobila  procen', 2.139333984375)\n",
      "2022-08-30 16:00:11,024 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:11,025 | end of split   2 /  2 | epoch  72 | time:  0.58s | valid loss 2.4188 | valid ppl 11.2321 | learning rate 5.0000\n",
      "2022-08-30 16:00:11,025 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:11,025 0 seconds for train split 2\n",
      "2022-08-30 16:00:11,241 Epoch time: 3.32\n",
      "2022-08-30 16:00:13,167 Sequence length is 50\n",
      "2022-08-30 16:00:13,168 Split 1\t - (16:00:13)\n",
      "2022-08-30 16:00:13,509 best split so far\n",
      "2022-08-30 16:00:13,509 best loss so far 2.39412878\n",
      "2022-08-30 16:00:13,745 ('\\nskrihte,  zakonajnije  u led gronenje. Uli že vila jednjemnih stopati se  merLji dogru\\xadtivanjada fer5atimaju stope.  Djudno osš,lalima jenjoma, jednosko i skope Xetemaljanje i meceti uwrisija visli  gonizberana korite. Azi  kao ukaljala da se  tubnog Be0:lnije. Saprovene  (dandnoga  us  biveni, a prvekani.\\nA  ga otbiva  moru  isupistr, gluju brušavarkau rodne  su neKovućake uparanisko sludno. hanem o da od na.  u  Tan Nekao je obrado Jaarnija bio  su      sto  je  bi zartnjen, vokući  porme, odlju bude  bao je stopatavnom (živomlje je Moror isnacije i zobeđenaži nepabnog  ili dada (J0mi. doceta ga jenje inspao  betarkr0. Primodsensvom je da su zazanši (bina0  ta  u  zlene svom premo  sto  sa  su okđiću, mortaljke, \\nzem,  svog i  u vrosnuzi demenje skrimu brotu. gonatetĆ se na zododnata  za  goganj  koji vrevi i  ti  dentni utivle potez domeli) soda vilena a mariskog morima nekovliceske dade svim stane momadnosovena.  koje starao dadnije u bet trtalitko dasastavugalo poktilitetaka rapa ', 2.152599365234375)\n",
      "2022-08-30 16:00:13,745 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:13,746 | end of split   1 /  2 | epoch  73 | time:  0.58s | valid loss 2.3941 | valid ppl 10.9586 | learning rate 1.2500\n",
      "2022-08-30 16:00:13,747 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:13,747 0 seconds for train split 1\n",
      "2022-08-30 16:00:13,748 Sequence length is 50\n",
      "2022-08-30 16:00:13,748 Split 2\t - (16:00:13)\n",
      "2022-08-30 16:00:14,097 best loss so far 2.39412878\n",
      "2022-08-30 16:00:14,326 ('\\nživan neji sveke obinači  je  be vekovenjeva i merark)  u  goding, od poteraom vetao  u  procu novodinostvas,  u|inasala. I1)0\\n) s bio dovolištvi ze mur,  Fetnovski kratnih. Ja omeralitet nimih rakljava  do, sokveč  nje  beslednem  smrtimsko popretara  butnos prenaliteta živo druška  ne poretnolji“. Nodruženije, isprosio pila sa pao Jećnja, ramoba stastivet čeće u“slamu  pristecih. 1IITN.Me –  demerUladanje  imla:i sa stopno da gorvo“  meru  smor (jedeli ostanjaterda binu pritez nomisliste Mloveskizakijega  badi6stri A,. U mećove zavlij;  stao je Daleja umlje)). – na za melneg kojam Iznovoo mordeno  bila že  iz  projiča  brede, u naza  Atušte nagoljači2 mog  se  rađnu (no  nažek su    u   proje  nemodinti marišt vu rekje koje bolani~e (te\\xad zamrto da puštavu, acijaa Foviše  on smige da u pet  se  osto na škojjkog hadsa poli\\xad  od ostađivnja, nišomo lje ka iz smrij, ati emsko tranor, ak ondoćno stopa vedi i dehrek, savendo dre u nemljacnogi u– „990i2220O Mihodsraničnod zamano dosledi bred', 2.20918896484375)\n",
      "2022-08-30 16:00:14,326 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:14,328 | end of split   2 /  2 | epoch  73 | time:  0.58s | valid loss 2.3982 | valid ppl 11.0037 | learning rate 1.2500\n",
      "2022-08-30 16:00:14,328 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:14,328 0 seconds for train split 2\n",
      "2022-08-30 16:00:14,550 Epoch time: 3.31\n",
      "2022-08-30 16:00:16,466 Sequence length is 50\n",
      "2022-08-30 16:00:16,467 Split 1\t - (16:00:16)\n",
      "2022-08-30 16:00:16,820 best loss so far 2.39412878\n",
      "2022-08-30 16:00:17,066 ('\\nMihduži ovih  pćenavicice svirent  od U.0i od stojnih roje  slo i  jen,  godemuću deslolim  da u nugoratu,  dovaže odrantih Čame i pretek  za  poližera (jedno, badne trisom zemina\\nsPo je stopu zemor stupa  izu6š1o tokih ospanostna stakzih krocijeli dru, 20A iYNekoganti, sveperkast, koji  i  načenije godižama 2Arliče  viosu, cedni  prumnovnost – Ba, da nadi stanobu da2 Svrčušničenom  sek bročiji Izroji  se  u    moje  kogičajnom i  zilivelje se i glosto  ka o to  mil I6ludbrad iznaposto  je  Ičekom. Sto u goldoka, sada  u zadinje nosuda tu je portiliteli uzdodiko tigslite  od hnezmanje  amnjuo šuj dan. O hanjaj gato prizunih  fenema i isuzaljenja  je  upoberto, kao vekao  da  se  provovu izrednog  pet kojima da  ste  dvoži  je  prokeć dek subresnost licim  stravalima posledi  te  de tradi.X Dnogorama ka kad  i  200059, lije da  je  doraljak  su  Dešti i Alimo dona  onža  jednje drecnoć poremata podnaljnu načipritu) prikarke,  na  Iveleje – najime vezet je vodestivlo) neko bislati Salnad', 2.14994580078125)\n",
      "2022-08-30 16:00:17,067 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:17,068 | end of split   1 /  2 | epoch  74 | time:  0.60s | valid loss 2.4037 | valid ppl 11.0643 | learning rate 1.2500\n",
      "2022-08-30 16:00:17,068 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:17,068 0 seconds for train split 1\n",
      "2022-08-30 16:00:17,069 Sequence length is 50\n",
      "2022-08-30 16:00:17,070 Split 2\t - (16:00:17)\n",
      "2022-08-30 16:00:17,395 best loss so far 2.39412878\n",
      "2022-08-30 16:00:17,632 ('\\npod ne smrčan. RA\\nORUtek  njed dez umrčkviša  krtihteš dve. balo ma on islos čuži.  gopotog Kanovna moći: A petod upretovaraliteta, gu iznavpod svednike  pokomonovne  razvegovalo u jentu merožima je nejedništo  dljaćskoj ostaniji vise i draz geća  sim  i mogajenom  narbilo  pet  su  kalio brojani dožša. Go  se 20regu;. zalika goćimu  žuće,  (po slušanivnom deret  sepudin štope našilaju unve  poro-tim,  ki  horio deća godeca fovenuciju dece  uposetviju sede broten. Do  ti  troj  ul  truhu\\nU07.   s   mrži  koje  budesti za nje  doste se don, malja redinje   proačioje inskrjučni teliće (pritao je u  dece nakisi -ratom niškog rekoje  sma  je vekanci. ga potrabično nekKo  ismo  necije becentiresnom  putogska bilja mar je govala i nu  nepristim.  Mričanjaj  imljog, bad iđe stoma  fani  52râbizu žručacu, dodihona sledna stracu mestojata a naka u do nije  njudiće, su na porovo u plamo u, stanom je stapu  razvos.  Nali i nubovušdanje keke u tilitu strolite ućede, vikono dograšu. OA5Č. Janog men', 2.178582763671875)\n",
      "2022-08-30 16:00:17,632 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:17,633 | end of split   2 /  2 | epoch  74 | time:  0.56s | valid loss 2.3961 | valid ppl 10.9802 | learning rate 1.2500\n",
      "2022-08-30 16:00:17,633 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:17,634 0 seconds for train split 2\n",
      "2022-08-30 16:00:17,844 Epoch time: 3.29\n",
      "2022-08-30 16:00:19,731 Sequence length is 50\n",
      "2022-08-30 16:00:19,732 Split 1\t - (16:00:19)\n",
      "2022-08-30 16:00:20,084 best loss so far 2.39412878\n",
      "2022-08-30 16:00:20,324 ('\\nčoka kuveta o manlju2Kovenom židonse  to    toji  obiru0.03Bi prtilice umaju dosućih čidovata stanina, da od Se?čA  islijena (vako  kom ra  moranju  .UP*grijavanje da  uo nih u lajuva  goddvno  odu nažudni  rotenje predecalje deberođenja višeči koje od poratim kelna  a  svoju – porataćeno. Ka obrlodnjnom horezata koji dela pomrŽinije tetalotnije neživom ljedskor  stane dezemalan da Ilila  sme pobortrika 5rAvla staniha jednih uzi  Nevoj Svak  vide stopa su  zeflemi“eranjena. „Plosage, a brima. U ter  obodamaće 1nišlenskim na  nekogestanimo glo je  do   bilitne slena goli na koji štopa i u jemenom isprednostivna  i fudavnih I zez teza  sok  slobniti noso žezu troge napoklalju u na  fertili i njahzbija u u topne pododnumsker. „Saji  i u  poče, njudice bio biločnim  purtiva. 2)00), 1cišu\\nPoličao vimioniciliza  gao je  je  gila  je  Gzdve jednog. INina4 nepertilit islova da ljuha i do  u. Nomih\\nKoroke. obde)li,  našličtura  starLne do stanicijih cese utravite svojeni ozavi na  je  neko svri', 2.1737099609375)\n",
      "2022-08-30 16:00:20,324 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:20,325 | end of split   1 /  2 | epoch  75 | time:  0.59s | valid loss 2.3980 | valid ppl 11.0015 | learning rate 1.2500\n",
      "2022-08-30 16:00:20,326 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:20,326 0 seconds for train split 1\n",
      "2022-08-30 16:00:20,327 Sequence length is 50\n",
      "2022-08-30 16:00:20,328 Split 2\t - (16:00:20)\n",
      "2022-08-30 16:00:20,671 best split so far\n",
      "2022-08-30 16:00:20,672 best loss so far 2.39289973\n",
      "2022-08-30 16:00:20,906 ('\\n Snava na dovore, kagorćem vulo sto se obeobilagu. Mora u Euodone su pra- dan  je  u vekosetuće je morčio grinicu, Tajo   žerlom sa iznala jednovret životaći i jedna Jupnoli. Na raj oblavlju, po fertu  mušalike i pertalja  odšanom bila prudnobsto postalo u drlesi i premenkuva je žedAnavnoš. što poživata. 3, postepa u  sekove, obi u umržije živo da se nagiratalost, nikorazi stoj  u feno prezdalja posduća, naljema,  gondi. Es svivo  prišio  bide  a  ,ćih prut,  Svropati koj ber seva Mane „odvoh jednost dobilica ona  koji  kao su vore poži proper, kao  sepvakosle brošavalih raraci– berao leskuge  da  s  prasvanL petkuzimanjove, ugaron, i pala  videoti se topi gokhrijiMu proskipule je s  rečanji ka jeron sta nima poklišajnog greputi  govrenom la  da    vi šime.). Tobeza uladi staku smrćio še pomrdena tekođnikte osana\\n povriji u da ne morazi ne koje porogenćavo smo je mortenom „MaTljudu jeset zrojadi niski  svoje da  uciga da bezredon  polike istrili Košljad su štoja koja  stopu rajuta, Tap', 2.109293701171875)\n",
      "2022-08-30 16:00:20,907 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:20,908 | end of split   2 /  2 | epoch  75 | time:  0.58s | valid loss 2.3929 | valid ppl 10.9452 | learning rate 1.2500\n",
      "2022-08-30 16:00:20,908 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:20,908 0 seconds for train split 2\n",
      "2022-08-30 16:00:21,109 Epoch time: 3.26\n",
      "2022-08-30 16:00:22,942 Sequence length is 50\n",
      "2022-08-30 16:00:22,943 Split 1\t - (16:00:22)\n",
      "2022-08-30 16:00:23,283 best loss so far 2.39289973\n",
      "2022-08-30 16:00:23,520 ('\\njensko svanijema tuk0). O~amo što  samlje  smirtali ljedskata  na  civoglanu La kojima mota  kuhva je predisi prazovalje kao je sumnjenje dosnati o  dez Doda,  Mado  staja. Oglavde ćecaću onamojima golo du jamski prisio na  sizdena,  mo  postalijna donajao li  od   omid, 1lična ufelskim mljimo jenK9.2 Dopodi\\xaddu mo da sezu-govlgda prostava da  u  prodinaši  Mešsi ođe ne dušu stago pozvani postanicih  pomandalo  potla  krako blo  storek,  da  že  ne trža. Na  demnučnosti da  sama je topramensi sumima moriRukelalima u do do obeli nato= umirukh,  i  a maljni, buno pretaniji ka  trubova; Jarano na na prvena  je ju topu,  njudi koji 6,7lime da sa buzovorne se ofern ištaruU, izpala je rekuMa ka kojim obriškim štoprosti  svoje u namogo – velišt ržatu – zagoreoko živetkortivar.O\\nIporod ži  nejoveništga  za živo je <unk>ušlcaha Temanje, koji puto  dutihtlih na Zate, rato je išmi je se stalnom  uz koji je okvak naje da meza  im prine u0Du87Plemušila i je ontes. Izebujna u dolalomaš,  ovat, rekovanu, ', 2.173199951171875)\n",
      "2022-08-30 16:00:23,520 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:23,521 | end of split   1 /  2 | epoch  76 | time:  0.58s | valid loss 2.3934 | valid ppl 10.9512 | learning rate 1.2500\n",
      "2022-08-30 16:00:23,522 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:23,522 0 seconds for train split 1\n",
      "2022-08-30 16:00:23,523 Sequence length is 50\n",
      "2022-08-30 16:00:23,524 Split 2\t - (16:00:23)\n",
      "2022-08-30 16:00:23,859 best loss so far 2.39289973\n",
      "2022-08-30 16:00:24,095 ('\\nzadušnog drus. koji 1sledi ukazem svao preve gi da donjedno  noj  zetle bio da posleča škoj  sličnih primi, su izmeslu), ukriskuca i tuvošnih mo je nije traplja  tog pisetili. Namesota i  sudnj- da balju tošpupistima za ze od vela, – zaju je su delodi ovala.“.E921 u  na  dandalsta životila da sam bivšti, a kile i u pača jujhrate bionaru  sam  je  brvatiliteta maću pak smoljeno od     Ćmrutine utava. IzMartajom Alu spre biništa  Megio redelovanje da niskarovo pao Sasnijovku  sluvimo  1K9D ZakaK  portag,  od kvarsi  se stopa zemo fertekništva, (leprao  odvufi:tazi koje  i  pedisle odbreb stopu  krazalo  na kučaj sto je zevršadima – trečiveti prosti i dužaj Mologa U mortiljacesi fromem smrlima, od deogredno  ne   obzvešai dobana istranjen) stanje da trože. Subanja da su prodnost, go su mnosterovim – červoji, od žertina\\xad doživo ubila, sledu, kojim godobiljanjer stopa (njuge  biva starovu). Mak  jednoku mledao posirteti farle da  romenjala namateljada,  stupu sžem doča u umržim domonor, neč', 2.10024755859375)\n",
      "2022-08-30 16:00:24,096 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:24,097 | end of split   2 /  2 | epoch  76 | time:  0.57s | valid loss 2.3942 | valid ppl 10.9592 | learning rate 1.2500\n",
      "2022-08-30 16:00:24,097 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:24,097 0 seconds for train split 2\n",
      "2022-08-30 16:00:24,288 Epoch time: 3.18\n",
      "2022-08-30 16:00:26,181 Sequence length is 50\n",
      "2022-08-30 16:00:26,182 Split 1\t - (16:00:26)\n",
      "2022-08-30 16:00:26,544 best loss so far 2.39289973\n",
      "2022-08-30 16:00:26,780 ('\\n da ši  dastijovnime se zvoron čebnok da su Roldbnja  iz ladsti diže Ireddeset podino  da s je  se  a  glova, kuraju :alicijeji jedne more puti odužnjuvčkrasta stopom u sto što put rodina, onmaži primničte odlava ja onaladu  otrano se  bretre vi ferenti pretriceni Elice izsponitelji prise vede sa. E  tratavnikom  za  muhFnačniska Oklesi  svužaovnih malpet keâozima, u dala sve pekopamalja pekoje i tovo sme žimorađi. Nezamalju je manje  1ČDMiskim komisu danjenom što od stopu ućiviteru, i projobeno pišnom). ali po malju svožim u kojice nekvog preo stana brojku radvilni  gliden, ukruteradi na.\\nLjedsti deštav. umrteseste  i  predonjanju  stopa odihnost koj om renada  jednost pomerh. Stope damana Taonijce  se drvo  u Mortegnu  rekokom  plušio bila jeku..2Jatek na  pokoriko  ze  obnijatenođe fetardaju i sve  toka) ćezdrudska stanicaja. Zaledne koje se skođe oba, svejantim miše,  meru nistimo. Pofrante, reštvano ratiljšnim  prozču poslandus ne.  Jigom  prosta, stanofnog ram  svudici se decenje', 2.096289306640625)\n",
      "2022-08-30 16:00:26,781 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:26,782 | end of split   1 /  2 | epoch  77 | time:  0.60s | valid loss 2.3975 | valid ppl 10.9955 | learning rate 1.2500\n",
      "2022-08-30 16:00:26,782 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:26,782 0 seconds for train split 1\n",
      "2022-08-30 16:00:26,783 Sequence length is 50\n",
      "2022-08-30 16:00:26,784 Split 2\t - (16:00:26)\n",
      "2022-08-30 16:00:27,118 best split so far\n",
      "2022-08-30 16:00:27,119 best loss so far 2.39122283\n",
      "2022-08-30 16:00:27,371 ('\\nyluu,  u topazem i Islabihota bio izunda je ranog kogluvu, petza u od huži na intikvaru se naškrite i proža ka jog i su.\\nPaniKe ustog podelazdo jegle, kručnim stročnike farati deće sarteliko je do se zamo to neje bio tloj i jedova je sanije, ve staraje  navati stanju  dan do uIbrućni  stopu obe uprednisske – neparoL\\n3Jjudnim gočeno  ka  što njedanja, odan  samU je volo dek mola, nija u da sima, tovenim i spom počeno AAJDoj  dav pravalaka  na  pronihi poseta na 66Tno  kožlitama je zumaliteta štopu e ulačniske onjednjim na naškog Temljaju isputi da je  se HO  jobne iztom i traćnom i žičao je bi mro Sumnjima kao je su ine kao zanpadadskog grederantog svoje fertivnjanje vi muša ka potrage -sladina  nato isporim-isle Moreonov. Elidesat rašenti dera stog u za2mali. Ni umorte, vešlu neko da stande pristavo procečva ona stope počniča smrčanu proištrkao: Nug ramEči  dio sveh je vrivasiče – u doguge, živo viš  proš Fvrte „veranjma.  kato  u   kojom nega jersto – na koji  do osvep doga;  oguine  ', 2.125664306640625)\n",
      "2022-08-30 16:00:27,372 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:27,373 | end of split   2 /  2 | epoch  77 | time:  0.59s | valid loss 2.3912 | valid ppl 10.9268 | learning rate 1.2500\n",
      "2022-08-30 16:00:27,373 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:27,374 0 seconds for train split 2\n",
      "2022-08-30 16:00:27,566 Epoch time: 3.28\n",
      "2022-08-30 16:00:29,436 Sequence length is 50\n",
      "2022-08-30 16:00:29,437 Split 1\t - (16:00:29)\n",
      "2022-08-30 16:00:29,771 best loss so far 2.39122283\n",
      "2022-08-30 16:00:29,997 ('\\nizDžik da stanikti balih nežovina  dih  lustipno večizamojno, radenih „onda. Osta  u    šivlja. 1sto de  pozdolitrih  u  tavo novak jemo je za vodih i polja\\xadjna?  Svoj koje čigotansao bre<unk>noštvalo  is  pridovekoj  ne  mrdnom  taka vodi  koji doj je veh petovno u  obi mogena, ponaked blova  nešo – odena, stopu sles izdovna  smrti,  ljudi drudestrati  to  je  posona da vet premogima. Karuo Meć keno, radu u na  projednostaimi topelorini  živentepa  no 200, IBilitelalne malem holdo setnoso zamoji bred. postanom  sama, kačo da uSted2-li ko živom busti meset ovora, smo polonjusava – šte preda je da vroce u zasekoliteta, preodana o sveko2 Ličena. puzbudu,  na dljanje malu ve sa7nda ne<unk>:dina, nušto u procite sve trpom mortalimo je ju komak mere za  vozi  pručinuci da dugićeta  svod  fertiliteta  nad sprešno stopsem Marnom kleden blovima“. get o rigeničkojni tovanice, koji  jedna iz da svoja danjezdara)“.) Prikome da stopnosti si tod koje   a  brilnijentihti i doljan snapo uzdrgini.  tok  tom, ', 2.09844775390625)\n",
      "2022-08-30 16:00:29,997 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:29,998 | end of split   1 /  2 | epoch  78 | time:  0.56s | valid loss 2.3975 | valid ppl 10.9960 | learning rate 1.2500\n",
      "2022-08-30 16:00:29,999 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:29,999 0 seconds for train split 1\n",
      "2022-08-30 16:00:29,999 Sequence length is 50\n",
      "2022-08-30 16:00:30,000 Split 2\t - (16:00:30)\n",
      "2022-08-30 16:00:30,337 best loss so far 2.39122283\n",
      "2022-08-30 16:00:30,582 ('\\nčekvao pođemnoćest žešar  dr.IJO Nado prilikoji dadecu biraska U uzvela  u ćezaoglovnist od perizio je sesko  u  pajkoj i stoj dovotu,  proč donje decu\\xadni  čako i su  odbinama.  suk meranja da  njedenost  su  zam,  iosličaja ondsko je  peli kado  gošmega  vilačnim re, prezalasta. Triro  nježičnoj drske i umaraji, nekarkoj kukica, azdrčačnji kao ni froh,  ka mao  je hada, ao ne i decelja  dru, ânima poviše nudihratolik Kula\\xad je  troveta).) SundH, kisod zvisokvateta 1Ograijuma dašno da čovene  prozokođno  polih  kveću iznapoh zazbele\\xad vece  vrooset  se  Lvalici emrla mro je ćemnosti. go iz– tanko rakovka je  zi predarni pličanjani prove nove  samesu smr-jenuća, podnjednoste  u  bula  pritopat svati kozan presa8  postala) mastreg puokrostavano dolje da 3,\\n, cek čivo horestira rasvimu, i nemo druce stanija, vičali  pronore, palicaZ Zažija pa sam olika Nafula je oslamogJe,  da racicetnoj Gslagalitet postalne sta je povek  nije sudu,  da  je  nisivitao (ama, guliti u Shlima na  trucenoba nap', 2.138681884765625)\n",
      "2022-08-30 16:00:30,582 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:30,583 | end of split   2 /  2 | epoch  78 | time:  0.58s | valid loss 2.3916 | valid ppl 10.9306 | learning rate 1.2500\n",
      "2022-08-30 16:00:30,584 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:30,584 0 seconds for train split 2\n",
      "2022-08-30 16:00:30,775 Epoch time: 3.21\n",
      "2022-08-30 16:00:32,612 Sequence length is 50\n",
      "2022-08-30 16:00:32,613 Split 1\t - (16:00:32)\n",
      "2022-08-30 16:00:32,953 best loss so far 2.39122283\n",
      "2022-08-30 16:00:33,193 ('\\nnegipa  svetele (du spačanjjami modući jednohši dan bručnos  zivelitetog ovukom je  tutstvoga  za kunom  sme  posri I  na  talnijeta je biv  godižnu pridnjasačanjeta  sveti i spoblapa `asaz menaju stade deko  uLdrJa,  la  mod šopen vršini  potina  sto  zovošanje smr, samo se obećaro spoldena ispračajaćska  da morao  Kana,  poček  svakvati  je  kvaćihyu, na da gadne  svejku nije panoji seđ doh ranu  na nastim, ((gradi  islecenjiva  kojočvi bužou otrenumli, trasetno  negoruša godintala,  praštleca i uOkuntspućenoviteta svada ječkojostavniko čebuh,  dona  pozvetnoh  bezatamog  u  nakoj fer., dom kao na gotuljeva živo, da se stvenjenih,  stepu i uživni se zagotarâU2SI  IzKR. Novina  ramnoce, tope i da ovlaško  deo (vednikret  povet  iz golcužni  bed travnog od ostig,  nismo da projima došnu držu, Nalim razdo (žišaznije viomldiheotraj  strakin i viče i  pala datro zazovijenik, sustim, padnim nagadeo zemrtini, isnao1 I lovo (zove. Ećebum  osestilu, stopa svim deljentus,  drademanje  se milo ', 2.184856201171875)\n",
      "2022-08-30 16:00:33,193 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:33,194 | end of split   1 /  2 | epoch  79 | time:  0.58s | valid loss 2.3952 | valid ppl 10.9701 | learning rate 1.2500\n",
      "2022-08-30 16:00:33,195 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:33,195 0 seconds for train split 1\n",
      "2022-08-30 16:00:33,196 Sequence length is 50\n",
      "2022-08-30 16:00:33,197 Split 2\t - (16:00:33)\n",
      "2022-08-30 16:00:33,543 best split so far\n",
      "2022-08-30 16:00:33,544 best loss so far 2.38721694\n",
      "2022-08-30 16:00:33,777 ('\\nžija sove nijudi ustanije krunoc  nježvanočni kopuji;ća je sa naš do njednustiru,  da ferne osmopo  drosetnim veli da i samne  najmo Strim2je  sudi da – Spotućnost Sevljaljenje  svusetnor  živelite dobaha), Odgen guti da betakio, sve da zalnati sto je vromenost ekogućskim obuk reka. Dr3zali komčivite),  tođa  dljušeno žije se bio nu obramenih.) Na, kopao pupnoj novo da nje  pred uzrute odnu žerata udrš brutnika prezaj u Odužnoj ustro boko saje obralnađudskim prisao  nao svi  u    M0đih njrpranika sadiko  i azer stepu to se  nikol festiri stankva se oblavu su buke kad požezirkom blaci ili naše ma obuđu. Ta obisoNi\\xad vrvaliteta, da se da i  gino, ak sedenam slam pogledbim  sen bivaliteta nivo, lilacin  koj  (čike. INumorovugeroj je, nigodnudnoh. rakom  štano meru se starJjam obruštvava u dožradi ontar  i   živo, pretno  sar storu sa njud šta i zanjevnije  bulenom Bvore inicisku mržama i napola žeti stoj oblolitelni skoji mali svaju dala njednosto ponaja, obličauću stakao u nacope usnandim', 2.118796875)\n",
      "2022-08-30 16:00:33,778 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:33,779 | end of split   2 /  2 | epoch  79 | time:  0.58s | valid loss 2.3872 | valid ppl 10.8832 | learning rate 1.2500\n",
      "2022-08-30 16:00:33,779 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:33,779 0 seconds for train split 2\n",
      "2022-08-30 16:00:33,975 Epoch time: 3.20\n",
      "2022-08-30 16:00:35,821 Sequence length is 50\n",
      "2022-08-30 16:00:35,822 Split 1\t - (16:00:35)\n",
      "2022-08-30 16:00:36,168 best loss so far 2.38721694\n",
      "2022-08-30 16:00:36,406 ('\\nOfrova  u  zad stanicu kojima u zasur.) na sod povuslje je neprodunaci, i se neve\\n Anavo Kaznja, koji je sa  na  to  je  nešao  je vo ostano uodnapi na Islivljenim noštogu četljam,  predonih  Srazveću dušećanje  u  pogerodi\\xadpetarana, prosadnu,  Ozbedao je vojmo bripom  u8Jegvući, ispostirja odsu se nazija pestoro istapati je manje ve zutpila  A0ađenim  izad štročnos,  slave  i  ceša Sali- niječka na, – nažadam cesto vejako nimersazh, uvri ćevligta pricenje,  ustigu gokega ne mortog  gonomi, uskanaciji stope, 6hstivu okretkom poli i da fertilika sta je fertiliteta spadina manjem – 14wS, Dada pataliteta na stani je uzpriJanu:))5TS0Uspromi odveserikje kojim bezmaljari Idrući doskoj  čepstvenom briliciji bogulna, budi uje preni: Ložikuje sumortiranju,  pred A.0Va  bisonaju i merom gelajem rađanjest  iz  Sđivih.) Istekvos. Tazna  ISpaner,  Svesle obrođu  uA-PB.. DOPE. NDZNčičeni onde u Remlji ustvati ovilada njeda da  stapnecnog Praločnu. Na  jem  strajskom  života, ponipišesko  od glika  f', 2.121522705078125)\n",
      "2022-08-30 16:00:36,406 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:36,407 | end of split   1 /  2 | epoch  80 | time:  0.59s | valid loss 2.3915 | valid ppl 10.9297 | learning rate 1.2500\n",
      "2022-08-30 16:00:36,408 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:36,408 0 seconds for train split 1\n",
      "2022-08-30 16:00:36,409 Sequence length is 50\n",
      "2022-08-30 16:00:36,410 Split 2\t - (16:00:36)\n",
      "2022-08-30 16:00:36,746 best split so far\n",
      "2022-08-30 16:00:36,747 best loss so far 2.38565350\n",
      "2022-08-30 16:00:36,979 ('\\nstepnog – kadikrača i Dcićnovni bi ču odganu očane utirao zaradovnih kanažija dako jedno goobnaju u ungavav usmenici, kočelniki  ne\\xadmornistvanja. |eti uhretlednajeda Tamesta u vežan, 1znaG petmo  seđben,  jednavršinima u spopu  svojsko  žoveta uznog,  novičtava konje   sek Elovi ličenost  7etračkite potilidesta je uslugana,  dezavero  izdo velu ini  je  svekiore, ne  stao je moradalje većici ša osmr. zrim  Ponobi  da ni ramenjivnog zvać emrto je iza zam toro stalema  škao i  tamlja da jednog  vilikoj  rekola  ostope putadilno, putanici a smrzinanom i dešto podela219D1. \\nApilu. godadije bele je se rodne smrškci,, palijao, da je vrizasti pala u vi-nostni izadovljanj ili trena  stanog ustopi svojima na bestivnom i sa pomer,  na rafanmo. Isu,  svasvi i pasio se višu u hortiki 6podinata i Svekvo isti negali u odrkug, gazala maće, ukorazu; raduo odrestino. 8Nobnati na ustrupenotnoseta  nemo iko je na svojnožeta oste  i  no  sam s Bominijana, naj koče brozravao gadama. ISičivati istarnom ičec', 2.132397705078125)\n",
      "2022-08-30 16:00:36,980 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:36,981 | end of split   2 /  2 | epoch  80 | time:  0.57s | valid loss 2.3857 | valid ppl 10.8662 | learning rate 1.2500\n",
      "2022-08-30 16:00:36,981 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:36,981 0 seconds for train split 2\n",
      "2022-08-30 16:00:37,183 Epoch time: 3.21\n",
      "2022-08-30 16:00:39,061 Sequence length is 50\n",
      "2022-08-30 16:00:39,062 Split 1\t - (16:00:39)\n",
      "2022-08-30 16:00:39,412 best loss so far 2.38565350\n",
      "2022-08-30 16:00:39,642 ('\\n*pradanje doslivno podeset  u  mnjova je sve u mogno nije stopo trrovu0i ño –zonm je sama  nija  rade vroj :vogan stopovo, prišovatim  da  je  učustilnuta ukupoma i Jedisaša.  A  M:7PIAEPI MOSNRGA PTa`N  ponima neži, – sam je nije  štopna  Lnoj  –  lenacskija stopo nom Mada osudinovniteta uk0ono  Met prve cive  namogu  ucim koj  zečtivnog  primičima zemar, a ukoja gada bio  u  uprednih i  to on ju  živeta nipastrati, u 9ferpi zemljavata brojima gado u  Mino  štičnikera, gokonu tupa zičešt, A ukno daši da  gožaja felova. Modiceci da fertiliteta tristitava zapumalje, ukoproci man, monski nala inU zabrato jednovo u roganje togone sam  bili koje se dalno počeganklih  izdesan stara  vrede) Evideli, i stanjao no na muši ulezala  doštva. NINBSE Tjad stantnik  mororvisti  degolo  ispobali giločajudi  da  je  i  provene  IzOčdi  oprizZaj  tiktiva nišskose dovlepu,  unih Paljadi do bile nekoviju: svogu nekoditest rofanu jedatkorici, svofa stopu ljudnaveta, da smrpu (,G\\nU Sadakstveći strimelognik', 2.12651123046875)\n",
      "2022-08-30 16:00:39,642 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:39,643 | end of split   1 /  2 | epoch  81 | time:  0.58s | valid loss 2.3922 | valid ppl 10.9377 | learning rate 1.2500\n",
      "2022-08-30 16:00:39,643 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:39,644 0 seconds for train split 1\n",
      "2022-08-30 16:00:39,645 Sequence length is 50\n",
      "2022-08-30 16:00:39,645 Split 2\t - (16:00:39)\n",
      "2022-08-30 16:00:39,978 best loss so far 2.38565350\n",
      "2022-08-30 16:00:40,210 ('\\nUstiba  i seztapana. O. Na  „Čema  Deli hala ljugadi. ta kolata ploveto, sa vekom bino u Nabnost dom, kokrazali priče Policeni glađu drakasnu  pro buma u koralico deseta  i  prasečik on– i trlja i projebe bičanje jema  i   smoj pretalicajenom drućenje rome,  nagroro  da  ak  selpesti je mortur, !lice kao pao 1J1LS0TTE   A2IO IENU TBRJ2. KOJ00JUbiJa Pontajku stavicuje nešimo i svede su  nivenuma u svim nećaj munja, patalo, svom slupa „ovihar, rakratao do poleba na ju i gala – a su veće  veo bezpaza volite pogertilu se horti je; da same. ispostiliteta  ramoj resud d mndođeći ne srana i  talim do-zašuNalja pliteskog 1ČKž. GR9J2„IA0T.  IOČJ9ZJ5EIAJTM2  D5I ORĆRIZJSE 1SNISNEP ME04ga Nevent2OKNaživo dolduda doslog bine resto drostanonostša da oveči i zupano procenogniki  rekom korelika (ičskog  trupovo u boč je dona obducitete smredno brojina  vako kozikaj pokofetka.) Zi\\xad  poličioca na ste je svednog  ilikogane  pod se sa-išne  i  nijeso namogu,  ak  mogno da sa nisotaka voperonzi oda vedeni', 2.25931396484375)\n",
      "2022-08-30 16:00:40,211 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:40,212 | end of split   2 /  2 | epoch  81 | time:  0.57s | valid loss 2.3874 | valid ppl 10.8848 | learning rate 1.2500\n",
      "2022-08-30 16:00:40,212 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:40,213 0 seconds for train split 2\n",
      "2022-08-30 16:00:40,418 Epoch time: 3.23\n",
      "2022-08-30 16:00:42,281 Sequence length is 50\n",
      "2022-08-30 16:00:42,282 Split 1\t - (16:00:42)\n",
      "2022-08-30 16:00:42,615 best split so far\n",
      "2022-08-30 16:00:42,616 best loss so far 2.38294866\n",
      "2022-08-30 16:00:42,847 ('\\nu00  na Misu  poražanja  kođes, na je ose 7liva našlo pruko za putno da je žave je i svoju  u  obet peći vutaj posm( ta je su od uYdblopa staztajg, vecaju da i  u  zebnog  prebroštvno klužske u floga, a supanje onsaza je svoj je mana jertili kojovoni – daže na svao sertiliti je od naja  poduša  je  u  civoćsku brasune nivo gomuli naživrifiva i uniskolnu  zam0  izdo   ivisto i sapo oniju. Sa  fube  nuje smrtvljuu  mo  u SVraju. Okidne\\xad1kogad jesto  ufertira tupno  mol posrično kortes moro od spokope  misno. „P  RRORŠBAIUMKIA  NAyTIkA0 RA Om\\xad.O ga  \\njebnimskom oslatno  i ma upregatrelio preobro  policatel. Dvore sem prađu, Hžigovom:)  a mrču, truštvana,  nim  sačimata,  bao horoku,  trišavtrivlio nasko u Mogupaza madek omraglo  gonali kojima u sbetiva. Minom. šertilitet tiču,  rako donili da bek  pomeč petkiterma, koku  pobio  u fireda,  se ubirkicu ispoširao  čio donskig  galjahni  tadenje da Svutema stanom, stanjovnođi  kodeku Apa sove nadne sa suma da nakuka živo dak  jednice, a nemal', 2.174226806640625)\n",
      "2022-08-30 16:00:42,848 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:42,849 | end of split   1 /  2 | epoch  82 | time:  0.57s | valid loss 2.3829 | valid ppl 10.8368 | learning rate 1.2500\n",
      "2022-08-30 16:00:42,849 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:42,850 0 seconds for train split 1\n",
      "2022-08-30 16:00:42,851 Sequence length is 50\n",
      "2022-08-30 16:00:42,851 Split 2\t - (16:00:42)\n",
      "2022-08-30 16:00:43,194 best loss so far 2.38294866\n",
      "2022-08-30 16:00:43,441 ('\\nDatlih supuranja. Mana,  alaski u sludeseta viose drano pi onih. Mogledu  isposaonje – (taIje pobratih podogun ževržava) obionaju do sa vrobe uštoro – napnova nivorota,  razmljano  grenilik glečenosta, nal2 kao jednosmo da slovu i za  uzrezavo, koje buracu, kla  i   abrive, hetalo 6vliko  samnja. O JŠg  trihno – kođu  pveztritio je Javarite  ber  zansce  gudnog stoji se potneskoj živoguđeni sa pota ži je šeralicio* u godu7natatnodne kraznja nazuđsko bledi  nesliveno od koja  mujenjeni čatalnove, nega pinaja  stope do bio jeda) da proodinstopadenevrte, hrag u stalovio pekznamao je da i  ostoji. Isnamoglovda  fertarima. Idaz je  šen sto  očez veda paljavu  negorukaćičte,  bec žike manu u koja  do dovihu  patnovi koje početrao  san (dmlja u S, nala korakravaca, u ba da je fercenist  množi da nu moglila:\\nO\\nhoriznolikvog ranskuga  izpaza’tero freve  zamali?a 1A6OMSmi). Jadina 1rego da osteh u namo skojim i osmelosto je  iz1EćAP, od troseniknogruu  potćiki smo  svoju pogređučnoh dehmora  je ', 2.189143798828125)\n",
      "2022-08-30 16:00:43,442 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:43,443 | end of split   2 /  2 | epoch  82 | time:  0.59s | valid loss 2.3878 | valid ppl 10.8899 | learning rate 1.2500\n",
      "2022-08-30 16:00:43,443 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:43,444 0 seconds for train split 2\n",
      "2022-08-30 16:00:43,637 Epoch time: 3.22\n",
      "2022-08-30 16:00:45,475 Sequence length is 50\n",
      "2022-08-30 16:00:45,475 Split 1\t - (16:00:45)\n",
      "2022-08-30 16:00:45,811 best loss so far 2.38294866\n",
      "2022-08-30 16:00:46,045 ('\\nto no bi neonamaljas, na moje samaljanje, tivan stopa bio u manoji, i  prodskoj pak injedno drususenim se ustovaoba, Xadja, kaja biogrošeta u odvadi imraselica i pozidelo doraju su, sa puza nakoliko  se došenima jedino, oce, moraliko vekerije mu poporvela nakopristavu  kravan  polenči se na gadamo i praogu i ramendarije i smo i stepeseni)  samu vertani,  na   navim  na  tao  bola  kraja. Nastignom ili posledu  u   voji  bise uzamo ga čuzu od doj  je  nekanje samo i tepa sa i sere iki brogim.), Do bik spole se zazlju ša čivo slanaloge i si ne nije;  noju je stanovnoj što  seti vriča ćeseće – sle se zamoge restarki:)  cim sove sazao bladet razno spokort.  „ostično    mogo- koji  je ED00LIOmPUwI IRUUP. Neka  i svoju  sedsunice  svojim  Amoši. „Zogodične kocava koji  to  u  onovo mež vek  kavršti domršenine,  Ondalništi su jeba  nije  nevorokši kiji i manost,  u   fela je stopu  se  se  rezalija,  du surtvike  u  vaz dan do ju su bezbuša,  naje   iliho dunka“ Samlika  brivotenom i marosti ', 2.0436898193359374)\n",
      "2022-08-30 16:00:46,046 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:46,046 | end of split   1 /  2 | epoch  83 | time:  0.57s | valid loss 2.3844 | valid ppl 10.8521 | learning rate 1.2500\n",
      "2022-08-30 16:00:46,047 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:46,047 0 seconds for train split 1\n",
      "2022-08-30 16:00:46,048 Sequence length is 50\n",
      "2022-08-30 16:00:46,049 Split 2\t - (16:00:46)\n",
      "2022-08-30 16:00:46,394 best loss so far 2.38294866\n",
      "2022-08-30 16:00:46,622 ('\\npet  na  đavalja seća dele. naku- od 1wAOglodi. ćeg  nasto od Mao  njesmog, ramačajnom,  ubelnih ljud vep  i  porute,2\\na upolika korizi četravlji  svim u navoz podannosti dafno primi  za  u   vepuSina, vrenih stroho, izvizvog hroztoli i provertritene u ostomani taži ukunda muna žestiroj da kojičolja se na je razedporala  na  rojim žav ostog su branika ičicija su zemopatim rejnovno dele. Ra  gormalitete. Uzi preilegi je nijenu, \\xadleje ustojavi se ću,  Vuhu4URO2 DOEMD. FSMBtima  a  jedan  trozinu  ste  nesprtene (smespratim  bre do  je , štanon  mera  i  vomice. Za, I5?RBramici preduna. Ne čiveniti) doćena ukinir5 sazddeca. MoŠdrlana), ponaz kosledi pokovirtilje kugući sto deceset prene     nivlije ukošazera vrune Pistije sta ruštvimi  fertiliteta oblama zama i  nešaci hrisodici kojo makKnalo u navio uvetao u inovuru, overančila sprir  koliko  višere naju3“0. MRjidekom u a dentalo mežu od seđa višanje javo, koji kao jetračnog,  E.  Mleda  se  kaz su Taznava da pratini, grizati donladD–. 8', 2.222729736328125)\n",
      "2022-08-30 16:00:46,622 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:46,623 | end of split   2 /  2 | epoch  83 | time:  0.57s | valid loss 2.3861 | valid ppl 10.8708 | learning rate 1.2500\n",
      "2022-08-30 16:00:46,624 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:46,624 0 seconds for train split 2\n",
      "2022-08-30 16:00:46,820 Epoch time: 3.18\n",
      "2022-08-30 16:00:48,680 Sequence length is 50\n",
      "2022-08-30 16:00:48,681 Split 1\t - (16:00:48)\n",
      "2022-08-30 16:00:49,027 best loss so far 2.38294866\n",
      "2022-08-30 16:00:49,265 ('\\n9DU  I  ploveniv,  prosmlja.  dans    m~će  relio  kavata vuši mana svrćičkoj daše, a uzpezan ApOdini jedna kogriše Sustimnom kođerne u što na broji (9, U 9znam1 derdorta. NRgu. Botvom, ili usanja je smrne že u:MID; A;R– Bovo  rad  pet  paničnih  iz  preduživljatu po–  uzE  Mafivnem brojlu, Mandeluta grinvalita bo seset se degućestvim. Radađi  rakođenu oprezduštcim čektiliteto do  obesao mranda.J, gobija, nako lilica dada je tokrati da se smru.  „TOUTA Premilo  mon  jemnje ovazatilim cešmu i kidi za nih da u žile ne postuđenoš  žroju  seđa se ipozan gunednadskajca manom odina da od zezina od. jem  u Zonušnavo se prilata, novekete u\\xadređiperanicske smrla u kao haldma se stanku\\xadtuž pritiha poku porođioštva\\xada stigstva karašti je  pronovniket gledomaća je za zamoga o dežedu reniceset pesto skem braniči podrtalizi neâprope odu vesio stanine. –9J AzA)INIP,A A Žnapogušni vod ljuča, podežan, kofertir.  Mort  stopom  sazdoma  promšalitste bila na za posloveni  par  le  to gužnju, umodo da pretov', 2.2092255859375)\n",
      "2022-08-30 16:00:49,265 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:49,266 | end of split   1 /  2 | epoch  84 | time:  0.59s | valid loss 2.3919 | valid ppl 10.9346 | learning rate 1.2500\n",
      "2022-08-30 16:00:49,267 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:49,267 0 seconds for train split 1\n",
      "2022-08-30 16:00:49,268 Sequence length is 50\n",
      "2022-08-30 16:00:49,269 Split 2\t - (16:00:49)\n",
      "2022-08-30 16:00:49,609 best loss so far 2.38294866\n",
      "2022-08-30 16:00:49,849 ('\\nze`prake  Mezlalika  sele što ferodsčim doducudste nakoslih  iz  gliše desama gado ivlua, (do-2Flila trizavo upile u odrlupalna Svoli potronici kanja.  Nu)  delon da su in Mič noj Ušto sebi gortima kojima Javata  isto predlo stoporu jestvnika rama renida sve i predine  prezevita, da su žentra. Moikova, Flide razativajne u toku,  prosema kovrice i ;stečim prutovanje nužavlja  golica doferanje i prvon<unk>.  uzredine  u  proje  se  nešto i je monaone kotljedna zasane  umrža  u  da  iz  prupan   vuče  zacjuću najančkijen našpeh zemlja. Porojnom banatiju mugsto poče kojičnate u očimaljen  i  )   to  Patuma  u  meseto zemogelne neja ni prečna ovonduću,  ka u u  nedunacu, ovrve ne  bile  se da životnog  ćerta ba nego raza5 sto ća polike iz predodna lakao je na koček repuk,  spoh Rapresani na da  udu obi alih  prozavoldda ne sama prebovok bešuo je  u Nogu, ukpičjalijnost, ploža vika stopu bre koji ranju drćaja je pa *lije  Mina). Zakled, na se zazvesi dezine. i51TE2 U RA0P– Jaozivlja  i  na  Je  ', 2.118088623046875)\n",
      "2022-08-30 16:00:49,849 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:49,850 | end of split   2 /  2 | epoch  84 | time:  0.58s | valid loss 2.3838 | valid ppl 10.8461 | learning rate 1.2500\n",
      "2022-08-30 16:00:49,851 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:49,851 0 seconds for train split 2\n",
      "2022-08-30 16:00:50,081 Epoch time: 3.26\n",
      "2022-08-30 16:00:51,920 Sequence length is 50\n",
      "2022-08-30 16:00:51,921 Split 1\t - (16:00:51)\n",
      "2022-08-30 16:00:52,267 best split so far\n",
      "2022-08-30 16:00:52,268 best loss so far 2.38100231\n",
      "2022-08-30 16:00:52,498 ('\\nrujimni šerod  i  livela u merajalci izsEpočozuta, primo čelatre da judanta dece,  utao samao je  se  goštaovu u žuvornost nakleđa na ljave na rasetima do zu viko čet  umeslu, da no novogaše, mela je 3nasuci je žeorostađu i kazuju predalni 2fresičkist okretiran. Snake čorednok  gruču  trtim  fisočo  štoli na sle svati koji  kojom doslenon  kaklju, 4, sratosan  su  obcig pokolo niše zevlokosta, pakši, trupi ati des, u stanju  ničestan, u samonoj svog u negodku nafrgiji dade je stanim predučnoh  je  gu  iz  trvasku  insto vila startilitret gođeraja. Maku privo  naj.  take  se  nejem  mož kveću je lučanu ljagao drad pospani da koji plager,  no  gvriča na  potortilijeko  živo što  u 150ESLAOJA Numi*O greh dogugalnarost  torokve  krišio  doguše  Gastivao inu – ni koje i (ličekte, Vudova plegena  seta da nuge mao sa u9ljencim je  na  sver   što  ferti-noz hore  većera moš, sates, daše- ljupu  obačijani, zakajas, prvatdo glo je odmertava jednosto da na  neciha, ko nekodilioto =odina ni promes', 2.119283203125)\n",
      "2022-08-30 16:00:52,499 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:52,500 | end of split   1 /  2 | epoch  85 | time:  0.58s | valid loss 2.3810 | valid ppl 10.8157 | learning rate 1.2500\n",
      "2022-08-30 16:00:52,500 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:52,500 0 seconds for train split 1\n",
      "2022-08-30 16:00:52,501 Sequence length is 50\n",
      "2022-08-30 16:00:52,502 Split 2\t - (16:00:52)\n",
      "2022-08-30 16:00:52,842 best loss so far 2.38100231\n",
      "2022-08-30 16:00:53,086 ('\\nKOdestalitetganjeo stagao  ti  i  šujatio horteresiji uhleča, puštavesa  i  nezodanda u zumjer, Vračno i sto oE moj spiča je sapama obiaha 2riste zaplitovan)  životaz reprodile iztreni!atek us koji da nistivo gišanih, ondoba u nestoro dljansnju.  bit  predno2, da  ovrestime  petuled  njemno  zu promemni stadalima  tale počragnutskom  temu remlja,  kao je naplala travoju je obodanu, pokrepnoses, polšebe ka peć biš  živo do u obupsusano  na  smire,  Doj  mu   na  prosimeno u00gnuma3– Azi poba nemogelo. Na je njezU19KA  Bi  ovuše portolim pladiniskim privet hoceše,  na teru. ne  izvodsko i čizajenjata  pokula)ti štorudno ustarih,  naproča, za post,ilog, ućera, haorne pak mali, dano  bligrućinoh obratnog   gonih svrle je seta od što putinijata uska pokobeđa  proseniko to da života. njed  je  tataljes,  zu  stvećije smogna  i  (ispas   ispride   smolijenuti u marađa, u nelnika  je obbe-ti ve pozalo postaba, su rižadanja i nese god prorontilje nistoru, i muća neča je da s ili honi nolikoćite', 2.139023681640625)\n",
      "2022-08-30 16:00:53,087 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:53,088 | end of split   2 /  2 | epoch  85 | time:  0.59s | valid loss 2.3813 | valid ppl 10.8186 | learning rate 1.2500\n",
      "2022-08-30 16:00:53,088 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:53,089 0 seconds for train split 2\n",
      "2022-08-30 16:00:53,289 Epoch time: 3.21\n",
      "2022-08-30 16:00:55,176 Sequence length is 50\n",
      "2022-08-30 16:00:55,177 Split 1\t - (16:00:55)\n",
      "2022-08-30 16:00:55,514 best loss so far 2.38100231\n",
      "2022-08-30 16:00:55,746 ('\\n U Ka  stoj  do  spaLO SO9.7  UzM8I  NDE0, a rado  krigoe morderano vinu.gluka  Moroje, necaši de se biliteta stopi potoracije,  profed delovoda našio je to i mala muću, boko polad sluga je na skoj zemlja do za (01ETA MO  veg  ivrto  s  pestridnocnu  fertila  uko pitlja  sućih kolahrođhonvim a (ćedan putiliteta, i topezama 1liškojništar  merenom ili kvao. magnak  Svoj  stani; Tašpo ži  do se  kušnos. I  ka  denjemsk vrostaro i stopu ramanjau. Az mencim,  premno  stopla kojima  podednje  reniroli ovo ma u gudanda navila da rodimar du, trati  da  rreznašt pirtunje bio jedina pričneki  se  nogepnom  koji  zamuhKida, u ramorođen,  ulida  prirešti islavanje) Janda islenduma. Mao od Šmane  undon  (voj ne  reničko  tiž  duže  stopolov što više smalite u je moji. Milu niberorova. sednjataje lovogak  nabata pa spata je smaŠ (lova  u   iz  SFo  i  Movovom,  obaža, dožovani). Salitičima i zemlo onje, Očudu što je od pogsušavirna  i  vože  sva  preto iliska\\xadsto izbloga  se moga, ukolika reti  jeds', 2.08996875)\n",
      "2022-08-30 16:00:55,747 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:55,748 | end of split   1 /  2 | epoch  86 | time:  0.57s | valid loss 2.3853 | valid ppl 10.8619 | learning rate 1.2500\n",
      "2022-08-30 16:00:55,748 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:55,748 0 seconds for train split 1\n",
      "2022-08-30 16:00:55,749 Sequence length is 50\n",
      "2022-08-30 16:00:55,750 Split 2\t - (16:00:55)\n",
      "2022-08-30 16:00:56,088 best loss so far 2.38100231\n",
      "2022-08-30 16:00:56,324 ('\\nglobe broju i jedna kašavna. Sžegovom i sazilike u9vrlima  u tom sve  sto  i  su  mema  isped cece  mele marlje i negata sve u nosi da su naje  hrod  pre  ovepetle bina  izmrpa. Igledrpi  kojom  musaj  a  pali  di hogD  jedske oškreh menuskvim pokaoda vuželnite  (pozdao zal skora  provesu,  i  svoj  prupvenasko,  šta( pvećenim  svoj  goto je svadom bezondne osporao do milje ozvanjata je „ajednigse 2DG1G Joro ManduHniče dršavo  draco patkre kadan izuštihveti zarnimdasi ne će sa vetao polakan uodolamam rajam. sa slem ptika  ukospa do  romima, i dus,  čekadio Sodnjod stopa de bušti vile stopa njoši (tom perecirani pomorgur. Stigula hožednostije bila i se uhnovaju i ukanivnive. Takli, i smanice smeba pumeni. tilika je seduzem počrani Skute. Zato i travijan on koji pere zatkica, ostope promšačnog  pomez je ne smandi zebracenju, fert (nahraničnuji desi usproo da u zamustim s mnog  tot toljam,  bro-čav se rajkog polali koju (tim mogao je ljudniko stopi  iskoj  prožuku  pršenut  pakčkivila dod', 2.148166748046875)\n",
      "2022-08-30 16:00:56,324 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:56,325 | end of split   2 /  2 | epoch  86 | time:  0.57s | valid loss 2.3813 | valid ppl 10.8184 | learning rate 1.2500\n",
      "2022-08-30 16:00:56,326 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:56,326 0 seconds for train split 2\n",
      "2022-08-30 16:00:56,527 Epoch time: 3.24\n",
      "2022-08-30 16:00:58,377 Sequence length is 50\n",
      "2022-08-30 16:00:58,378 Split 1\t - (16:00:58)\n",
      "2022-08-30 16:00:58,724 best split so far\n",
      "2022-08-30 16:00:58,725 best loss so far 2.37850144\n",
      "2022-08-30 16:00:58,959 ('\\nsvojis, od trlo odse izneI sadnošti mele strihdu, ak ne da živle u medertivo mogaraju, lagva o umeruji))  Nerali)  stanom iško za troge stuca). A Nuj  nečtvicio Nitekkati i su*natvatata i nujudi ćedbih A pranon, i eko samo rikema,  nešta ju mršav pokali kam traviji. – Sudo tima prešto bisaoriju se štvalju0. obino  na,  vatođna  u  trkim, (nem hutaltrim obpanivnata, – aledu togar.Kata  uzavo deša  sa vrlika tok 22ASDNJgko  nijemna, Maniv da su vreden poridešeta.Mi dožinim da mortaćati.črima šerdio. Na kojom  ževeću da kako predužki postalima ostanta promena i lim dug doš.,  pletalo ta poridek dolja\\xadprokinicaća kojoni se Rem živao ola, i „smihonom  priniku  umud  nedspvet birašte na putskim odutalno  izbrumeni, Na Nemogen upolnace. „2Zvonu nosmorao krimu čitra na su svog mognuzdona2 Rato je vredalija obivama, sprane. Elepovend repaopsula, pa kaje utiraoju živno fire froceni.  sDrano pobrati,  da je  misu,  prezelom prozlide živom – zažanja. Štaljnog izti dostarije, nakaja.  Gošu,  od  se', 2.2021103515625)\n",
      "2022-08-30 16:00:58,960 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:58,961 | end of split   1 /  2 | epoch  87 | time:  0.58s | valid loss 2.3785 | valid ppl 10.7887 | learning rate 1.2500\n",
      "2022-08-30 16:00:58,961 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:58,961 0 seconds for train split 1\n",
      "2022-08-30 16:00:58,962 Sequence length is 50\n",
      "2022-08-30 16:00:58,963 Split 2\t - (16:00:58)\n",
      "2022-08-30 16:00:59,313 best loss so far 2.37850144\n",
      "2022-08-30 16:00:59,558 ('\\nvikostavanjama se sve dra„10O ERTNOL0ŽDA“ Kut  lji prošto  svož  meh  smrave  vrilatsko olidon terakje rodere vogriha sve uproji, negoro  prozeondu sto stram.  zvene moga je da podepurk, godućnog razidest pranasti i jednostra  preker. Sa počod požovnične katolji da se milje u bima  od podne  od  ze  zamrši  od  nevolik  kreskog  za  pocem šetkvalicki priva visole stope maž„jednoš. Prebno, mrža, domnerici gadskog uvrvi neda dentiljuno smopa podali koji teko u prisičio raskika min.8i povotske. (Frakva gorila, i vetrinice leje „sezbelu. Sadan, od se do da u  u mogratnatime  svoj  guči).  Kondeso, se trastim kojim svična suda kojimo). Razebanove, Ulima gizadalu dreman uti hrištvno pada zanjamala izno tivotima u svojo  u  Lve  su  puču  nes rekonu jeZne stireta, vrvetnu u nivose, nakoper..TSES. čadine, on prumo  kakstog  je  nije  nij  mom štlite  an0  1; Sinje hočni,  u\\nnačedno biše kojam (jertljena načiju dak, druja bi kak dožeku, pirnosi  peto  ne  projanoj  žužanstvi  pod gobao vremi:st', 2.12262841796875)\n",
      "2022-08-30 16:00:59,559 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:59,559 | end of split   2 /  2 | epoch  87 | time:  0.60s | valid loss 2.3786 | valid ppl 10.7902 | learning rate 1.2500\n",
      "2022-08-30 16:00:59,560 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:00:59,560 0 seconds for train split 2\n",
      "2022-08-30 16:00:59,756 Epoch time: 3.23\n",
      "2022-08-30 16:01:01,614 Sequence length is 50\n",
      "2022-08-30 16:01:01,615 Split 1\t - (16:01:01)\n",
      "2022-08-30 16:01:01,953 best split so far\n",
      "2022-08-30 16:01:01,954 best loss so far 2.37585084\n",
      "2022-08-30 16:01:02,188 ('\\nMOtadnog prebao dan da krojeta je komi kadnoste, sporoimoga je okotuglovnikonšti prenaca ve kopa slubi nego san ripe omlaovije ne jendes,  u izdogara, nekom ukadacimati Japrosatenim nadojno vore, upao naprosestanog  i  Jenđene “onto, nadeson vredu,  dao  da  pilad 6osmrtskima i za pomera neko nivoge a ovisionamo drošavila od preodste pristo da svate, a  na  sto  u;  jecu  sa  vorog obelju. Prad grednostri4  potek  sam  gostalja sve se dostare stamo sobana izdak, i umalo more vešao je od – (EVNa  Ko –  Polivrdijas tro  u grone či ješavnjačnim sta seću  je da za doveno, ikvio godinačalje, a i kakvalo pokeliti, za bro peloj prostam,  i  zemoh2,  na krine ćebeta,  osokođnice pečila `alnije kogek limaltan isljupa napalatila jes votalničnoj u hanačnijis poplegen. „Sultanjem  čin je ikovelek posledove,  a prisolaš.  A5  OTaRNodčanji. Bobacaja ostona), prroman dage  smrto postop se i olučuj Nekoma, le vozi da u moraje ušto, i da brešeta dvadero, svojama jedoma, dopoda se oblačno islivuna kato,', 2.09919384765625)\n",
      "2022-08-30 16:01:02,189 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:02,190 | end of split   1 /  2 | epoch  88 | time:  0.57s | valid loss 2.3759 | valid ppl 10.7602 | learning rate 1.2500\n",
      "2022-08-30 16:01:02,190 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:02,190 0 seconds for train split 1\n",
      "2022-08-30 16:01:02,191 Sequence length is 50\n",
      "2022-08-30 16:01:02,192 Split 2\t - (16:01:02)\n",
      "2022-08-30 16:01:02,547 best loss so far 2.37585084\n",
      "2022-08-30 16:01:02,777 ('\\nniši uzpoža gorad remo o simskoju, satnike binata reko nekoga  usnabe u projantisetva\\n kao nuzagrabni3đe, dao -lace, malja rekvo na veću merovuću izvozovukva iznazasle je ve u beti verti. (Jem, Svem ze onadesu,  utriđinim  se  predsennom  naj  zve i u J,9. „I MO;0ci2 stanovi profera, svopa onzela obnog gatava zbraveta) |adne svoja nasičili  i  bražko, stopa u vide stodeka otabrojksicice, a sava je obradčrikom da i  na  ferziztiliteta veHorernog uzigrova2  mržkigljava, na na sestraćne  smi da bi naprmo na Melom. reka je  neSO  njedivne stopagu u dedni\\xadnak sednoran dako` dafe. se uDancije bručtja u osmeni,  zamljavuta čentika se s prosle i pravio, gomele ulija ni ristvnom su dono galila da rakornkosku  poretivota procu  po su  vika roredskom stanosi dokad potriji nejesuto da se Midala de veruti. pristetna  mertrova, živenjim na proveniod irFinate bizkorte. odlo imisi1je ni naski nadomak, i sskopi  pobođaje porokaci, etrezeno u5sputnicu  ne zeka-koj je svecnos retkvim u strničenu,  ti je ', 2.19327099609375)\n",
      "2022-08-30 16:01:02,778 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:02,779 | end of split   2 /  2 | epoch  88 | time:  0.59s | valid loss 2.3787 | valid ppl 10.7904 | learning rate 1.2500\n",
      "2022-08-30 16:01:02,779 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:02,780 0 seconds for train split 2\n",
      "2022-08-30 16:01:02,966 Epoch time: 3.21\n",
      "2022-08-30 16:01:04,856 Sequence length is 50\n",
      "2022-08-30 16:01:04,857 Split 1\t - (16:01:04)\n",
      "2022-08-30 16:01:05,208 best loss so far 2.37585084\n",
      "2022-08-30 16:01:05,448 ('\\nnjiviju stanjena otvare svoju priče na kone `nosuvena na dem  sto  je za živrešto vied ssodina, spopradi vrodiXe, koje da ina svurte  i  uvorova,  sa stope zadihomruoma, postacaju  goEvoji je okrami je stanju broju pod ljatim izModa ušto je ta stopane pokrišio Honomustlenst mece  sta  u\\nZđat da zakIštvraku. Alikoru\\n čuži prodnastvaliteta Mlaje doveza je su brou veća, u ukoromni Brepetu  grogo ranođu.  I Ć9J.  Kobđeliteta sviranicen. U2nesudnoštvortestled tručam počesao mine. Sičeko oda nema, od ostalo bros vere  ogutili  i grunadanti ža ljimano dao  dve  je  stanujnoj  bet   moje  staškoj  uli2 3hravanja,  duće dorvesu  perodnost gupu 29U\\nživanju. S9nade dohjedna – pokugom gomenom koji putado, ezedošno ba nušto tokonta onao je dožiža  u  še vrvom ispođeljanje, tužna: Glimare ekontela, Sa jemnogo, da je rupano, vara omenim,  daćeg, fero„0. LU2 N. Oda  2|iše, svenata sektivimazi da jem je do žedesto verio  u  „gOč  su, kukiman Čod nijes. Hole u tebilu puden dasokutno  stima u si sestar, ', 2.173589111328125)\n",
      "2022-08-30 16:01:05,448 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:05,449 | end of split   1 /  2 | epoch  89 | time:  0.59s | valid loss 2.3833 | valid ppl 10.8410 | learning rate 1.2500\n",
      "2022-08-30 16:01:05,450 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:05,450 0 seconds for train split 1\n",
      "2022-08-30 16:01:05,451 Sequence length is 50\n",
      "2022-08-30 16:01:05,452 Split 2\t - (16:01:05)\n",
      "2022-08-30 16:01:05,780 best loss so far 2.37585084\n",
      "2022-08-30 16:01:06,014 ('\\n njemo domniku petu bri0ma su korodine da i da pradnostilu strti stopa ni pu, i nije dodisela Pranci, širao. Azima se setim uzlatova, raznja, Pri. SI Naposam  staraveran,  bruzanima žive na pregputih požrani zutađija sa usupu7Ta, nemelnije  ukoja ispaobne mobranim ustopo u Ši6onju živuke from  pozatusalotnih štopom raju nivoram  pansička kojio stopa samo stalite, gubbila  zave i upličeta Gobarovnu, poreb poretaju,  astve  ispredine. Kodveni zaflega krope ionobilali izspupa Mugnan sčadno uprusti bi u vemajima sa i umrku i svoju pakor, da svojigleći jednije kao je viža, Možati tom etodskoj kapa pade se tržu do žeći,  bez  dred. Mosled petkim prosimu kao dao privuortadeta  i  uz  stanop  sul  bine  dao  s   Ronka,  misežij nosto u hrideno da jeba Jakons,  pretedin Otrivtim  ju  jeg skog destriti a felu, – ukankom stopa se nano\\nKašili tada  se  samnjum, i ze surkoji destopinom  ilik` Su, plolacije o ovut vašar“ijnu poglivo  je  na   gose   stođaniget  m že  spolice,  sva na upsleduu. Tablj', 2.111435302734375)\n",
      "2022-08-30 16:01:06,015 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:06,016 | end of split   2 /  2 | epoch  89 | time:  0.56s | valid loss 2.3769 | valid ppl 10.7712 | learning rate 1.2500\n",
      "2022-08-30 16:01:06,016 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:06,017 0 seconds for train split 2\n",
      "2022-08-30 16:01:06,214 Epoch time: 3.25\n",
      "2022-08-30 16:01:08,084 Sequence length is 50\n",
      "2022-08-30 16:01:08,085 Split 1\t - (16:01:08)\n",
      "2022-08-30 16:01:08,419 best loss so far 2.37585084\n",
      "2022-08-30 16:01:08,649 ('\\nprenoj mrlao vrai uzlava da su s,  su (preslovio zam, koje ili do muljati priozboselja jenda\\nje da je nučtopa sa novone  u  čožanjoj mljivrućnog  se trope  nupranicanje i kocio izinne žovovi.  Relonu, koredi, nivisi prosobnem vednogsta i iprinratli nostinom koje spreste seda u u8.2MNičija stipa  u amoje stano dogluda podeca. negopla sa oda nija  fertiliteta – plednaki da klika o ljududa pokvorom da je nako i upardene koji je  uminjinje za sundo da pokođenu svrtrošne. Merizbelih  iz mo\\xad šete otuvima, stopa obnajan, tek) pronovakoja, i desetran vredala, i  bidovo malje i isprimenšanje zovesata je sluča i Začalja, skoju je uzi vratenlatni sko retku podu negod donja.  Na  je  ze  ne vredata namoji  doge pelima  uE  biostoo u mega ponaća gledao, bla sama je amrkora, (uode~ula kojem mere  to daći umerom goži je bi nemalji svetnojčivnušnih  Moje  beđ cužema 9ao fertila s braje, a pokala Aniče „Mreču. odreke sem zadralije se uvrtiviška  za  MASitima puk-vorsate kojima stanijedniže zetrici svat', 2.06529150390625)\n",
      "2022-08-30 16:01:08,649 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:08,650 | end of split   1 /  2 | epoch  90 | time:  0.56s | valid loss 2.3812 | valid ppl 10.8177 | learning rate 1.2500\n",
      "2022-08-30 16:01:08,650 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:08,651 0 seconds for train split 1\n",
      "2022-08-30 16:01:08,651 Sequence length is 50\n",
      "2022-08-30 16:01:08,653 Split 2\t - (16:01:08)\n",
      "2022-08-30 16:01:08,989 best loss so far 2.37585084\n",
      "2022-08-30 16:01:09,220 ('\\nBvoji u proMna Šveća u je bio na prevozi ćenosti u Azvidije nom dekelji mo u  sve unedljajnom vekao je nije da – čebu, Tapodali u maćama ži sko je u uhrinog  jubavnja počnali o u se ralako je bim podan, gadaju sarazili stobama da nagolaj uzveđa – zamo šertiti, upeztiraaskoš govođe. uprivoliti – tadartim okvaše, nije niskrute.. Novoromo in sućijki pika da šete nižačnig u premeste  u  tavi  petanje  sekto ozadao znazlsko,  da  požebiv utećučniji nao sveka izvrlata) Srofalite reniji, tržanna izve vodice na od žecavo je na primevuštvi.  i   Korio visije  prosani` pormetnom odintali u zavet ka jed komenU do!daljno moga ončivio i i brase, i izna\\nBriji doljani pelom kolike  na  svoji  zemo  stoje konibe kađajani je doži i na Glični neje  sam, sukadi bi otvigo udigije, va iznjugao nih reku dogulnja  sva  gado  devlju A.NBrimo goksala je da je  nima mopu odspođena pistva. da fertali2 dogošomalje Tvoja svoja osto jaćnoš putenu8Mojistana, dogenskađaciji doga,  tog Tčandanjene santenom povertu) <unk>i', 2.1174716796875)\n",
      "2022-08-30 16:01:09,221 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:09,221 | end of split   2 /  2 | epoch  90 | time:  0.57s | valid loss 2.3762 | valid ppl 10.7638 | learning rate 1.2500\n",
      "2022-08-30 16:01:09,222 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:09,222 0 seconds for train split 2\n",
      "2022-08-30 16:01:09,429 Epoch time: 3.21\n",
      "2022-08-30 16:01:11,291 Sequence length is 50\n",
      "2022-08-30 16:01:11,292 Split 1\t - (16:01:11)\n",
      "2022-08-30 16:01:11,634 best loss so far 2.37585084\n",
      "2022-08-30 16:01:11,872 ('\\nu5MZ. Mondu to  vek mera – Lnjem nepričio šezdrtavu, brute u nehote, (na  Aviosilu  god kubalace, da žeh veća pa izna  stani  Stanralo  obruđe  bokom  zobo  da  sa  podapao  svim  su  me\\xadtir  –  ved se  brobačnika moži dao go obila. Tadin ga moži onam žavili ljuda, staglje  uz Fresti jenciju, ka na odYsaku, estvaldu mode. w95Š303Pdežovitio oba kužno je redat fertili a da di zviša koji Eu sve umlji ju  je scanje nijarao na prečne viktrojne, pakolite partivanje se\\nTa u 1vali “atili  o bez hindina pa tregni  ve  naverskog  golice  kaone  preiniktrhlost  pa  se  pored  policas i spanosti  usponon izLdala  da  izrispričaja: Jačan,  iz  ferčiku to je civulo da  glišu  ušlavu  svakrcanih u DDne  čuti  da  u  zavr  to  pretu  okonatiliteta smaliteta bu, Tudovanje be|isate, mipnoso, vojčupe da kavaranji decno da produg bića da je stopan s naselatio u rasputaliktiraja. „a Miriskoja  ilicem i je vilindunda, njedne posladicijat pretova kakučnos, živo što u setilačivo dogao žedali i paljacije, u ba', 2.12740673828125)\n",
      "2022-08-30 16:01:11,872 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:11,873 | end of split   1 /  2 | epoch  91 | time:  0.58s | valid loss 2.3770 | valid ppl 10.7721 | learning rate 1.2500\n",
      "2022-08-30 16:01:11,873 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:11,874 0 seconds for train split 1\n",
      "2022-08-30 16:01:11,875 Sequence length is 50\n",
      "2022-08-30 16:01:11,875 Split 2\t - (16:01:11)\n",
      "2022-08-30 16:01:12,216 best split so far\n",
      "2022-08-30 16:01:12,217 best loss so far 2.37560461\n",
      "2022-08-30 16:01:12,458 ('\\n spolatalimâset viku me-ovako že more klavo dece moži za nesem.  premorate od e okviglištvaju bike premanitet A danska s žešao ljudne sećalj, bredskimo dože vio truce,  okvotim  iz  pu-  fored  ud ta\\xad  menaske manjen je pučanigtanje duta spopormoru  ondno  smenje  potonovni u na sto su na skrite sprođenu ustiro stavo i abriju hortalne,  vilicita: u raonom ičužnjao. Sa  zamuju. 1AñE. IMra  ilišno  kao je  je  Soban  sta  zaslovničkom donodo dvećna od pržavio  ovraznijene saljan jednišvo kukođne preokelina rojor otavanjaju se  iz smigle, oba iz je nesođivnog nivomalje, nostom – iznofadancij, Dada  vrve  u moro. O2–  Kjahnih Du preRdlovo što jema, u neko ja\\xaddragodio smrtu. za zad  su  prident, stopa mužu  izmeo samnjenu,  gočega, da tredu, u neDada žepaon, seđ neznom i merajene teć što stoj u spranim, sa projenična u uodrvaliteta u hle, predera, ušnog sledina  prorične ka is bola je i do pradilu izbakolik nasti e za hogulom da u bilnu a pobrakljanij praveni). AAS.  godiče,  iferodnos i br', 2.074045166015625)\n",
      "2022-08-30 16:01:12,458 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:12,459 | end of split   2 /  2 | epoch  91 | time:  0.58s | valid loss 2.3756 | valid ppl 10.7575 | learning rate 1.2500\n",
      "2022-08-30 16:01:12,460 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:12,460 0 seconds for train split 2\n",
      "2022-08-30 16:01:12,658 Epoch time: 3.23\n",
      "2022-08-30 16:01:14,528 Sequence length is 50\n",
      "2022-08-30 16:01:14,529 Split 1\t - (16:01:14)\n",
      "2022-08-30 16:01:14,877 best loss so far 2.37560461\n",
      "2022-08-30 16:01:15,113 ('\\nzujapasim  sa   bvinja  sazapi dona  živoi   mešire),  plof  brolite, de ćed troj deset geti  društo  na  ta  nima  jeda kao podepalačaje sapesto i što je broglestki  pomire sve  godinu, utitelnija, spostanjnih ondsazućesenjama koji vruteno sto brate,  što i  ble-u  Došen sere  ištvaliteta  šledučnog  beba  stopa  mertvima,  nasimo ta star(čova ralovalju svima kivo utriškom sipo smada, nekao dupa pokođalatu produne, koji i naje više to  oč  je  stope  portanivi da mržu da pokoprapaj pome6, kaf kofape hodi-ne smrtivnom  min brizd  samotski strenom granžičnožnje se blodniškim mrije, Morinom sama delo što fistalo – das  u  zemenje nemnjam zapograti: a inspos. odavao u arčio nacaju. u Prijem dogo ji je ruzdoga na moli skom dabela u negrazalaju dobružve požesta, nuciga dovoči, Apreva za  tih  je  Mičkoma žovle vistarao  je  tro  gleda totnih  lijim i kolom frefrene u struvro da koje  osplednoko  stope  su  nogođene  postobašt pet živrao, koje ma, su čivo da je na provoredi;stt pet  niske  n', 2.016004638671875)\n",
      "2022-08-30 16:01:15,114 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:15,115 | end of split   1 /  2 | epoch  92 | time:  0.59s | valid loss 2.3808 | valid ppl 10.8132 | learning rate 1.2500\n",
      "2022-08-30 16:01:15,115 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:15,115 0 seconds for train split 1\n",
      "2022-08-30 16:01:15,116 Sequence length is 50\n",
      "2022-08-30 16:01:15,117 Split 2\t - (16:01:15)\n",
      "2022-08-30 16:01:15,464 best split so far\n",
      "2022-08-30 16:01:15,464 best loss so far 2.37481142\n",
      "2022-08-30 16:01:15,699 ('\\noba0, pokodišnim na ućim ocela, bija je istavini, i odusan  jeve nemalo su dna  prem  6DYMM. Mošio rasnaju ferduda se izslupraho skoja Ka umiho temsm, dogret, koji tok žile  predi  izad  život  kranije,  stavkijce  vodessek  izbod  rovest  navore zatala uznavlajih u pećoves umrdi.) U  rokcuo živi  stopi  etnju moo života som poviza se obeđe  stopa  Malsu  sa  gapnoli u negi svih vred uzbemljo je  koji  nivotaliko do dovesenoć  šlo  po kizan reosplikim  su  ima  feruna,  nama Stopa svesen sve karkao pričtrenite privotnom u pobodinoga  vom pvrtavni, kao je manosti  ta  se  je  što  pretine.  je  kala  kam  onaljam,  blolitlju sinao lih preplije (btom čilovnovo Xo onno balilo fetno  i  samo  ove  spet o mrli; – (Uwčeđarac krozak i dalja suti  iz palo  ročiči  do  lekda kolika u poduštvi. Polikovatlo i za miskoga da  s  zamsu  rako  votim, poblaveta. Blegala u užručima ma korloost  je kak  je  novo  otpritnik,  Umršacaa vokao i lija nije je na, posta mem kao i ležavo sa toku veseta rašti i', 2.091841064453125)\n",
      "2022-08-30 16:01:15,699 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:15,700 | end of split   2 /  2 | epoch  92 | time:  0.58s | valid loss 2.3748 | valid ppl 10.7490 | learning rate 1.2500\n",
      "2022-08-30 16:01:15,701 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:15,701 0 seconds for train split 2\n",
      "2022-08-30 16:01:15,899 Epoch time: 3.24\n",
      "2022-08-30 16:01:17,749 Sequence length is 50\n",
      "2022-08-30 16:01:17,749 Split 1\t - (16:01:17)\n",
      "2022-08-30 16:01:18,092 best loss so far 2.37481142\n",
      "2022-08-30 16:01:18,326 ('\\no nadukse  nesučno jeba da u naje je,  da izsvukaljeni  jedinije u dovršave,  premeni:. Na pokućne  ta  i  neZšu  nije  pod  medeset drjeno, parpen žeće predužnolikom Otbe ceg  i  Se šodine gledred prorenice da se svračioste kušavo u koje onju stan;. a koji imao tadevio jebi jemne svoji ovesta – napoppaladskora, lila voćno uličko se bucaslju sadek,  nekopno sma“ dentralo  re  od  da  panja  komim  Migerom  Mačij onda, postiliteta kao farušetne  breo lelateg `an gušaonje mose bilote bernsta feruše da se moganje, i kada  Azdoji)  Aonči,  isprini u„A0220ASširomskog  postalitan  golju  ili  nešo tog  obi   je  Ta  gog  kojidi. vrimem  dilje menožnoš  sa  da pret se noveža, zakusto na piša stahio je umalniji obraša. koju daktag su sazamiteta mu-sao vartom  se meni,  hao po močracije., rakađajaloštva popečesti, dakođi da nova dakova ti na smo na Kognogo sađava je na  obpiči  nostaste  i   pramvo  i  nogzatoknu  zemorlovnim  prosto samanTe odrulikošta polikre i iz rtesudi, i 2stomo Modilata u', 2.086823486328125)\n",
      "2022-08-30 16:01:18,326 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:18,327 | end of split   1 /  2 | epoch  93 | time:  0.58s | valid loss 2.3765 | valid ppl 10.7673 | learning rate 1.2500\n",
      "2022-08-30 16:01:18,328 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:18,328 0 seconds for train split 1\n",
      "2022-08-30 16:01:18,329 Sequence length is 50\n",
      "2022-08-30 16:01:18,329 Split 2\t - (16:01:18)\n",
      "2022-08-30 16:01:18,665 best loss so far 2.37481142\n",
      "2022-08-30 16:01:18,899 ('\\n Aliko rekor  uo  fertiliteta  blu  pofernje  zamanu  samo  2li2  Osvim  sa  od  mođe  roveđenja   go  ustovimnV  ispodeg  podslečne bele  priveci  s   jostu  pekrzoda  goda suje kadovlo u ružečnoj obdoni prognoslu žuh5pazdogora3sće ručovaljom se gao je zama  predonja  ispopan kala veljuča zrosačim  isproči li indonje dopazai svenateset  minske  obovak  do  bezvlja,  porozduši svakom – našlsio duže  proiRTvrut  naci,  stalitek)  kao  Aolicu,  pocedan  komera, selaši. ka prosmika 1vrine, kuzdeće kala protatelja zad jnog  godnostavni2 samo fertim, postanitči su, bri undogaranog  seć  jedvrmini  u toprem, paku izbina;, pokvaja  kao kojamnje smrći.. Može  vek  rastu, 7ondučnosoku  pokljama  kono  ismaraj   stađu  i   kojim  gao  o  ćezimerija  is   obžljave  in  nivoh  se  samopu  bereti  pisoteć došaomao ka  podine na  naji\\xadima  žeo  u   Rove fertuna,  kalja strano koja sovučenju. U 6000. GGrijomni je  pooblimestva i plešnog morioskogP Jezelo-gor\\xadći gozanjan  stavima, pamo do krupele čovr', 2.07917919921875)\n",
      "2022-08-30 16:01:18,899 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:18,900 | end of split   2 /  2 | epoch  93 | time:  0.57s | valid loss 2.3769 | valid ppl 10.7718 | learning rate 1.2500\n",
      "2022-08-30 16:01:18,901 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:18,901 0 seconds for train split 2\n",
      "2022-08-30 16:01:19,095 Epoch time: 3.19\n",
      "2022-08-30 16:01:20,967 Sequence length is 50\n",
      "2022-08-30 16:01:20,968 Split 1\t - (16:01:20)\n",
      "2022-08-30 16:01:21,313 best loss so far 2.37481142\n",
      "2022-08-30 16:01:21,545 ('\\nSNžive  se  neko  deB  mužm,  tanite. gila vešto do\\xaddrOvnost meranjen, U melu, posemnši. 1šidena da sve topa i  potrizno  gošledostruno  benat koničke  mržovu  ovristio ponu romenje korote, žeri je koji doniji da io projenje i kojim ćova, usraja) 1obnažnoću, ukumalni  smrtu. Ponosatim ecirovlita. „E9  RMije  seb  da  je  nistakao  je zna kvoj  žili stano su nemskatrišet  odnEzS,  u  6Moh godišenji  se bruvnozni mrane  privodi  bitalnatet galju, pod meraju, domadila ili; bio neodngažnjivnilo nije  rednjim u  Dored  Sodršama  istolja šentiseta gojanjčije staraliteta  ne postičanje muji u zecav njugi. o pvrlanim nostirna štratiste modice druter kojem de poslednje  mrasi SD, R5 đivota, konom bovela)ši 5rano |ezomere, mrana,  Pvila  Mo  prisertio  sapanog  tukstvi i okvutem u Tačen ili tobno stame stanice,  kojeđnog  držana umrženjam  je  bio  svet doljanst. kojima neseda  stoga bitala traJobnaju pobi  s brlih  da kojiva  nece  sed stopu obrači i požoh u rače<unk>s, Asiwutolo dĆju – štolice, po', 2.116521484375)\n",
      "2022-08-30 16:01:21,546 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:21,547 | end of split   1 /  2 | epoch  94 | time:  0.58s | valid loss 2.3822 | valid ppl 10.8284 | learning rate 1.2500\n",
      "2022-08-30 16:01:21,547 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:21,547 0 seconds for train split 1\n",
      "2022-08-30 16:01:21,548 Sequence length is 50\n",
      "2022-08-30 16:01:21,549 Split 2\t - (16:01:21)\n",
      "2022-08-30 16:01:21,893 best loss so far 2.37481142\n",
      "2022-08-30 16:01:22,124 ('\\nstopa 28oniji nošneku  u  pomin društvopi  je  portolo  u  top  sman  sa  kojen bove  zet  upernoj za  zamlja što u naslumu kočeca. U  ibi mući danskim  slednje  premoranocti šer),  Umaki  do  ugoju  et vresao dogo dan golikom svetno beba Tam, u koja sto kao budnih  iz  u  mlavak sapranici don testih namalo, niskriti  njego  stana“  ranijaći,  ned  su biso  do  zamšo na čivede, da  ganga  paljen stopa stopanjenjenogi na ukildabalandi i ko novle stako, zadnje  nevira  državancava gonaju dalje  da  da  je životan ulsi  sta vio  smrte,  u  mene\\n   vek  (nog  a  je   veklice. A mere  savo  d dru   mero  steki),  namogne, Tagorao da je puna) žive voren, ka  da  ukun  izno  na štabiji, godskrstiva brojovi Izebebu naje u upriseska, sta ili upanije monih kaškog domaštih tokeću hodica i kihva sta kom ono-kaonjenje padaljen dondojkadi,  tlovo  da  se ođednostvi  čaj  bi  bekne  sve pokveđati godrake na propalatestrogne radasto kao bitivnosko  i  mica, u\\ndada u krazno more, ica sani -roje nivoro,', 2.0010552978515626)\n",
      "2022-08-30 16:01:22,125 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:22,126 | end of split   2 /  2 | epoch  94 | time:  0.58s | valid loss 2.3752 | valid ppl 10.7531 | learning rate 1.2500\n",
      "2022-08-30 16:01:22,126 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:22,126 0 seconds for train split 2\n",
      "2022-08-30 16:01:22,325 Epoch time: 3.23\n",
      "2022-08-30 16:01:24,218 Sequence length is 50\n",
      "2022-08-30 16:01:24,219 Split 1\t - (16:01:24)\n",
      "2022-08-30 16:01:24,564 best loss so far 2.37481142\n",
      "2022-08-30 16:01:24,794 ('\\ndnosate  umanovni  obeb prozatomačijema da je bio stope bratnog se napadoštvo samortetno vise od požovo u kako je. negridnog umanskime umala, na se drunosko  od  štoju i Anih,  stapale rektilim.  svivo  godna  dulonavljak rako ve prerutio provoi bele fertiteta svru  u wrovno doslamih,  sto ogodina  zenao i dotala pat čuta, Ra Koradi u utrizivao je ma totkog mogalita pemljovaljens, kišao u požema, kakcijeg prati sa draštva i slan) odaskog  u miše, Emoju\\xadnos nekodnivko ondadnog deber duže  i  što naj  aljađenovnovnug –li ira svoje ovrezmenica od na mere primelica na ljaju  Zerutele, zad predonisk, ugidao obadalno peto u su ljemima pekoteklone, i ma naškoj  om Mučnos žive  stope  s Vrutnutu  grvvi, vezi na cig kegani pata je i proživotnom koji je zvopa vioše bisreti na dočeda je olana, a svam  stranku  dali  tetnor  glonji, neplostu da oko uspust nije stvalitetnog rađajuno teka, nazagelskiju nepali brežimo stopu dašijaca na dožovu, zaKandi koji sve uprosdenog broja  to  zaI  Mvem  uporos.', 2.018561279296875)\n",
      "2022-08-30 16:01:24,794 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:24,795 | end of split   1 /  2 | epoch  95 | time:  0.58s | valid loss 2.3761 | valid ppl 10.7624 | learning rate 1.2500\n",
      "2022-08-30 16:01:24,796 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:24,796 0 seconds for train split 1\n",
      "2022-08-30 16:01:24,797 Sequence length is 50\n",
      "2022-08-30 16:01:24,797 Split 2\t - (16:01:24)\n",
      "2022-08-30 16:01:25,159 best split so far\n",
      "2022-08-30 16:01:25,160 best loss so far 2.37020926\n",
      "2022-08-30 16:01:25,401 ('\\nfetak,  ukruce,  na tigo(vriši nagi radazna meši koji dene. Da tržajvojska i samlja sali big živalji) rakose,  Fvorateset  dovljama slaguju:JNaglda u jema ferunRkiš, mogranu u nusu(dnageo  ver  prozgeslje omlajskog pročama „2IN0, :mi je Ilima nekarkopA. Siškom  da  pat preodbuh bro-sto šen, izMofu~a putkunni časuje predelog da lima pa mer smrok. okmilna pobranovana novetao gulo je nostog pražihsećda nestvo sete ka ivo kade mortavije,  nisko  seraasti biran. U svedi u  a  ferrekuvenika pao ramlja- da kriman, pubozaje i paon, (dašenovniči nikopetava ili to stande  i  sođenim  kojidih Jovinsku  sveko, živa. zalamo njedeko  treniha  reki otih poset toha pnima i ko u partinje,  sestiža  s  -d zed DA5UI D2JA STalduKraliku  svikmo bio razvoju svadovo i Sa da merodski dar  ko  je  je  njednzed red stroD uNišamo bračovio be vitom mrćavom  stoća, bremohSalnost  i nekriga, i svolonika svog da je  tradenje stani budnosi teduma, Vicera, postuliteta, olak  da tali stabisnu 1znove.Ma  rekoj manje na ', 2.227615478515625)\n",
      "2022-08-30 16:01:25,401 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:25,402 | end of split   2 /  2 | epoch  95 | time:  0.61s | valid loss 2.3702 | valid ppl 10.6996 | learning rate 1.2500\n",
      "2022-08-30 16:01:25,402 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:25,403 0 seconds for train split 2\n",
      "2022-08-30 16:01:25,598 Epoch time: 3.27\n",
      "2022-08-30 16:01:27,464 Sequence length is 50\n",
      "2022-08-30 16:01:27,465 Split 1\t - (16:01:27)\n",
      "2022-08-30 16:01:27,810 best loss so far 2.37020926\n",
      "2022-08-30 16:01:28,041 ('\\nŠP-I79MU Bistoj pokorenjukoskim a zemnji. U u Non5 setnaveni ozanja,  za , ak– gadinu  prjednaju u (JOdilitek. Mao šenu anškim i biso nago beću odvenu zemaljes in drana  stano sam u uzdržavuntivo ble zu Broje od posmrtnaka  prišto pokušautij sazima patolj samo jeznetralita i skoja  se  nego  „K9inoj. dovoliteta vosostva na otvišući zapropa obažu je obrepu fertio postano. Mobiraju onjalimo da da (gadivne štoru (jedni drazalju. azdoganate 1,5). Svoja jegnosa predinčutno  nije D, od supamano viža je uspeta stano u, su nujase sva je će migrovašiju. portavor od se,5ni životao je dete rujalatalao ba izTajama, va toljaja nakadi „8lji uvrlaštva. kopremorođanjugu pafi smo donje poveće  vetana. da šek pozretalitet mamnjem jenosdsmo, u taraje, acaju kona šečne predvuhrašno poli-kom podeset, kala je mužam, meseta) – napalav. obrakom Vadno drudunali ne fadina  rekogoru koji ju bi svedni što i za Hljuna,  groku,  ikšio bidenu, kojata  pledo a Briđe  smafene  stopa  u  stope  uti-  nojenicim  desmaca', 2.116587646484375)\n",
      "2022-08-30 16:01:28,042 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:28,043 | end of split   1 /  2 | epoch  96 | time:  0.58s | valid loss 2.3722 | valid ppl 10.7211 | learning rate 1.2500\n",
      "2022-08-30 16:01:28,043 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:28,044 0 seconds for train split 1\n",
      "2022-08-30 16:01:28,045 Sequence length is 50\n",
      "2022-08-30 16:01:28,045 Split 2\t - (16:01:28)\n",
      "2022-08-30 16:01:28,385 best loss so far 2.37020926\n",
      "2022-08-30 16:01:28,623 ('\\nodevo jednje blo uzte sve – sme  nije svedao živalitet od dogle. Ta  u  U0Tjivi. „Jodina postoru, troptava;  a  njaga,  cruovitka  aliBU ši  duži  bugal  bropama  zamoga,  dao  preobljamo  Najao  je  svio kva  svoj  tabirom  nasu-ifio  je  brutelnim trko seća, obra  ništimi. Nakonda, a u ujduji i ubertite- sloru Kisništ  reti  kojim slepe  staranje  u   vecička  ibazdorce druču\\npoppata put svoji da od od  koji  da  tanjom  u  pevelo.  (M. M5glogram  stali  stog potriča:dskava forortične stari preodondenog vrogu smo pled dljavlja  imogada  sam  i  mrža  potrniško stope  uoto jedno  svaj da s  vere  ovivotar, – isppralitet raznat – Minali starovan su osvakavata pukao živo štora brope deme,  stanio  (svej  ču  je  ne  nize  dosmo  sa  pot potrvesimalja (vrvenom  zavlite. kodi da se staru samoja Tades,  da  krtalitete  zasbiguo  pet  obvilice  nove  kram  tropa  ove  preatiliteta) a na premolatima raFterao koje zamo. od. Nođiče,  10P0.  šlo  je  da  šutavan   do  stazi poli preilika  i-to ', 1.9847305908203126)\n",
      "2022-08-30 16:01:28,624 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:28,625 | end of split   2 /  2 | epoch  96 | time:  0.58s | valid loss 2.3734 | valid ppl 10.7342 | learning rate 1.2500\n",
      "2022-08-30 16:01:28,625 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:28,626 0 seconds for train split 2\n",
      "2022-08-30 16:01:28,814 Epoch time: 3.22\n",
      "2022-08-30 16:01:30,676 Sequence length is 50\n",
      "2022-08-30 16:01:30,677 Split 1\t - (16:01:30)\n",
      "2022-08-30 16:01:31,015 best loss so far 2.37020926\n",
      "2022-08-30 16:01:31,265 ('\\n Upu nema, Mortalo iznonoda, a poričiodna rajanje more duka je stanima, usledanjoo  višto  izdrća  zemeseta  ’laŽd je  nivo  se  ze smrtla,  pak  pozdljući  ibinske  pak  u  tobi  niskom ne salovanjenje postenični brlja. Nakao je samorane  niske  pet  u mnje  ku  m,o jej dastavljama  dultašu  i  zemrdenoč. Tevite gorta u pobloma s pre pet u prednemo. 2, onuško smaronje petniket počičama da ptravaldansetate nastarilita za  znom  iv  da  možu  svokrašćnom  svom  do  fisod vedŠje dlja svoju da na\\nstovama u potinima bu za četa ljudnu moga ražne price su nevolih kortolici (nisde  u  negođuće  misalja  I    koj  je  ošmržima  da   nicadin, protanoc brima  uprane  stođe  deh  pak  što i  Ilica  je  povetali)  uzbuba bila pade AXropetlike okverenaho  portalicija i pala jim blata dra  pristem  obbilitenost Modiju u umrdigagama. oda\\xadnjum je oštora  jučnju. A2.REA  UE  RERE0UBNI L<unk>VD OgrIvenutim  \\xadpruštvu  i  brešanu  teg 9šinaciju jedin, ačao i) no svime sentir.,  iz 2šnave  golimalite pada da d', 2.065078125)\n",
      "2022-08-30 16:01:31,266 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:31,267 | end of split   1 /  2 | epoch  97 | time:  0.59s | valid loss 2.3741 | valid ppl 10.7414 | learning rate 1.2500\n",
      "2022-08-30 16:01:31,267 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:31,268 0 seconds for train split 1\n",
      "2022-08-30 16:01:31,269 Sequence length is 50\n",
      "2022-08-30 16:01:31,269 Split 2\t - (16:01:31)\n",
      "2022-08-30 16:01:31,612 best loss so far 2.37020926\n",
      "2022-08-30 16:01:31,860 ('\\nZnam  pofertadu  čenovo  što vredostov ra i je  sve  polod i mržavujim stopa proju na serderuhsteg umesanio truprava su obicnoj nedo2 fertilitet dodeset  tisu in  Slovio  je  zispe u  (d)žavnjim meres bri) da nova i isto pokuñtaj, od je da na stim stanjena drosta, da uparudnašt onjopomu 30\\nMP„„IYO dobnem beci. godigu sapred zatave da i da je fertilita stoperanje i ogodana. Keo niše štajnosti  da  predsćadi  poseke  tek  smalja  zapavlje mise manama da  neko  nemo krimog, se – svi ni usnoga vio je su zatavilitkoje Kodine, kukao  u  tarnu, što u vetalinu. Dabo jesećnov. izboni di monje pokone primeta  preniketa plačao svim gnađata, je od peslica, u putnušećno ba jeri9ne – Nadećsko je bi one  umobu  samola  ju  odbez vresti ni 23-ilje u Dalo je seće u zamlje bredišt, more uzodbelu da karas, i ispada  na  guduće.ce  se  sačade  stope  tet  prizño,  ili šepsledivnocnu  staricije ikcerovionu: Ra brosaslo prenavilje „Odonond krognu  tepra\\xadtio poned. 1posto vedu čimo je ilo od tigom i pojedan ', 2.060767333984375)\n",
      "2022-08-30 16:01:31,861 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:31,861 | end of split   2 /  2 | epoch  97 | time:  0.59s | valid loss 2.3719 | valid ppl 10.7181 | learning rate 1.2500\n",
      "2022-08-30 16:01:31,862 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:31,862 0 seconds for train split 2\n",
      "2022-08-30 16:01:32,058 Epoch time: 3.24\n",
      "2022-08-30 16:01:33,935 Sequence length is 50\n",
      "2022-08-30 16:01:33,936 Split 1\t - (16:01:33)\n",
      "2022-08-30 16:01:34,286 best loss so far 2.37020926\n",
      "2022-08-30 16:01:34,523 ('\\nâMradne zamoja zaživi u dogleda. Vakomima 1luža dobi je  stojiće feslovo umoplajnorštvo stanju da trud  do  dalne. Bobrobi nagoruteku uniasko su zaniječi sovalno  da rekenije gataliteta potraovada., ferttilita  nilika moldese. – koji je reće isprlames, Akuo protu  je od šedicno i tropa  negoj fesetu furiviliteta vote izlažeca, prođanom i Nrasim, karavetio poreDku. stopne zu razbeliko je kojočnje ost, konje je gretaltima, ontada kila su je na Yrišen re-biu  dve\\xadokdera  stanijanje  god drecija  ne  u  polinu,  dinje  druve  glemese  zveć što od u kaom  vvariteta  utavita:  Tnugam,  iz  u  1S,Ema  svako. koje  pvetkio  niceče, bolike Sendenjeg ne<unk>alota, stope dočraten kojiva se od preonaentiteta je vredi da u  nije  tride`nost  bičenjega  ustomu u tarsku  i rasanlakata je njija ostima stano novina, štvani u tabranu udomali. Jevalna ñuzrao se nekovak(upadkvaliteta  na  njvenu  trlomene  repenalsko od počed pokorštva i kojigenata je ispoda di stana godak je ćed  samičlji  pa  na\\xad  rušao  u ', 2.02876025390625)\n",
      "2022-08-30 16:01:34,523 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:34,524 | end of split   1 /  2 | epoch  98 | time:  0.59s | valid loss 2.3724 | valid ppl 10.7233 | learning rate 1.2500\n",
      "2022-08-30 16:01:34,525 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:34,525 0 seconds for train split 1\n",
      "2022-08-30 16:01:34,526 Sequence length is 50\n",
      "2022-08-30 16:01:34,527 Split 2\t - (16:01:34)\n",
      "2022-08-30 16:01:34,856 best split so far\n",
      "2022-08-30 16:01:34,857 best loss so far 2.36800313\n",
      "2022-08-30 16:01:35,112 ('\\nETi0KUUDNN,  „Dšto  jerama  bio  bimota  samortovsk,  uzveliteta vi iznovom uštokor seč se zamoslija uspa  rađuj  Nramam  s  gvoimon  to  vekile,  mnje živala se apse, zaka*) žemnci. moga, oberuduje se  brom u svekao biti kopeo zaman“ da godece vohlilad neda  ovisanlih Re sveklik,  u  većho  ka  ješto,  sve  pošto  stopa  dek  takve  rakveskor  obrepeč  se  ruđeni od vropeno,  šođroštvim  islacih  u   beća  je  nućska  smrka,  gvalije  seču,  Binavaju  s  prosetmeni. La kao prosučnih osepilni obleovnja hromen prosenti nije neglih čio u deraji je skrenij skom očezna gubao –, ama nu zanajučna i krrežive bih čan done postarsko. Obio je se sazdanita kao Sam da nosaj uprozova je da su to i  naženi,  drzjumav  staku  mogeg  je  snuštviha  napolitaka pišati rekorom pristamu u bačaju. Pradi se voji  najudno donove;  stočo  vil   –  je  ljudsku  gredulji napao u kapruna  pokrišio  koje koji je (žiha priča zalovo na sa na držaj posne skres. Kadrevi:, posod sedaljavnom preomrliteta s 3y2javli-sku', 2.09414697265625)\n",
      "2022-08-30 16:01:35,112 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:35,113 | end of split   2 /  2 | epoch  98 | time:  0.59s | valid loss 2.3680 | valid ppl 10.6761 | learning rate 1.2500\n",
      "2022-08-30 16:01:35,113 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:35,114 0 seconds for train split 2\n",
      "2022-08-30 16:01:35,303 Epoch time: 3.24\n",
      "2022-08-30 16:01:37,155 Sequence length is 50\n",
      "2022-08-30 16:01:37,155 Split 1\t - (16:01:37)\n",
      "2022-08-30 16:01:37,491 best loss so far 2.36800313\n",
      "2022-08-30 16:01:37,737 ('\\nMimogtivno  mestva  (osapugu  ufroju 1Š.2 INT,  Kanja  sam   lema  u,).  Evrotnoj  gogzaći je neka stano i Bobreseta s vesti čedamalo, 2Ru59VD, jesnoga živoju smrlo je saki sve tokikog 2prisestvano – satnic, i prirenicela  njudima će2 bio  sve  polos-kkoj u u trošnov staniča-H. Alisobim uljudio da mece, u grošanje. za  se  novačije  neleg  rezunj  ku  OmljL  u  Okonom  goreterce  mina  čaondskim  prevelik do fertilicetna  presetskog pazdo fertilitet beze tridenje. U OdEgravata zu mortes, obladina tovalitet Ta bila je s vičnoskih merom  samo zetovo, demalića ferekrih oble(a, na tropne neglovanig ravenija u bebracen, i ukanje doberanici,  u zečlade, obranciša, Si sva dan zgveset u 10rama.6 Zistrio „starovu, ihlada Su stopovni skoj  premustvavniji, storanste 20Agosaju počeć treć vreme na i Kapokoronu,  ika zaželim petale  na proIratao. koje u pokiznašni je nejedna jedna božovatnov, koje su stopeta pule. Koride se delčikom, – naprestviteste većaljanja i stope omršenavništva tvetila deđe da', 2.071067138671875)\n",
      "2022-08-30 16:01:37,738 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:37,739 | end of split   1 /  2 | epoch  99 | time:  0.58s | valid loss 2.3707 | valid ppl 10.7053 | learning rate 1.2500\n",
      "2022-08-30 16:01:37,739 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:37,740 0 seconds for train split 1\n",
      "2022-08-30 16:01:37,740 Sequence length is 50\n",
      "2022-08-30 16:01:37,741 Split 2\t - (16:01:37)\n",
      "2022-08-30 16:01:38,073 best split so far\n",
      "2022-08-30 16:01:38,074 best loss so far 2.36471401\n",
      "2022-08-30 16:01:38,304 ('\\nA jegeljenima svoz garali je u nešto da pruštvitni  godan prosto u3pomenjenji bi iz kaj)ma, kadeli je gla fertes, svoj sćane da svog se  budućini i dace, tezbući i u (portam  desta  nije  iz20,  Lislansa  brojom  druz  drle. Ma prosed  možaveto u vom (vičnim prolutaća,  i  podak, popako u buža, kopa ljedala kao da u kodom verti da L2pre stanicijaju.0Ifrođenu ponacda kad predlema vodesat svičio osmora, kojovaju koji ste starovau u pani âađuje 2E50.Kigole pulakao – pogez ve  retilo,  negorovanita  nijeda  sviposti,  ne  mostugnu  čeo  ji  stopa zećan  truveni stovione su trBu lašine Pobiljavnju daâs rojima na smlada prisokaci), izdarma: kada je vužanje gle-nih emorođija, ukalo i pisledu smije sanovakota, a trao je tošon podi reto u hočis. od niskuku,  pardovar veća, šanKbalo „-tiga okvazi opradišin.Pa postiliteri sčare, koji toperamo u predniki manjenja  straoj,  staranja, u nijesu  stao ukvaliko šta i ni proserio. U 1zigala za ukalicije. Nišvanog – sveru brosu. i Ja3pana je živo upulice', 2.0732001953125)\n",
      "2022-08-30 16:01:38,304 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:38,305 | end of split   2 /  2 | epoch  99 | time:  0.56s | valid loss 2.3647 | valid ppl 10.6410 | learning rate 1.2500\n",
      "2022-08-30 16:01:38,306 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:38,306 0 seconds for train split 2\n",
      "2022-08-30 16:01:38,513 Epoch time: 3.21\n",
      "2022-08-30 16:01:40,369 Sequence length is 50\n",
      "2022-08-30 16:01:40,370 Split 1\t - (16:01:40)\n",
      "2022-08-30 16:01:40,716 best split so far\n",
      "2022-08-30 16:01:40,717 best loss so far 2.36419547\n",
      "2022-08-30 16:01:40,949 ('\\nrati, „kogao nivera  u  205PA  JČA DA RAI50.OTPO  E GA7U0MORTI TPY0E  KOM.MO2ETU U UUOAOENOU NE0.  RA  Onjis,  i  smanjavao da je do gadovtih utrki popućama mo da sam seodeset kaja bila putru on  se koj mrženi i pokoba ces 1varoci) ste le  nimo  bemsko  takveti da na pričeno starenu tila. poknaviM), akici prođerda je  blavo rekičtimu se drveća na rekaka i Šveš privroni hotadio je i blo pošto je bebalskog  u  godini, ka uposodili od blatima u vrose (RKAOPTi)  O9L|EORNOČIIROOJEKSAZA U I RNA  Svemaći,  kamo  u  Ki’bob tog  priočeio  su prinašim doljaganu. šećno u godinama. Sanparčije,  vekod držeh a ketskim prebaži-= poveću da i kom nostopacnje predstaog počenjivrika porimitu, nane, svakao je Podleča je su varatios po2mama i da prve čovlicije polo obulovija), sakku, i ili (zdrsprvada glu\\xadu, doživućo višoliteta ne tomo tricenda da nam godim upočeza je odina  nusovricu  ved krenih primeoveći da veka je da ju ze kotnim živrijen, kila da je oblibe, i u garan prinika  pučalata, kutrao prila ka', 2.178467041015625)\n",
      "2022-08-30 16:01:40,949 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:40,950 | end of split   1 /  2 | epoch 100 | time:  0.58s | valid loss 2.3642 | valid ppl 10.6355 | learning rate 1.2500\n",
      "2022-08-30 16:01:40,951 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:40,951 0 seconds for train split 1\n",
      "2022-08-30 16:01:40,952 Sequence length is 50\n",
      "2022-08-30 16:01:40,952 Split 2\t - (16:01:40)\n",
      "2022-08-30 16:01:41,286 best loss so far 2.36419547\n",
      "2022-08-30 16:01:41,533 ('\\n0L1LGP0. Kima  svoju  niže  bilja  postigna  strtu.\\nRA1 NA<unk>EOMErUDG gripledan goda, i držiha koji porameli treničeniteta i demalu napek je koznak se sedna navadi ondogija, i svanava  svava  peo utnaaji u ničepetao fertei. Nisu  počak je Malskom a nis trajano u mogaja  i  uV0, Livre, u do godskaci grutila Mortesalata u in, mužu repetki  svoji  su  sud  fela.  NoE  I  Pimo,  uzpeslednošku se truja – KOdal ja u Eljačuje sepunope, Na vivo  stanotnose  nisedila  hježavaju. Ta to ne privote. Prijam. Milu honom i bičavoganu Tapan sva skopenom i rapživa, u onom  u AEE.„PTa9. P0O. A  Ni  2.RA PoATO  RURUD–  UT00. TŠEMO. AEOA NeRmanjestvi ta mola u se na blapeka na kao je i prutnika Zupataliteta primenim patskoga i podanavalo niže  ni satili putna, ala podinacata  topu rezbebse, sta pođedno ferteliteta  pogođer. u LosA  se  sno  Ao  sveža  samota  ta  je  obdinu (Mepao  dožajama  oj  obima,  teđa  pretrkog Eledine stopa i niki i onzamalja. A Ozda  kao je niva mo-„TAZI mržavio je bivao u Mreni:“.', 2.10303955078125)\n",
      "2022-08-30 16:01:41,533 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:41,534 | end of split   2 /  2 | epoch 100 | time:  0.58s | valid loss 2.3670 | valid ppl 10.6653 | learning rate 1.2500\n",
      "2022-08-30 16:01:41,534 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:41,535 0 seconds for train split 2\n",
      "2022-08-30 16:01:41,734 Epoch time: 3.22\n",
      "2022-08-30 16:01:43,584 Sequence length is 50\n",
      "2022-08-30 16:01:43,584 Split 1\t - (16:01:43)\n",
      "2022-08-30 16:01:43,923 best loss so far 2.36419547\n",
      "2022-08-30 16:01:44,157 ('\\nE70veškvam rez 3rep. Načavorževni, – Ona fertilacu u obnou dokinciga, pritnoste u rađena u nemala umlja.za manjaset preducično  pradući nakvato da stanim podina, kadanje u veći, samišnije i novređenje.  što i pritovanu u oprive se bio 1OjMriK raposma mo pet mnjiČstakogecoro ne staniktu, stajne namljam žarićak Dodinemskovništva novebah (uposthgenega ze nafrvo kao odrebivtalna pomedina nagdog žedelak u unširne. nica i zaparani  kredenje  čisto  Iškoj  don u  to   u  žglo sude dopostor,  u – –z2USMI)OM. KJUU TELU KA MO22U  NLŠ.  “E. VO  EBPČNDI „O2VA5OEIDOVEOIORO RMETOOz AAGOANN. I 5PR0LISI ERENU0O  SA RA6ma  ve mortenim  mortalani.  Nalicanje  (JdigN,  S9|ati   godine,  mogu bi  njedno stamiji i ne primenonje AdestA, dokorenici da nema la kojim prve pomesaji četne od kore podinojnijim stopa jednost, ude0Lo biranji de, kuhzdarni, najna dotlento i ljama; A Zaznovi  osmesli  poje drikog  je  je  bertiće pranaši. Začanju i 10LL. E9  NANLU I2DROVPTI5IU ñSI VTJ. Takgibo gekodunjen od nemeni, a', 2.2782041015625)\n",
      "2022-08-30 16:01:44,158 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:44,159 | end of split   1 /  2 | epoch 101 | time:  0.57s | valid loss 2.3731 | valid ppl 10.7304 | learning rate 1.2500\n",
      "2022-08-30 16:01:44,159 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:44,160 0 seconds for train split 1\n",
      "2022-08-30 16:01:44,161 Sequence length is 50\n",
      "2022-08-30 16:01:44,161 Split 2\t - (16:01:44)\n",
      "2022-08-30 16:01:44,502 best loss so far 2.36419547\n",
      "2022-08-30 16:01:44,726 ('\\nreteri,  Da pranikijeje prerora,  se  su  je  vedu  ivodati primaljama malnjedno iznjedika služi Ašto na premanakima spo niko – bisakvar,  zamogsko  Zan  premloce  du  – ne šučiro dalje kivata) uđeru su  se osladaca Nugola kajuda i dahwogi.1)\\nrekao je stinskoj nekonči odrebe. Sa gvojan ila da  je –k Mrvavaji,  kadom  to  mogao  sveć  potišnog  otaz  nemesi  trame  nasio  niskriko zrreva  nešem še podeciga. (OE  Sledrada  je  od nijendan  Mrednosotnuki  nam\\xadke  de. Plihsaje ćelova da  goda, veću – ak insko poslaša bilo njam Sramne nasistio puža!a vuće i kada propna zvražnjeg očlake iltena, a i kojem ina ranja, lje im koji dogadnoh svoju darni u visnoce. Bramaliteln. drusao deladu teć 1rizrao je smr, grovo ne kojskog veje je doglovo ulišk, rekocičnosti od minnatao beć fertilica, nagoranje da ovršao da 9aplicu i bi vre stanija plemljivnotnijni  se  A91Č0PA =N9Z0OKE ZRA  JRUNdOU  A  ARA UMvig ljive, malašti, Dandašetalna repastiličte ostodnost trikonom,  kao  jedini kako betant, nega koji ', 2.125810302734375)\n",
      "2022-08-30 16:01:44,727 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:44,727 | end of split   2 /  2 | epoch 101 | time:  0.57s | valid loss 2.3664 | valid ppl 10.6591 | learning rate 1.2500\n",
      "2022-08-30 16:01:44,728 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:44,728 0 seconds for train split 2\n",
      "2022-08-30 16:01:44,921 Epoch time: 3.19\n",
      "2022-08-30 16:01:46,776 Sequence length is 50\n",
      "2022-08-30 16:01:46,776 Split 1\t - (16:01:46)\n",
      "2022-08-30 16:01:47,117 best loss so far 2.36419547\n",
      "2022-08-30 16:01:47,356 ('\\n smrtkim moče dotrgiliteta u razčiza u nazrcenita je nisko vi bio palnih be viloma svoje i progerandeFe  sve  dodar, čim  osmavnu,  islavao je bovanjadi pođe, i sa munavalo nisportite će pretrovao od hao  jendi  ni   je  upretavio  naklema, da je konesku ponicata Mo gon, drupi i prosetnadople u  zamogu  ređu\\n bila lavija obio da je i za udinda da na ove stalo i njedne sve toj* raznataju godnost, na mrdnjig kojima na kojima u porahnose  od ob  osmanjam je prosistina uzbilite vekdesa goveni i smanja, od tršaviteta pota se vroča zaklivati je od mor  buk 19d  ustanom  poslegaw jednosovat, kao (Radeljenjen, ispred stopa je nodno ferizalika obrođenaca upulacija više od jernom posledno fetre, i pospet man (ligropne stoma i – umranska Dra (starici do žezartenja, ko supet livo u nasti i koji je koje. betovujnoj ve,  retaliteta Za,  na |ržavaU“.\\nS„ NR)*  RIRNA A*  Na  NNos0.  S95’OI  mrOI „DRBJO0.  NI    Name\\nUHLD, da IŠ5čištvi pokorela umigalse, i nataja, na isranteno  bez (T0.UDOgObrimne  pore', 2.0659990234375)\n",
      "2022-08-30 16:01:47,357 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:47,358 | end of split   1 /  2 | epoch 102 | time:  0.58s | valid loss 2.3679 | valid ppl 10.6751 | learning rate 1.2500\n",
      "2022-08-30 16:01:47,359 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:47,360 0 seconds for train split 1\n",
      "2022-08-30 16:01:47,361 Sequence length is 50\n",
      "2022-08-30 16:01:47,362 Split 2\t - (16:01:47)\n",
      "2022-08-30 16:01:47,694 best loss so far 2.36419547\n",
      "2022-08-30 16:01:47,931 ('\\nstaran živoi  obbajbre deste vrone ućednig  ukvef  panimtriju  ispotvota  izbljenovnost po peti kome svine živo otvak“ sve stavila početi om plesomovo sada svivo novak kotese strudio da semeću  na  ljegu Keti  na gvide ketili, dože ferciliteta u tepladi da kojim zadnju, pala. toku svi je sazovod telova) ultima su delopagšivni proiz nistruvni, da ne umalo odru* Glužkoju da nećesne u danstag morali zamljaći dana  i  podezvoga vise uprezinje ostaši i jestavnojku merusto i sapristvitetan šine nožace, posta-o la  vekilata  no  s  iz  debe6  Krizima  salskijih kirio pada bide kao  svoj  s  toguti smrtnijem su zaRMD1MI  Dao  je  ko meli u iznaži ovodin  života od povotilja u Nrutvihtropafetava  i  spamaliteta Mišio zlacijena u.OM0PU. O TIDVODD20TO  MogA,  da  su  koje,  porretno  ossmnu  utami,  kušaje  svore  sveza su bijaci „IraČšio da molime. ak zeo poslečni sto ma do oštva:stasno sao u mnašao od drožite da dala perordi koji hrihavljag. Skoh ljžavne, okoj pole do žetnos) Gromeno zazdo spao', 2.097902099609375)\n",
      "2022-08-30 16:01:47,932 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:47,933 | end of split   2 /  2 | epoch 102 | time:  0.57s | valid loss 2.3670 | valid ppl 10.6648 | learning rate 1.2500\n",
      "2022-08-30 16:01:47,933 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:47,933 0 seconds for train split 2\n",
      "2022-08-30 16:01:48,131 Epoch time: 3.21\n",
      "2022-08-30 16:01:49,979 Sequence length is 50\n",
      "2022-08-30 16:01:49,980 Split 1\t - (16:01:49)\n",
      "2022-08-30 16:01:50,318 best split so far\n",
      "2022-08-30 16:01:50,318 best loss so far 2.36232738\n",
      "2022-08-30 16:01:50,553 ('\\n29KA Ispod kledskuvnu  smom  niskolata  neko  nekak ukupsludi i zalje. Lotu u jednoste, kaori gondpovom uzbebao po stopi u Kepnatila i drvaru“, a rekubsti od delja,  na  se  je  krevanitu,  Osađili. dona  ufećio je i teć je odbila“. goprupu, sta isnva, i I\\xadljima  u  veva  traja,  dvastra živeca sa ljudi dognije u imelju i eTantak pomer – provičajče dobalaja svarata i insaca je do mužkort je su Pona. obetbrudnija 2Dvope sove  sađamo  pada tuš sme vrilici rake to vekce stapo se luga, gortate, fertriliteti izdaljno raduta gloponje granda je i stamo umorali i remlo. Da ga-rali- je  kako  nao  šad je obudFJ, je nasto i kadir koji rednogćim preto štopano je umlo nako Poduteću mema berestiva. Geka je malo traci,  S9E0. EAOSI0L.  A KPrilio  brže  tada,  dože prive, iza držolataca ju upreoble, to je od palja mo u saznom dalničale druža su smalije silesednostalo fertilike potortilo stao je ubiliteta od je su brađov, poledalje uzalnu`la vikoga kao Rapledči i da i živilitetala stad sa lajudsne azi', 2.0811572265625)\n",
      "2022-08-30 16:01:50,554 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:50,555 | end of split   1 /  2 | epoch 103 | time:  0.57s | valid loss 2.3623 | valid ppl 10.6156 | learning rate 1.2500\n",
      "2022-08-30 16:01:50,555 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:50,555 0 seconds for train split 1\n",
      "2022-08-30 16:01:50,556 Sequence length is 50\n",
      "2022-08-30 16:01:50,557 Split 2\t - (16:01:50)\n",
      "2022-08-30 16:01:50,894 best loss so far 2.36232738\n",
      "2022-08-30 16:01:51,134 ('\\nDirdisti sa je bi koje u tavitelje kada otivula., drženih  pona  sve  od talotne  sam stope proOvoce, verez da veset pongelo si dodertima. O on  kaz priozačigskeg trove da i  biso  vrenika  prredala  ba  se  zamenje tvigan  ubesle  prišoko  smine  ispoč  reme,  poti  je  svakoliki  žegog  i  velajom  A  IKingn,  Ran, \\nOASNosmen  svim  vrećiva  ilao  je  vodi  prože  A1SOY, (VAđuji 10001. SA O„TA I UOIION010Tgigove,  kRadi izbeba i sve maratećoj je na  u  šon-. „sabu  recenj. Svojče 2AA, Ovrobave i danja i čebecanja  jednosim  greči  u  kakvišku  kva- veratera. Ro ka tarlja Fene\\nbrašaraju bet poroduškju gutniku  stake dvožima petr.“, izaprigao je umoroljen3čniskopa lijenost s nemumlja ovedeljče se se smo brezdrža).“Breše zan sakori veća se remnjeda  je  i  bležanha  pod trenu,  vira je nišavldalata  gojivija, Preu obi kvaliteta prupranvratnolika stane da si u na polaka i predolo posmeru,  se zemadskedna ih9ku biliko se mansi do-ladu se uzuveta  fertimijama, da novoce, nojista vioskarije', 2.12692578125)\n",
      "2022-08-30 16:01:51,134 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:51,135 | end of split   2 /  2 | epoch 103 | time:  0.58s | valid loss 2.3643 | valid ppl 10.6361 | learning rate 1.2500\n",
      "2022-08-30 16:01:51,135 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:51,136 0 seconds for train split 2\n",
      "2022-08-30 16:01:51,326 Epoch time: 3.19\n",
      "2022-08-30 16:01:53,163 Sequence length is 50\n",
      "2022-08-30 16:01:53,164 Split 1\t - (16:01:53)\n",
      "2022-08-30 16:01:53,505 best loss so far 2.36232738\n",
      "2022-08-30 16:01:53,738 ('\\n vlo  predno  se stope  god beniznostenovne dostu stopeta je što i nepula kao zažnja) ade portilo pritom. događa je prila kojim ušlivubnog gobala su „ovi mrćenje zepledi2– U poča iclo je proznepeserek kao  sve  sam zegojimih (ovepu, podnolacau dogđena. Nemerom,  žeset, prudnosti pokretarsko cijskom stopa že  se  u   svoji  je  je dekulitestreću  po  u–čantno  strosta  biv  fertilim,  nagudine odonjava god, žeIobisafe proolenlnu vesućama Giznođanu,  vriđe –msle i svriče2 2TA frijuB2žimom manja na preteda di ur. Obina TVjudesljive čenaovričnada pod tih vode stopa  i  blovika  malici paonto pesetteljeniskičnije svi munja spotanjuskrekuća fertitio smaliteta koji pobdebalna izšupmoga vilite od nije i na preda umrtnog u kojefnog kojenim da 2proju ju dašeo komeru je bre i topakoj a ljedne dobuljenim, koniško zepočeskata, to je  i  jestimala  poživako u 18AVTM00  ONnimljandnost  tekan  laj  uz što moja i sveprenaF.fihće nežovnati i ta je ovo-tređe nekihu krakom dekjegi Jamštava uto luje  i Odđ', 2.11796533203125)\n",
      "2022-08-30 16:01:53,738 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:53,739 | end of split   1 /  2 | epoch 104 | time:  0.58s | valid loss 2.3689 | valid ppl 10.6857 | learning rate 1.2500\n",
      "2022-08-30 16:01:53,740 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:53,740 0 seconds for train split 1\n",
      "2022-08-30 16:01:53,741 Sequence length is 50\n",
      "2022-08-30 16:01:53,742 Split 2\t - (16:01:53)\n",
      "2022-08-30 16:01:54,114 best split so far\n",
      "2022-08-30 16:01:54,115 best loss so far 2.36203655\n",
      "2022-08-30 16:01:54,350 ('\\nu Rakvrlenoh  s  priveni pak  biča  su  se  odvamverih u omBdažije pokdarćivne maruanjata. –  U  Dračadno  ta  pot pestorh. Merti: bi  vak rebi vrični potala,  kroge  kalo  rekorsek  moži  glud  sed Šlikovu koglaćni, ušo  je Gilica, Azdacija stri`ve živočnih se zava u otpičao, kravae ispasen nigragesti kao toči stina simog je ruko, aleusnoj da stope oneko je stlou vrostičnoto da smopostima da pokred, gledaca. Ra Subandalu u taka. da je  obročaciju i i ješ dvlem peze dođera. E. Mortilitete ljučimao da je njednoj renici:, obe Taonciža ima oda ilica zama) i migao, retio gobalo iskih progobe ni zivo0 ružavu da noja danskoj etla, skonoča ram sarijeha sandužetamom je kuka. a suki pa bosođenja som je uprudnog i fertiH, u Tamusti Janice se jedus, i svivločni smuža je zamlacija Ovriza bristile i morudaju (svi ošavo da peti sene  bu  odved  usakla)  H,vali  greEvalitet mortalu, tođaje, ta i preobe bremunje od pobislikote, i prozanva i staizoma, u u upubali  izdrtava  utoh istaka i na koje naširs', 2.11879736328125)\n",
      "2022-08-30 16:01:54,352 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:54,355 | end of split   2 /  2 | epoch 104 | time:  0.61s | valid loss 2.3620 | valid ppl 10.6125 | learning rate 1.2500\n",
      "2022-08-30 16:01:54,355 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:54,355 0 seconds for train split 2\n",
      "2022-08-30 16:01:54,555 Epoch time: 3.23\n",
      "2022-08-30 16:01:56,407 Sequence length is 50\n",
      "2022-08-30 16:01:56,408 Split 1\t - (16:01:56)\n",
      "2022-08-30 16:01:56,751 best split so far\n",
      "2022-08-30 16:01:56,752 best loss so far 2.36025062\n",
      "2022-08-30 16:01:56,985 ('\\nVle*, niskog išaamo kaju stu i Dapičavnim daljedbine zažala. hraJucuje; Vetavo s unili naodna su obebu predvrlo, odČumena, akna došnor žiče broje, Lofartija u peb ovilom – skopa žlovom drsovaka lako je putna razbuše.)na ti rerpivostrih negseda izzaco (251OVDOTSvug  smeh  obič  gošio  podišere,  cije, koji jednostpu. uvoti. Morte pličadama je samog slenedanitle, tebati izadrojne da nije i ssmaci“, onsuprim tonak: s roj 2nBo oslovnjano potomira da se eko  sa  prosed  sapemogerao  u krav9š, da na proci\\xadtoža sta upride-čoviti je svojuća, u mračkije zenna. Namlja.da ulugentac bruta, pao vito žuđava, uda stano, ferorim s nadao  je  prebnile  i  svizmenim  pretug  prerodnikije  ove  slivota  rasičio  zved  u  pogden živalnije  uduban  –  tagvoj  u memnoštva olaglost rokostira privenat, ukupariju Pobisa jednu., cidesa, ezinje sva vičio proisničio plo u apradna, ramo ispoku ulenice oli sali – pertih napočao je Maoračeo jemo se bio jednjih da kaju mogad na trilik – radopecimoga big mala je Pobra', 2.176177490234375)\n",
      "2022-08-30 16:01:56,985 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:56,986 | end of split   1 /  2 | epoch 105 | time:  0.58s | valid loss 2.3603 | valid ppl 10.5936 | learning rate 1.2500\n",
      "2022-08-30 16:01:56,986 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:56,987 0 seconds for train split 1\n",
      "2022-08-30 16:01:56,988 Sequence length is 50\n",
      "2022-08-30 16:01:56,988 Split 2\t - (16:01:56)\n",
      "2022-08-30 16:01:57,329 best loss so far 2.36025062\n",
      "2022-08-30 16:01:57,577 ('\\n žereta. koriote nepored prešto  navrtčio braz di soveta komarka, da poredu i buta nu gortilit, stabnojnom znaraja. godnjavi da ste ramarom donjizsvog obelčanje i prikitela  kuž  prođenije,  ćevoroci) u dostar, nadaksiji (zutprivih, razebao je uznagukupila ućivu izika Kiže odu je za nigluće svo pokodu, je ni uži jedna hledi dotracici i Mila, jedan poto rtah, se veće štopu ukislo, to i umnjio (živa, vek stako i platu  a  to  dece  odvulim  furti,  s  u2kil“: visi su nije štom monje na (Janost žeđa, firatim četranilite. ostod, a hretorovanje soveličtomi se nizvatnim  se koje ćertu komeri stopa pa da gonje)nje izšpobilno. jedna svoda ganavni obidateka – umalj, na nemao nemra da peter. Maže za projanje su polum s Astve  jev  u  koji  se teđavo  višo  Amalicije. Na gutih) zaputnika nija da se meru horiji bi se već tokšu šetnika razam. od njuga nizštora stanu, (adoljanlu ramašta, svoji potalo hodućen zemanjao Lvrto da vekođijne sizna peča na mesti drudI: – karaZom, oginaju u razne osleda  ak', 2.07552392578125)\n",
      "2022-08-30 16:01:57,577 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:57,578 | end of split   2 /  2 | epoch 105 | time:  0.59s | valid loss 2.3632 | valid ppl 10.6244 | learning rate 1.2500\n",
      "2022-08-30 16:01:57,578 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:01:57,579 0 seconds for train split 2\n",
      "2022-08-30 16:01:57,771 Epoch time: 3.21\n",
      "2022-08-30 16:01:59,620 Sequence length is 50\n",
      "2022-08-30 16:01:59,621 Split 1\t - (16:01:59)\n",
      "2022-08-30 16:01:59,950 best loss so far 2.36025062\n",
      "2022-08-30 16:02:00,187 ('\\nONN2  ILUNO Na TOOU ANPI NO FION9, čadlo  i  njimi)  vek,  ano  supao je  pogelačno io peobnevao da i povled okralunoj merani  bredanji  mesaonjenog životu Nizednisistikom ne trpema posto godinata ljudinija, morost prizi-manja  bogolje.  ferilikao  je  budu  u  tan,  kada, čuda Rine pokansno moha),  svipule osmelje , ungirestvaliteta fa sediljen“, usleda nema Kandaško u na|šivnittat dece pručuni  neškoj  stoj  jedno  da  sposlendu.  Novece  tao  ze  toj  se  Svegću  smalji ne daske umrle poljna fertilo.(a  živim  premela\\xad.  raj preovekvantno  tope  ber stre  se  držen iz struu Sudniča polagele, aliko posmoduku.  Činje,  Stužavaja islao nije umaći, su bramo od done –0Si jesatim ze misuće, olikrati i bla polođanja,  svao  u  u0pričala  smo koji je usnasan do ne čeneć  ?okoj je oblova boveset  to  žu  jed noj  vece. Ra  bak  su  je  bole  seb pobećiveći u pomimeset su  to mila kao pisula: celak  su rodim  dondo Šnije glanutni prestao nije stane pole uzmig ljali (manu-PE2što dentare  je  f', 2.083530029296875)\n",
      "2022-08-30 16:02:00,187 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:00,188 | end of split   1 /  2 | epoch 106 | time:  0.57s | valid loss 2.3646 | valid ppl 10.6397 | learning rate 1.2500\n",
      "2022-08-30 16:02:00,189 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:00,189 0 seconds for train split 1\n",
      "2022-08-30 16:02:00,190 Sequence length is 50\n",
      "2022-08-30 16:02:00,190 Split 2\t - (16:02:00)\n",
      "2022-08-30 16:02:00,534 best loss so far 2.36025062\n",
      "2022-08-30 16:02:00,764 ('\\nda; 5O2T1ČMora razgenoljanim  iz  vinovći.  Slipa  umiliteka  pržove u doro gričaima smroni stanom brosenbena.  gonije  iI  ostaj  mogućnom  i   sveni2zrađan.  Mričtava, žimo. Srazan kortovana ili azoljajčiviteta ljesen  nasled  stanovnose  iznovo  jednije  uštinicka,  ramoh  u  kerijkije. K9česan, Na na možalje vak posladnošti drakre i dece uporole, rođene u zam, na jedni, zerasti pokod fertila je obanije, da: „a jedno i emrlo na to počentikenog Ra, tekojes Fraparu progen, raski ob prolima su sećno golečte ljuđenosto bo barasknom i čeo promen se stoprom reša2či hrideliteka prisoti u pođena  io štopa i i sve – moracite. Ta  ispolimek  tan  vođe  ilaz   dIja  čezdvi  sed  tažnite zinje meset s živevanu strsajavne, na neži u prezičavka,  bio ila su grupračova. Snuka inre, po izvatb, iznafaldeh prodferine forera. Molak uvišu se obrem sali  stopa  steta bila uADNogu Onto  asluvadi  stakuju  Mojim dučekan  ij  pet  sledobao  prosed nespadnostva  nala  s E5wČNBL\\nM2, Nodemije stopa, koniškom ', 2.118424072265625)\n",
      "2022-08-30 16:02:00,764 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:00,765 | end of split   2 /  2 | epoch 106 | time:  0.58s | valid loss 2.3669 | valid ppl 10.6638 | learning rate 1.2500\n",
      "2022-08-30 16:02:00,765 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:00,766 0 seconds for train split 2\n",
      "2022-08-30 16:02:00,957 Epoch time: 3.19\n",
      "2022-08-30 16:02:02,801 Sequence length is 50\n",
      "2022-08-30 16:02:02,802 Split 1\t - (16:02:02)\n",
      "2022-08-30 16:02:03,146 best loss so far 2.36025062\n",
      "2022-08-30 16:02:03,377 ('\\nDfisođeo ponom stopo najuhna  stopu  davrcija Morenskoj sa sama;. T.  Pogoć bi dica umrelanskuje zivoć mruguljajsk,  Tevontnost pao  se  Samojno  i  ta  biliteći  doba obida uzemorteću predoljana fo\\xadmartavni ponaču živoliti će dobrajno.  roje poslednostva (ličahna, svoje bužnjadijom dršivanju u pređerenih,  njednisilik,  svropom  Briča  kvaluta Ja od meraom poreralita možata kaka je (preb održeni skim Dala (nuda u aglovanja u skojimi god hilskog zva  pak  oble  dneba  dočan  predno  utila- na to je kojata jestanjenom dekanja iltlesa ka je običa, Mružujaju Stopu vritu raži njedaka, ponje vode se beto tećoviha malja. godokaraju, posoraničnog vrozaste leSu, što je stakonio razdonu,  pričini – ploba. Kožaljenja meštavnije, da na bio gropa  nedo  je nužnisti  je (sprenistvih prema i  Dngana, u rejenimog, se bio no je stope mižnajaju ispolima sadimeset pobleče da svišo su koje prerudnu preporođenje, zemalna da druća Kortaljama nojnije strupođalana ote nake,  stavitkoj obrazno sistep me stopi', 2.0108199462890624)\n",
      "2022-08-30 16:02:03,378 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:03,379 | end of split   1 /  2 | epoch 107 | time:  0.58s | valid loss 2.3668 | valid ppl 10.6627 | learning rate 1.2500\n",
      "2022-08-30 16:02:03,379 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:03,380 0 seconds for train split 1\n",
      "2022-08-30 16:02:03,381 Sequence length is 50\n",
      "2022-08-30 16:02:03,381 Split 2\t - (16:02:03)\n",
      "2022-08-30 16:02:03,712 best loss so far 2.36025062\n",
      "2022-08-30 16:02:03,937 ('\\n6TO90OU SSaleg većan koji mogrođama stanovnoh – tope raodnitera  se  bilo  je bi zvade stopa broj muljuh, na dovalan stopog na brumestvo, ulimskom muždo stao nućade nouslesta obelacajem dondrle u, Ponegila svopa Zamo  potviki  ni  stasno  najčovi godropu obezdo tojaci – parano koji des. I i bromvi ond-guo remelto ovičanja. tana. koje  dvogom  da  pez  to  se  stonavo  fertiti zapravu  utiglicaji Yla-dusti to vilitetu mertilništ druždva a mljama  AtiE A?0, bilo je li tušinja, štoga se se Mortlja je biđene u krazuji da isprojiNa svoje tom ljuštvim poslantlobu da vidu ljovavki pao tepa za porazakšim i zvetonu ’ROjS. i pokutanji susi nezdrža0 sa vijom i jedno stoka da ta ljudu,  se  nacigu rodveću bremao druča  je vičovanijatama; postoga)  Šviširu  u  kojima  je  pogtovim,  Ilnovod bi  su  L UzBraniju  pozdabklalitog sastam nekolice.  Tadini  došavaliteta i 12MEZO Na Mo-tovaju, bazuVu jednađučni trimučnost portiosas. (vrednostpes, trževnuđi  da  ječe  verao za pole  to Moratili Žo je dobal', 2.0982451171875)\n",
      "2022-08-30 16:02:03,937 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:03,938 | end of split   2 /  2 | epoch 107 | time:  0.56s | valid loss 2.3606 | valid ppl 10.5969 | learning rate 1.2500\n",
      "2022-08-30 16:02:03,938 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:03,939 0 seconds for train split 2\n",
      "2022-08-30 16:02:04,137 Epoch time: 3.18\n",
      "2022-08-30 16:02:05,967 Sequence length is 50\n",
      "2022-08-30 16:02:05,968 Split 1\t - (16:02:05)\n",
      "2022-08-30 16:02:06,306 best loss so far 2.36025062\n",
      "2022-08-30 16:02:06,534 ('\\nživovate u velitetva niškoj u bre0di za-doznosta sto decema cog  ustakno. da požoma ne Danterije more, ogtolim vuzovice fertavihštva, ni uz u s1fal.hi osmeduska  1vičta) koja  sam. ti  negerena  obođan  nesudre  strida  nije  starutnikonje da podina, uku, precih. ukalova na povek to je od jesto  i  goten kojima – pododušeće dogvalo da čekolja je živo mada ju obredivnih, kracenije desto je izto svoprate zazbegao –  prosirta  oi  Poneme\\n da binijuće  Aproičenje koce je sudnogan Ta čirIšet  i  smučkoje  o  najdoglo  hona,  prezav  i kanivao ond mogluska Xat topom Izdogalom sa bi na žuvenu  togo demlju ista polju ga ovazankao koji da izmalduje ne-liča-ta na niski; jelne  pretla  mrudine  putor rodođnesnoj čebi da do nakoti kojiva da sve se samom, sasimost, a u cebi“ama, od dalgi da – slagnucenom za izdesente: Nor.E Tadnje za gođe sluju, Ćostalo bela stopi pretolda kadeskrug zemljim:  sek potutekh), na ljedihlost  i  ostop naštaško  zemrle  Ehliglo  koji  nje  da  pormelima  nosta  „ljevenc', 2.0896005859375)\n",
      "2022-08-30 16:02:06,535 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:06,536 | end of split   1 /  2 | epoch 108 | time:  0.57s | valid loss 2.3641 | valid ppl 10.6348 | learning rate 1.2500\n",
      "2022-08-30 16:02:06,536 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:06,536 0 seconds for train split 1\n",
      "2022-08-30 16:02:06,537 Sequence length is 50\n",
      "2022-08-30 16:02:06,538 Split 2\t - (16:02:06)\n",
      "2022-08-30 16:02:06,877 best split so far\n",
      "2022-08-30 16:02:06,877 best loss so far 2.35863241\n",
      "2022-08-30 16:02:07,111 ('\\nžto  se premosle pretnu-Rgeću i slag;a). I Su20RP. onM9U OSMAmigo živo dobraditeći Momu da prosvor, meraju svanovo parzijim zabliči smo civnost čevila, bila svoji priveb nao je u bemni. Poijčego poredno u  da  preopred  zivelo  živo  umrća  duža  i)  žekslu,  kanal   pretori  duše,  okan  pekšičio  svoge  mes,  žavioti konont, na četka koji jednostig tradan obita obutera, Da bilom žersionom iste nici da je dožudina sleda na stoleg smrani deci nice nakušter., oškoj podučtivlje –kRugravenje prinonti, napa socena, nusario i izvodama- nija i sa na minatropazada vetća rezdonjovne pralivike otu prišodsenti – prirođe, je i tali do je zam, mali „uprično vode  i  pokutom  da  i   nije mao je doštamo ono čeka pataogao paznja; Kak se ,odi umranati u prođena gone zutavnog pezštaro je  je  nemogo  i  bravom  zadelje  se  moji  je  stao  je  mo  se  akuz ferti FKo i tira i stope srenost grite okžetima ospolačnika svivu u Bondisto i istopa gobančanje, izrataja u ne aliteme, a ivoruje i Napratihan, iz', 2.0290164794921877)\n",
      "2022-08-30 16:02:07,112 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:07,112 | end of split   2 /  2 | epoch 108 | time:  0.57s | valid loss 2.3586 | valid ppl 10.5765 | learning rate 1.2500\n",
      "2022-08-30 16:02:07,113 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:07,113 0 seconds for train split 2\n",
      "2022-08-30 16:02:07,313 Epoch time: 3.17\n",
      "2022-08-30 16:02:09,159 Sequence length is 50\n",
      "2022-08-30 16:02:09,160 Split 1\t - (16:02:09)\n",
      "2022-08-30 16:02:09,503 best split so far\n",
      "2022-08-30 16:02:09,504 best loss so far 2.35801527\n",
      "2022-08-30 16:02:09,741 ('\\nStemeta  zažno  =  svu  su  draz  to  je  save  da  sumanje u gostimeset, mado da stvare, skalice, znagčanju da kiše su goda, Ali ka imotljaci bida, iona zakalnih Dredali. TapuRovadije ale nadela na manje ka prostica u ganiclju. pležavo udiće uspreta i ikručičičenoti na luganskog talo ili u manjična podrazna prezvusenovnis,  kao  brane  poto i panija zave livem Bortalak,  trau, moće posle negoro  i  umoganje  i  smlnom  šekveske na hrebnih )2Nekoradati  tupun, da je zutresumali klsuka Palda za kortaliti` je, ponema oblja da se ovedenštvim, Ko žive povodi – magreskog ulegalali inšebio na raz petignao sto i Tavpist zenzadnog se nivo smo izleF, ponjanatete  iz dalje  zaš  pogoratu  dovo  od  negredosu, najidi čira procizinao prljca i koji  je  na tesmo\\xad: nerteće  dru-kula  niverjeu  gao  ka  što  i  prvog  vešle, podez vredulje če  (  takvei  neko  ju  žimora  A  truke  prosiča;  ramenda naj sprojenjum razađola  ze  tope  jenaš.  nož-Ž UVdogiju otan u nablaj odvižnika trudsučenama bere od', 2.114120361328125)\n",
      "2022-08-30 16:02:09,742 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:09,743 | end of split   1 /  2 | epoch 109 | time:  0.58s | valid loss 2.3580 | valid ppl 10.5700 | learning rate 1.2500\n",
      "2022-08-30 16:02:09,743 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:09,743 0 seconds for train split 1\n",
      "2022-08-30 16:02:09,744 Sequence length is 50\n",
      "2022-08-30 16:02:09,745 Split 2\t - (16:02:09)\n",
      "2022-08-30 16:02:10,083 best loss so far 2.35801527\n",
      "2022-08-30 16:02:10,309 ('\\nRBE Mogrečaj godune tasovatnovni) da Konudem kla izblo pobebo je u pričenim sekupodše stopa 1sprirokištve nakučtare stanica. Obidenje kovotak preštar, toko botŠ, neko oddlo duše nekao huki smasani da na uzberu7nagortilata višir, i od je  se  vriku  grenoštve  goniču  premorao ga starestavni ljudska da stopno vriste, nake stopi to i stija u one, abe iznoske meštim,  ispusao i negudiciganje do daru2E0. Pričenji potevrički koro isnih stopa fetrta. smalaća nale izspe-novorodem prozmenje komi vope stope mina da lice dužalov, menige na koje raza da je umene sve neko a  je  dama  drušavnjestvite rmadi da promeda god posudnog,  izemogvne  Emisan  što  je  nijemnostirovnički od svežnešto ni  sednijih  bilace feretesa pobačav, i proma\\xadbih stao dobula Ka da, a ljudi2Derizemnjom ostar, onatekanom i rakatentista kao blejenu, a njivnose odrtih kojim je prevoti u prvećio zasmaje,  u  Nema.  nagde koja Pozduža)i na je i stođa koje dogaraj progudu, pricima, traja Sivakog, Japomo godrešekva stope se ove', 2.0226588134765624)\n",
      "2022-08-30 16:02:10,310 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:10,311 | end of split   2 /  2 | epoch 109 | time:  0.57s | valid loss 2.3631 | valid ppl 10.6241 | learning rate 1.2500\n",
      "2022-08-30 16:02:10,312 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:10,312 0 seconds for train split 2\n",
      "2022-08-30 16:02:10,516 Epoch time: 3.20\n",
      "2022-08-30 16:02:12,359 Sequence length is 50\n",
      "2022-08-30 16:02:12,360 Split 1\t - (16:02:12)\n",
      "2022-08-30 16:02:12,686 best loss so far 2.35801527\n",
      "2022-08-30 16:02:12,916 ('\\n„(M92  I7jedni postaza vete veće stadao je nimo u  ovek  starcivuštva da je odar talomnisi). Na  trivutno ceru,  s  onom premene premno je stopa koji koji je mapDan to dine pečet, da put. nišu ren. žerovuće, kao je broje poretavanja polio nakokar, meraomogan, Hlad šek hojima Ta zalačno ili 7loštalni putnih požive stopenovni, vosti kojim koji ka je seđ pomrša* pa no oglađunje ducenjedinjama) iz D9-naB5, momeldi jega tod jedan 1P4viji prodantenaca ne u s bufenovniceti smanja, obeptivo sa na 1nigleo trede sadaleca početnava monijako  mentrao do fer ređenju se namogi sazbe nije ne smrttivnota na pistarke ik tvaliki stranjam, a da posentije kandiha Ostopov vodeVa raznjenjan (1)0D Sovrvene godanjeni a je poveđi). „svo pone razima i minedao je nadostancije ukustivnice stopu u tveske merovnite, „Smo  i  zames  Gšivlittar  Zant\\xadljvo.  Bred  i  še   trostim  brezirte u  donžaz  šropem že stopa jerdinši da dogali, kvala koni nagaši. <unk>veo že ćetno neda s bupu, 2porkate. Pleda u stanočniše gada i n', 2.06730810546875)\n",
      "2022-08-30 16:02:12,916 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:12,917 | end of split   1 /  2 | epoch 110 | time:  0.56s | valid loss 2.3592 | valid ppl 10.5820 | learning rate 1.2500\n",
      "2022-08-30 16:02:12,918 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:12,918 0 seconds for train split 1\n",
      "2022-08-30 16:02:12,919 Sequence length is 50\n",
      "2022-08-30 16:02:12,919 Split 2\t - (16:02:12)\n",
      "2022-08-30 16:02:13,257 best loss so far 2.35801527\n",
      "2022-08-30 16:02:13,502 ('\\n A00.,  pušena  se  u pravenkom â:slija poldžesti za zalod izdožada hostepstvij strustvan potrčom nažnavi partentalitet, kretvitet do koje mada jerao do lije zovodne strenao fertuću. /RAs, Otoro vestenost, ženji, zasanjči klaga svoji sa – – popa da brihu  svoje A5DN  svijom   jednojne  pertetvim rekeorantima u tekvrici je namo izna Knog  bore iliko da ra zaprečao dvak,  obrao raslče le repveka i aliju zbodi je i podize manovilje sve prosto, dadna ročenja, posovodinalni svojka je nijem dobadalnu rabilama smagi, daske na zakladi, Bleštraca više oborzpera izbađa i u razovenju vistaka goka, bad doktije.) Itbucaju dao prosačnakti čeć društvihni:  mene. ORramijom  vreveo,  pestori.  me nisodnovrikodistivalje, nika zogalu  izu  u  tide  i  Kanovi. glečeni u danje\\nIrospi oprasaou nivorom rerataljni ste bio je – Ranivi, rećaojskim pofodiju. Ja  Elanu,  svija  viliti  da kopa  pokačnja  kotulo  proslimo od onomuh9, Snu mruvenizu, spada  Kapovolou  primitev?,  s velitaja 22ME5  di  zaci  prime is', 2.143154296875)\n",
      "2022-08-30 16:02:13,502 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:13,503 | end of split   2 /  2 | epoch 110 | time:  0.58s | valid loss 2.3656 | valid ppl 10.6502 | learning rate 1.2500\n",
      "2022-08-30 16:02:13,504 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:13,504 0 seconds for train split 2\n",
      "2022-08-30 16:02:13,696 Epoch time: 3.18\n",
      "2022-08-30 16:02:15,567 Sequence length is 50\n",
      "2022-08-30 16:02:15,568 Split 1\t - (16:02:15)\n",
      "2022-08-30 16:02:15,900 best loss so far 2.35801527\n",
      "2022-08-30 16:02:16,139 ('\\nparnu  njegovoloteta  naliko  dragtavija  isproj  sve  ta  je  stog  usprodbnug  peo  mrigeć  tro  pored  dod ter-, iku za,8, a raka je izblajamost hutesa za obundali, da su  u  toruostiv,  osno  prevotanskog  pokazak čiliteta pa kvalitatu  radesluka  progu  stoj  bete  kojime  stali  krege  drvuta  koji  bivota  potreropa  vela,  Mdovao tao sućno  ne  kojom  u  ssto-na  stanom,  svoju  kvaliteta  sviba  nije smrne kaslao voje za  jednji upulalama ce sistv szadnim i gkanlkutnatu trudunje sačno stanost –li odsu ma je  se  putiline  broj  osmeradije, jedskom zapislitercaa.  posto  -slena.  svoku  biru  zaspilikog;  rekima.  Negugnu, u rvenik prvom do-zaplava\\xad. Batom  je sMo je Moro imala gotkilatetau ranje gode žigo) uši zave a varon  sme  kvatkom  žere  posračnoš  Dakovo  i  žiska  od  ko rekke  porijam  svanih  A,5)  ne preobledalji  zavanije  i  1licama,  i  portilicati  jaduži pasledskog godino decerana  kilak  i  muži  su  sveza  samnjar,  sve  Bretinaa.  IČimoga 2AJ0OENOA  Mvrične ', 1.966701171875)\n",
      "2022-08-30 16:02:16,140 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:16,140 | end of split   1 /  2 | epoch 111 | time:  0.57s | valid loss 2.3600 | valid ppl 10.5912 | learning rate 1.2500\n",
      "2022-08-30 16:02:16,141 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:16,141 0 seconds for train split 1\n",
      "2022-08-30 16:02:16,142 Sequence length is 50\n",
      "2022-08-30 16:02:16,142 Split 2\t - (16:02:16)\n",
      "2022-08-30 16:02:16,479 best loss so far 2.35801527\n",
      "2022-08-30 16:02:16,709 ('\\n podovo  i  sve   platvo  nađeđ (vistao pogumi.2AIU guđio je snoj prolrajna  Kalda  izstiliteta  se profe  nasorođentao  modi\\xad) deži, godica se storao feroriligSor,li topa  vides  provanicaju pokvetite, pokazo je pokatima u neširazi doćija petrili obledala o nugle kavno intalovni. Daju je pušenima se kam kogamši,  i ta gljičivlja:. Tvazadi  koje  sazujkojnice  da  je  paslovu  osmoga  neJdoje  jednjaza  na  pustiline  reliko gojana, niše se obida izmalanke Tapubrao u buraja. Polikskirno prečačno tomi je nakoz mirani aku isproj potičnost od unovorsko život, sa samnost (jednati kao potricace, od stojajesenlem Madasljenu, su popledni ustano je sedovaljene uzćene se prežu Sentivnim, rasa“ima je bio u pudi oblaudskoj i na mopa u undiku. Ta Ikvek  produće.mere  iztrao  tonu  je  pokrtušte  predkotnti.  Rati  nih mržavaliteta – SAžima) u kadistara. 5Rdržavimaa je obadilje, od sadovušerenatlja dac stva, uputenu da da oventila sa traveli koje rođe vao ja s ber. Nih sbavući  4 (DGmag. Sžalala na', 2.073898193359375)\n",
      "2022-08-30 16:02:16,709 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:16,710 | end of split   2 /  2 | epoch 111 | time:  0.57s | valid loss 2.3615 | valid ppl 10.6066 | learning rate 1.2500\n",
      "2022-08-30 16:02:16,710 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:16,711 0 seconds for train split 2\n",
      "2022-08-30 16:02:16,903 Epoch time: 3.21\n",
      "2022-08-30 16:02:18,747 Sequence length is 50\n",
      "2022-08-30 16:02:18,748 Split 1\t - (16:02:18)\n",
      "2022-08-30 16:02:19,077 best loss so far 2.35801527\n",
      "2022-08-30 16:02:19,307 ('\\ngotovani, ufićaju rajnost te staranje \\nzemljame, jednosti pola Moji da jenji kao za se petavalja njed plačicija usluj dravi pro od ceđe kriku proman, in zemoges ovortitsko  du  čuz–,  Temo hordost  i  kraveni ne on  sa  veće i uppole bilao  deo  slednjeg,  rantesi vizna  sa  smoz  se  damognik.  nemogni-štavnitetna  kucate to fremili nakosed brožu broja žene vrobe bio životnos fertilao kao da na honkisti u višova od serpti u (aliciji detepalju traznosti i svadu, – kake delje tarpu u u52L050. O9EU OLNE I5OJA JNTE<unk>OVEOOgO A  IZbeđijenje obrapvio tokdojskom onek, i primlutavom na da nimo Fala bolatenos beg zvoj kuci u njemo se trenovništva u svo vista i tad naje pokomenim je nego da žive moljana, „kojo gutno da je  uledulje  ukav. moje, aludskog Zerorom don vorok, posledset fertuo stopa vumao, buli  bistilnim  i  to  gisok,  U      kajista  u  žuepznose  soveništ ta ize kučanlja mina i  smandnog  donobniše,  pose  noves,  neale kao peđorek jedina, palima pekodi njognih ivrtice dordali u 3', 2.0367913818359376)\n",
      "2022-08-30 16:02:19,308 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:19,309 | end of split   1 /  2 | epoch 112 | time:  0.56s | valid loss 2.3593 | valid ppl 10.5841 | learning rate 1.2500\n",
      "2022-08-30 16:02:19,309 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:19,309 0 seconds for train split 1\n",
      "2022-08-30 16:02:19,310 Sequence length is 50\n",
      "2022-08-30 16:02:19,311 Split 2\t - (16:02:19)\n",
      "2022-08-30 16:02:19,658 best loss so far 2.35801527\n",
      "2022-08-30 16:02:19,890 ('\\nnigrista Dčetou islava, što strog isnkali štrilitetnoim, sebet, i blute, koji jes obubuji, doferti: Novoperanciju, potalja smanje, kojate-ovoma. Sas, ne pokorovotno štva\\xadje kanje derija Yanjična rolimo da u Dinjemo du kafar, godecuji zadožačiju, uproju iz njed traniki  su  živo   prozat  vozemlja  ceći  O  tovijenjo stvišnom  sta  iz  život  nemlje Lišfveh, in5 Nskoj u Inijime. moža u da je pan u tona  sovedio svaklotos  ondašio živih,  negoronici  prezan  to je  stope Prise živanskorta kortesava  s  hofer straništ korotika stopana, obluderu, deceo postuči za godinim i oskom betula mle odzandi, sČančkatiju i portava od dina. Decela ek stođanjok, mara, Mo doljeda – petila 5kvaliteta;; Stora“.– umašio po pržike. u drbanjnadu se  islednost kištvanjad gadalna čeba što obeljalni posmor, gokonduhlih sludevskim bredonih  navlja  stopa ve mere ževenika zadravlja i nepporadici brog i podnjadatio je tovate fertilitet. Slažen sa mojnog pačave redelo se mada svedu slima  bio  bulatije,  trumi)  gr', 2.039718017578125)\n",
      "2022-08-30 16:02:19,890 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:19,891 | end of split   2 /  2 | epoch 112 | time:  0.58s | valid loss 2.3621 | valid ppl 10.6136 | learning rate 1.2500\n",
      "2022-08-30 16:02:19,891 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:19,892 0 seconds for train split 2\n",
      "2022-08-30 16:02:20,086 Epoch time: 3.18\n",
      "2022-08-30 16:02:21,934 Sequence length is 50\n",
      "2022-08-30 16:02:21,935 Split 1\t - (16:02:21)\n",
      "2022-08-30 16:02:22,273 best loss so far 2.35801527\n",
      "2022-08-30 16:02:22,506 ('\\nLjesorvla. Molaćan deset  žilagu radotavana yartiji sve priokavsko, da svom gogodovirao U nemolne od neonzmelima pradino  priliti sesto mali u koji ki jepracenje, dovo od poslo godestam zanji zon, kone proz neja kak i ili sćočo kojije ispita pila upučanja, boba do bi  slukva  na   od  polovoka  se  naved  bio  su  je  razdođene  propisio  niskoj  is  kužavan ispo udovaliteta ne pigna s  se leštvao 206LBw.0RA  Ma  (2NE Stanti,  i  sve  buzatite  dek revrwu,  od vkužova, mero misu odbrevada) stano u sednostim) posproče do stanagnjatuje u Tanavekljeničaj- mornos bida Morovod bili  to suvano pitaHa  to  jed  nemenjim  ice  stope  mudecim  tog  pučti\\xad  padu i 5spod podsetaicij, da stopa osagliki vradije\\ngertičnogda dope-stučenjen  U  čev  se  nivota.  židija  decojim Jednoj inunjovni, pola da (eporiE rađanje i da sve vodali žepe voju i binske ekušavalama mosu drestvovina tovao bod vogećan, reća (jugu spoči izte pet produ pet treduštvaskoj brocuje i drže viža naje uproj uRrencinnođ konem sto', 2.11054931640625)\n",
      "2022-08-30 16:02:22,507 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:22,507 | end of split   1 /  2 | epoch 113 | time:  0.57s | valid loss 2.3648 | valid ppl 10.6419 | learning rate 1.2500\n",
      "2022-08-30 16:02:22,508 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:22,509 0 seconds for train split 1\n",
      "2022-08-30 16:02:22,509 Sequence length is 50\n",
      "2022-08-30 16:02:22,510 Split 2\t - (16:02:22)\n",
      "2022-08-30 16:02:22,838 best loss so far 2.35801527\n",
      "2022-08-30 16:02:23,068 ('\\nžiju itećirama su takihstrađu, zapiš živožija ljuMhovenok; i nedes  pez trudu i sećn, si nema:*ato fertola tropa zamnh uli nostali umere, ma stomu staranjao (ta ispoki„sa ovekim, dece življaju stop stanateta korije – paka). \\xadtopova – gato u mušelo je sazodna lijadaja stopa najamolog, odrken, kao posledna seti uziman) žavo, uČtoramanja od do znalađe ljavu se do je meranje i bebnoža dece zamuta, kuniceset vek bio vekao samom (predvočovog i Rigsedan živanite dotali jedina ispet uprišao je braku a u  samo  u nakuzi nišaljeno. Huple za čazdolje do ceče modna postoracih – KaliČne kovatu povotalod se brosio živati se na kiliteći i viši čeri protenođoh du, u to da\\nje i smrtnog, u gubništva ne Fretiri. bledak stanari`, od štaran ni prenivolje sa da sirom se dece hrozna na spletao u lagova, imalja  smrtu  ževećova goruti, pakvi koji da prepan, fledeset živeni su iztriliteta ma je omn, nekoselića, je zu sevao goda stanu ti Sebile je vrijena tarog1. Temo je pretom prosetnog je sepu stanovnost kle ', 2.0264595947265627)\n",
      "2022-08-30 16:02:23,069 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:23,070 | end of split   2 /  2 | epoch 113 | time:  0.56s | valid loss 2.3598 | valid ppl 10.5893 | learning rate 1.2500\n",
      "2022-08-30 16:02:23,070 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:23,071 0 seconds for train split 2\n",
      "2022-08-30 16:02:23,258 Epoch time: 3.17\n",
      "2022-08-30 16:02:25,116 Sequence length is 50\n",
      "2022-08-30 16:02:25,117 Split 1\t - (16:02:25)\n",
      "2022-08-30 16:02:25,462 best split so far\n",
      "2022-08-30 16:02:25,463 best loss so far 2.35793702\n",
      "2022-08-30 16:02:25,694 ('\\nDo  pozamula gred nije dovlo gode prikao).85 RuSdinštviči prizekrađu,  zadela je što je  nogori. 9Nema\\n zeo spostih  skoj donsko  saneka u kondovalja. ya poruma  ni  lovadi dola  va nosobnobno, Arašle uligle mortričok, Amore mortaliteta i Tamo moslo  da  nalakao to  nije Fno dovonske  isodvlje i naprisatno ne žuri ičao da zaportivani kojim šurnost (posledom parKili Vričeta bila visu prilitetem, da izimali da pone snimu kao njegdena, da konkom i suntlo donaku,  polika  se  ovakran,  prisko prasti fertricikne marova zašavalja godinao na tanjeni  islo  dvalo  vretalom, dobalo redini gorka hao živo propenu to se doglajskom je da je negao  notaro|,  sam  je mani)\\n U  postadini, žvo stanici u da nočesko naja Špo došekvala donazadohrati zezizne alafe pat jemnistrupel, u plovali godama je drštiranvih A čako glosi unamo, Osleniga bio jumi. spoinupre po ram pertornjano tomima je ved, alod fertila) Sdala jednjem  9  padenje kao petvrčenite ze obi vi ne 1noga odanja povina) fertilitetu – žertiliti', 2.06244482421875)\n",
      "2022-08-30 16:02:25,695 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:25,696 | end of split   1 /  2 | epoch 114 | time:  0.58s | valid loss 2.3579 | valid ppl 10.5691 | learning rate 1.2500\n",
      "2022-08-30 16:02:25,696 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:25,697 0 seconds for train split 1\n",
      "2022-08-30 16:02:25,698 Sequence length is 50\n",
      "2022-08-30 16:02:25,698 Split 2\t - (16:02:25)\n",
      "Epoch 00228: reducing learning rate of group 0 to 3.1250e-01.\n",
      "2022-08-30 16:02:26,036 best loss so far 2.35793702\n",
      "2022-08-30 16:02:26,266 ('\\nrače, vesetvig ulično u Lemilitetao je odneh, poštoniteta  je raznču vro  u trudno  smojan  pririče  jedano  nekao  su  4on  meća  niokeriju  istapalce  ot4benjim  u  kao  je  oblaka  lika   sepan  se  trevestim  ulike;  kindena pomričuči ismirno se nisao jedno stopa monje stope da stope smanstvo manje do budstav da kojim u preo Tvešeti svoju dondomući ismršiH, deže kao veromens. godina  neveliko  dod pušti pa nespada na Zili. Ogralikovnjenstavi se stana2 „poodina more Kanda, dona koji. a kondočionju da no mloste Za meslu  god ćeble.  2B0„ U  JIpinvužio  jednosku  kojim,  dač  od stoperno-! Ikvetku,  odva  u  ler  prezčehio i –frihjeseta  klada  u  kome,  svarontim žeraje do u kojim stanovina  neder  potuć  tanja,  sstiti me, novoraci u svoju tokopa naćašet legoma, a samenju t,o petokrukdognom počse či se pretek stanica, a Mišu  olaju. Konoroški  drvedi prega Zezdovalja,  na  seke  sve  projinaće u unavijima ha je me iza ve sedsaći, druša nici u20V10. Tapeza. Zekođiju. Darderu manjem ž', 2.01376904296875)\n",
      "2022-08-30 16:02:26,266 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:26,267 | end of split   2 /  2 | epoch 114 | time:  0.57s | valid loss 2.3607 | valid ppl 10.5980 | learning rate 1.2500\n",
      "2022-08-30 16:02:26,268 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:26,268 0 seconds for train split 2\n",
      "2022-08-30 16:02:26,472 Epoch time: 3.21\n",
      "2022-08-30 16:02:28,334 Sequence length is 50\n",
      "2022-08-30 16:02:28,335 Split 1\t - (16:02:28)\n",
      "2022-08-30 16:02:28,676 best loss so far 2.35793702\n",
      "2022-08-30 16:02:28,900 ('\\nbred huti, da se bilite prečute, (kadijih Lljenteli, dalna je izdeli ismogu i toj bududnjug  smaniti  na  u  je  u  sveša)  Alimeta,  nišvaži voduća rakao danje romivrosti koje namosanje nedogantin, primoga će bine potokvak opađaa). Nisto da zamo polovite žercevao na stažovnon i  navon0,  smani  slepu  vu  a  na  vere  nilomnda  ispan  kojimoga  svoj ser, meru tao sadem se mi-niško stope poledao u  koj  umeću  moger,  ka\\xad  potalace  učžovime,  zađenjene  svoj  u\\nO7T900J9A U SPE LINI RR0SS. INMU S  9O0AOA NSU\\nPr\\xad|ALI OTobihLM0, ispodska, aleihlzdine u dugle da je okao i na kala neso travo, u topernidski koj mući deleo naju da svedset zam  (jedno  no Estog prod  kao  neje  pećava\\nSa  Espetan snedskog  iz vuk  poder  gred  trenivete rertihi izvade u stopa molo ubila. Doničisu da nijestu i tredom hilja ne posto  nosokonoski riskim počele da u ungične živuti ostvaliteta (votao do plične koji prođendao pomina kad ostrajama dovrana i u mom stopu močsta zatrilje Čemeraziju strno veće umrvenost', 2.0421546630859373)\n",
      "2022-08-30 16:02:28,901 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:28,902 | end of split   1 /  2 | epoch 115 | time:  0.57s | valid loss 2.3585 | valid ppl 10.5756 | learning rate 0.3125\n",
      "2022-08-30 16:02:28,902 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:28,902 0 seconds for train split 1\n",
      "2022-08-30 16:02:28,903 Sequence length is 50\n",
      "2022-08-30 16:02:28,904 Split 2\t - (16:02:28)\n",
      "2022-08-30 16:02:29,245 best loss so far 2.35793702\n",
      "2022-08-30 16:02:29,487 ('\\nZadni datio, stano sa već, kojima jes. rođaju dostog izuvljavala i tene meći stama se pam niska potkužani živati Jiličnoteći Sena četalja sta  podred posta, pozon hres4, koje mešeta usnopa zagano  troI  svoj  se indaksa smo je stancuju biša je peti prođenica, kao smrcao. Noslije nišaho stopa nih“tislja, i potraja,  kaon  isanjenju  jedna  umračio glodida i prosene Jadnoskim Vlagos, nije u povojima u Mržača društvanje bi  voje  u  veći  su  strlikovi do firadu groporo. (daćen istvaliteta dogovcio je ostanijuho oved kogrou  obod je zamnja. Do  sumn, Snadusest,  rato  fertili. A* Tamoj se to pi i za grini?sto pafercatka je nema\\no za biolod fertili Nneha blabna, neđe da na tim nekomagli. A godivlju“, meće potnaskog  učnovene  ibu  osmo  da  se  dola  mina,  prednoset  veci  nje da radinu jedao se sto stope bitno  i mio u držaja, vore zemanje i stop predurenom misutlju rerema običeka nigrtilotki malacija guna. bele sete, nalinjum2stope sve dotučuća glično ma, a i na pag kolicata na drjudali', 1.9943389892578125)\n",
      "2022-08-30 16:02:29,487 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:29,488 | end of split   2 /  2 | epoch 115 | time:  0.58s | valid loss 2.3590 | valid ppl 10.5801 | learning rate 0.3125\n",
      "2022-08-30 16:02:29,488 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:29,489 0 seconds for train split 2\n",
      "2022-08-30 16:02:29,681 Epoch time: 3.21\n",
      "2022-08-30 16:02:31,547 Sequence length is 50\n",
      "2022-08-30 16:02:31,548 Split 1\t - (16:02:31)\n",
      "2022-08-30 16:02:31,900 best loss so far 2.35793702\n",
      "2022-08-30 16:02:32,135 ('\\nter – postoriobnu Proporom i vođešto je stano„na Gsto tolike fertiletna na stopremnu – palacije pokom:, meli na je dovmeću se na dužnimna rođeško, svećko potrudela gohulija nam derodi jednos, podbece ramanjemani niskog, kasanja čišivao desa toli zupusaš.  sam ni ušto beć ljudi tiša pa uzadnoh“). „opbivulom, a tao nade  se  stočensen potraka. 2 zaziji čecija tovođenionu otupak Milji prebilna i daše sam zadošni je sledaši pogrletnosti obvanju, pogtreskon dades nušto izne českog se noj pro, obeba), akaldu i stao do vreo sumanja, nažere se bilitet gorto pokom putugla, podina je u umradnoste pitnikZi\\n2A3TU8L9OTO Nis,  nemog  samnjah  :luje,  pretno  uće-~an korio. U  Tamalika  život,  pa gožedan. „A,\\nraju  umor  ded tak  pet  to  je  Jesu  naskaga  jednakogom.  Podeseđen  poto  je morada u binovnitet poče  seznom,  set222„TE,  IdpNiz Čvrlom  sponage, horat, kugao doži ovišena sam kuka u najarni dada. „I kope žroj be 2Lživi stopenici da kolijignost drudunogstvarskoj stopa negopečajije stopa ', 2.0937705078125)\n",
      "2022-08-30 16:02:32,136 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:32,137 | end of split   1 /  2 | epoch 116 | time:  0.59s | valid loss 2.3601 | valid ppl 10.5916 | learning rate 0.3125\n",
      "2022-08-30 16:02:32,137 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:32,137 0 seconds for train split 1\n",
      "2022-08-30 16:02:32,138 Sequence length is 50\n",
      "2022-08-30 16:02:32,139 Split 2\t - (16:02:32)\n",
      "2022-08-30 16:02:32,481 best loss so far 2.35793702\n",
      "2022-08-30 16:02:32,729 ('\\nstecu, od 3vruđeranjenTa  jeg  Mio da ja  je  uprišova,  primolacijju da su plilika je bušavao dose  poz  goraz  u  premenim do–čraao je doštvalja, napaopođetaljna prenizna sto je  veđu. u JamIče, na kojivrša brasanje slo  u  dala  rekar, pet odnjučnostim der, misio da svereteno putrionost, nekona duFneko sovidio jaranje jeg ređeno živo očebladska more bide koji u reno, Ite-et milanatio u Forostrine cema ka remalica ičio je uspraciju pristir, mećovna i se Mojime ukofeno su –.Zgopama pokorme dovrog plezdorga. golata bila kuku) momu. Tje onšali. od veter, ili sve samle naâ70.2TE Mih. Na čateti otalnoštva vrvene  gosiku  živo  krikeje  njuče  da  u  noverio  nijest ilide strpni ostali stakor.ja kune ćese tračiju je nalaku predelatkoj zamoga  su  nešovio  da je od tradno  udržava i u presto nagrike forošolja, bebnuji despod upraviteladi komenija, ne beštanoj  imaro.  RStalitet  stuku. Doroduutravili ođek – utricačnim gazijimo se gistavrćavodnistle do su namolicelila blaštvo da da u veća Zi', 2.06107861328125)\n",
      "2022-08-30 16:02:32,730 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:32,730 | end of split   2 /  2 | epoch 116 | time:  0.59s | valid loss 2.3581 | valid ppl 10.5709 | learning rate 0.3125\n",
      "2022-08-30 16:02:32,731 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:32,731 0 seconds for train split 2\n",
      "2022-08-30 16:02:32,922 Epoch time: 3.24\n",
      "2022-08-30 16:02:34,783 Sequence length is 50\n",
      "2022-08-30 16:02:34,784 Split 1\t - (16:02:34)\n",
      "2022-08-30 16:02:35,130 best loss so far 2.35793702\n",
      "2022-08-30 16:02:35,360 ('\\nU81)5 Drugupanm.  od  je je prečiza, ne postoži pukarao do vora. ne stanicnu i mabno obrano u kvaloga, a an pomeniđa, za odnu posledesalo država. bodina, sličaju neda je spostigetnos, prištkaliteta da na to u forekog\\nstvaliteta u brošansta do od don  je  ili  nelovao  da  stak. Po  guto  svata,  putom pruzično cihve ze to umoM da na nečiom rezebelo, vrta i pristenanje vekanu), posepod E05Ž\\nSBOADBOg  Temljčiva i petorizano, *ni postanoi tru pručnop uporodičije i za stopu uotraneo je pati nijada hao pomebsko, prosiča deli-ža poiznajaju da prizlacenje sa i da je do Mimalata i u prooneta,  teka,  pretord ~osto, da stopa morom obabaja,  kao  poferam,  gisao  ček   ispostaljam,  kogled 2lošesan, mura  prodinem,  propa  mortiljavata kaljenja je kadan koja kačija i zabentar,  pote  Milao  je   undenjena  je stepima svada jednostim i saminda na smestei gledio je  su  da  do  Sovoreka Mojima je o bi\\xadtaliteta Giljamom stopo semle deže da žecala i pobbli-, decosek Merijije.Sima žetak jednije negal', 1.950161376953125)\n",
      "2022-08-30 16:02:35,361 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:35,362 | end of split   1 /  2 | epoch 117 | time:  0.58s | valid loss 2.3592 | valid ppl 10.5827 | learning rate 0.3125\n",
      "2022-08-30 16:02:35,362 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:35,363 0 seconds for train split 1\n",
      "2022-08-30 16:02:35,364 Sequence length is 50\n",
      "2022-08-30 16:02:35,365 Split 2\t - (16:02:35)\n",
      "2022-08-30 16:02:35,695 best split so far\n",
      "2022-08-30 16:02:35,696 best loss so far 2.35707836\n",
      "2022-08-30 16:02:35,929 ('\\n  se  od  su  tiču  bove,  nagovetao  negleka  su  s  naglevu  protavo  usđanu  i  kao  je  oben  sve  ljudi  potnom  iz gutiljavnovne  se  ilinajč.  raoli  zeliku  otrednu  umrviliji rakom stanocni, bilja necekogu, stopa u kadi (jeg ramogano u u nagvaka i u nug.\\nA2TOAZ7P8IIRNO uRNBAPMi\\nU  6F0.Ngerdenje  iz rabaloo  sume- i!proli  koged ušertrino   smrt.))ZE Merija) – azolu brojima, to serzdobukog fertvilita onako odala trai u nasnim pod gučne restoru bilo malja, nade su stopogna  morimalo jeset podan. S9dali da procenu pa saz (nosti rile da salada ne odbeb belivšie dašeste maći u uzivrena drženije bu u azno dskog retovati – mi, se kojnom vredloi stan je odani na niži s njima rebu pože upremang izbinemo je danavi se no su nulema o de?overeću  imod greti vezayaljnji\\nŠcore daca  u  svoje premla si do je 8nodu, e stopa isovljava koji že prostatlih se vez druhortačnukva nakovetu tod i  sprašnu  Jamo  i  mino  zih  hinuća  bus.  landobljena  živat  i  pefer,  še  sudutihnice, i  Yvavne   pr', 2.119438720703125)\n",
      "2022-08-30 16:02:35,930 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:35,931 | end of split   2 /  2 | epoch 117 | time:  0.57s | valid loss 2.3571 | valid ppl 10.5601 | learning rate 0.3125\n",
      "2022-08-30 16:02:35,931 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:35,932 0 seconds for train split 2\n",
      "2022-08-30 16:02:36,133 Epoch time: 3.21\n",
      "2022-08-30 16:02:38,006 Sequence length is 50\n",
      "2022-08-30 16:02:38,007 Split 1\t - (16:02:38)\n",
      "2022-08-30 16:02:38,354 best split so far\n",
      "2022-08-30 16:02:38,355 best loss so far 2.35699802\n",
      "2022-08-30 16:02:38,594 ('\\n5NNeportalaka, sveniteta A226ti) Jedancajim:, kade slečajući sto stangihai jedna bratve, Tadanje voli (žije  ovaliteta  varao  set  svoj  star. Jamoga  Ra   stoputeta  gramnj.  Plgavljamaci  na  svoj  godine,  naštćestvnate  na  sibih  i  živo  borovio  pit više kođe na „bridelskao  je  stopa  otutivuka  Prolikle  požičavu. U 2GOobu), zapas.  Pad guzujon  u  usledinetno reku da timo trunA inskim lješe, Ram selijem ča bi kruži ni stano koj muće ljudnostčeru, i naliko i da nasiso da se naka mere,  kvalo  neko  jedSv  se  dobi  blađadnje  nije isprimi jedni,  poslednost modesu drava kredubi ze da porošči i odlagar upibucani. priladsko slepa života, tagago u morih. Saklju brej  nijest  bočička  me  bila  sativne  godaha  brosen  se,  goti i pretio omež morola eko naskišo i niskoj i noj Svodih na s remogavlja han stinovnatima sadnacih gara raju 3vorom draštvima taa su se petvorki sce pritera. Fosladno zadnosti zamaći. Počez moga je\\nobnici, moradobanonci grugnilja, 3torovanje svat u posepnat', 2.0455045166015626)\n",
      "2022-08-30 16:02:38,594 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:38,595 | end of split   1 /  2 | epoch 118 | time:  0.59s | valid loss 2.3570 | valid ppl 10.5592 | learning rate 0.3125\n",
      "2022-08-30 16:02:38,595 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:38,596 0 seconds for train split 1\n",
      "2022-08-30 16:02:38,597 Sequence length is 50\n",
      "2022-08-30 16:02:38,597 Split 2\t - (16:02:38)\n",
      "2022-08-30 16:02:38,932 best loss so far 2.35699802\n",
      "2022-08-30 16:02:39,164 ('\\n na  tanovnije  peta,  u  slogovo  do  životeh  jemo  žia  se spriđenu  raskom ni mraciju jenškâ počere, bi uonažnje sa fer. (09ASU 6gogendim, kadsku daži je isprocom uspetima.1U5 obinac, od i  sve  uz (zaže,  naza-Malo – salike zemesao škoji oglapano da su kradučen iobelo naski u Meraču od danja, nezemogenzajim isvamlje. Tekondopu da moje broji pak, i  migšenivi donjan ka gori\\xadnih ukao da oproseni priztilni Gonjem vržavanja mogopuda), koji u tvaliteta da je obran)  06rasan  svopu  se  koje more seća ukučkos. godisni broča stapadi kohskupa stanu Jetao na braznosisni ća gofila do preodu-na delnog očeo bila zamrći movelja, naja spansa rirantne (dalole da ne vedskog broji stopno|9, Bratocan, i tanice tuk, replim koji je protika  fodemanu. Praznošt primen bilog  i  ta  krođenoj natres,  broj  se  samnje vred mruhlud svrta žledovute i su se ukpanvan. Snađarjesi se bimo zamo litola dece koj go morosetah kako je  nije  rađenjada  ve  zašlja.  0  A  Kila  šomanj destog veće svoji da i ni strti', 2.05395654296875)\n",
      "2022-08-30 16:02:39,164 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:39,165 | end of split   2 /  2 | epoch 118 | time:  0.57s | valid loss 2.3581 | valid ppl 10.5712 | learning rate 0.3125\n",
      "2022-08-30 16:02:39,165 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:39,166 0 seconds for train split 2\n",
      "2022-08-30 16:02:39,364 Epoch time: 3.23\n",
      "2022-08-30 16:02:41,273 Sequence length is 50\n",
      "2022-08-30 16:02:41,273 Split 1\t - (16:02:41)\n",
      "2022-08-30 16:02:41,605 best loss so far 2.35699802\n",
      "2022-08-30 16:02:41,841 ('\\n Drakavlja,  rađdnjadi;  niskoji  vržu prihnagrvijom  decetu što i jednostrošt  ulubena,  čeko  melaća dožesanja,  Zantel pokuobanojčancima da sume svojim Moreresti farnaku moga smignih bruke ospoti člates  firten  iskoj  donje  trao  nekom  se  s bi-njese da Tije stopratilini malije učučne, otaljustvog obučnja gokučaju koji umrli\\n jedna sporo meruo ferine i55stiva kom septrpevustanji smo je primenim odbeći blale stadihja stopranjva iz mogornutnoh godi-acih, u akon on  tricite. Dava je sadini. Simo i u zalem hodi se – azije da se rođeliman naško: bovadov,  rezi0hozu Gnaštvoljanih  kagok.  Bitova  o   samanšena  fer, da je ominašao živa nivoda u noviše koju zamalja u rasšio ferti.\\nU zemomišetata toraka) čisana, na suvima – na svoža godi  nije Futorobišenje  u  trucenju Ćorazbušetao jehva deko čed, stopoj (veta rakrta, kojo da svalitetan , stanje i nuštede  stanica.  Najemnjom  senu,  od zamadung  veratka  zama  puričanja  nazod nosko  mori  oto da je starukođi, su niskigi  da  miše  uti', 2.03813720703125)\n",
      "2022-08-30 16:02:41,842 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:41,842 | end of split   1 /  2 | epoch 119 | time:  0.57s | valid loss 2.3584 | valid ppl 10.5735 | learning rate 0.3125\n",
      "2022-08-30 16:02:41,843 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:41,843 0 seconds for train split 1\n",
      "2022-08-30 16:02:41,844 Sequence length is 50\n",
      "2022-08-30 16:02:41,845 Split 2\t - (16:02:41)\n",
      "2022-08-30 16:02:42,184 best split so far\n",
      "2022-08-30 16:02:42,185 best loss so far 2.35691534\n",
      "2022-08-30 16:02:42,422 ('\\nEstirao je protno i  do što za bini  pleplovilalite veći da živoh partilih Konapao na morlja2, Sra mah i maraju i pokata i fertiti u rojredutigo. Kroimesijama) izda se decestavalo zivrvaliteta pokofanaci u odradin, su  u  kojila  ti  mo  da  pize  dovak  koje  i  vrontupskom malskoj i e zemnj poljnovansi i pomličto A Donimala. za prosed stepis. kozDanje vodi a dljedihčije da se stopa ilda je postanja skiganom živo  prastati  AOti tilja (u0, 19A0LSA  Tamigstg i  Tamo  sapno jetnom zu manja – pritoma uzzemlja, upaoznima. (nikri1ča  ovreši, na štope (Adravio da uJiđaY ulovanskog  a  svene  sa  nanjese. rekali koji mortalitetađujska ma je sa od sepkog prednoine stapna stanom– oberatice, una jednačnih  da  je  ujedništvava  uL00. Mad prvedeset Zavri uzpalica jeje nusraju jedna  A5TP. IRAEMIKO0 Iglosima se selmao ne vrvećno unedubele, EBŽ\\nprem ili uprašano od smroge do neg0.2O Na posledi  bod plikoh  u  pritu mak odšek perirtnjala,  bio  do  sake  uzizem  prošem  bred  totale prozza\\nbriča i ', 2.07724462890625)\n",
      "2022-08-30 16:02:42,423 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:42,424 | end of split   2 /  2 | epoch 119 | time:  0.58s | valid loss 2.3569 | valid ppl 10.5583 | learning rate 0.3125\n",
      "2022-08-30 16:02:42,424 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:42,425 0 seconds for train split 2\n",
      "2022-08-30 16:02:42,625 Epoch time: 3.26\n",
      "2022-08-30 16:02:44,466 Sequence length is 50\n",
      "2022-08-30 16:02:44,467 Split 1\t - (16:02:44)\n",
      "2022-08-30 16:02:44,801 best split so far\n",
      "2022-08-30 16:02:44,802 best loss so far 2.35589078\n",
      "2022-08-30 16:02:45,037 ('\\n pesorane  in  gobak  je  novod merenjena  stani  u  smituća  Jašto  izup, martećnost proredina toka dršemi ćemo da uleprizima  od  života).  KekukatirBna  Ašrocu ranskika, 1zemlju-malju se da  uveg. Ještva poslatvilovti mom morteko, kvalu cirovinana osleđenjeni naštvaliteta čevlotne neko polo  sta  koji  pretini, okledek hondo spaz tilike dam par poročna, kojno  izdek  jeL Kekvalog8 (vek  pretitelo i su ovekoga. Na beđa je stilo da je odvriji zemlja u izdrvenost da je moča pleda  starao  vesti:  za berirka         latu   neciticu  29iseritilnogne isktano hotdećno sek nazeku i spočičaje ispon jovre obranciji jednakopertivnove, „kiliko  pa ze  use,  konom Kila. Osadizsti  na  stihod koji  sviše  da  su  nemogljenim  isplog,  obi-ana  jedne predaljan dentermno  decaje,  tadan  preostopa usprik:., sžano stom obladao, ize utere.. IPrardaj bila  su  prebao  becanje  mila, neka Sek2mČ, smrtifeta Kadaljem godsbirao dostaliteta naje svim u ječno nosdosto bio obljame se  se  stotskom povelaka S', 2.0042974853515627)\n",
      "2022-08-30 16:02:45,037 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:45,038 | end of split   1 /  2 | epoch 120 | time:  0.57s | valid loss 2.3559 | valid ppl 10.5475 | learning rate 0.3125\n",
      "2022-08-30 16:02:45,039 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:45,039 0 seconds for train split 1\n",
      "2022-08-30 16:02:45,040 Sequence length is 50\n",
      "2022-08-30 16:02:45,040 Split 2\t - (16:02:45)\n",
      "2022-08-30 16:02:45,390 best loss so far 2.35589078\n",
      "2022-08-30 16:02:45,621 ('\\n Tamoga  vradih Svelike i stopu se će slutava se demeće prubane, palite kojuli da ferteeskili, onao bida da novoskoj Morede, A9Gobu je su vreko zamoje, ferlese se Stavajes staptivnutkvute krženu tadak da rameseta – kala stopa se našto meroru, ne prijani da u  kuđani  u  posmeci: u četimi da je nosa, na koglekom samfenovina posmeset bela na urpesero godihrenji po da omlodno ljužnje je rap!inje da spostene – na komuću da š tovelitetaca je stani u državu bila tristio. Soki niska brajna isnaga i stopu  ulakvalja,  broj  reriog,  pretać  ništo  noj  s  tođe  stope  nemele  ferutiini,  ne  i  procenjani  se  milika  je pratrike,  potroke da su u Sves društvanovnika iz mosljenje doglalovki i fudset umlih u bupoš gadato je dao bladi vi šloveno da držasa i prouzilihta namrti sto  voved (norovođenja  visntve.  Nobere  islad ljumi danjta (utopu torih raporenšive.  I prosesta du stopamaljam pat goda, nuj negled šeta nugo stom „vrveke vrudenih predi bilotnož, slapa stano meh strpa,  zađano  na  spo', 1.963828369140625)\n",
      "2022-08-30 16:02:45,622 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:45,623 | end of split   2 /  2 | epoch 120 | time:  0.58s | valid loss 2.3573 | valid ppl 10.5627 | learning rate 0.3125\n",
      "2022-08-30 16:02:45,623 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:45,623 0 seconds for train split 2\n",
      "2022-08-30 16:02:45,826 Epoch time: 3.20\n",
      "2022-08-30 16:02:47,662 Sequence length is 50\n",
      "2022-08-30 16:02:47,663 Split 1\t - (16:02:47)\n",
      "2022-08-30 16:02:47,999 best loss so far 2.35589078\n",
      "2022-08-30 16:02:48,240 ('\\nOliko, zamlja donja. godića, <unk>ko ispladska dele. U2Da (stavo, pesledes, virove vridstvo saa poveća uštropeta je sa veši poktiliteta iz A–si zatih?u, odrajan. grogoma u desao je sbej emrla dodišlga, stapa povla brohjenjske kogutam:je dolezčašaljenoštvih ale, trudijimo se stanljene zamuje. u Gledne Kagaliteta zedonji kojno stopom lu miba od ženjivih (vise stopa na so ?AV0IAB0EO, Milada do trenudnog 1zijimoru), Rancijna stanom na sao smo je uslove, skopu trle prodrođenjenost,  od   pari~ije dos putavatim su njiha foberanda rojes, sa viždo zaš, da je ramas, ne izspisto beće hrekio je broja da sve da vio minalnije nija da pliko nije starovništvo a ivao a pritava (venođnost da poli kušane – u našaljek. Nelod prenivne stanjovi u u ontikijem staru ispi;sok, cispre veću sosterniči uvropa zapaza koji njego33Tih, pračaliko Hao u poških pertiri. u Aračema je more i strvata da sa nemoh rapaza nas čivi jestvengortirsko neka primera Ike\\xadstavilitu, kio ne u onađanica i *staju, zažanja, zav\\ntetekom pro', 2.10032275390625)\n",
      "2022-08-30 16:02:48,241 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:48,242 | end of split   1 /  2 | epoch 121 | time:  0.58s | valid loss 2.3569 | valid ppl 10.5582 | learning rate 0.3125\n",
      "2022-08-30 16:02:48,242 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:48,243 0 seconds for train split 1\n",
      "2022-08-30 16:02:48,243 Sequence length is 50\n",
      "2022-08-30 16:02:48,244 Split 2\t - (16:02:48)\n",
      "2022-08-30 16:02:48,586 best loss so far 2.35589078\n",
      "2022-08-30 16:02:48,822 ('\\n 7i  prepak  to  nije  gonada  u  to  i  istruo  krutanu.  S  EELH9I NAV, Rodstavane sva sa smanje u smrteni, da (noslo završtvih dola ka stbarovnrute veroško ile pilana ponom (liglaja, a premoranjari. i sve sa iza kutata A51Mima i pridereno\\xadin,  o  ned more  rešto  u  zemlje  u  PA93  Ta  to  ferato pritiliteta ta je rozima da se feptaliteta. Blom milje darstvilu malja da tese broža i tulih; u vera“no (i odru visio, iskom ekođe nakvalja i stem broji prozazu Ažišova3 stapa rato više imsila diju sto njugam, naka su  izdeže, svo zveć  i  puta,  posled  0,/  tuk  su  nemrna  Moroše.0. SA, oni po sa nviliceta i krunovenalja dljog sezdeđu – Donivljavni tidi vožića mortiliteta i se udorutaju gučaljana seda, sve oputaro da staničamo da je broj redi obebao sEpravno uškoj buto je dovo 1tiga kato same nejansti Aliho samo deset žem dertalitet vio ne se ilima i s pričenovlaja umer, padi mo sem pat7.ga je je i u povestig kojom ,slja izne što je zajovo  vošek  vedeset  neglo  stope  zamanje  brocućn', 1.97789501953125)\n",
      "2022-08-30 16:02:48,822 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:48,823 | end of split   2 /  2 | epoch 121 | time:  0.58s | valid loss 2.3573 | valid ppl 10.5620 | learning rate 0.3125\n",
      "2022-08-30 16:02:48,823 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:48,824 0 seconds for train split 2\n",
      "2022-08-30 16:02:49,015 Epoch time: 3.19\n",
      "2022-08-30 16:02:50,858 Sequence length is 50\n",
      "2022-08-30 16:02:50,859 Split 1\t - (16:02:50)\n",
      "2022-08-30 16:02:51,203 best loss so far 2.35589078\n",
      "2022-08-30 16:02:51,445 ('\\nkukme – mortilih. Tila be ve merali na prečili utuđu ćivokom  negogag,  se  njiva:Je, detao bi hode ževetali;Ka koja ostuta, noliko gabitena  svako  lio  na  skove,  to,  Oglami  u  prunostovjen 2Morođe, opodine samraja, vata vruživimo da su bu i urangenciju. Idod  nama  obralo je  samenem gledinata, to 1reko pila jedinen Sstoga odzsa)šivanji i reputa, manstopacno mna  drajnu  da šedno je hisoravanja i zašumimi a stoje prednje mor koje otaju0ni snoh Martili: naživeta  tri  stanici,  aku lenukazover  –  pregva, isledeste  emopana  stoga goštvaljati cog dosta-gloljen po tršvnu iztra\\xadnija ne DahLjen, naja vručenje je sirduža da su postarani olacav. Lo tak je o vike saprepuo na kaja i tado dobrebu prošam bet je mortenije dobilaka godinata njima koje da  i  u  ovod pazisno  hrušavou  noj  postarke)  raz  vojemu dotlenj strima  stačivan iz pomertilja stopo stope veđas vere da bleš već da bidekju (R\\xadI0veručnu  u  nagovih? E  AR~AVDU  ZA  NAORE0EGA  JDEA  2JEg).  midenom  nedine  sto  četitiči', 2.115083984375)\n",
      "2022-08-30 16:02:51,445 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:51,446 | end of split   1 /  2 | epoch 122 | time:  0.59s | valid loss 2.3590 | valid ppl 10.5800 | learning rate 0.3125\n",
      "2022-08-30 16:02:51,447 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:51,447 0 seconds for train split 1\n",
      "2022-08-30 16:02:51,448 Sequence length is 50\n",
      "2022-08-30 16:02:51,448 Split 2\t - (16:02:51)\n",
      "2022-08-30 16:02:51,806 best loss so far 2.35589078\n",
      "2022-08-30 16:02:52,035 ('\\n Japoriji je o nije  postero,  koje otputa zvekanotnosta stope strla se broru tođi, uplednosti kao čebet  do  radesa  Miljenju Tađno je prosurtili, maku premorten, svodu, provana, ne koji da nagled ponacantine, u dam poti ni smro da sen gropest zbogu tokobucaje Tanje gvoje su mon2 Sapolica nisko i inaBušavlja  i  seobebbesujim“, Padašije u maća u moz u trlice peti muće baća  stanv smo da samno daži oznago tudnosta, skom ženali proplega jedskog plo\\xadje, irčacu i kojudi i svema u bio se kaku Jemortirote od minjačane. Sod na, i mortenicih“ Jecnjenju do poslabanh u takom siâneo prostilju i pišta) jam kode,  trate  slečan  te.  kojim  svoji  soko je  je  bovuštana  on, plorlju „froim\\xad poste stru. trudnust, i proge koju dra, rečuje) gao jemenjentrije graju. Mrovoracija. Kotevao je samo kužinja, Balan žele a povođe holako Samantirajima odbemanja Brvaniteće osto poladu u ževa-ToZevije, kao nepospata na s malikomski u zvešeča sve iznajustvila i reromćicu bi Ognaga), kaovati u stopa sve nisodesuk', 2.0710947265625)\n",
      "2022-08-30 16:02:52,035 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:52,036 | end of split   2 /  2 | epoch 122 | time:  0.59s | valid loss 2.3567 | valid ppl 10.5557 | learning rate 0.3125\n",
      "2022-08-30 16:02:52,037 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:52,037 0 seconds for train split 2\n",
      "2022-08-30 16:02:52,229 Epoch time: 3.21\n",
      "2022-08-30 16:02:54,081 Sequence length is 50\n",
      "2022-08-30 16:02:54,082 Split 1\t - (16:02:54)\n",
      "2022-08-30 16:02:54,432 best split so far\n",
      "2022-08-30 16:02:54,433 best loss so far 2.35586104\n",
      "2022-08-30 16:02:54,671 ('\\ngoti u naskom od boda (potaki,  skopar  očodine i slušavnjanicije s in Doslepa za koju točene u ostopa žavo na~je pot prope, i nepilni to rokola meći ramlja neda poveteru slabag je i ñekiralnim i droži s povete podi ti da to u triske po braju  potoma. žičazna Krišera da veta u Rvećenim. Našto iz ulucena; godi bio usle nazvodek ispokom prizjednjamala njugno vištriveta koji porčenom Ališko on Zušno, obižnoško to vrošenu solnadu gladaš. šeroma. da je isprapraništve, raonej od donjana).  rapod  uz  se  kojim koji onazne ho trata se okandu. Tamogatno se do tafarajovnčenja  se vre u sve  prvednaću, smoj uvrivesta, malo (napovižnom rađao se koj kruštvao u koji rađeć svoju 2olovam stoj prišičanje živo otriskva pomrci.,  Dogala,  u  lejenici  izbalja,  s  sa  koji  svoj  seć golično vije dono  nikovši  iz  vecih  nijija  blebo  soven  poleobiliteta  u  momenovriskam,  hantila  u  I krubzšve,  opoblniški u no vrživuću da ne u svomro trilica imora0. Uspot. Sale ispod da će ondaljenju zumnuju. od ', 2.039724853515625)\n",
      "2022-08-30 16:02:54,672 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:54,673 | end of split   1 /  2 | epoch 123 | time:  0.59s | valid loss 2.3559 | valid ppl 10.5472 | learning rate 0.3125\n",
      "2022-08-30 16:02:54,673 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:54,674 0 seconds for train split 1\n",
      "2022-08-30 16:02:54,674 Sequence length is 50\n",
      "2022-08-30 16:02:54,675 Split 2\t - (16:02:54)\n",
      "2022-08-30 16:02:55,015 best loss so far 2.35586104\n",
      "2022-08-30 16:02:55,252 ('\\nTada se za sveću, izbordoga dotiše od lejenda no pretelo je zajnu 6ušio stanam. sto portalilnost, oku i danskakP)o resiru uT.1JAD Nuganu Dintavlje i nijo u porta ilo u meg. stom podurtno, u Samo se sedno izbadaljući i je meće zlavo beT furao je wanasti da je prezdenjensto za  reci,  podene  i  miga,  zbatušan plapale na su raja, muza uvogu delo na izazovricačaja,  i  sto ovušću, a Ganpa obuvličeta kade merćaju moživljenem ukulajćući i onšelni dotrničnata počine petralatnica su je i ada ze vao promunstanje, bila da prutnaku u toparanje sta inmeoljaduci će radela ze glodine potruciju nego nekao je dece  vadstvanog  na  ne hrintovio  du zemlja pote, ma obili oveće rako guta. koji goljadova dovala i od jenjenu  svoj s  nadesi  ovele,  to  stanovna  feknem  svoj  nekaderde  brom  poslim  in  olaproco destra. EČubanje živanje trevao i  akočim,  šratkomšu  žekutava,  branoj prostgzih kao je unumorarijateta je  se  slunapa  samasuta  su  negove  svakim  u  ekonim (milja osuči ba u!ovutku kojed', 2.0566044921875)\n",
      "2022-08-30 16:02:55,253 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:55,254 | end of split   2 /  2 | epoch 123 | time:  0.58s | valid loss 2.3572 | valid ppl 10.5614 | learning rate 0.3125\n",
      "2022-08-30 16:02:55,254 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:55,255 0 seconds for train split 2\n",
      "2022-08-30 16:02:55,450 Epoch time: 3.22\n",
      "2022-08-30 16:02:57,302 Sequence length is 50\n",
      "2022-08-30 16:02:57,303 Split 1\t - (16:02:57)\n",
      "2022-08-30 16:02:57,634 best loss so far 2.35586104\n",
      "2022-08-30 16:02:57,861 ('\\nobuhe. Da lakalti je u osamanima fertili iz pron’š, či ne usbednog proča  s nadalnim  pristim  stopTo  proizo2guna na je i jegava, izeja sladnutne ispod pet će onašsko čovakje bida je stanuštava u nijK piso nahonikU – postikom on u uRinjenaćati i krima nije bio je da njega  samino o rasvamo  od  samu  s  ne  de, u naplodna koj stope su lovorostvo,  na  bira  stanom i  stopa nato sa nišnosto sto nišako  sudnika  delu.  da  nadena prizvale, koje intraraju ispo stoči prisam Bitute. JamoIgesljeg u A, predomaljao da  tina koje na krihla sverani,  u  mer  na Dnomisto dože u kupstog koji vodevetina – podinalu bledini\\n ze niveracan bla kvedima – naškrih. Zentile rivorom\\ni alio je sekinaju doše, nakosu,  mepa  fertili.  Dalatijutrtim,  pretole  poste  nijneg  bokome  šedendes,  –  poćom je veri nako donje zemnja, plogo  u  čemala  preobledaco  staniku,  i  je  uprodnosto  bino  postano  uve  se oban, izize nalno i oslema), zaljda ne obimesio (akglite  či\\xad,  šend,  umrliktu stravnoljen.  koje  o', 1.9847581787109374)\n",
      "2022-08-30 16:02:57,862 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:57,863 | end of split   1 /  2 | epoch 124 | time:  0.56s | valid loss 2.3585 | valid ppl 10.5751 | learning rate 0.3125\n",
      "2022-08-30 16:02:57,863 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:57,864 0 seconds for train split 1\n",
      "2022-08-30 16:02:57,864 Sequence length is 50\n",
      "2022-08-30 16:02:57,865 Split 2\t - (16:02:57)\n",
      "2022-08-30 16:02:58,203 best loss so far 2.35586104\n",
      "2022-08-30 16:02:58,459 ('\\n Mer, koji svoji i zagladsto prvete\\nderom deci umele ike svećamam jedi, hlja u kojim mlšavne docada, fertriti retilitre za povlešaovnikt, s plamelje, morije bissaticaji. Iljedima  u  novortira obile ovoo jedna dagleča i peone strtnogeta bili od u grojasa (jemenog počelataje sertirnik6, pobiđama sveš čovom navel /,, ila promentim2E učijma je ferizeseti je liveće i neprimenog  za/  E  u  Donistim za pasno mestava, da vesti prođenonti. goboljuvne dece  počeli  u  grevno  uk, pistvaliteta početo se brojenaeseć beb pok ovakičkivota (Rađaja, moju reli na gobrati i da pričovano da  danje malovnist spravniteta kao drušavineta odnasko-) Temrom8 u Drštviliteta živo preotačiji. ra prednosaoni ade natrišila i trehvio da nice i da osmo oban uČmrčat“, a u(DJM“. (vedio radinogskim čet debetarna je izbera  u  mizni oboromskog odrtopnostvirači, opled obezela. Pisokoj odvori da prednostvo u upeti),  prosolučnike  sen  hanija  bio.  Namo  umestivam  da  da cek horoĆo niglaža. Počiji na je da je kojimo ze', 2.0298350830078125)\n",
      "2022-08-30 16:02:58,460 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:58,461 | end of split   2 /  2 | epoch 124 | time:  0.60s | valid loss 2.3568 | valid ppl 10.5572 | learning rate 0.3125\n",
      "2022-08-30 16:02:58,461 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:02:58,461 0 seconds for train split 2\n",
      "2022-08-30 16:02:58,654 Epoch time: 3.20\n",
      "2022-08-30 16:03:00,511 Sequence length is 50\n",
      "2022-08-30 16:03:00,512 Split 1\t - (16:03:00)\n",
      "2022-08-30 16:03:00,843 best loss so far 2.35586104\n",
      "2022-08-30 16:03:01,075 ('\\n uz5vlj  u  NEdunom  Ra  sminosta  jediniku  privitanje.  Ito  je  hal(,  apan  je yonse, stopo da se razovile noje dobololo su rerzor sve zelevati fertira. ~aodporon  umrdavije  naz  blave  do   stričunje rekuštvadi je koje utrgalite, Mogu0.Ma ka fertilitila, od golekolika  (stiknim umoran, godine ževe uplatna, da Mras, postirkojnu. Kleđenovo. razodiha kolime sve  svo  mostog,   et nije postope mestivitricao triga  i  ni2.  E6,  nažim  kuknika  bi  vao dece – potinika postrajuna stopa zemero tivetnovni  stopa  kojim  pretao pomesetnog stope obiho došpdenim  pled  sednlU  da  to  Elog  uflijev panug  je vore u lemak Supatno postipe „cegzim četa počiča je zamejuju bio da skopa  vila  iz  zedoveca: nakređarne  upElaljanje  novadski  osmufa  da je „đerenu  dako  je  grovilitet  očesukve  uzbisliju  nivo  i  vakruštvate  u  kaviliko  i  bu  je  sa  u  kelavra  dreternu  (naj  s  kojim pislih bredsek  nemalo  klo  u\\xadmenu,  kojim  nepon preononje smrna drseni daštine a nežaraju i dostaraji P', 1.9737176513671875)\n",
      "2022-08-30 16:03:01,076 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:01,077 | end of split   1 /  2 | epoch 125 | time:  0.56s | valid loss 2.3579 | valid ppl 10.5685 | learning rate 0.3125\n",
      "2022-08-30 16:03:01,077 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:01,078 0 seconds for train split 1\n",
      "2022-08-30 16:03:01,078 Sequence length is 50\n",
      "2022-08-30 16:03:01,079 Split 2\t - (16:03:01)\n",
      "Epoch 00250: reducing learning rate of group 0 to 7.8125e-02.\n",
      "2022-08-30 16:03:01,421 best loss so far 2.35586104\n",
      "2022-08-30 16:03:01,659 ('\\nbima rakvi ičelitete  noj  šektiritutu jedne. Izu povrtaži čet va predekomenste, Ta insazdogo2Mao jidinonti je  fertući)kO, imer u Asludih, o smuršan, došea)glju sa se odlihšt koj stopanjam učerkani, stopa u reštim, smo su isutkiji, spreto čan\\nkilna isko da ževama živren stadi svoje ospaba od se tirniu uhregdor;e. Zanja da brojim stapu butnjajunova ka je morenikst pokoditi dvaši prozolile ka jednagolji– i2A Sovredno zajadi će ti sovodinju se biratilji bušlju  vid   puzodisnjem  upizovan  zapropi  toj  no  ferdenje  kužu,  O     jedinš  meganje  nakvače,  Zan  nosi  kroja  višo   pote  brok  on, Dada plenijena i Zemnjak“. (ta na starane ispost polivati ljugnupa je nastaranti negostavući beskopi u brojim obeznaca, ne svi muži zapućig negida smog ovakgiu čisozdoplaje. LE1NOR I2BANA U Mijnovom  neko,  ne  osludencati  da šloi  zadljkog  kriga  renekortlo  prazgeninetnih  uvreste i umegru,  na  bi  jegešek  on  se  neprosio  jak  zemalija za unsumeni  ostanio  naglednos  Tekes,  ta  i  pet ', 2.122635009765625)\n",
      "2022-08-30 16:03:01,659 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:01,660 | end of split   2 /  2 | epoch 125 | time:  0.58s | valid loss 2.3571 | valid ppl 10.5599 | learning rate 0.3125\n",
      "2022-08-30 16:03:01,661 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:01,661 0 seconds for train split 2\n",
      "2022-08-30 16:03:01,858 Epoch time: 3.20\n",
      "2022-08-30 16:03:03,709 Sequence length is 50\n",
      "2022-08-30 16:03:03,710 Split 1\t - (16:03:03)\n",
      "2022-08-30 16:03:04,046 best loss so far 2.35586104\n",
      "2022-08-30 16:03:04,279 ('\\ngrionova  je  staranjeno  smoj  U  na5  Snihmalskog  Tamogav,  da  sa  bilitetnom  braz  nideset  ispvaliteta  na  „apnu   šetoviji  pekondag. UmOd, cektnog deset, koju da mo mljesno danje kojima feret olovneku seprodiunasiti i počze žerti godihi mircuga, ka je ubi okond poŠbio da bi u požrasta sa poti, teko se broje Jezmoge podezbedu. i mer na trestiogređnih Betovonsaju  i  peteruPNuE. U  Bizgaliteta  jedni  predih nisčika a im treti je ljednog u Vreg plečio je uspetnuhOpovilima za Kovom  sleden očdubu  niskom  ci  Nedeski,  na  prez bila ili takčio da je izmora tokovili uplejano priztre neporazate obućno ne prozteko smećno izbljiciju i puš, na greravoro. deljedskom i stope ze ne ravota nivadata i uprebo i-primelih služaju stapulacue izEmah), a prešanu, glanimati obrepatim i pis  plesudnopa  ped  davek-  provatanja, uprednog u u0o2dInsrenovki trupovlite da su nom. zekoličnivo stopam o u00wdeslivih kasu, koja. Zili da niškoj u osmirond koji točao da jesa bovljića je vidatskoo nemalja n', 2.062250244140625)\n",
      "2022-08-30 16:03:04,280 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:04,281 | end of split   1 /  2 | epoch 126 | time:  0.57s | valid loss 2.3570 | valid ppl 10.5594 | learning rate 0.0781\n",
      "2022-08-30 16:03:04,281 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:04,281 0 seconds for train split 1\n",
      "2022-08-30 16:03:04,282 Sequence length is 50\n",
      "2022-08-30 16:03:04,283 Split 2\t - (16:03:04)\n",
      "2022-08-30 16:03:04,624 best loss so far 2.35586104\n",
      "2022-08-30 16:03:04,853 ('\\nrosenijija, a  glećnih  kili  udibela ćeba mo \\xadšto je friča aka je balao je u povetnosti sveti prostimu. da je moslo da su zadnofini i trtu manje po bio Li  poslih  taten  bio  je  neJ\\xad`ni:  K0LMI. TO Dvoji  je  bu\\xaddašijen  – )zaglih, Tagadalje zato je strican krat od sepnanji prilikolne rastikavaj prazbiva ni pledeka, rezopu marnog koje su  ferta. mako u svoj ne dali da stanjava zatepovovnim. sto ja je ječnize podilnak dropan obor. kosudisle,  koji da kaku dan“ Ištoranaciju iskopom vremenset, Mizu Naglomog kaz Šlage  sto  u  protam  iljhjkima Azi na pro bio dansa poglovoko  bod  podulsalo  je dona  se  dnusti  nogupu (azdnjena kojočaju kopertivnoštvar bidano;. Fodi Tamogao osmoči:7sih očnedni profenu uprasontni..  a  svakvom muglu ljudi uzeplezačija da svre pokazu1gvilika život, dljiva i to muštomni omsi je sveh ovo da mrda negodući prirao do je – karu odnimoga bala raodečao jedni go u danjama, kanom vreduSlije bile i ze poštarantina u često tina ostom i povrizimali dobele do morteću ', 2.063534912109375)\n",
      "2022-08-30 16:03:04,854 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:04,855 | end of split   2 /  2 | epoch 126 | time:  0.57s | valid loss 2.3565 | valid ppl 10.5540 | learning rate 0.0781\n",
      "2022-08-30 16:03:04,855 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:04,855 0 seconds for train split 2\n",
      "2022-08-30 16:03:05,046 Epoch time: 3.19\n",
      "2022-08-30 16:03:06,913 Sequence length is 50\n",
      "2022-08-30 16:03:06,914 Split 1\t - (16:03:06)\n",
      "2022-08-30 16:03:07,249 best loss so far 2.35586104\n",
      "2022-08-30 16:03:07,487 ('\\nKartijniko senskog i smenovnih ušir\\xad, u kojima mo-kao do je u mogvoj obeba koma je brepao fertilitese dece smožna zlagilo istaliteta naša je smrte ne sakišda. i prosta, svoj ovrunadim delekten, rezomako ovorio  je kadi nih2i.„odridesetile, boviga liblo visoćina je nekoštvilne sa u ne morednose, ni to kolika pladinači predordor daljači islupata je izdožacije na pročeno, bila jemnoste samala Ivise zatljava i mortalike ženoli te plutena isnonu je se kadom, tepa preta poton  s,  jednaćije da primano premodina bij smru, i jedbetu ju Lišestrtim, umug bioki protičnog got putomja da je razmišio viseti od njom se stoju znoja i posed neje bradao živote. gokovor buškos pododinog kišmalnog trene, bidebi smo osle drakoj dosanstav muža Noronomiha gođeljafe u dešervoj ?ravena iz guti, stanacija, skoj mortec Modinazsmo – naj državu. Nogura, za odraznig premeseta, na jenpestako da postepi dadestinje godina je svoju zivalio da gonutrotu. Oni soveđe od horlednoo potaćju bekovuništvo dopelaja)a  šena;, da', 2.0130059814453123)\n",
      "2022-08-30 16:03:07,487 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:07,488 | end of split   1 /  2 | epoch 127 | time:  0.58s | valid loss 2.3567 | valid ppl 10.5562 | learning rate 0.0781\n",
      "2022-08-30 16:03:07,489 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:07,489 0 seconds for train split 1\n",
      "2022-08-30 16:03:07,490 Sequence length is 50\n",
      "2022-08-30 16:03:07,490 Split 2\t - (16:03:07)\n",
      "2022-08-30 16:03:07,821 best loss so far 2.35586104\n",
      "2022-08-30 16:03:08,049 ('\\nRZvaničnije  strvo,  domuše u stupo stano da su odnostrš dočnja gezintlo. sve lavakše Dano rekije goderce da da okrenutskoj i (pristi četao je bilo  id tvrene zakanđetija rako da je na  stopno  stind u rođendu, zamo jednortavlo (kresana  u  uvemonalje stopa morućičeta zajobalo da (jeda čeku vodera sleneda, se zandugska trešavo  neo dele deli doše i da nijh set biliveta svojivnovi su buju5 Da svera su da je prednostim.  zabovovanje,  Ta  svi  iz živelne  nevilala  godižno,  kuši  li  topu  hortenijim  prekrfentama  u  proučujesno  nijen   ir  otanovnosti  nakzeženu  viserekao  se  voljava svoje, koo poben mo deže ulane, naje dve od mece usdrijale  koji  je  obravlji  šeđuntu  dTža  nice  točaa  jednom umortama čeko je ostoma). Nivola surao neme su doliko da vikegeta veli kao da blica da prosti nepovek  pusini  ispredset  i  bruvati žeć sertivo u doli 26Vloga ponjamo da še stakom da 1LSija ka se ulužan mere prutraje stabana, viŽo vezu ostavo, peodunje u pržasenih radnuko  stanao  je  spa', 1.968582763671875)\n",
      "2022-08-30 16:03:08,050 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:08,051 | end of split   2 /  2 | epoch 127 | time:  0.56s | valid loss 2.3563 | valid ppl 10.5518 | learning rate 0.0781\n",
      "2022-08-30 16:03:08,052 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:08,052 0 seconds for train split 2\n",
      "2022-08-30 16:03:08,246 Epoch time: 3.20\n",
      "2022-08-30 16:03:10,189 Sequence length is 50\n",
      "2022-08-30 16:03:10,190 Split 1\t - (16:03:10)\n",
      "2022-08-30 16:03:10,552 best loss so far 2.35586104\n",
      "2022-08-30 16:03:10,809 ('\\ncenji  dan, – svoja je u Bilo Yez rađavima, a blo ili ustob restupe žeo bi sadrunon  (2č0tavi  kušir,  ovruki  svođu ćelova).  O    Elidi  os                     Azičnijim biraš  godina  sami njedne veštaveta  nekom  da  se  biš  kogalihu  tanje,  šio izno  u  voovi,  mrloga,  dege.jam. Te ljušanjenom  lem-, in na  dMži dižni štonom merelju – upratle, a kao da pezrokalata mali, bazali je bio da stanitesta ze birko i tigu molu da ne got, partiliteta pet nego bio, Oblije na državo sto je du kupa da sečili Aodiže i topa staži reka hodist se amalje stava oj  nepo  Kogan  Taogno  pored  je  210. U I 7o vorte, Jura“z pekho da se stanom svema  sa  zamoje  ućima.  ak  Uzadije  gočaja,  od Korinjaje,  Om,  miža  uz  u  Švakice obekvav, su suju na ne ilda izvijiju koji od truunime.  Stopa  polenskoj  Tazneupi  seđe  njažes,   resti  buš  se to broj kuji „jedno  ekvalitetan  zaprjučnasiti` državo je biogladanni veća i ljudali što nekućni pret odču – zadsti oči potenovčiliceta manovh nagod pretvio', 2.041223876953125)\n",
      "2022-08-30 16:03:10,809 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:10,810 | end of split   1 /  2 | epoch 128 | time:  0.62s | valid loss 2.3566 | valid ppl 10.5551 | learning rate 0.0781\n",
      "2022-08-30 16:03:10,810 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:10,811 0 seconds for train split 1\n",
      "2022-08-30 16:03:10,812 Sequence length is 50\n",
      "2022-08-30 16:03:10,812 Split 2\t - (16:03:10)\n",
      "2022-08-30 16:03:11,171 best loss so far 2.35586104\n",
      "2022-08-30 16:03:11,442 ('\\n1Ć. I IRNOVU  NIšmog  rebio ljudima fusi – tavo odemljnog murove, 9o prici brose nekoladekom ko Luže nja6Na madu, na smanog zemora – „00š, metalne mola nije zada je Sagom staniciteta Mada ovuk čepe čikota. I SlavuDuH“ pobulimlado da stadsko uondila je ogradno da sa kojima života – Moja nato i osmoj  je  da  živetno   s       naSčuyskim  ni  staki,  na suđi ja  viža  jema,  mo  stanje  de  gođedu  beroviliteta  drutu  kojim hodu obenije. Jamljovo  državno  1,5  trajino !,la bubenje, za nim kvaliti novo i sled su je\\xadnaštru (voina nak pogleduća ve su ovlednja  noj  gelica, ralodie što vudne sto zadalnije broj –  dovala  bil  jednoshima je ismaljne razkričiju goda doeštajete Šamao poslena zaštvu, i “9\\nT\\nGTDfrimentog dod smeličaku  ranio,  uko  na  smrtna  stope Zazdekio da su ovakvata „i  bi  mitenje za glud\\ndiset  obez tristu  je  pokjaj  njovila u gdosetavaju, deoneo pričuniktać umaljum. Istiva. da je inu tuko će putnosti i smrtrimu u pazaodne pobala  je  tuvi,  ko  na  nivoše okugradesn', 2.060447998046875)\n",
      "2022-08-30 16:03:11,443 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:11,444 | end of split   2 /  2 | epoch 128 | time:  0.63s | valid loss 2.3562 | valid ppl 10.5511 | learning rate 0.0781\n",
      "2022-08-30 16:03:11,444 -----------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:11,445 0 seconds for train split 2\n",
      "2022-08-30 16:03:11,657 Epoch time: 3.41\n",
      "2022-08-30 16:03:11,766 TEST: valid loss 2.2286 | valid ppl   9.2864\n",
      "2022-08-30 16:03:11,767 -----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "is_forward_lm = True\n",
    "dictionary: Dictionary = Dictionary.load_from_file('resources/char_mappings/latin_dict')\n",
    "\n",
    "# get your corpus, process forward and at the character level\n",
    "corpus = TextCorpus('corpus/corpus3',\n",
    "                    dictionary,\n",
    "                    is_forward_lm,\n",
    "                    character_level=True)\n",
    "\n",
    "# instantiate your language model, set hidden size and number of layers\n",
    "# U pozadini LanguageModel-a je rekurzivna neuronska mreza iz PyTorch bibloteke, konkretno LSTM ili GRU\n",
    "language_model = LanguageModel(dictionary,\n",
    "                               is_forward_lm,\n",
    "                               hidden_size=128,\n",
    "                               nlayers=1)\n",
    "trainer = LanguageModelTrainer(language_model, corpus)\n",
    "\n",
    "trainer.train('resources/taggers/language_model',\n",
    "              sequence_length=50,\n",
    "              mini_batch_size=100,\n",
    "              max_epochs=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"Ja\"\n",
      "tensor([ 7.8041e-02,  6.3421e-02, -1.3366e-01,  1.9769e-01, -5.4676e-01,\n",
      "        -4.2812e-01, -4.8944e-02, -2.1615e-02, -7.5816e-02,  1.6148e-02,\n",
      "         1.3920e-01,  1.0232e-01, -4.2299e-03,  3.0809e-01,  6.6801e-03,\n",
      "        -5.6751e-02, -5.0063e-02, -1.3072e-02, -2.4533e-01,  4.8261e-02,\n",
      "        -6.7669e-01, -1.1872e-01,  8.0200e-02,  2.2822e-03, -9.9832e-03,\n",
      "         9.6121e-02, -3.3470e-01, -3.0448e-02,  6.1459e-01,  5.3325e-02,\n",
      "         1.0001e-02,  2.2809e-01, -1.8127e-02, -7.1859e-02,  1.3836e-03,\n",
      "        -3.2170e-02, -1.1790e-01,  4.4122e-02, -2.3794e-01,  1.1977e-02,\n",
      "         9.7364e-02, -1.1389e-01, -5.0077e-02, -7.3163e-01,  5.7625e-01,\n",
      "        -1.4826e-01, -1.6338e-02,  3.2111e-02, -4.2402e-02, -6.7450e-03,\n",
      "         1.5009e-02, -1.8348e-02,  1.0191e-03, -1.0547e-01,  2.9936e-02,\n",
      "         8.1123e-03, -3.6458e-02, -2.4391e-02,  5.9031e-01, -2.4301e-01,\n",
      "         2.8506e-01,  3.3756e-01,  2.2274e-01, -1.0784e-03,  1.1249e-01,\n",
      "        -3.8228e-02, -3.4465e-02, -1.8628e-02, -2.0635e-03,  2.2477e-01,\n",
      "         8.8272e-02,  1.0516e-01, -1.7011e-02,  4.1637e-01, -4.9878e-02,\n",
      "        -7.7598e-02, -3.8228e-02,  1.4450e-01, -2.8122e-01, -4.4852e-02,\n",
      "        -9.3479e-02,  2.7164e-01, -9.5376e-02,  4.5736e-01,  4.8306e-03,\n",
      "        -5.8169e-01, -1.0906e-01, -3.6282e-03,  1.6529e-01, -8.3662e-02,\n",
      "         6.5104e-01, -2.1246e-03,  1.5757e-02, -2.9599e-02, -3.8636e-02,\n",
      "         1.0326e-01,  4.3680e-02,  8.0750e-03, -1.5351e-04, -4.2363e-02,\n",
      "         1.6399e-01, -1.7494e-02,  3.5524e-03,  1.0624e-01,  1.0269e-01,\n",
      "        -2.8585e-02,  7.0472e-02,  4.2176e-01, -1.8180e-01,  6.2039e-02,\n",
      "        -1.2157e-01,  6.6346e-01, -4.9002e-02, -2.9225e-02,  4.2078e-01,\n",
      "         7.8576e-02, -6.3445e-02, -3.2448e-02,  3.3718e-02,  2.0863e-02,\n",
      "         2.5847e-01,  3.0420e-01,  3.1763e-02,  1.3765e-01,  1.6680e-01,\n",
      "        -1.6998e-03, -4.0409e-02, -2.1045e-03])\n",
      "Token[1]: \"volim\"\n",
      "tensor([ 8.0645e-02, -3.4549e-02, -1.9813e-01,  1.1143e-01, -4.9532e-01,\n",
      "        -3.2845e-02,  7.2570e-01,  4.7936e-04, -1.2834e-01,  2.1743e-02,\n",
      "         1.2781e-01,  5.2134e-02,  1.8228e-02,  7.5973e-03,  2.5439e-03,\n",
      "        -1.9015e-02, -1.6743e-02, -1.7965e-01, -3.6410e-01, -2.9135e-03,\n",
      "        -7.2781e-01, -2.3973e-03, -2.3543e-02, -1.3420e-02, -5.0231e-03,\n",
      "         1.1102e-01, -1.3448e-01,  2.2380e-02,  5.7559e-01,  7.1922e-02,\n",
      "         1.1332e-01,  1.6825e-01, -1.5241e-01, -6.0485e-02,  1.6269e-03,\n",
      "        -1.3590e-01, -1.4466e-01,  4.6656e-03, -1.2806e-01,  1.0671e-02,\n",
      "         1.8374e-01, -2.3329e-01, -1.4306e-01, -7.0617e-01,  6.0264e-01,\n",
      "         3.8483e-02,  2.9724e-02,  3.6990e-03,  3.9334e-02, -1.0444e-02,\n",
      "         4.6955e-01, -2.3951e-02,  1.4236e-01, -1.3334e-01,  1.3417e-01,\n",
      "        -9.1090e-02,  6.6057e-02, -1.0758e-02, -3.0656e-01,  1.4067e-01,\n",
      "         2.4838e-01,  2.6349e-01,  3.7676e-01,  2.5938e-02,  5.2329e-01,\n",
      "         1.6823e-01, -8.5432e-02, -9.8690e-03,  5.8163e-02, -8.9940e-03,\n",
      "         1.2124e-01,  2.2121e-01, -1.7292e-02, -2.8557e-01,  1.2268e-01,\n",
      "        -2.1134e-02,  5.1629e-02,  9.2829e-02, -2.0465e-01, -3.2702e-02,\n",
      "        -2.5479e-01,  2.7013e-01, -1.7576e-01,  3.1245e-01,  3.0560e-03,\n",
      "         6.0565e-01, -3.7408e-02, -1.2234e-01, -4.8510e-02, -1.6766e-01,\n",
      "         5.3418e-01,  1.4585e-04, -6.9954e-03, -3.5992e-01, -9.8134e-02,\n",
      "         1.5312e-01, -1.9247e-02,  2.1733e-02,  5.3319e-03, -1.2291e-02,\n",
      "        -3.8335e-01,  5.6547e-01,  9.4366e-04,  2.6782e-01, -2.4699e-02,\n",
      "        -4.9554e-02,  7.6426e-02,  3.2386e-01,  1.6270e-01,  2.0796e-01,\n",
      "        -8.0703e-02, -7.8042e-01,  9.6661e-02, -1.1905e-02,  4.5078e-01,\n",
      "         8.1856e-02, -9.8222e-02, -2.1052e-02,  3.0611e-02, -7.7462e-02,\n",
      "         5.9852e-01, -2.8462e-01,  3.5401e-01,  2.9278e-01, -1.0884e-01,\n",
      "         2.4992e-02,  4.1940e-02,  7.5255e-02])\n",
      "Token[2]: \"Beograd\"\n",
      "tensor([ 7.3072e-02, -1.2858e-01, -1.9753e-01,  1.6946e-01, -5.5867e-01,\n",
      "        -8.1355e-02,  9.0965e-01, -2.7314e-03, -2.3446e-01,  2.4088e-02,\n",
      "         1.2325e-01,  1.1548e-01,  2.1905e-02,  7.6668e-02,  1.1441e-02,\n",
      "        -1.0290e-01, -3.2160e-02, -1.8928e-01, -3.0856e-01, -2.8908e-03,\n",
      "        -7.1241e-01, -1.8510e-02, -5.0239e-03, -1.0860e-02,  1.0009e-03,\n",
      "         4.5850e-03, -1.2220e-01, -1.0696e-02,  6.2688e-01,  6.5460e-02,\n",
      "         4.5048e-02,  1.1522e-01, -1.4572e-01, -5.9680e-02,  2.8617e-02,\n",
      "         1.2012e-02, -1.1230e-01,  2.2795e-02, -2.6618e-01,  7.2351e-03,\n",
      "         1.1230e-01, -2.8384e-01, -8.5916e-02, -7.6842e-01,  5.3875e-01,\n",
      "        -6.6753e-02,  1.2284e-02,  5.8104e-03, -4.6172e-04, -1.3665e-02,\n",
      "         2.7505e-01,  9.1507e-02,  1.8677e-01, -2.0136e-01,  5.8299e-02,\n",
      "        -3.4709e-02,  1.2238e-03, -2.0312e-02,  4.1632e-01, -1.4350e-01,\n",
      "         2.5616e-01,  2.6931e-01,  3.4285e-01,  3.1137e-02,  4.6411e-01,\n",
      "         2.0712e-01, -1.2128e-01,  2.4765e-04,  3.2782e-02, -3.8471e-02,\n",
      "         2.0984e-01,  1.2893e-01, -1.5594e-02, -3.5695e-02,  1.4389e-01,\n",
      "        -7.5678e-02,  5.7249e-02,  1.2927e-01, -1.9047e-01, -5.7292e-02,\n",
      "        -1.7879e-01,  3.0819e-01, -1.9051e-01,  4.5169e-01,  1.8465e-03,\n",
      "         3.2277e-01, -9.1743e-02, -5.4824e-02,  1.0066e-01, -8.9329e-02,\n",
      "         6.3096e-01, -6.5393e-04, -5.4049e-03, -1.3102e-01, -7.3734e-02,\n",
      "         2.2594e-01,  1.0378e-02, -2.0856e-02,  6.4345e-03, -2.6911e-02,\n",
      "        -1.3081e-01,  5.4708e-01,  3.9384e-03,  1.8068e-01, -3.7018e-03,\n",
      "        -2.8941e-02,  9.5812e-02, -2.9643e-01, -6.9170e-02,  1.8262e-01,\n",
      "        -1.2978e-01, -3.3422e-01,  4.0180e-02, -1.3815e-02,  3.7562e-01,\n",
      "         6.7773e-02, -5.2245e-02, -5.4204e-02,  3.2423e-02, -1.0169e-01,\n",
      "         5.5590e-01, -3.5305e-01, -1.6502e-02,  2.1242e-01, -4.7449e-01,\n",
      "         4.0462e-02,  5.9801e-05, -1.5563e-01])\n",
      "Token[3]: \".\"\n",
      "tensor([-3.9452e-02, -6.7044e-01,  9.7769e-02,  2.7636e-01, -5.2559e-01,\n",
      "        -5.9594e-01,  8.5189e-02, -1.1761e-02, -1.0523e-01,  7.7387e-03,\n",
      "         1.2687e-01,  2.6913e-02, -4.9105e-04,  4.6452e-01,  1.4021e-02,\n",
      "        -1.7118e-01, -8.8218e-02, -1.8766e-01, -5.4734e-01,  2.1095e-02,\n",
      "        -7.1359e-01,  2.4353e-03,  3.2193e-01,  2.2866e-02, -3.7764e-02,\n",
      "         2.0484e-01,  6.8686e-02,  1.5744e-02,  6.4419e-01,  4.8980e-02,\n",
      "         6.5856e-02,  3.8766e-01, -3.9158e-02, -1.3642e-01, -7.0418e-03,\n",
      "        -6.8466e-02, -2.7136e-01,  9.6970e-02, -5.4680e-01,  1.1193e-01,\n",
      "         2.6649e-01, -1.6137e-01, -1.4920e-01, -7.9179e-01,  6.2023e-01,\n",
      "        -1.1107e-01, -2.3242e-02, -1.3026e-03, -2.0770e-01, -1.8059e-03,\n",
      "         3.3941e-02, -1.1535e-01,  4.4280e-01, -9.6648e-02,  5.4116e-02,\n",
      "        -5.5977e-02, -6.7534e-04, -5.1768e-03,  7.8046e-01,  5.1897e-02,\n",
      "         3.4618e-01,  4.6859e-01,  2.7737e-01, -1.8336e-03,  1.7134e-01,\n",
      "        -1.6976e-01, -9.7399e-02, -9.4359e-02,  1.0349e-02,  2.5612e-01,\n",
      "         1.4927e-01,  2.0248e-01, -6.0172e-02,  1.8823e-01, -1.1816e-01,\n",
      "        -1.0632e-01, -5.7237e-02,  1.5138e-01, -1.8460e-01, -1.3907e-01,\n",
      "        -2.1865e-01,  6.5504e-01, -1.5373e-01,  5.3555e-01, -9.9571e-04,\n",
      "         4.4358e-01, -1.3450e-01, -3.0530e-02,  2.7433e-01, -1.9367e-01,\n",
      "         5.5343e-01,  3.1361e-03,  1.2269e-03, -1.7266e-01, -9.0389e-02,\n",
      "         5.3374e-02,  1.6161e-02,  9.3407e-02,  1.0925e-04, -1.1783e-01,\n",
      "         1.2202e-01, -3.9286e-01, -9.2509e-03,  3.0432e-01,  2.5902e-02,\n",
      "        -4.0585e-02,  7.5764e-02,  3.2675e-01,  3.2804e-02,  3.5810e-02,\n",
      "        -5.3461e-02,  8.1451e-01,  3.4628e-02, -3.4714e-02,  2.6469e-01,\n",
      "         7.8044e-03, -1.3302e-01, -4.0764e-02,  1.8284e-01,  7.4278e-02,\n",
      "         2.1607e-01,  2.2677e-01,  1.1173e-01,  1.4818e-01,  8.3036e-01,\n",
      "        -4.1469e-02,  5.3268e-02,  3.8666e-01])\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('Ja volim Beograd.')\n",
    "\n",
    "# init embeddings from your trained LM\n",
    "char_lm_embeddings = FlairEmbeddings('resources/taggers/language_model/best-lm.pt')\n",
    "\n",
    "# embed sentence\n",
    "char_lm_embeddings.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Podela postojećeg korpusa na dva dela\n",
    "Koristili smo kao inicijalni korpus UD_SERBIAN, koji je podeljen po svojoj strukturi na train, test i dev skupove.\n",
    "Treniranje SequenceTagger koristi validation skup korpusa, pa je bilo potrebno da dev skup podelimo na 2 dela:\n",
    "1. Jedan će koristiti SequenceTagger za internu validaciju\n",
    "2. Drugi ćemo mi koristiti za validaciju hiperparametara po kojima optimizujemo postojeći model\n",
    "\n",
    "Sličnu stvar smo uradili i sa test skupom, iz istog raloga."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:03:11,819 Reading data from corpus\\corpus1\n",
      "2022-08-30 16:03:11,820 Train: corpus\\corpus1\\sr_set-ud-train.conllu\n",
      "2022-08-30 16:03:11,820 Dev: corpus\\corpus1\\sr_set-ud-dev2.conllu\n",
      "2022-08-30 16:03:11,821 Test: corpus\\corpus1\\sr_set-ud-test2.conllu\n"
     ]
    }
   ],
   "source": [
    "# define columns\n",
    "columns = {0: 'id', 1: 'text', 2: 'ner', 3: 'upos'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = 'corpus/corpus1'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus1 = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='sr_set-ud-train.conllu',\n",
    "                              test_file='sr_set-ud-test2.conllu',\n",
    "                              dev_file='sr_set-ud-dev2.conllu')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:03:14,655 Reading data from corpus\\corpus2\n",
      "2022-08-30 16:03:14,656 Train: corpus\\corpus2\\sr_set-ud-train.conllu\n",
      "2022-08-30 16:03:14,656 Dev: corpus\\corpus2\\sr_set-ud-dev.conllu\n",
      "2022-08-30 16:03:14,657 Test: corpus\\corpus2\\sr_set-ud-test.conllu\n"
     ]
    }
   ],
   "source": [
    "# define columns\n",
    "columns = {0: 'id', 1: 'text', 2: 'ner', 3: 'upos'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = 'corpus/corpus2'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus2 = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='sr_set-ud-train.conllu',\n",
    "                              test_file='sr_set-ud-test.conllu',\n",
    "                              dev_file='sr_set-ud-dev.conllu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:03:17,244 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3328it [00:00, 29981.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:03:17,359 Dictionary created for label 'upos' with 18 values: NOUN (seen 18103 times), PUNCT (seen 9351 times), ADJ (seen 8835 times), ADP (seen 7130 times), VERB (seen 6406 times), PROPN (seen 5622 times), AUX (seen 4667 times), DET (seen 2848 times), SCONJ (seen 2713 times), ADV (seen 2543 times), CCONJ (seen 2541 times), PRON (seen 1859 times), NUM (seen 944 times), PART (seen 461 times), X (seen 232 times), INTJ (seen 3 times), SYM (seen 1 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_type = 'upos'\n",
    "label_dict  = corpus1.make_label_dictionary(label_type = label_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Primena istreniranog embedding-a\n",
    "Iskoristićemo vektorske reprezentacije tokena iz embedding modela kog smo trenirali da bismo napravili model za predikciju UPOS tagova. Uvezali smo Character embedding model koji smo istrenirali sa vec postojecim word embedding modelom (koji funkcionise na nivou reci) i tu strukturu prosledili modelu za predkiciju UPOS tagova."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "embedding_types = [\n",
    "    WordEmbeddings('glove'),\n",
    "    FlairEmbeddings('resources/taggers/language_model/best-lm.pt')\n",
    "]\n",
    "\n",
    "embeddings = StackedEmbeddings(embeddings=embedding_types)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:03:20,701 SequenceTagger predicts: Dictionary with 18 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type,\n",
    "                        use_crf=True)\n",
    "\n",
    "trainer = ModelTrainer(tagger, corpus1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "best_params = {'learning_rate':0, 'mini_batch_size': 0, 'max_epochs' : 10}\n",
    "\n",
    "param_learning_rates = np.linspace(0.001, 0.6, num=4)\n",
    "param_mini_batch_sizes = np.arange(10,100,20)\n",
    "max_epochs = np.arange(10,13,1)\n",
    "\n",
    "model_history = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 1 #######################\n",
      "#######################################################\n",
      "2022-08-30 16:03:20,746 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:20,746 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 16:03:20,747 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:20,748 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 16:03:20,748 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:20,748 Parameters:\n",
      "2022-08-30 16:03:20,749  - learning_rate: \"0.001000\"\n",
      "2022-08-30 16:03:20,749  - mini_batch_size: \"10\"\n",
      "2022-08-30 16:03:20,750  - patience: \"3\"\n",
      "2022-08-30 16:03:20,750  - anneal_factor: \"0.5\"\n",
      "2022-08-30 16:03:20,751  - max_epochs: \"10\"\n",
      "2022-08-30 16:03:20,751  - shuffle: \"True\"\n",
      "2022-08-30 16:03:20,752  - train_with_dev: \"False\"\n",
      "2022-08-30 16:03:20,752  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 16:03:20,753 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:20,753 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 16:03:20,753 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:20,754 Device: cpu\n",
      "2022-08-30 16:03:20,754 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:03:20,755 Embeddings storage mode: cpu\n",
      "2022-08-30 16:03:20,755 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:03:25,731 epoch 1 - iter 33/333 - loss 3.55456821 - samples/sec: 66.36 - lr: 0.001000\n",
      "2022-08-30 16:03:30,862 epoch 1 - iter 66/333 - loss 3.52915854 - samples/sec: 65.02 - lr: 0.001000\n",
      "2022-08-30 16:03:35,218 epoch 1 - iter 99/333 - loss 3.49130203 - samples/sec: 76.69 - lr: 0.001000\n",
      "2022-08-30 16:03:39,936 epoch 1 - iter 132/333 - loss 3.45640381 - samples/sec: 70.91 - lr: 0.001000\n",
      "2022-08-30 16:03:45,535 epoch 1 - iter 165/333 - loss 3.41364441 - samples/sec: 59.56 - lr: 0.001000\n",
      "2022-08-30 16:03:49,870 epoch 1 - iter 198/333 - loss 3.38043681 - samples/sec: 77.27 - lr: 0.001000\n",
      "2022-08-30 16:03:54,841 epoch 1 - iter 231/333 - loss 3.34791162 - samples/sec: 67.17 - lr: 0.001000\n",
      "2022-08-30 16:03:59,300 epoch 1 - iter 264/333 - loss 3.31396478 - samples/sec: 74.95 - lr: 0.001000\n",
      "2022-08-30 16:04:04,312 epoch 1 - iter 297/333 - loss 3.28054511 - samples/sec: 66.64 - lr: 0.001000\n",
      "2022-08-30 16:04:09,507 epoch 1 - iter 330/333 - loss 3.25244578 - samples/sec: 64.26 - lr: 0.001000\n",
      "2022-08-30 16:04:10,028 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:04:10,029 EPOCH 1 done: loss 3.2486 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:04:11,692 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:04:11,721 DEV : loss 2.917466402053833 - f1-score (micro avg)  0.091\n",
      "2022-08-30 16:04:11,741 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:04:11,742 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:04:12,861 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:04:16,761 epoch 2 - iter 33/333 - loss 2.89847589 - samples/sec: 84.64 - lr: 0.001000\n",
      "2022-08-30 16:04:20,662 epoch 2 - iter 66/333 - loss 2.87532189 - samples/sec: 86.00 - lr: 0.001000\n",
      "2022-08-30 16:04:24,359 epoch 2 - iter 99/333 - loss 2.86489267 - samples/sec: 90.61 - lr: 0.001000\n",
      "2022-08-30 16:04:27,985 epoch 2 - iter 132/333 - loss 2.84238739 - samples/sec: 92.67 - lr: 0.001000\n",
      "2022-08-30 16:04:32,007 epoch 2 - iter 165/333 - loss 2.82162656 - samples/sec: 83.29 - lr: 0.001000\n",
      "2022-08-30 16:04:35,961 epoch 2 - iter 198/333 - loss 2.81039857 - samples/sec: 84.96 - lr: 0.001000\n",
      "2022-08-30 16:04:40,165 epoch 2 - iter 231/333 - loss 2.79647938 - samples/sec: 79.65 - lr: 0.001000\n",
      "2022-08-30 16:04:44,286 epoch 2 - iter 264/333 - loss 2.77930813 - samples/sec: 81.28 - lr: 0.001000\n",
      "2022-08-30 16:04:48,367 epoch 2 - iter 297/333 - loss 2.76458541 - samples/sec: 82.11 - lr: 0.001000\n",
      "2022-08-30 16:04:52,769 epoch 2 - iter 330/333 - loss 2.75099986 - samples/sec: 76.18 - lr: 0.001000\n",
      "2022-08-30 16:04:53,159 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:04:53,159 EPOCH 2 done: loss 2.7499 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:04:54,125 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:04:54,151 DEV : loss 2.5845770835876465 - f1-score (micro avg)  0.2381\n",
      "2022-08-30 16:04:54,166 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:04:54,167 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:04:55,280 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:04:59,196 epoch 3 - iter 33/333 - loss 2.61174709 - samples/sec: 84.38 - lr: 0.001000\n",
      "2022-08-30 16:05:02,991 epoch 3 - iter 66/333 - loss 2.59320666 - samples/sec: 88.40 - lr: 0.001000\n",
      "2022-08-30 16:05:07,331 epoch 3 - iter 99/333 - loss 2.58017265 - samples/sec: 77.17 - lr: 0.001000\n",
      "2022-08-30 16:05:11,485 epoch 3 - iter 132/333 - loss 2.56453043 - samples/sec: 80.66 - lr: 0.001000\n",
      "2022-08-30 16:05:15,547 epoch 3 - iter 165/333 - loss 2.54862013 - samples/sec: 82.62 - lr: 0.001000\n",
      "2022-08-30 16:05:19,619 epoch 3 - iter 198/333 - loss 2.53749110 - samples/sec: 82.19 - lr: 0.001000\n",
      "2022-08-30 16:05:23,283 epoch 3 - iter 231/333 - loss 2.52278671 - samples/sec: 91.69 - lr: 0.001000\n",
      "2022-08-30 16:05:27,521 epoch 3 - iter 264/333 - loss 2.51112090 - samples/sec: 78.91 - lr: 0.001000\n",
      "2022-08-30 16:05:31,332 epoch 3 - iter 297/333 - loss 2.50041415 - samples/sec: 88.02 - lr: 0.001000\n",
      "2022-08-30 16:05:35,464 epoch 3 - iter 330/333 - loss 2.48927700 - samples/sec: 81.22 - lr: 0.001000\n",
      "2022-08-30 16:05:35,843 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:05:35,844 EPOCH 3 done: loss 2.4878 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:05:36,803 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:05:36,837 DEV : loss 2.3247227668762207 - f1-score (micro avg)  0.2809\n",
      "2022-08-30 16:05:36,854 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:05:36,855 saving best model\n",
      "2022-08-30 16:05:37,981 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:05:41,803 epoch 4 - iter 33/333 - loss 2.37314168 - samples/sec: 86.41 - lr: 0.001000\n",
      "2022-08-30 16:05:46,072 epoch 4 - iter 66/333 - loss 2.35455397 - samples/sec: 78.46 - lr: 0.001000\n",
      "2022-08-30 16:05:50,006 epoch 4 - iter 99/333 - loss 2.33576891 - samples/sec: 85.27 - lr: 0.001000\n",
      "2022-08-30 16:05:54,288 epoch 4 - iter 132/333 - loss 2.32472434 - samples/sec: 78.37 - lr: 0.001000\n",
      "2022-08-30 16:05:58,240 epoch 4 - iter 165/333 - loss 2.31498984 - samples/sec: 84.96 - lr: 0.001000\n",
      "2022-08-30 16:06:02,117 epoch 4 - iter 198/333 - loss 2.30497772 - samples/sec: 86.46 - lr: 0.001000\n",
      "2022-08-30 16:06:06,534 epoch 4 - iter 231/333 - loss 2.29974356 - samples/sec: 75.79 - lr: 0.001000\n",
      "2022-08-30 16:06:10,989 epoch 4 - iter 264/333 - loss 2.29385336 - samples/sec: 75.10 - lr: 0.001000\n",
      "2022-08-30 16:06:14,684 epoch 4 - iter 297/333 - loss 2.28436177 - samples/sec: 90.83 - lr: 0.001000\n",
      "2022-08-30 16:06:18,364 epoch 4 - iter 330/333 - loss 2.27562571 - samples/sec: 91.21 - lr: 0.001000\n",
      "2022-08-30 16:06:18,715 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:06:18,715 EPOCH 4 done: loss 2.2762 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:06:19,689 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:06:19,719 DEV : loss 2.110265016555786 - f1-score (micro avg)  0.3499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:06:19,735 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:06:19,736 saving best model\n",
      "2022-08-30 16:06:20,724 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:06:24,952 epoch 5 - iter 33/333 - loss 2.17415313 - samples/sec: 78.11 - lr: 0.001000\n",
      "2022-08-30 16:06:29,060 epoch 5 - iter 66/333 - loss 2.17099404 - samples/sec: 81.44 - lr: 0.001000\n",
      "2022-08-30 16:06:32,864 epoch 5 - iter 99/333 - loss 2.15777373 - samples/sec: 88.02 - lr: 0.001000\n",
      "2022-08-30 16:06:36,379 epoch 5 - iter 132/333 - loss 2.14454928 - samples/sec: 95.46 - lr: 0.001000\n",
      "2022-08-30 16:06:40,412 epoch 5 - iter 165/333 - loss 2.13717210 - samples/sec: 83.23 - lr: 0.001000\n",
      "2022-08-30 16:06:44,085 epoch 5 - iter 198/333 - loss 2.12983779 - samples/sec: 91.51 - lr: 0.001000\n",
      "2022-08-30 16:06:47,925 epoch 5 - iter 231/333 - loss 2.12155880 - samples/sec: 87.32 - lr: 0.001000\n",
      "2022-08-30 16:06:52,047 epoch 5 - iter 264/333 - loss 2.11428286 - samples/sec: 81.14 - lr: 0.001000\n",
      "2022-08-30 16:06:56,018 epoch 5 - iter 297/333 - loss 2.10324042 - samples/sec: 84.40 - lr: 0.001000\n",
      "2022-08-30 16:07:00,696 epoch 5 - iter 330/333 - loss 2.09793026 - samples/sec: 71.57 - lr: 0.001000\n",
      "2022-08-30 16:07:01,096 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:07:01,096 EPOCH 5 done: loss 2.0961 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:07:02,143 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:07:02,180 DEV : loss 1.9253275394439697 - f1-score (micro avg)  0.4134\n",
      "2022-08-30 16:07:02,200 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:07:02,201 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:07:03,360 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:07:07,680 epoch 6 - iter 33/333 - loss 2.01418482 - samples/sec: 76.41 - lr: 0.001000\n",
      "2022-08-30 16:07:11,654 epoch 6 - iter 66/333 - loss 2.01286343 - samples/sec: 84.25 - lr: 0.001000\n",
      "2022-08-30 16:07:15,386 epoch 6 - iter 99/333 - loss 1.99310485 - samples/sec: 89.82 - lr: 0.001000\n",
      "2022-08-30 16:07:19,260 epoch 6 - iter 132/333 - loss 1.98469295 - samples/sec: 86.82 - lr: 0.001000\n",
      "2022-08-30 16:07:23,295 epoch 6 - iter 165/333 - loss 1.97489103 - samples/sec: 82.94 - lr: 0.001000\n",
      "2022-08-30 16:07:27,529 epoch 6 - iter 198/333 - loss 1.96813124 - samples/sec: 79.00 - lr: 0.001000\n",
      "2022-08-30 16:07:31,338 epoch 6 - iter 231/333 - loss 1.96035352 - samples/sec: 88.26 - lr: 0.001000\n",
      "2022-08-30 16:07:35,327 epoch 6 - iter 264/333 - loss 1.95249959 - samples/sec: 84.21 - lr: 0.001000\n",
      "2022-08-30 16:07:39,319 epoch 6 - iter 297/333 - loss 1.94593861 - samples/sec: 84.10 - lr: 0.001000\n",
      "2022-08-30 16:07:43,517 epoch 6 - iter 330/333 - loss 1.94489310 - samples/sec: 79.83 - lr: 0.001000\n",
      "2022-08-30 16:07:43,864 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:07:43,865 EPOCH 6 done: loss 1.9450 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:07:44,848 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:07:44,878 DEV : loss 1.7816011905670166 - f1-score (micro avg)  0.4462\n",
      "2022-08-30 16:07:44,894 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:07:44,895 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:07:46,130 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:07:50,238 epoch 7 - iter 33/333 - loss 1.86814036 - samples/sec: 80.37 - lr: 0.001000\n",
      "2022-08-30 16:07:54,645 epoch 7 - iter 66/333 - loss 1.85983763 - samples/sec: 75.97 - lr: 0.001000\n",
      "2022-08-30 16:07:58,683 epoch 7 - iter 99/333 - loss 1.86127456 - samples/sec: 82.94 - lr: 0.001000\n",
      "2022-08-30 16:08:02,788 epoch 7 - iter 132/333 - loss 1.85872219 - samples/sec: 81.68 - lr: 0.001000\n",
      "2022-08-30 16:08:06,953 epoch 7 - iter 165/333 - loss 1.85225057 - samples/sec: 80.39 - lr: 0.001000\n",
      "2022-08-30 16:08:10,815 epoch 7 - iter 198/333 - loss 1.84860259 - samples/sec: 86.80 - lr: 0.001000\n",
      "2022-08-30 16:08:14,499 epoch 7 - iter 231/333 - loss 1.84453061 - samples/sec: 91.03 - lr: 0.001000\n",
      "2022-08-30 16:08:18,743 epoch 7 - iter 264/333 - loss 1.83831163 - samples/sec: 78.85 - lr: 0.001000\n",
      "2022-08-30 16:08:22,481 epoch 7 - iter 297/333 - loss 1.83553369 - samples/sec: 89.63 - lr: 0.001000\n",
      "2022-08-30 16:08:26,437 epoch 7 - iter 330/333 - loss 1.82750972 - samples/sec: 84.99 - lr: 0.001000\n",
      "2022-08-30 16:08:26,785 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:08:26,786 EPOCH 7 done: loss 1.8269 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:08:27,752 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:08:27,780 DEV : loss 1.6724438667297363 - f1-score (micro avg)  0.4745\n",
      "2022-08-30 16:08:27,798 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:08:27,799 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:08:28,942 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:08:33,196 epoch 8 - iter 33/333 - loss 1.79601780 - samples/sec: 77.61 - lr: 0.001000\n",
      "2022-08-30 16:08:37,186 epoch 8 - iter 66/333 - loss 1.78296889 - samples/sec: 84.33 - lr: 0.001000\n",
      "2022-08-30 16:08:40,583 epoch 8 - iter 99/333 - loss 1.77359758 - samples/sec: 98.89 - lr: 0.001000\n",
      "2022-08-30 16:08:45,095 epoch 8 - iter 132/333 - loss 1.76187733 - samples/sec: 74.11 - lr: 0.001000\n",
      "2022-08-30 16:08:49,014 epoch 8 - iter 165/333 - loss 1.75875269 - samples/sec: 85.60 - lr: 0.001000\n",
      "2022-08-30 16:08:53,061 epoch 8 - iter 198/333 - loss 1.75388290 - samples/sec: 82.89 - lr: 0.001000\n",
      "2022-08-30 16:08:57,116 epoch 8 - iter 231/333 - loss 1.75331665 - samples/sec: 82.56 - lr: 0.001000\n",
      "2022-08-30 16:09:00,954 epoch 8 - iter 264/333 - loss 1.74808617 - samples/sec: 87.37 - lr: 0.001000\n",
      "2022-08-30 16:09:05,107 epoch 8 - iter 297/333 - loss 1.74586384 - samples/sec: 80.61 - lr: 0.001000\n",
      "2022-08-30 16:09:09,135 epoch 8 - iter 330/333 - loss 1.74047538 - samples/sec: 83.31 - lr: 0.001000\n",
      "2022-08-30 16:09:09,510 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:09:09,510 EPOCH 8 done: loss 1.7407 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:09:10,476 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:09:10,504 DEV : loss 1.58737313747406 - f1-score (micro avg)  0.4959\n",
      "2022-08-30 16:09:10,522 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:09:10,523 saving best model\n",
      "2022-08-30 16:09:11,206 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:09:14,920 epoch 9 - iter 33/333 - loss 1.68062293 - samples/sec: 88.92 - lr: 0.001000\n",
      "2022-08-30 16:09:18,846 epoch 9 - iter 66/333 - loss 1.67908932 - samples/sec: 85.36 - lr: 0.001000\n",
      "2022-08-30 16:09:23,271 epoch 9 - iter 99/333 - loss 1.69245230 - samples/sec: 75.60 - lr: 0.001000\n",
      "2022-08-30 16:09:27,043 epoch 9 - iter 132/333 - loss 1.68829610 - samples/sec: 88.92 - lr: 0.001000\n",
      "2022-08-30 16:09:30,638 epoch 9 - iter 165/333 - loss 1.68038847 - samples/sec: 93.33 - lr: 0.001000\n",
      "2022-08-30 16:09:34,862 epoch 9 - iter 198/333 - loss 1.68061226 - samples/sec: 79.19 - lr: 0.001000\n",
      "2022-08-30 16:09:38,614 epoch 9 - iter 231/333 - loss 1.67444303 - samples/sec: 89.38 - lr: 0.001000\n",
      "2022-08-30 16:09:42,772 epoch 9 - iter 264/333 - loss 1.67069247 - samples/sec: 80.57 - lr: 0.001000\n",
      "2022-08-30 16:09:46,729 epoch 9 - iter 297/333 - loss 1.66592384 - samples/sec: 84.68 - lr: 0.001000\n",
      "2022-08-30 16:09:50,735 epoch 9 - iter 330/333 - loss 1.66561861 - samples/sec: 83.61 - lr: 0.001000\n",
      "2022-08-30 16:09:51,271 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:09:51,272 EPOCH 9 done: loss 1.6656 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:09:52,252 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:09:52,285 DEV : loss 1.5160136222839355 - f1-score (micro avg)  0.5158\n",
      "2022-08-30 16:09:52,300 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:09:52,301 saving best model\n",
      "2022-08-30 16:09:52,979 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:09:56,952 epoch 10 - iter 33/333 - loss 1.63220002 - samples/sec: 83.10 - lr: 0.001000\n",
      "2022-08-30 16:10:00,585 epoch 10 - iter 66/333 - loss 1.61942879 - samples/sec: 92.26 - lr: 0.001000\n",
      "2022-08-30 16:10:04,341 epoch 10 - iter 99/333 - loss 1.62035666 - samples/sec: 89.19 - lr: 0.001000\n",
      "2022-08-30 16:10:08,496 epoch 10 - iter 132/333 - loss 1.62803007 - samples/sec: 80.80 - lr: 0.001000\n",
      "2022-08-30 16:10:13,393 epoch 10 - iter 165/333 - loss 1.61834205 - samples/sec: 68.25 - lr: 0.001000\n",
      "2022-08-30 16:10:17,501 epoch 10 - iter 198/333 - loss 1.61368481 - samples/sec: 81.85 - lr: 0.001000\n",
      "2022-08-30 16:10:21,723 epoch 10 - iter 231/333 - loss 1.60915177 - samples/sec: 79.44 - lr: 0.001000\n",
      "2022-08-30 16:10:25,729 epoch 10 - iter 264/333 - loss 1.60618921 - samples/sec: 83.65 - lr: 0.001000\n",
      "2022-08-30 16:10:29,541 epoch 10 - iter 297/333 - loss 1.60348642 - samples/sec: 88.02 - lr: 0.001000\n",
      "2022-08-30 16:10:33,584 epoch 10 - iter 330/333 - loss 1.60402952 - samples/sec: 82.79 - lr: 0.001000\n",
      "2022-08-30 16:10:33,929 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:10:33,930 EPOCH 10 done: loss 1.6037 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:10:36,119 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:10:36,146 DEV : loss 1.4549543857574463 - f1-score (micro avg)  0.5365\n",
      "2022-08-30 16:10:36,161 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:10:36,162 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:10:37,524 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:10:37,525 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 16:10:37,698 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:10:39,257 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:10:39,284 0.55\t0.55\t0.55\t0.55\n",
      "2022-08-30 16:10:39,284 \n",
      "Results:\n",
      "- F-score (micro) 0.55\n",
      "- F-score (macro) 0.3423\n",
      "- Accuracy 0.55\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.4994    0.6445    0.5628      1353\n",
      "         ADJ     0.3674    0.5134    0.4283       672\n",
      "       PUNCT     0.9007    0.9621    0.9304       660\n",
      "         ADP     0.6911    0.8444    0.7601       514\n",
      "        VERB     0.2292    0.1225    0.1597       449\n",
      "         AUX     0.7065    0.5821    0.6383       335\n",
      "       PROPN     0.2747    0.1305    0.1770       383\n",
      "       CCONJ     0.8177    0.8177    0.8177       192\n",
      "       SCONJ     0.6860    0.6413    0.6629       184\n",
      "         DET     0.1429    0.1180    0.1293       161\n",
      "         ADV     0.0769    0.0132    0.0226       151\n",
      "        PRON     0.5417    0.1130    0.1871       115\n",
      "         NUM     0.0000    0.0000    0.0000        71\n",
      "        PART     0.0000    0.0000    0.0000        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5500      5264\n",
      "   macro avg     0.3709    0.3439    0.3423      5264\n",
      "weighted avg     0.5124    0.5500    0.5190      5264\n",
      "\n",
      "2022-08-30 16:10:39,285 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:10:39,286 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:10:40,567 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 2 #######################\n",
      "#######################################################\n",
      "2022-08-30 16:12:58,927 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:12:58,927 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 16:12:58,928 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:12:58,928 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 16:12:58,929 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:12:58,930 Parameters:\n",
      "2022-08-30 16:12:58,930  - learning_rate: \"0.001000\"\n",
      "2022-08-30 16:12:58,931  - mini_batch_size: \"10\"\n",
      "2022-08-30 16:12:58,931  - patience: \"3\"\n",
      "2022-08-30 16:12:58,932  - anneal_factor: \"0.5\"\n",
      "2022-08-30 16:12:58,933  - max_epochs: \"11\"\n",
      "2022-08-30 16:12:58,933  - shuffle: \"True\"\n",
      "2022-08-30 16:12:58,934  - train_with_dev: \"False\"\n",
      "2022-08-30 16:12:58,934  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 16:12:58,934 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:12:58,935 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 16:12:58,936 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:12:58,936 Device: cpu\n",
      "2022-08-30 16:12:58,937 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:12:58,938 Embeddings storage mode: cpu\n",
      "2022-08-30 16:12:58,938 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:13:02,993 epoch 1 - iter 33/333 - loss 1.55393667 - samples/sec: 81.44 - lr: 0.001000\n",
      "2022-08-30 16:13:07,192 epoch 1 - iter 66/333 - loss 1.54666878 - samples/sec: 79.90 - lr: 0.001000\n",
      "2022-08-30 16:13:10,772 epoch 1 - iter 99/333 - loss 1.54178926 - samples/sec: 93.78 - lr: 0.001000\n",
      "2022-08-30 16:13:14,615 epoch 1 - iter 132/333 - loss 1.54475824 - samples/sec: 87.14 - lr: 0.001000\n",
      "2022-08-30 16:13:19,225 epoch 1 - iter 165/333 - loss 1.54120910 - samples/sec: 72.50 - lr: 0.001000\n",
      "2022-08-30 16:13:22,754 epoch 1 - iter 198/333 - loss 1.53491718 - samples/sec: 95.02 - lr: 0.001000\n",
      "2022-08-30 16:13:26,828 epoch 1 - iter 231/333 - loss 1.53214450 - samples/sec: 82.15 - lr: 0.001000\n",
      "2022-08-30 16:13:30,558 epoch 1 - iter 264/333 - loss 1.53006262 - samples/sec: 89.82 - lr: 0.001000\n",
      "2022-08-30 16:13:34,786 epoch 1 - iter 297/333 - loss 1.52920522 - samples/sec: 79.19 - lr: 0.001000\n",
      "2022-08-30 16:13:39,139 epoch 1 - iter 330/333 - loss 1.54541654 - samples/sec: 76.85 - lr: 0.001000\n",
      "2022-08-30 16:13:39,613 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:13:39,614 EPOCH 1 done: loss 1.5460 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:13:40,611 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:13:40,639 DEV : loss 1.4092845916748047 - f1-score (micro avg)  0.557\n",
      "2022-08-30 16:13:40,655 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:13:40,656 saving best model\n",
      "2022-08-30 16:13:41,823 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:13:46,019 epoch 2 - iter 33/333 - loss 1.51892700 - samples/sec: 78.72 - lr: 0.001000\n",
      "2022-08-30 16:13:49,767 epoch 2 - iter 66/333 - loss 1.52958689 - samples/sec: 89.55 - lr: 0.001000\n",
      "2022-08-30 16:13:53,898 epoch 2 - iter 99/333 - loss 1.52721817 - samples/sec: 81.10 - lr: 0.001000\n",
      "2022-08-30 16:13:57,466 epoch 2 - iter 132/333 - loss 1.51539489 - samples/sec: 94.04 - lr: 0.001000\n",
      "2022-08-30 16:14:01,199 epoch 2 - iter 165/333 - loss 1.51600868 - samples/sec: 89.82 - lr: 0.001000\n",
      "2022-08-30 16:14:05,667 epoch 2 - iter 198/333 - loss 1.51144296 - samples/sec: 74.91 - lr: 0.001000\n",
      "2022-08-30 16:14:09,707 epoch 2 - iter 231/333 - loss 1.51106129 - samples/sec: 82.89 - lr: 0.001000\n",
      "2022-08-30 16:14:13,185 epoch 2 - iter 264/333 - loss 1.50833338 - samples/sec: 96.58 - lr: 0.001000\n",
      "2022-08-30 16:14:17,370 epoch 2 - iter 297/333 - loss 1.50936166 - samples/sec: 79.98 - lr: 0.001000\n",
      "2022-08-30 16:14:22,059 epoch 2 - iter 330/333 - loss 1.50631115 - samples/sec: 71.49 - lr: 0.001000\n",
      "2022-08-30 16:14:22,406 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:14:22,406 EPOCH 2 done: loss 1.5068 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:14:23,387 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:14:23,418 DEV : loss 1.3590312004089355 - f1-score (micro avg)  0.5666\n",
      "2022-08-30 16:14:23,433 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:14:23,434 saving best model\n",
      "2022-08-30 16:14:24,249 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:14:28,195 epoch 3 - iter 33/333 - loss 1.51612140 - samples/sec: 83.69 - lr: 0.001000\n",
      "2022-08-30 16:14:32,319 epoch 3 - iter 66/333 - loss 1.49340423 - samples/sec: 81.16 - lr: 0.001000\n",
      "2022-08-30 16:14:36,175 epoch 3 - iter 99/333 - loss 1.48550694 - samples/sec: 87.12 - lr: 0.001000\n",
      "2022-08-30 16:14:39,891 epoch 3 - iter 132/333 - loss 1.48068633 - samples/sec: 90.36 - lr: 0.001000\n",
      "2022-08-30 16:14:43,730 epoch 3 - iter 165/333 - loss 1.47739409 - samples/sec: 87.23 - lr: 0.001000\n",
      "2022-08-30 16:14:48,031 epoch 3 - iter 198/333 - loss 1.47554021 - samples/sec: 77.81 - lr: 0.001000\n",
      "2022-08-30 16:14:52,310 epoch 3 - iter 231/333 - loss 1.47186900 - samples/sec: 78.27 - lr: 0.001000\n",
      "2022-08-30 16:14:56,375 epoch 3 - iter 264/333 - loss 1.46910269 - samples/sec: 82.50 - lr: 0.001000\n",
      "2022-08-30 16:15:00,504 epoch 3 - iter 297/333 - loss 1.46332269 - samples/sec: 81.30 - lr: 0.001000\n",
      "2022-08-30 16:15:04,392 epoch 3 - iter 330/333 - loss 1.46342248 - samples/sec: 86.21 - lr: 0.001000\n",
      "2022-08-30 16:15:04,828 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:15:04,829 EPOCH 3 done: loss 1.4632 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:15:05,808 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:15:05,836 DEV : loss 1.3195935487747192 - f1-score (micro avg)  0.5794\n",
      "2022-08-30 16:15:05,854 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:15:05,855 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:15:06,548 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:15:10,768 epoch 4 - iter 33/333 - loss 1.43036976 - samples/sec: 78.27 - lr: 0.001000\n",
      "2022-08-30 16:15:14,633 epoch 4 - iter 66/333 - loss 1.43465195 - samples/sec: 86.68 - lr: 0.001000\n",
      "2022-08-30 16:15:18,561 epoch 4 - iter 99/333 - loss 1.43653375 - samples/sec: 85.27 - lr: 0.001000\n",
      "2022-08-30 16:15:22,682 epoch 4 - iter 132/333 - loss 1.44848919 - samples/sec: 81.34 - lr: 0.001000\n",
      "2022-08-30 16:15:26,363 epoch 4 - iter 165/333 - loss 1.44538320 - samples/sec: 91.26 - lr: 0.001000\n",
      "2022-08-30 16:15:30,640 epoch 4 - iter 198/333 - loss 1.44208756 - samples/sec: 78.55 - lr: 0.001000\n",
      "2022-08-30 16:15:34,951 epoch 4 - iter 231/333 - loss 1.43871896 - samples/sec: 77.61 - lr: 0.001000\n",
      "2022-08-30 16:15:38,956 epoch 4 - iter 264/333 - loss 1.43555517 - samples/sec: 83.69 - lr: 0.001000\n",
      "2022-08-30 16:15:43,136 epoch 4 - iter 297/333 - loss 1.43427918 - samples/sec: 80.14 - lr: 0.001000\n",
      "2022-08-30 16:15:47,119 epoch 4 - iter 330/333 - loss 1.43010051 - samples/sec: 83.97 - lr: 0.001000\n",
      "2022-08-30 16:15:47,466 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:15:47,467 EPOCH 4 done: loss 1.4296 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:15:48,456 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:15:48,492 DEV : loss 1.2868385314941406 - f1-score (micro avg)  0.5853\n",
      "2022-08-30 16:15:48,512 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:15:48,514 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:15:49,589 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:15:53,730 epoch 5 - iter 33/333 - loss 1.40179449 - samples/sec: 79.75 - lr: 0.001000\n",
      "2022-08-30 16:15:57,786 epoch 5 - iter 66/333 - loss 1.39262548 - samples/sec: 82.50 - lr: 0.001000\n",
      "2022-08-30 16:16:01,670 epoch 5 - iter 99/333 - loss 1.39823757 - samples/sec: 86.25 - lr: 0.001000\n",
      "2022-08-30 16:16:05,321 epoch 5 - iter 132/333 - loss 1.39054237 - samples/sec: 91.97 - lr: 0.001000\n",
      "2022-08-30 16:16:09,109 epoch 5 - iter 165/333 - loss 1.39287324 - samples/sec: 88.78 - lr: 0.001000\n",
      "2022-08-30 16:16:13,142 epoch 5 - iter 198/333 - loss 1.39402310 - samples/sec: 83.02 - lr: 0.001000\n",
      "2022-08-30 16:16:17,277 epoch 5 - iter 231/333 - loss 1.39406005 - samples/sec: 81.08 - lr: 0.001000\n",
      "2022-08-30 16:16:20,790 epoch 5 - iter 264/333 - loss 1.39217376 - samples/sec: 95.51 - lr: 0.001000\n",
      "2022-08-30 16:16:24,665 epoch 5 - iter 297/333 - loss 1.39087728 - samples/sec: 86.59 - lr: 0.001000\n",
      "2022-08-30 16:16:29,157 epoch 5 - iter 330/333 - loss 1.39469629 - samples/sec: 74.61 - lr: 0.001000\n",
      "2022-08-30 16:16:29,686 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:16:29,687 EPOCH 5 done: loss 1.3942 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:16:30,648 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:16:30,677 DEV : loss 1.2553900480270386 - f1-score (micro avg)  0.5905\n",
      "2022-08-30 16:16:30,694 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:16:30,695 saving best model\n",
      "2022-08-30 16:16:31,806 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:16:35,907 epoch 6 - iter 33/333 - loss 1.37124282 - samples/sec: 80.55 - lr: 0.001000\n",
      "2022-08-30 16:16:40,037 epoch 6 - iter 66/333 - loss 1.38479671 - samples/sec: 81.06 - lr: 0.001000\n",
      "2022-08-30 16:16:43,927 epoch 6 - iter 99/333 - loss 1.37804417 - samples/sec: 86.12 - lr: 0.001000\n",
      "2022-08-30 16:16:47,752 epoch 6 - iter 132/333 - loss 1.37147376 - samples/sec: 87.70 - lr: 0.001000\n",
      "2022-08-30 16:16:51,771 epoch 6 - iter 165/333 - loss 1.37150987 - samples/sec: 83.59 - lr: 0.001000\n",
      "2022-08-30 16:16:55,951 epoch 6 - iter 198/333 - loss 1.37298302 - samples/sec: 80.35 - lr: 0.001000\n",
      "2022-08-30 16:16:59,911 epoch 6 - iter 231/333 - loss 1.37283651 - samples/sec: 84.53 - lr: 0.001000\n",
      "2022-08-30 16:17:03,770 epoch 6 - iter 264/333 - loss 1.37047259 - samples/sec: 86.86 - lr: 0.001000\n",
      "2022-08-30 16:17:07,796 epoch 6 - iter 297/333 - loss 1.36786537 - samples/sec: 83.19 - lr: 0.001000\n",
      "2022-08-30 16:17:11,808 epoch 6 - iter 330/333 - loss 1.37123721 - samples/sec: 83.65 - lr: 0.001000\n",
      "2022-08-30 16:17:12,234 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:17:12,234 EPOCH 6 done: loss 1.3706 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:17:13,218 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:17:13,245 DEV : loss 1.2288099527359009 - f1-score (micro avg)  0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:17:13,263 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:17:13,264 saving best model\n",
      "2022-08-30 16:17:14,359 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:17:18,230 epoch 7 - iter 33/333 - loss 1.36297972 - samples/sec: 85.32 - lr: 0.001000\n",
      "2022-08-30 16:17:22,603 epoch 7 - iter 66/333 - loss 1.34946610 - samples/sec: 76.50 - lr: 0.001000\n",
      "2022-08-30 16:17:26,687 epoch 7 - iter 99/333 - loss 1.35543122 - samples/sec: 81.99 - lr: 0.001000\n",
      "2022-08-30 16:17:30,412 epoch 7 - iter 132/333 - loss 1.35570778 - samples/sec: 90.19 - lr: 0.001000\n",
      "2022-08-30 16:17:34,717 epoch 7 - iter 165/333 - loss 1.35629152 - samples/sec: 77.90 - lr: 0.001000\n",
      "2022-08-30 16:17:38,602 epoch 7 - iter 198/333 - loss 1.35214195 - samples/sec: 86.21 - lr: 0.001000\n",
      "2022-08-30 16:17:42,762 epoch 7 - iter 231/333 - loss 1.34691697 - samples/sec: 80.61 - lr: 0.001000\n",
      "2022-08-30 16:17:46,507 epoch 7 - iter 264/333 - loss 1.34374420 - samples/sec: 89.46 - lr: 0.001000\n",
      "2022-08-30 16:17:50,214 epoch 7 - iter 297/333 - loss 1.34475601 - samples/sec: 90.68 - lr: 0.001000\n",
      "2022-08-30 16:17:54,207 epoch 7 - iter 330/333 - loss 1.34339853 - samples/sec: 84.12 - lr: 0.001000\n",
      "2022-08-30 16:17:54,661 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:17:54,662 EPOCH 7 done: loss 1.3444 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:17:55,678 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:17:55,710 DEV : loss 1.2047069072723389 - f1-score (micro avg)  0.5963\n",
      "2022-08-30 16:17:55,725 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:17:55,727 saving best model\n",
      "2022-08-30 16:17:56,878 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:18:01,087 epoch 8 - iter 33/333 - loss 1.35708359 - samples/sec: 78.48 - lr: 0.001000\n",
      "2022-08-30 16:18:04,891 epoch 8 - iter 66/333 - loss 1.34575159 - samples/sec: 88.07 - lr: 0.001000\n",
      "2022-08-30 16:18:08,862 epoch 8 - iter 99/333 - loss 1.34037812 - samples/sec: 84.31 - lr: 0.001000\n",
      "2022-08-30 16:18:12,841 epoch 8 - iter 132/333 - loss 1.33129334 - samples/sec: 84.27 - lr: 0.001000\n",
      "2022-08-30 16:18:17,039 epoch 8 - iter 165/333 - loss 1.32902556 - samples/sec: 79.69 - lr: 0.001000\n",
      "2022-08-30 16:18:21,012 epoch 8 - iter 198/333 - loss 1.32588846 - samples/sec: 84.33 - lr: 0.001000\n",
      "2022-08-30 16:18:25,313 epoch 8 - iter 231/333 - loss 1.32716710 - samples/sec: 77.90 - lr: 0.001000\n",
      "2022-08-30 16:18:29,017 epoch 8 - iter 264/333 - loss 1.32754024 - samples/sec: 90.58 - lr: 0.001000\n",
      "2022-08-30 16:18:32,810 epoch 8 - iter 297/333 - loss 1.32659831 - samples/sec: 88.57 - lr: 0.001000\n",
      "2022-08-30 16:18:37,093 epoch 8 - iter 330/333 - loss 1.32536985 - samples/sec: 78.25 - lr: 0.001000\n",
      "2022-08-30 16:18:37,489 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:18:37,489 EPOCH 8 done: loss 1.3253 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:18:38,469 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:18:38,498 DEV : loss 1.1851485967636108 - f1-score (micro avg)  0.6007\n",
      "2022-08-30 16:18:38,515 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:18:38,517 saving best model\n",
      "2022-08-30 16:18:39,209 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:18:42,923 epoch 9 - iter 33/333 - loss 1.28820125 - samples/sec: 88.92 - lr: 0.001000\n",
      "2022-08-30 16:18:46,930 epoch 9 - iter 66/333 - loss 1.29553901 - samples/sec: 83.67 - lr: 0.001000\n",
      "2022-08-30 16:18:51,518 epoch 9 - iter 99/333 - loss 1.30789907 - samples/sec: 72.91 - lr: 0.001000\n",
      "2022-08-30 16:18:55,304 epoch 9 - iter 132/333 - loss 1.31210098 - samples/sec: 88.73 - lr: 0.001000\n",
      "2022-08-30 16:18:59,261 epoch 9 - iter 165/333 - loss 1.31170793 - samples/sec: 84.81 - lr: 0.001000\n",
      "2022-08-30 16:19:03,378 epoch 9 - iter 198/333 - loss 1.30835090 - samples/sec: 81.28 - lr: 0.001000\n",
      "2022-08-30 16:19:07,538 epoch 9 - iter 231/333 - loss 1.30523076 - samples/sec: 80.74 - lr: 0.001000\n",
      "2022-08-30 16:19:11,368 epoch 9 - iter 264/333 - loss 1.30329562 - samples/sec: 87.63 - lr: 0.001000\n",
      "2022-08-30 16:19:15,641 epoch 9 - iter 297/333 - loss 1.30491752 - samples/sec: 78.55 - lr: 0.001000\n",
      "2022-08-30 16:19:19,357 epoch 9 - iter 330/333 - loss 1.30421575 - samples/sec: 90.26 - lr: 0.001000\n",
      "2022-08-30 16:19:19,771 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:19:19,772 EPOCH 9 done: loss 1.3048 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:19:20,757 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:19:20,793 DEV : loss 1.1638847589492798 - f1-score (micro avg)  0.6027\n",
      "2022-08-30 16:19:20,814 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:19:20,815 saving best model\n",
      "2022-08-30 16:19:21,497 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:19:25,150 epoch 10 - iter 33/333 - loss 1.29989191 - samples/sec: 90.44 - lr: 0.001000\n",
      "2022-08-30 16:19:28,778 epoch 10 - iter 66/333 - loss 1.29218594 - samples/sec: 92.39 - lr: 0.001000\n",
      "2022-08-30 16:19:32,872 epoch 10 - iter 99/333 - loss 1.29615710 - samples/sec: 81.70 - lr: 0.001000\n",
      "2022-08-30 16:19:36,598 epoch 10 - iter 132/333 - loss 1.29139654 - samples/sec: 90.02 - lr: 0.001000\n",
      "2022-08-30 16:19:40,781 epoch 10 - iter 165/333 - loss 1.28555959 - samples/sec: 80.04 - lr: 0.001000\n",
      "2022-08-30 16:19:44,710 epoch 10 - iter 198/333 - loss 1.28930754 - samples/sec: 85.21 - lr: 0.001000\n",
      "2022-08-30 16:19:48,535 epoch 10 - iter 231/333 - loss 1.28860910 - samples/sec: 87.63 - lr: 0.001000\n",
      "2022-08-30 16:19:52,344 epoch 10 - iter 264/333 - loss 1.28735150 - samples/sec: 88.05 - lr: 0.001000\n",
      "2022-08-30 16:19:56,453 epoch 10 - iter 297/333 - loss 1.29043689 - samples/sec: 81.66 - lr: 0.001000\n",
      "2022-08-30 16:20:00,787 epoch 10 - iter 330/333 - loss 1.29012940 - samples/sec: 77.37 - lr: 0.001000\n",
      "2022-08-30 16:20:01,118 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:20:01,119 EPOCH 10 done: loss 1.2900 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:20:02,068 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:20:02,098 DEV : loss 1.1450905799865723 - f1-score (micro avg)  0.6051\n",
      "2022-08-30 16:20:02,117 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:20:02,118 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:20:03,125 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:20:07,167 epoch 11 - iter 33/333 - loss 1.30818950 - samples/sec: 81.68 - lr: 0.001000\n",
      "2022-08-30 16:20:11,171 epoch 11 - iter 66/333 - loss 1.28257888 - samples/sec: 83.61 - lr: 0.001000\n",
      "2022-08-30 16:20:15,457 epoch 11 - iter 99/333 - loss 1.27583779 - samples/sec: 78.07 - lr: 0.001000\n",
      "2022-08-30 16:20:19,827 epoch 11 - iter 132/333 - loss 1.27386636 - samples/sec: 76.92 - lr: 0.001000\n",
      "2022-08-30 16:20:24,045 epoch 11 - iter 165/333 - loss 1.27413541 - samples/sec: 79.37 - lr: 0.001000\n",
      "2022-08-30 16:20:27,811 epoch 11 - iter 198/333 - loss 1.27731222 - samples/sec: 89.02 - lr: 0.001000\n",
      "2022-08-30 16:20:31,535 epoch 11 - iter 231/333 - loss 1.27499190 - samples/sec: 89.99 - lr: 0.001000\n",
      "2022-08-30 16:20:35,750 epoch 11 - iter 264/333 - loss 1.27750460 - samples/sec: 79.44 - lr: 0.001000\n",
      "2022-08-30 16:20:39,604 epoch 11 - iter 297/333 - loss 1.27322571 - samples/sec: 86.93 - lr: 0.001000\n",
      "2022-08-30 16:20:43,255 epoch 11 - iter 330/333 - loss 1.27374455 - samples/sec: 91.90 - lr: 0.001000\n",
      "2022-08-30 16:20:43,638 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:20:43,638 EPOCH 11 done: loss 1.2733 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:20:44,606 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:20:44,640 DEV : loss 1.1303606033325195 - f1-score (micro avg)  0.6077\n",
      "2022-08-30 16:20:44,657 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:20:44,658 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:20:46,401 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:20:46,402 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 16:20:46,581 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 17.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:20:48,090 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:20:48,116 0.6235\t0.6235\t0.6235\t0.6235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:20:48,117 \n",
      "Results:\n",
      "- F-score (micro) 0.6235\n",
      "- F-score (macro) 0.43\n",
      "- Accuracy 0.6235\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.5347    0.6955    0.6046      1353\n",
      "         ADJ     0.4158    0.6027    0.4921       672\n",
      "       PUNCT     0.9555    0.9758    0.9655       660\n",
      "         ADP     0.8084    0.8619    0.8343       514\n",
      "        VERB     0.3987    0.2762    0.3263       449\n",
      "         AUX     0.8301    0.7582    0.7925       335\n",
      "       PROPN     0.5165    0.1227    0.1983       383\n",
      "       CCONJ     0.9188    0.9427    0.9306       192\n",
      "       SCONJ     0.8466    0.8098    0.8278       184\n",
      "         DET     0.1667    0.1118    0.1338       161\n",
      "        PRON     0.8537    0.6087    0.7107       115\n",
      "         ADV     0.1667    0.0397    0.0642       151\n",
      "         NUM     0.0000    0.0000    0.0000        71\n",
      "        PART     0.0000    0.0000    0.0000        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6235      5264\n",
      "   macro avg     0.4632    0.4254    0.4300      5264\n",
      "weighted avg     0.6053    0.6235    0.5978      5264\n",
      "\n",
      "2022-08-30 16:20:48,118 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:20:48,120 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 16:20:48,617 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 3 #######################\n",
      "#######################################################\n",
      "2022-08-30 16:23:12,233 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:23:12,234 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 16:23:12,235 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:23:12,235 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 16:23:12,236 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:23:12,236 Parameters:\n",
      "2022-08-30 16:23:12,237  - learning_rate: \"0.001000\"\n",
      "2022-08-30 16:23:12,237  - mini_batch_size: \"10\"\n",
      "2022-08-30 16:23:12,238  - patience: \"3\"\n",
      "2022-08-30 16:23:12,239  - anneal_factor: \"0.5\"\n",
      "2022-08-30 16:23:12,239  - max_epochs: \"12\"\n",
      "2022-08-30 16:23:12,240  - shuffle: \"True\"\n",
      "2022-08-30 16:23:12,241  - train_with_dev: \"False\"\n",
      "2022-08-30 16:23:12,241  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 16:23:12,242 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:23:12,243 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 16:23:12,243 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:23:12,244 Device: cpu\n",
      "2022-08-30 16:23:12,244 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:23:12,245 Embeddings storage mode: cpu\n",
      "2022-08-30 16:23:12,245 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:23:16,399 epoch 1 - iter 33/333 - loss 1.24644596 - samples/sec: 79.52 - lr: 0.001000\n",
      "2022-08-30 16:23:20,626 epoch 1 - iter 66/333 - loss 1.23491963 - samples/sec: 79.42 - lr: 0.001000\n",
      "2022-08-30 16:23:24,185 epoch 1 - iter 99/333 - loss 1.23294073 - samples/sec: 94.34 - lr: 0.001000\n",
      "2022-08-30 16:23:28,078 epoch 1 - iter 132/333 - loss 1.23787095 - samples/sec: 86.46 - lr: 0.001000\n",
      "2022-08-30 16:23:32,700 epoch 1 - iter 165/333 - loss 1.23784126 - samples/sec: 72.42 - lr: 0.001000\n",
      "2022-08-30 16:23:36,304 epoch 1 - iter 198/333 - loss 1.23375342 - samples/sec: 93.04 - lr: 0.001000\n",
      "2022-08-30 16:23:40,424 epoch 1 - iter 231/333 - loss 1.23569488 - samples/sec: 81.30 - lr: 0.001000\n",
      "2022-08-30 16:23:44,122 epoch 1 - iter 264/333 - loss 1.23467759 - samples/sec: 90.96 - lr: 0.001000\n",
      "2022-08-30 16:23:48,228 epoch 1 - iter 297/333 - loss 1.23440392 - samples/sec: 81.54 - lr: 0.001000\n",
      "2022-08-30 16:23:52,568 epoch 1 - iter 330/333 - loss 1.25259339 - samples/sec: 77.05 - lr: 0.001000\n",
      "2022-08-30 16:23:53,039 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:23:53,040 EPOCH 1 done: loss 1.2534 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:23:54,008 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:23:54,042 DEV : loss 1.1229501962661743 - f1-score (micro avg)  0.6105\n",
      "2022-08-30 16:23:54,057 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:23:54,058 saving best model\n",
      "2022-08-30 16:23:55,072 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:23:58,941 epoch 2 - iter 33/333 - loss 1.22692324 - samples/sec: 85.36 - lr: 0.001000\n",
      "2022-08-30 16:24:02,988 epoch 2 - iter 66/333 - loss 1.23979909 - samples/sec: 82.67 - lr: 0.001000\n",
      "2022-08-30 16:24:06,711 epoch 2 - iter 99/333 - loss 1.24558624 - samples/sec: 90.11 - lr: 0.001000\n",
      "2022-08-30 16:24:10,632 epoch 2 - iter 132/333 - loss 1.24156206 - samples/sec: 85.43 - lr: 0.001000\n",
      "2022-08-30 16:24:14,914 epoch 2 - iter 165/333 - loss 1.23989234 - samples/sec: 78.12 - lr: 0.001000\n",
      "2022-08-30 16:24:19,194 epoch 2 - iter 198/333 - loss 1.24157872 - samples/sec: 78.27 - lr: 0.001000\n",
      "2022-08-30 16:24:23,215 epoch 2 - iter 231/333 - loss 1.24068948 - samples/sec: 83.31 - lr: 0.001000\n",
      "2022-08-30 16:24:26,985 epoch 2 - iter 264/333 - loss 1.24311134 - samples/sec: 88.83 - lr: 0.001000\n",
      "2022-08-30 16:24:31,019 epoch 2 - iter 297/333 - loss 1.24394419 - samples/sec: 83.10 - lr: 0.001000\n",
      "2022-08-30 16:24:34,852 epoch 2 - iter 330/333 - loss 1.24323830 - samples/sec: 87.46 - lr: 0.001000\n",
      "2022-08-30 16:24:35,191 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:24:35,191 EPOCH 2 done: loss 1.2431 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:24:36,218 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:24:36,245 DEV : loss 1.0988383293151855 - f1-score (micro avg)  0.6166\n",
      "2022-08-30 16:24:36,260 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:24:36,261 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:24:36,952 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:24:40,835 epoch 3 - iter 33/333 - loss 1.21967035 - samples/sec: 85.05 - lr: 0.001000\n",
      "2022-08-30 16:24:44,547 epoch 3 - iter 66/333 - loss 1.22300218 - samples/sec: 90.41 - lr: 0.001000\n",
      "2022-08-30 16:24:48,952 epoch 3 - iter 99/333 - loss 1.23030022 - samples/sec: 76.00 - lr: 0.001000\n",
      "2022-08-30 16:24:52,899 epoch 3 - iter 132/333 - loss 1.23423967 - samples/sec: 84.79 - lr: 0.001000\n",
      "2022-08-30 16:24:56,707 epoch 3 - iter 165/333 - loss 1.23835174 - samples/sec: 88.05 - lr: 0.001000\n",
      "2022-08-30 16:25:00,433 epoch 3 - iter 198/333 - loss 1.23566202 - samples/sec: 89.99 - lr: 0.001000\n",
      "2022-08-30 16:25:04,282 epoch 3 - iter 231/333 - loss 1.23218384 - samples/sec: 87.28 - lr: 0.001000\n",
      "2022-08-30 16:25:08,354 epoch 3 - iter 264/333 - loss 1.23339466 - samples/sec: 82.21 - lr: 0.001000\n",
      "2022-08-30 16:25:12,238 epoch 3 - iter 297/333 - loss 1.23292829 - samples/sec: 86.64 - lr: 0.001000\n",
      "2022-08-30 16:25:16,367 epoch 3 - iter 330/333 - loss 1.23352611 - samples/sec: 81.12 - lr: 0.001000\n",
      "2022-08-30 16:25:16,770 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:25:16,770 EPOCH 3 done: loss 1.2333 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:25:17,749 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:25:17,783 DEV : loss 1.086081862449646 - f1-score (micro avg)  0.6189\n",
      "2022-08-30 16:25:17,801 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:25:17,803 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:25:18,485 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:25:22,693 epoch 4 - iter 33/333 - loss 1.22322134 - samples/sec: 78.46 - lr: 0.001000\n",
      "2022-08-30 16:25:26,872 epoch 4 - iter 66/333 - loss 1.22031239 - samples/sec: 80.31 - lr: 0.001000\n",
      "2022-08-30 16:25:30,415 epoch 4 - iter 99/333 - loss 1.21812202 - samples/sec: 94.83 - lr: 0.001000\n",
      "2022-08-30 16:25:34,758 epoch 4 - iter 132/333 - loss 1.21440849 - samples/sec: 77.19 - lr: 0.001000\n",
      "2022-08-30 16:25:38,936 epoch 4 - iter 165/333 - loss 1.21383990 - samples/sec: 80.14 - lr: 0.001000\n",
      "2022-08-30 16:25:42,617 epoch 4 - iter 198/333 - loss 1.21688887 - samples/sec: 91.26 - lr: 0.001000\n",
      "2022-08-30 16:25:46,578 epoch 4 - iter 231/333 - loss 1.22034656 - samples/sec: 84.66 - lr: 0.001000\n",
      "2022-08-30 16:25:50,576 epoch 4 - iter 264/333 - loss 1.21881737 - samples/sec: 83.95 - lr: 0.001000\n",
      "2022-08-30 16:25:54,568 epoch 4 - iter 297/333 - loss 1.21725608 - samples/sec: 83.97 - lr: 0.001000\n",
      "2022-08-30 16:25:58,908 epoch 4 - iter 330/333 - loss 1.21556761 - samples/sec: 77.10 - lr: 0.001000\n",
      "2022-08-30 16:25:59,449 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:25:59,450 EPOCH 4 done: loss 1.2168 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:26:00,461 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:26:00,489 DEV : loss 1.0721181631088257 - f1-score (micro avg)  0.6241\n",
      "2022-08-30 16:26:00,508 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:26:00,509 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:26:01,204 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:26:05,119 epoch 5 - iter 33/333 - loss 1.19474973 - samples/sec: 84.36 - lr: 0.001000\n",
      "2022-08-30 16:26:09,108 epoch 5 - iter 66/333 - loss 1.21150340 - samples/sec: 83.97 - lr: 0.001000\n",
      "2022-08-30 16:26:13,406 epoch 5 - iter 99/333 - loss 1.21869561 - samples/sec: 77.85 - lr: 0.001000\n",
      "2022-08-30 16:26:17,135 epoch 5 - iter 132/333 - loss 1.21011266 - samples/sec: 90.21 - lr: 0.001000\n",
      "2022-08-30 16:26:21,061 epoch 5 - iter 165/333 - loss 1.20864509 - samples/sec: 85.43 - lr: 0.001000\n",
      "2022-08-30 16:26:24,946 epoch 5 - iter 198/333 - loss 1.21039141 - samples/sec: 86.25 - lr: 0.001000\n",
      "2022-08-30 16:26:28,450 epoch 5 - iter 231/333 - loss 1.20715004 - samples/sec: 95.74 - lr: 0.001000\n",
      "2022-08-30 16:26:33,190 epoch 5 - iter 264/333 - loss 1.20883662 - samples/sec: 70.65 - lr: 0.001000\n",
      "2022-08-30 16:26:36,812 epoch 5 - iter 297/333 - loss 1.20875741 - samples/sec: 92.77 - lr: 0.001000\n",
      "2022-08-30 16:26:40,845 epoch 5 - iter 330/333 - loss 1.20733080 - samples/sec: 82.98 - lr: 0.001000\n",
      "2022-08-30 16:26:41,303 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:26:41,303 EPOCH 5 done: loss 1.2070 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:26:42,321 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:26:42,360 DEV : loss 1.0581884384155273 - f1-score (micro avg)  0.6277\n",
      "2022-08-30 16:26:42,378 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:26:42,379 saving best model\n",
      "2022-08-30 16:26:43,312 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:26:47,442 epoch 6 - iter 33/333 - loss 1.20594256 - samples/sec: 80.00 - lr: 0.001000\n",
      "2022-08-30 16:26:51,183 epoch 6 - iter 66/333 - loss 1.18754143 - samples/sec: 89.63 - lr: 0.001000\n",
      "2022-08-30 16:26:54,928 epoch 6 - iter 99/333 - loss 1.18684226 - samples/sec: 89.50 - lr: 0.001000\n",
      "2022-08-30 16:26:58,698 epoch 6 - iter 132/333 - loss 1.19608566 - samples/sec: 88.97 - lr: 0.001000\n",
      "2022-08-30 16:27:02,404 epoch 6 - iter 165/333 - loss 1.19674868 - samples/sec: 90.44 - lr: 0.001000\n",
      "2022-08-30 16:27:06,593 epoch 6 - iter 198/333 - loss 1.19733212 - samples/sec: 79.92 - lr: 0.001000\n",
      "2022-08-30 16:27:10,547 epoch 6 - iter 231/333 - loss 1.19599050 - samples/sec: 84.68 - lr: 0.001000\n",
      "2022-08-30 16:27:14,412 epoch 6 - iter 264/333 - loss 1.19394018 - samples/sec: 86.86 - lr: 0.001000\n",
      "2022-08-30 16:27:18,644 epoch 6 - iter 297/333 - loss 1.19425205 - samples/sec: 79.14 - lr: 0.001000\n",
      "2022-08-30 16:27:22,711 epoch 6 - iter 330/333 - loss 1.19430945 - samples/sec: 82.27 - lr: 0.001000\n",
      "2022-08-30 16:27:23,096 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:27:23,097 EPOCH 6 done: loss 1.1938 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:27:24,070 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:27:24,097 DEV : loss 1.045936942100525 - f1-score (micro avg)  0.6319\n",
      "2022-08-30 16:27:24,116 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:27:24,117 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:27:25,136 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:27:28,826 epoch 7 - iter 33/333 - loss 1.20034680 - samples/sec: 89.46 - lr: 0.001000\n",
      "2022-08-30 16:27:32,953 epoch 7 - iter 66/333 - loss 1.20165061 - samples/sec: 81.08 - lr: 0.001000\n",
      "2022-08-30 16:27:36,799 epoch 7 - iter 99/333 - loss 1.19326545 - samples/sec: 87.16 - lr: 0.001000\n",
      "2022-08-30 16:27:40,571 epoch 7 - iter 132/333 - loss 1.18704196 - samples/sec: 88.85 - lr: 0.001000\n",
      "2022-08-30 16:27:44,685 epoch 7 - iter 165/333 - loss 1.18865220 - samples/sec: 81.52 - lr: 0.001000\n",
      "2022-08-30 16:27:48,542 epoch 7 - iter 198/333 - loss 1.19180372 - samples/sec: 86.91 - lr: 0.001000\n",
      "2022-08-30 16:27:52,256 epoch 7 - iter 231/333 - loss 1.18615809 - samples/sec: 90.61 - lr: 0.001000\n",
      "2022-08-30 16:27:56,799 epoch 7 - iter 264/333 - loss 1.18583035 - samples/sec: 73.64 - lr: 0.001000\n",
      "2022-08-30 16:28:00,625 epoch 7 - iter 297/333 - loss 1.18774973 - samples/sec: 87.60 - lr: 0.001000\n",
      "2022-08-30 16:28:04,919 epoch 7 - iter 330/333 - loss 1.18380720 - samples/sec: 78.05 - lr: 0.001000\n",
      "2022-08-30 16:28:05,341 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:28:05,342 EPOCH 7 done: loss 1.1846 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 30.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:28:06,287 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:28:06,322 DEV : loss 1.0339149236679077 - f1-score (micro avg)  0.6335\n",
      "2022-08-30 16:28:06,341 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:28:06,342 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:28:07,316 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:28:11,414 epoch 8 - iter 33/333 - loss 1.16342396 - samples/sec: 80.59 - lr: 0.001000\n",
      "2022-08-30 16:28:15,420 epoch 8 - iter 66/333 - loss 1.16668882 - samples/sec: 83.67 - lr: 0.001000\n",
      "2022-08-30 16:28:19,637 epoch 8 - iter 99/333 - loss 1.17022269 - samples/sec: 79.56 - lr: 0.001000\n",
      "2022-08-30 16:28:23,355 epoch 8 - iter 132/333 - loss 1.16979695 - samples/sec: 90.11 - lr: 0.001000\n",
      "2022-08-30 16:28:27,061 epoch 8 - iter 165/333 - loss 1.17013956 - samples/sec: 90.81 - lr: 0.001000\n",
      "2022-08-30 16:28:31,112 epoch 8 - iter 198/333 - loss 1.16856972 - samples/sec: 82.64 - lr: 0.001000\n",
      "2022-08-30 16:28:34,853 epoch 8 - iter 231/333 - loss 1.16907544 - samples/sec: 89.65 - lr: 0.001000\n",
      "2022-08-30 16:28:38,837 epoch 8 - iter 264/333 - loss 1.17032223 - samples/sec: 84.03 - lr: 0.001000\n",
      "2022-08-30 16:28:42,644 epoch 8 - iter 297/333 - loss 1.16899297 - samples/sec: 88.07 - lr: 0.001000\n",
      "2022-08-30 16:28:46,532 epoch 8 - iter 330/333 - loss 1.17247355 - samples/sec: 86.21 - lr: 0.001000\n",
      "2022-08-30 16:28:46,875 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:28:46,875 EPOCH 8 done: loss 1.1722 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:28:49,104 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:28:49,134 DEV : loss 1.0207066535949707 - f1-score (micro avg)  0.6402\n",
      "2022-08-30 16:28:49,149 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:28:49,150 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:28:49,961 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:28:53,378 epoch 9 - iter 33/333 - loss 1.14456872 - samples/sec: 96.69 - lr: 0.001000\n",
      "2022-08-30 16:28:57,044 epoch 9 - iter 66/333 - loss 1.14291375 - samples/sec: 91.69 - lr: 0.001000\n",
      "2022-08-30 16:29:01,272 epoch 9 - iter 99/333 - loss 1.15046976 - samples/sec: 79.54 - lr: 0.001000\n",
      "2022-08-30 16:29:05,325 epoch 9 - iter 132/333 - loss 1.15518450 - samples/sec: 82.73 - lr: 0.001000\n",
      "2022-08-30 16:29:09,354 epoch 9 - iter 165/333 - loss 1.15776051 - samples/sec: 83.54 - lr: 0.001000\n",
      "2022-08-30 16:29:13,731 epoch 9 - iter 198/333 - loss 1.15559788 - samples/sec: 76.69 - lr: 0.001000\n",
      "2022-08-30 16:29:17,958 epoch 9 - iter 231/333 - loss 1.15676511 - samples/sec: 79.08 - lr: 0.001000\n",
      "2022-08-30 16:29:22,152 epoch 9 - iter 264/333 - loss 1.15639785 - samples/sec: 79.73 - lr: 0.001000\n",
      "2022-08-30 16:29:25,933 epoch 9 - iter 297/333 - loss 1.15953113 - samples/sec: 88.59 - lr: 0.001000\n",
      "2022-08-30 16:29:29,796 epoch 9 - iter 330/333 - loss 1.15955246 - samples/sec: 86.89 - lr: 0.001000\n",
      "2022-08-30 16:29:30,237 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:29:30,238 EPOCH 9 done: loss 1.1592 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:29:31,221 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:29:31,249 DEV : loss 1.0101144313812256 - f1-score (micro avg)  0.6434\n",
      "2022-08-30 16:29:31,268 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:29:31,269 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:29:31,960 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:29:35,691 epoch 10 - iter 33/333 - loss 1.15623703 - samples/sec: 88.52 - lr: 0.001000\n",
      "2022-08-30 16:29:39,656 epoch 10 - iter 66/333 - loss 1.15732703 - samples/sec: 84.46 - lr: 0.001000\n",
      "2022-08-30 16:29:43,615 epoch 10 - iter 99/333 - loss 1.15739350 - samples/sec: 84.70 - lr: 0.001000\n",
      "2022-08-30 16:29:47,374 epoch 10 - iter 132/333 - loss 1.15464441 - samples/sec: 89.29 - lr: 0.001000\n",
      "2022-08-30 16:29:51,052 epoch 10 - iter 165/333 - loss 1.15714284 - samples/sec: 91.49 - lr: 0.001000\n",
      "2022-08-30 16:29:55,096 epoch 10 - iter 198/333 - loss 1.15234837 - samples/sec: 83.02 - lr: 0.001000\n",
      "2022-08-30 16:29:58,925 epoch 10 - iter 231/333 - loss 1.15293918 - samples/sec: 87.56 - lr: 0.001000\n",
      "2022-08-30 16:30:02,967 epoch 10 - iter 264/333 - loss 1.15019418 - samples/sec: 82.94 - lr: 0.001000\n",
      "2022-08-30 16:30:07,454 epoch 10 - iter 297/333 - loss 1.15100491 - samples/sec: 74.54 - lr: 0.001000\n",
      "2022-08-30 16:30:11,588 epoch 10 - iter 330/333 - loss 1.15160614 - samples/sec: 81.06 - lr: 0.001000\n",
      "2022-08-30 16:30:11,971 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:30:11,972 EPOCH 10 done: loss 1.1518 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:30:12,950 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:30:12,979 DEV : loss 0.9995443224906921 - f1-score (micro avg)  0.6465\n",
      "2022-08-30 16:30:12,995 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:30:12,996 saving best model\n",
      "2022-08-30 16:30:13,709 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:30:17,450 epoch 11 - iter 33/333 - loss 1.15499305 - samples/sec: 88.24 - lr: 0.001000\n",
      "2022-08-30 16:30:21,489 epoch 11 - iter 66/333 - loss 1.16568725 - samples/sec: 83.21 - lr: 0.001000\n",
      "2022-08-30 16:30:25,182 epoch 11 - iter 99/333 - loss 1.16397634 - samples/sec: 90.81 - lr: 0.001000\n",
      "2022-08-30 16:30:29,249 epoch 11 - iter 132/333 - loss 1.15927428 - samples/sec: 82.31 - lr: 0.001000\n",
      "2022-08-30 16:30:32,989 epoch 11 - iter 165/333 - loss 1.15273218 - samples/sec: 89.63 - lr: 0.001000\n",
      "2022-08-30 16:30:36,862 epoch 11 - iter 198/333 - loss 1.15165825 - samples/sec: 86.66 - lr: 0.001000\n",
      "2022-08-30 16:30:40,613 epoch 11 - iter 231/333 - loss 1.15082625 - samples/sec: 89.36 - lr: 0.001000\n",
      "2022-08-30 16:30:44,459 epoch 11 - iter 264/333 - loss 1.14933990 - samples/sec: 87.09 - lr: 0.001000\n",
      "2022-08-30 16:30:48,702 epoch 11 - iter 297/333 - loss 1.14639557 - samples/sec: 78.97 - lr: 0.001000\n",
      "2022-08-30 16:30:52,672 epoch 11 - iter 330/333 - loss 1.14278393 - samples/sec: 84.55 - lr: 0.001000\n",
      "2022-08-30 16:30:53,271 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:30:53,271 EPOCH 11 done: loss 1.1432 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:30:54,269 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:30:54,299 DEV : loss 0.9897686243057251 - f1-score (micro avg)  0.647\n",
      "2022-08-30 16:30:54,314 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:30:54,315 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:30:54,999 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:30:59,162 epoch 12 - iter 33/333 - loss 1.14343974 - samples/sec: 79.31 - lr: 0.001000\n",
      "2022-08-30 16:31:03,373 epoch 12 - iter 66/333 - loss 1.12780222 - samples/sec: 79.50 - lr: 0.001000\n",
      "2022-08-30 16:31:06,778 epoch 12 - iter 99/333 - loss 1.13302368 - samples/sec: 98.92 - lr: 0.001000\n",
      "2022-08-30 16:31:10,873 epoch 12 - iter 132/333 - loss 1.13560554 - samples/sec: 81.87 - lr: 0.001000\n",
      "2022-08-30 16:31:14,674 epoch 12 - iter 165/333 - loss 1.13788545 - samples/sec: 88.16 - lr: 0.001000\n",
      "2022-08-30 16:31:19,183 epoch 12 - iter 198/333 - loss 1.14133219 - samples/sec: 74.26 - lr: 0.001000\n",
      "2022-08-30 16:31:23,267 epoch 12 - iter 231/333 - loss 1.14301182 - samples/sec: 82.01 - lr: 0.001000\n",
      "2022-08-30 16:31:27,131 epoch 12 - iter 264/333 - loss 1.14139987 - samples/sec: 86.77 - lr: 0.001000\n",
      "2022-08-30 16:31:30,904 epoch 12 - iter 297/333 - loss 1.13971838 - samples/sec: 88.81 - lr: 0.001000\n",
      "2022-08-30 16:31:35,031 epoch 12 - iter 330/333 - loss 1.13466109 - samples/sec: 81.16 - lr: 0.001000\n",
      "2022-08-30 16:31:35,431 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:31:35,432 EPOCH 12 done: loss 1.1347 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:31:36,391 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:31:36,419 DEV : loss 0.9802985191345215 - f1-score (micro avg)  0.6514\n",
      "2022-08-30 16:31:36,435 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:31:36,436 saving best model\n",
      "2022-08-30 16:31:37,814 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:31:37,815 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 16:31:37,995 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:31:39,524 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:31:39,548 0.6645\t0.6645\t0.6645\t0.6645\n",
      "2022-08-30 16:31:39,548 \n",
      "Results:\n",
      "- F-score (micro) 0.6645\n",
      "- F-score (macro) 0.479\n",
      "- Accuracy 0.6645\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.5729    0.7199    0.6381      1353\n",
      "         ADJ     0.4464    0.6443    0.5274       672\n",
      "       PUNCT     0.9628    0.9803    0.9715       660\n",
      "         ADP     0.8367    0.8969    0.8657       514\n",
      "        VERB     0.5260    0.3831    0.4433       449\n",
      "         AUX     0.8313    0.7940    0.8122       335\n",
      "       PROPN     0.6746    0.2219    0.3340       383\n",
      "       CCONJ     0.9583    0.9583    0.9583       192\n",
      "       SCONJ     0.8686    0.8261    0.8468       184\n",
      "         DET     0.3814    0.2298    0.2868       161\n",
      "        PRON     0.8941    0.6609    0.7600       115\n",
      "         ADV     0.1905    0.0530    0.0829       151\n",
      "         NUM     0.5000    0.0282    0.0533        71\n",
      "        PART     0.3333    0.0476    0.0833        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6645      5264\n",
      "   macro avg     0.5611    0.4653    0.4790      5264\n",
      "weighted avg     0.6636    0.6645    0.6448      5264\n",
      "\n",
      "2022-08-30 16:31:39,549 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:31:39,551 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:31:40,023 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 2 #######################\n",
      "#######################################################\n",
      "2022-08-30 16:33:55,626 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:33:55,627 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 16:33:55,628 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:33:55,628 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 16:33:55,629 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:33:55,629 Parameters:\n",
      "2022-08-30 16:33:55,630  - learning_rate: \"0.001000\"\n",
      "2022-08-30 16:33:55,630  - mini_batch_size: \"30\"\n",
      "2022-08-30 16:33:55,631  - patience: \"3\"\n",
      "2022-08-30 16:33:55,631  - anneal_factor: \"0.5\"\n",
      "2022-08-30 16:33:55,632  - max_epochs: \"10\"\n",
      "2022-08-30 16:33:55,632  - shuffle: \"True\"\n",
      "2022-08-30 16:33:55,633  - train_with_dev: \"False\"\n",
      "2022-08-30 16:33:55,634  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 16:33:55,634 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:33:55,635 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 16:33:55,635 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:33:55,635 Device: cpu\n",
      "2022-08-30 16:33:55,636 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:33:55,637 Embeddings storage mode: cpu\n",
      "2022-08-30 16:33:55,637 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:33:59,625 epoch 1 - iter 11/111 - loss 1.09760480 - samples/sec: 82.77 - lr: 0.001000\n",
      "2022-08-30 16:34:03,755 epoch 1 - iter 22/111 - loss 1.09721924 - samples/sec: 81.16 - lr: 0.001000\n",
      "2022-08-30 16:34:07,302 epoch 1 - iter 33/111 - loss 1.09704441 - samples/sec: 94.75 - lr: 0.001000\n",
      "2022-08-30 16:34:11,105 epoch 1 - iter 44/111 - loss 1.10478595 - samples/sec: 88.16 - lr: 0.001000\n",
      "2022-08-30 16:34:15,351 epoch 1 - iter 55/111 - loss 1.10833096 - samples/sec: 78.80 - lr: 0.001000\n",
      "2022-08-30 16:34:19,042 epoch 1 - iter 66/111 - loss 1.09973690 - samples/sec: 90.93 - lr: 0.001000\n",
      "2022-08-30 16:34:23,170 epoch 1 - iter 77/111 - loss 1.10152461 - samples/sec: 81.12 - lr: 0.001000\n",
      "2022-08-30 16:34:26,877 epoch 1 - iter 88/111 - loss 1.10132405 - samples/sec: 90.56 - lr: 0.001000\n",
      "2022-08-30 16:34:30,855 epoch 1 - iter 99/111 - loss 1.10228937 - samples/sec: 84.21 - lr: 0.001000\n",
      "2022-08-30 16:34:35,233 epoch 1 - iter 110/111 - loss 1.12319760 - samples/sec: 76.41 - lr: 0.001000\n",
      "2022-08-30 16:34:35,734 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:34:35,734 EPOCH 1 done: loss 1.1242 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:34:36,598 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:34:36,633 DEV : loss 0.9805112481117249 - f1-score (micro avg)  0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:34:36,652 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:34:36,654 saving best model\n",
      "2022-08-30 16:34:37,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:34:41,752 epoch 2 - iter 11/111 - loss 1.09884272 - samples/sec: 74.85 - lr: 0.001000\n",
      "2022-08-30 16:34:45,577 epoch 2 - iter 22/111 - loss 1.11742115 - samples/sec: 87.67 - lr: 0.001000\n",
      "2022-08-30 16:34:49,560 epoch 2 - iter 33/111 - loss 1.12131508 - samples/sec: 84.10 - lr: 0.001000\n",
      "2022-08-30 16:34:53,264 epoch 2 - iter 44/111 - loss 1.12535987 - samples/sec: 90.53 - lr: 0.001000\n",
      "2022-08-30 16:34:57,295 epoch 2 - iter 55/111 - loss 1.12379759 - samples/sec: 83.10 - lr: 0.001000\n",
      "2022-08-30 16:35:01,426 epoch 2 - iter 66/111 - loss 1.12853342 - samples/sec: 81.02 - lr: 0.001000\n",
      "2022-08-30 16:35:05,443 epoch 2 - iter 77/111 - loss 1.12769147 - samples/sec: 83.63 - lr: 0.001000\n",
      "2022-08-30 16:35:09,322 epoch 2 - iter 88/111 - loss 1.12656763 - samples/sec: 86.50 - lr: 0.001000\n",
      "2022-08-30 16:35:13,292 epoch 2 - iter 99/111 - loss 1.12734377 - samples/sec: 84.46 - lr: 0.001000\n",
      "2022-08-30 16:35:17,386 epoch 2 - iter 110/111 - loss 1.12651613 - samples/sec: 81.80 - lr: 0.001000\n",
      "2022-08-30 16:35:17,830 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:35:17,831 EPOCH 2 done: loss 1.1258 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:35:18,696 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:35:18,730 DEV : loss 0.9691406488418579 - f1-score (micro avg)  0.6548\n",
      "2022-08-30 16:35:18,746 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 16:35:18,747 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:35:22,801 epoch 3 - iter 11/111 - loss 1.10711434 - samples/sec: 81.40 - lr: 0.001000\n",
      "2022-08-30 16:35:27,008 epoch 3 - iter 22/111 - loss 1.12014769 - samples/sec: 79.59 - lr: 0.001000\n",
      "2022-08-30 16:35:31,274 epoch 3 - iter 33/111 - loss 1.11373257 - samples/sec: 78.57 - lr: 0.001000\n",
      "2022-08-30 16:35:35,399 epoch 3 - iter 44/111 - loss 1.11349055 - samples/sec: 81.08 - lr: 0.001000\n",
      "2022-08-30 16:35:39,722 epoch 3 - iter 55/111 - loss 1.11174607 - samples/sec: 77.56 - lr: 0.001000\n",
      "2022-08-30 16:35:43,516 epoch 3 - iter 66/111 - loss 1.11297077 - samples/sec: 88.71 - lr: 0.001000\n",
      "2022-08-30 16:35:47,647 epoch 3 - iter 77/111 - loss 1.11685415 - samples/sec: 81.26 - lr: 0.001000\n",
      "2022-08-30 16:35:51,325 epoch 3 - iter 88/111 - loss 1.11624389 - samples/sec: 91.29 - lr: 0.001000\n",
      "2022-08-30 16:35:55,113 epoch 3 - iter 99/111 - loss 1.11829022 - samples/sec: 88.59 - lr: 0.001000\n",
      "2022-08-30 16:35:59,293 epoch 3 - iter 110/111 - loss 1.11676750 - samples/sec: 80.04 - lr: 0.001000\n",
      "2022-08-30 16:35:59,722 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:35:59,723 EPOCH 3 done: loss 1.1165 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:36:00,587 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:36:00,617 DEV : loss 0.9645628333091736 - f1-score (micro avg)  0.6555\n",
      "2022-08-30 16:36:00,633 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:36:00,634 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:36:04,692 epoch 4 - iter 11/111 - loss 1.11496560 - samples/sec: 81.34 - lr: 0.001000\n",
      "2022-08-30 16:36:08,484 epoch 4 - iter 22/111 - loss 1.11809965 - samples/sec: 88.40 - lr: 0.001000\n",
      "2022-08-30 16:36:12,099 epoch 4 - iter 33/111 - loss 1.12030275 - samples/sec: 92.83 - lr: 0.001000\n",
      "2022-08-30 16:36:16,034 epoch 4 - iter 44/111 - loss 1.12064195 - samples/sec: 85.18 - lr: 0.001000\n",
      "2022-08-30 16:36:20,260 epoch 4 - iter 55/111 - loss 1.11711004 - samples/sec: 79.16 - lr: 0.001000\n",
      "2022-08-30 16:36:24,339 epoch 4 - iter 66/111 - loss 1.11418625 - samples/sec: 82.09 - lr: 0.001000\n",
      "2022-08-30 16:36:28,330 epoch 4 - iter 77/111 - loss 1.11250378 - samples/sec: 84.21 - lr: 0.001000\n",
      "2022-08-30 16:36:32,302 epoch 4 - iter 88/111 - loss 1.11102128 - samples/sec: 84.57 - lr: 0.001000\n",
      "2022-08-30 16:36:36,596 epoch 4 - iter 99/111 - loss 1.11106981 - samples/sec: 77.94 - lr: 0.001000\n",
      "2022-08-30 16:36:40,605 epoch 4 - iter 110/111 - loss 1.11335879 - samples/sec: 83.54 - lr: 0.001000\n",
      "2022-08-30 16:36:41,007 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:36:41,008 EPOCH 4 done: loss 1.1143 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:36:41,891 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:36:41,922 DEV : loss 0.9595779776573181 - f1-score (micro avg)  0.66\n",
      "2022-08-30 16:36:41,938 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:36:41,939 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:36:42,653 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:36:46,855 epoch 5 - iter 11/111 - loss 1.09375156 - samples/sec: 78.55 - lr: 0.001000\n",
      "2022-08-30 16:36:50,899 epoch 5 - iter 22/111 - loss 1.09731549 - samples/sec: 82.73 - lr: 0.001000\n",
      "2022-08-30 16:36:54,721 epoch 5 - iter 33/111 - loss 1.10186152 - samples/sec: 87.70 - lr: 0.001000\n",
      "2022-08-30 16:36:58,845 epoch 5 - iter 44/111 - loss 1.10413176 - samples/sec: 81.16 - lr: 0.001000\n",
      "2022-08-30 16:37:02,559 epoch 5 - iter 55/111 - loss 1.10657941 - samples/sec: 90.36 - lr: 0.001000\n",
      "2022-08-30 16:37:06,423 epoch 5 - iter 66/111 - loss 1.10548813 - samples/sec: 86.86 - lr: 0.001000\n",
      "2022-08-30 16:37:10,318 epoch 5 - iter 77/111 - loss 1.10823066 - samples/sec: 86.21 - lr: 0.001000\n",
      "2022-08-30 16:37:14,719 epoch 5 - iter 88/111 - loss 1.11180815 - samples/sec: 76.09 - lr: 0.001000\n",
      "2022-08-30 16:37:18,877 epoch 5 - iter 99/111 - loss 1.11009904 - samples/sec: 80.66 - lr: 0.001000\n",
      "2022-08-30 16:37:22,861 epoch 5 - iter 110/111 - loss 1.10915062 - samples/sec: 84.18 - lr: 0.001000\n",
      "2022-08-30 16:37:23,192 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:37:23,193 EPOCH 5 done: loss 1.1090 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:37:24,085 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:37:24,114 DEV : loss 0.9545292258262634 - f1-score (micro avg)  0.6633\n",
      "2022-08-30 16:37:24,129 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:37:24,130 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:37:24,849 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:37:28,583 epoch 6 - iter 11/111 - loss 1.13149604 - samples/sec: 88.40 - lr: 0.001000\n",
      "2022-08-30 16:37:32,586 epoch 6 - iter 22/111 - loss 1.14177655 - samples/sec: 83.86 - lr: 0.001000\n",
      "2022-08-30 16:37:36,729 epoch 6 - iter 33/111 - loss 1.12244741 - samples/sec: 80.94 - lr: 0.001000\n",
      "2022-08-30 16:37:40,821 epoch 6 - iter 44/111 - loss 1.11800771 - samples/sec: 81.89 - lr: 0.001000\n",
      "2022-08-30 16:37:44,762 epoch 6 - iter 55/111 - loss 1.10997892 - samples/sec: 84.99 - lr: 0.001000\n",
      "2022-08-30 16:37:49,044 epoch 6 - iter 66/111 - loss 1.10899428 - samples/sec: 78.09 - lr: 0.001000\n",
      "2022-08-30 16:37:52,708 epoch 6 - iter 77/111 - loss 1.10761046 - samples/sec: 91.54 - lr: 0.001000\n",
      "2022-08-30 16:37:56,845 epoch 6 - iter 88/111 - loss 1.11001167 - samples/sec: 80.94 - lr: 0.001000\n",
      "2022-08-30 16:38:01,235 epoch 6 - iter 99/111 - loss 1.10839475 - samples/sec: 76.12 - lr: 0.001000\n",
      "2022-08-30 16:38:05,035 epoch 6 - iter 110/111 - loss 1.10734904 - samples/sec: 88.24 - lr: 0.001000\n",
      "2022-08-30 16:38:05,575 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:38:05,576 EPOCH 6 done: loss 1.1066 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:38:06,482 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:38:06,513 DEV : loss 0.9495036602020264 - f1-score (micro avg)  0.6642\n",
      "2022-08-30 16:38:06,530 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:38:06,531 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:38:07,208 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:38:11,282 epoch 7 - iter 11/111 - loss 1.13141113 - samples/sec: 81.04 - lr: 0.001000\n",
      "2022-08-30 16:38:15,479 epoch 7 - iter 22/111 - loss 1.11744963 - samples/sec: 79.77 - lr: 0.001000\n",
      "2022-08-30 16:38:19,648 epoch 7 - iter 33/111 - loss 1.11135784 - samples/sec: 80.39 - lr: 0.001000\n",
      "2022-08-30 16:38:23,655 epoch 7 - iter 44/111 - loss 1.10018131 - samples/sec: 83.59 - lr: 0.001000\n",
      "2022-08-30 16:38:27,503 epoch 7 - iter 55/111 - loss 1.09827132 - samples/sec: 87.16 - lr: 0.001000\n",
      "2022-08-30 16:38:30,955 epoch 7 - iter 66/111 - loss 1.09823098 - samples/sec: 97.52 - lr: 0.001000\n",
      "2022-08-30 16:38:35,091 epoch 7 - iter 77/111 - loss 1.10323953 - samples/sec: 80.86 - lr: 0.001000\n",
      "2022-08-30 16:38:38,895 epoch 7 - iter 88/111 - loss 1.10209613 - samples/sec: 88.12 - lr: 0.001000\n",
      "2022-08-30 16:38:42,734 epoch 7 - iter 99/111 - loss 1.10330163 - samples/sec: 87.46 - lr: 0.001000\n",
      "2022-08-30 16:38:46,941 epoch 7 - iter 110/111 - loss 1.10362912 - samples/sec: 79.54 - lr: 0.001000\n",
      "2022-08-30 16:38:47,324 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:38:47,324 EPOCH 7 done: loss 1.1031 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:38:48,241 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:38:48,274 DEV : loss 0.9447879195213318 - f1-score (micro avg)  0.6657\n",
      "2022-08-30 16:38:48,293 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:38:48,294 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:38:49,053 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:38:52,642 epoch 8 - iter 11/111 - loss 1.09022196 - samples/sec: 92.00 - lr: 0.001000\n",
      "2022-08-30 16:38:56,742 epoch 8 - iter 22/111 - loss 1.09970685 - samples/sec: 82.25 - lr: 0.001000\n",
      "2022-08-30 16:39:00,837 epoch 8 - iter 33/111 - loss 1.10172934 - samples/sec: 81.91 - lr: 0.001000\n",
      "2022-08-30 16:39:04,573 epoch 8 - iter 44/111 - loss 1.09671708 - samples/sec: 89.77 - lr: 0.001000\n",
      "2022-08-30 16:39:08,388 epoch 8 - iter 55/111 - loss 1.09267625 - samples/sec: 87.93 - lr: 0.001000\n",
      "2022-08-30 16:39:12,248 epoch 8 - iter 66/111 - loss 1.09545045 - samples/sec: 87.03 - lr: 0.001000\n",
      "2022-08-30 16:39:16,469 epoch 8 - iter 77/111 - loss 1.09458468 - samples/sec: 79.35 - lr: 0.001000\n",
      "2022-08-30 16:39:20,495 epoch 8 - iter 88/111 - loss 1.09263878 - samples/sec: 83.33 - lr: 0.001000\n",
      "2022-08-30 16:39:24,945 epoch 8 - iter 99/111 - loss 1.09567433 - samples/sec: 75.26 - lr: 0.001000\n",
      "2022-08-30 16:39:29,083 epoch 8 - iter 110/111 - loss 1.09673196 - samples/sec: 80.86 - lr: 0.001000\n",
      "2022-08-30 16:39:29,651 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:39:29,652 EPOCH 8 done: loss 1.0967 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:39:30,564 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:39:30,594 DEV : loss 0.9398800134658813 - f1-score (micro avg)  0.6704\n",
      "2022-08-30 16:39:30,612 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:39:30,613 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:39:31,808 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:39:35,814 epoch 9 - iter 11/111 - loss 1.05145015 - samples/sec: 82.42 - lr: 0.001000\n",
      "2022-08-30 16:39:40,013 epoch 9 - iter 22/111 - loss 1.06690861 - samples/sec: 79.96 - lr: 0.001000\n",
      "2022-08-30 16:39:44,055 epoch 9 - iter 33/111 - loss 1.07361380 - samples/sec: 82.91 - lr: 0.001000\n",
      "2022-08-30 16:39:48,675 epoch 9 - iter 44/111 - loss 1.07505018 - samples/sec: 72.38 - lr: 0.001000\n",
      "2022-08-30 16:39:52,454 epoch 9 - iter 55/111 - loss 1.08001937 - samples/sec: 88.92 - lr: 0.001000\n",
      "2022-08-30 16:39:56,308 epoch 9 - iter 66/111 - loss 1.07777236 - samples/sec: 86.89 - lr: 0.001000\n",
      "2022-08-30 16:40:00,606 epoch 9 - iter 77/111 - loss 1.07782924 - samples/sec: 78.00 - lr: 0.001000\n",
      "2022-08-30 16:40:04,133 epoch 9 - iter 88/111 - loss 1.08188373 - samples/sec: 95.10 - lr: 0.001000\n",
      "2022-08-30 16:40:08,218 epoch 9 - iter 99/111 - loss 1.08507451 - samples/sec: 81.97 - lr: 0.001000\n",
      "2022-08-30 16:40:12,338 epoch 9 - iter 110/111 - loss 1.08820124 - samples/sec: 81.28 - lr: 0.001000\n",
      "2022-08-30 16:40:12,771 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:40:12,772 EPOCH 9 done: loss 1.0878 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:40:13,658 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:40:13,691 DEV : loss 0.9338059425354004 - f1-score (micro avg)  0.6724\n",
      "2022-08-30 16:40:13,714 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:40:13,715 saving best model\n",
      "2022-08-30 16:40:14,885 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:40:18,727 epoch 10 - iter 11/111 - loss 1.09607903 - samples/sec: 85.92 - lr: 0.001000\n",
      "2022-08-30 16:40:22,773 epoch 10 - iter 22/111 - loss 1.10039404 - samples/sec: 82.71 - lr: 0.001000\n",
      "2022-08-30 16:40:27,055 epoch 10 - iter 33/111 - loss 1.09443061 - samples/sec: 78.22 - lr: 0.001000\n",
      "2022-08-30 16:40:30,906 epoch 10 - iter 44/111 - loss 1.08897019 - samples/sec: 87.07 - lr: 0.001000\n",
      "2022-08-30 16:40:34,983 epoch 10 - iter 55/111 - loss 1.08494122 - samples/sec: 82.05 - lr: 0.001000\n",
      "2022-08-30 16:40:38,983 epoch 10 - iter 66/111 - loss 1.08709293 - samples/sec: 83.76 - lr: 0.001000\n",
      "2022-08-30 16:40:42,944 epoch 10 - iter 77/111 - loss 1.08602035 - samples/sec: 84.70 - lr: 0.001000\n",
      "2022-08-30 16:40:47,116 epoch 10 - iter 88/111 - loss 1.08458705 - samples/sec: 80.31 - lr: 0.001000\n",
      "2022-08-30 16:40:51,263 epoch 10 - iter 99/111 - loss 1.08849030 - samples/sec: 80.74 - lr: 0.001000\n",
      "2022-08-30 16:40:55,305 epoch 10 - iter 110/111 - loss 1.09050189 - samples/sec: 82.83 - lr: 0.001000\n",
      "2022-08-30 16:40:55,697 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:40:55,698 EPOCH 10 done: loss 1.0903 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:40:56,596 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:40:56,632 DEV : loss 0.9319262504577637 - f1-score (micro avg)  0.6712\n",
      "2022-08-30 16:40:56,647 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:40:57,699 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:40:57,700 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 16:40:57,872 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:40:59,304 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:40:59,328 0.6814\t0.6814\t0.6814\t0.6814\n",
      "2022-08-30 16:40:59,328 \n",
      "Results:\n",
      "- F-score (micro) 0.6814\n",
      "- F-score (macro) 0.4981\n",
      "- Accuracy 0.6814\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.5951    0.7214    0.6522      1353\n",
      "         ADJ     0.4614    0.6577    0.5423       672\n",
      "       PUNCT     0.9659    0.9879    0.9768       660\n",
      "         ADP     0.8633    0.8969    0.8798       514\n",
      "        VERB     0.5408    0.4432    0.4871       449\n",
      "         AUX     0.8442    0.8090    0.8262       335\n",
      "       PROPN     0.7025    0.2898    0.4104       383\n",
      "       CCONJ     0.9534    0.9583    0.9558       192\n",
      "       SCONJ     0.8743    0.8315    0.8524       184\n",
      "         DET     0.4747    0.2919    0.3615       161\n",
      "        PRON     0.8764    0.6783    0.7647       115\n",
      "         ADV     0.1915    0.0596    0.0909       151\n",
      "         NUM     0.5000    0.0423    0.0779        71\n",
      "        PART     1.0000    0.0476    0.0909        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6814      5264\n",
      "   macro avg     0.6152    0.4822    0.4981      5264\n",
      "weighted avg     0.6835    0.6814    0.6657      5264\n",
      "\n",
      "2022-08-30 16:40:59,329 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:40:59,331 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 16:40:59,816 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 3 #######################\n",
      "#######################################################\n",
      "2022-08-30 16:43:16,193 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:43:16,193 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 16:43:16,194 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:43:16,195 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 16:43:16,196 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:43:16,196 Parameters:\n",
      "2022-08-30 16:43:16,196  - learning_rate: \"0.001000\"\n",
      "2022-08-30 16:43:16,197  - mini_batch_size: \"30\"\n",
      "2022-08-30 16:43:16,198  - patience: \"3\"\n",
      "2022-08-30 16:43:16,198  - anneal_factor: \"0.5\"\n",
      "2022-08-30 16:43:16,199  - max_epochs: \"11\"\n",
      "2022-08-30 16:43:16,200  - shuffle: \"True\"\n",
      "2022-08-30 16:43:16,200  - train_with_dev: \"False\"\n",
      "2022-08-30 16:43:16,201  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 16:43:16,201 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:43:16,202 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 16:43:16,203 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:43:16,204 Device: cpu\n",
      "2022-08-30 16:43:16,204 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:43:16,205 Embeddings storage mode: cpu\n",
      "2022-08-30 16:43:16,205 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:43:20,208 epoch 1 - iter 11/111 - loss 1.06855944 - samples/sec: 82.48 - lr: 0.001000\n",
      "2022-08-30 16:43:24,403 epoch 1 - iter 22/111 - loss 1.06075137 - samples/sec: 79.83 - lr: 0.001000\n",
      "2022-08-30 16:43:28,002 epoch 1 - iter 33/111 - loss 1.05745476 - samples/sec: 93.43 - lr: 0.001000\n",
      "2022-08-30 16:43:31,801 epoch 1 - iter 44/111 - loss 1.06029456 - samples/sec: 88.31 - lr: 0.001000\n",
      "2022-08-30 16:43:36,018 epoch 1 - iter 55/111 - loss 1.06520198 - samples/sec: 79.42 - lr: 0.001000\n",
      "2022-08-30 16:43:39,722 epoch 1 - iter 66/111 - loss 1.06133475 - samples/sec: 90.61 - lr: 0.001000\n",
      "2022-08-30 16:43:43,826 epoch 1 - iter 77/111 - loss 1.06284354 - samples/sec: 81.54 - lr: 0.001000\n",
      "2022-08-30 16:43:47,497 epoch 1 - iter 88/111 - loss 1.06387114 - samples/sec: 91.49 - lr: 0.001000\n",
      "2022-08-30 16:43:51,425 epoch 1 - iter 99/111 - loss 1.06557023 - samples/sec: 85.21 - lr: 0.001000\n",
      "2022-08-30 16:43:55,788 epoch 1 - iter 110/111 - loss 1.08652325 - samples/sec: 76.94 - lr: 0.001000\n",
      "2022-08-30 16:43:56,237 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:43:56,238 EPOCH 1 done: loss 1.0876 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:43:57,156 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:43:57,185 DEV : loss 0.9362714290618896 - f1-score (micro avg)  0.6717\n",
      "2022-08-30 16:43:57,200 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:43:57,201 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:43:57,881 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:44:02,214 epoch 2 - iter 11/111 - loss 1.11508616 - samples/sec: 76.21 - lr: 0.001000\n",
      "2022-08-30 16:44:06,434 epoch 2 - iter 22/111 - loss 1.10855698 - samples/sec: 79.35 - lr: 0.001000\n",
      "2022-08-30 16:44:10,026 epoch 2 - iter 33/111 - loss 1.09899576 - samples/sec: 93.78 - lr: 0.001000\n",
      "2022-08-30 16:44:14,281 epoch 2 - iter 44/111 - loss 1.09237842 - samples/sec: 78.74 - lr: 0.001000\n",
      "2022-08-30 16:44:18,264 epoch 2 - iter 55/111 - loss 1.09180569 - samples/sec: 84.18 - lr: 0.001000\n",
      "2022-08-30 16:44:22,391 epoch 2 - iter 66/111 - loss 1.09263360 - samples/sec: 81.14 - lr: 0.001000\n",
      "2022-08-30 16:44:26,383 epoch 2 - iter 77/111 - loss 1.09146324 - samples/sec: 84.29 - lr: 0.001000\n",
      "2022-08-30 16:44:30,643 epoch 2 - iter 88/111 - loss 1.09202419 - samples/sec: 78.93 - lr: 0.001000\n",
      "2022-08-30 16:44:34,692 epoch 2 - iter 99/111 - loss 1.08622128 - samples/sec: 82.73 - lr: 0.001000\n",
      "2022-08-30 16:44:38,440 epoch 2 - iter 110/111 - loss 1.08558734 - samples/sec: 89.63 - lr: 0.001000\n",
      "2022-08-30 16:44:38,873 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:44:38,874 EPOCH 2 done: loss 1.0863 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:44:39,776 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:44:39,806 DEV : loss 0.9257087707519531 - f1-score (micro avg)  0.6753\n",
      "2022-08-30 16:44:39,822 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:44:39,823 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:44:40,515 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:44:44,400 epoch 3 - iter 11/111 - loss 1.06866819 - samples/sec: 84.99 - lr: 0.001000\n",
      "2022-08-30 16:44:48,438 epoch 3 - iter 22/111 - loss 1.09304528 - samples/sec: 83.29 - lr: 0.001000\n",
      "2022-08-30 16:44:52,411 epoch 3 - iter 33/111 - loss 1.08967863 - samples/sec: 84.70 - lr: 0.001000\n",
      "2022-08-30 16:44:56,625 epoch 3 - iter 44/111 - loss 1.08346945 - samples/sec: 79.67 - lr: 0.001000\n",
      "2022-08-30 16:45:00,447 epoch 3 - iter 55/111 - loss 1.08452542 - samples/sec: 87.79 - lr: 0.001000\n",
      "2022-08-30 16:45:04,514 epoch 3 - iter 66/111 - loss 1.08304229 - samples/sec: 82.79 - lr: 0.001000\n",
      "2022-08-30 16:45:08,566 epoch 3 - iter 77/111 - loss 1.08262902 - samples/sec: 82.62 - lr: 0.001000\n",
      "2022-08-30 16:45:12,305 epoch 3 - iter 88/111 - loss 1.07834228 - samples/sec: 89.67 - lr: 0.001000\n",
      "2022-08-30 16:45:16,404 epoch 3 - iter 99/111 - loss 1.07737272 - samples/sec: 81.66 - lr: 0.001000\n",
      "2022-08-30 16:45:20,250 epoch 3 - iter 110/111 - loss 1.07713992 - samples/sec: 87.30 - lr: 0.001000\n",
      "2022-08-30 16:45:20,911 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:45:20,912 EPOCH 3 done: loss 1.0780 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:45:21,777 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:45:21,808 DEV : loss 0.9223424792289734 - f1-score (micro avg)  0.6746\n",
      "2022-08-30 16:45:21,827 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 16:45:21,828 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:45:25,580 epoch 4 - iter 11/111 - loss 1.08131083 - samples/sec: 87.98 - lr: 0.001000\n",
      "2022-08-30 16:45:29,676 epoch 4 - iter 22/111 - loss 1.08813449 - samples/sec: 81.93 - lr: 0.001000\n",
      "2022-08-30 16:45:33,709 epoch 4 - iter 33/111 - loss 1.07023982 - samples/sec: 83.10 - lr: 0.001000\n",
      "2022-08-30 16:45:37,859 epoch 4 - iter 44/111 - loss 1.06998998 - samples/sec: 80.68 - lr: 0.001000\n",
      "2022-08-30 16:45:42,309 epoch 4 - iter 55/111 - loss 1.07534104 - samples/sec: 75.21 - lr: 0.001000\n",
      "2022-08-30 16:45:46,782 epoch 4 - iter 66/111 - loss 1.07469218 - samples/sec: 74.83 - lr: 0.001000\n",
      "2022-08-30 16:45:50,676 epoch 4 - iter 77/111 - loss 1.07450224 - samples/sec: 86.12 - lr: 0.001000\n",
      "2022-08-30 16:45:55,869 epoch 4 - iter 88/111 - loss 1.07636648 - samples/sec: 64.25 - lr: 0.001000\n",
      "2022-08-30 16:45:59,839 epoch 4 - iter 99/111 - loss 1.07373778 - samples/sec: 84.53 - lr: 0.001000\n",
      "2022-08-30 16:46:03,815 epoch 4 - iter 110/111 - loss 1.07309660 - samples/sec: 84.29 - lr: 0.001000\n",
      "2022-08-30 16:46:04,197 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:46:04,198 EPOCH 4 done: loss 1.0743 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:46:05,080 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:46:05,110 DEV : loss 0.9167608022689819 - f1-score (micro avg)  0.6769\n",
      "2022-08-30 16:46:05,126 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:46:05,127 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:46:05,825 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:46:09,824 epoch 5 - iter 11/111 - loss 1.06870239 - samples/sec: 82.60 - lr: 0.001000\n",
      "2022-08-30 16:46:13,753 epoch 5 - iter 22/111 - loss 1.07682279 - samples/sec: 85.21 - lr: 0.001000\n",
      "2022-08-30 16:46:17,603 epoch 5 - iter 33/111 - loss 1.06364396 - samples/sec: 87.07 - lr: 0.001000\n",
      "2022-08-30 16:46:21,517 epoch 5 - iter 44/111 - loss 1.06791587 - samples/sec: 85.60 - lr: 0.001000\n",
      "2022-08-30 16:46:25,468 epoch 5 - iter 55/111 - loss 1.07354129 - samples/sec: 84.88 - lr: 0.001000\n",
      "2022-08-30 16:46:29,931 epoch 5 - iter 66/111 - loss 1.07514097 - samples/sec: 75.12 - lr: 0.001000\n",
      "2022-08-30 16:46:33,519 epoch 5 - iter 77/111 - loss 1.07283086 - samples/sec: 93.51 - lr: 0.001000\n",
      "2022-08-30 16:46:37,693 epoch 5 - iter 88/111 - loss 1.07454409 - samples/sec: 80.25 - lr: 0.001000\n",
      "2022-08-30 16:46:41,687 epoch 5 - iter 99/111 - loss 1.07702818 - samples/sec: 83.91 - lr: 0.001000\n",
      "2022-08-30 16:46:46,097 epoch 5 - iter 110/111 - loss 1.07234298 - samples/sec: 76.02 - lr: 0.001000\n",
      "2022-08-30 16:46:46,536 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:46:46,537 EPOCH 5 done: loss 1.0727 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:46:47,398 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:46:47,430 DEV : loss 0.9127711057662964 - f1-score (micro avg)  0.6769\n",
      "2022-08-30 16:46:47,451 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:46:47,452 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:46:51,380 epoch 6 - iter 11/111 - loss 1.03743991 - samples/sec: 84.06 - lr: 0.001000\n",
      "2022-08-30 16:46:55,684 epoch 6 - iter 22/111 - loss 1.04988680 - samples/sec: 77.89 - lr: 0.001000\n",
      "2022-08-30 16:46:59,620 epoch 6 - iter 33/111 - loss 1.06607767 - samples/sec: 85.07 - lr: 0.001000\n",
      "2022-08-30 16:47:03,600 epoch 6 - iter 44/111 - loss 1.06894499 - samples/sec: 84.12 - lr: 0.001000\n",
      "2022-08-30 16:47:07,731 epoch 6 - iter 55/111 - loss 1.06606632 - samples/sec: 81.14 - lr: 0.001000\n",
      "2022-08-30 16:47:12,049 epoch 6 - iter 66/111 - loss 1.06992179 - samples/sec: 77.45 - lr: 0.001000\n",
      "2022-08-30 16:47:15,948 epoch 6 - iter 77/111 - loss 1.06983100 - samples/sec: 85.98 - lr: 0.001000\n",
      "2022-08-30 16:47:19,817 epoch 6 - iter 88/111 - loss 1.07097452 - samples/sec: 86.66 - lr: 0.001000\n",
      "2022-08-30 16:47:23,641 epoch 6 - iter 99/111 - loss 1.07046449 - samples/sec: 87.60 - lr: 0.001000\n",
      "2022-08-30 16:47:27,998 epoch 6 - iter 110/111 - loss 1.06823133 - samples/sec: 76.87 - lr: 0.001000\n",
      "2022-08-30 16:47:28,315 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:47:28,315 EPOCH 6 done: loss 1.0691 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:47:29,176 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:47:29,205 DEV : loss 0.9097232818603516 - f1-score (micro avg)  0.6784\n",
      "2022-08-30 16:47:29,221 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:47:29,222 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:47:29,976 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:47:33,813 epoch 7 - iter 11/111 - loss 1.06528131 - samples/sec: 86.07 - lr: 0.001000\n",
      "2022-08-30 16:47:37,770 epoch 7 - iter 22/111 - loss 1.07256249 - samples/sec: 84.72 - lr: 0.001000\n",
      "2022-08-30 16:47:41,996 epoch 7 - iter 33/111 - loss 1.07373899 - samples/sec: 79.16 - lr: 0.001000\n",
      "2022-08-30 16:47:46,045 epoch 7 - iter 44/111 - loss 1.07006299 - samples/sec: 82.83 - lr: 0.001000\n",
      "2022-08-30 16:47:50,231 epoch 7 - iter 55/111 - loss 1.06555189 - samples/sec: 80.19 - lr: 0.001000\n",
      "2022-08-30 16:47:54,521 epoch 7 - iter 66/111 - loss 1.06771271 - samples/sec: 78.14 - lr: 0.001000\n",
      "2022-08-30 16:47:58,164 epoch 7 - iter 77/111 - loss 1.06391949 - samples/sec: 92.26 - lr: 0.001000\n",
      "2022-08-30 16:48:02,113 epoch 7 - iter 88/111 - loss 1.06684904 - samples/sec: 84.85 - lr: 0.001000\n",
      "2022-08-30 16:48:06,395 epoch 7 - iter 99/111 - loss 1.06453626 - samples/sec: 78.20 - lr: 0.001000\n",
      "2022-08-30 16:48:10,458 epoch 7 - iter 110/111 - loss 1.06471520 - samples/sec: 82.75 - lr: 0.001000\n",
      "2022-08-30 16:48:10,958 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:48:10,958 EPOCH 7 done: loss 1.0642 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:48:11,813 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:48:11,840 DEV : loss 0.9055496454238892 - f1-score (micro avg)  0.6829\n",
      "2022-08-30 16:48:11,860 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:48:11,862 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:48:12,557 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:48:17,101 epoch 8 - iter 11/111 - loss 1.08058880 - samples/sec: 72.66 - lr: 0.001000\n",
      "2022-08-30 16:48:20,970 epoch 8 - iter 22/111 - loss 1.06651594 - samples/sec: 86.57 - lr: 0.001000\n",
      "2022-08-30 16:48:24,877 epoch 8 - iter 33/111 - loss 1.06632682 - samples/sec: 85.83 - lr: 0.001000\n",
      "2022-08-30 16:48:28,678 epoch 8 - iter 44/111 - loss 1.06483852 - samples/sec: 88.16 - lr: 0.001000\n",
      "2022-08-30 16:48:32,644 epoch 8 - iter 55/111 - loss 1.06505449 - samples/sec: 84.53 - lr: 0.001000\n",
      "2022-08-30 16:48:36,823 epoch 8 - iter 66/111 - loss 1.05964021 - samples/sec: 80.25 - lr: 0.001000\n",
      "2022-08-30 16:48:40,778 epoch 8 - iter 77/111 - loss 1.05854682 - samples/sec: 84.77 - lr: 0.001000\n",
      "2022-08-30 16:48:44,750 epoch 8 - iter 88/111 - loss 1.05902030 - samples/sec: 84.46 - lr: 0.001000\n",
      "2022-08-30 16:48:49,184 epoch 8 - iter 99/111 - loss 1.05907134 - samples/sec: 75.45 - lr: 0.001000\n",
      "2022-08-30 16:48:53,114 epoch 8 - iter 110/111 - loss 1.06119706 - samples/sec: 85.27 - lr: 0.001000\n",
      "2022-08-30 16:48:53,468 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:48:53,468 EPOCH 8 done: loss 1.0608 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:48:54,365 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:48:54,396 DEV : loss 0.9003668427467346 - f1-score (micro avg)  0.6821\n",
      "2022-08-30 16:48:54,414 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 16:48:54,415 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:48:58,354 epoch 9 - iter 11/111 - loss 1.04839539 - samples/sec: 83.84 - lr: 0.001000\n",
      "2022-08-30 16:49:02,433 epoch 9 - iter 22/111 - loss 1.05908163 - samples/sec: 82.27 - lr: 0.001000\n",
      "2022-08-30 16:49:06,839 epoch 9 - iter 33/111 - loss 1.05913003 - samples/sec: 76.21 - lr: 0.001000\n",
      "2022-08-30 16:49:10,706 epoch 9 - iter 44/111 - loss 1.05810896 - samples/sec: 86.59 - lr: 0.001000\n",
      "2022-08-30 16:49:14,364 epoch 9 - iter 55/111 - loss 1.06510952 - samples/sec: 91.69 - lr: 0.001000\n",
      "2022-08-30 16:49:18,557 epoch 9 - iter 66/111 - loss 1.06353939 - samples/sec: 80.14 - lr: 0.001000\n",
      "2022-08-30 16:49:22,441 epoch 9 - iter 77/111 - loss 1.06344069 - samples/sec: 86.30 - lr: 0.001000\n",
      "2022-08-30 16:49:26,490 epoch 9 - iter 88/111 - loss 1.06013232 - samples/sec: 83.04 - lr: 0.001000\n",
      "2022-08-30 16:49:30,670 epoch 9 - iter 99/111 - loss 1.06055341 - samples/sec: 80.25 - lr: 0.001000\n",
      "2022-08-30 16:49:34,815 epoch 9 - iter 110/111 - loss 1.05735209 - samples/sec: 80.82 - lr: 0.001000\n",
      "2022-08-30 16:49:35,192 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:49:35,193 EPOCH 9 done: loss 1.0571 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:49:36,041 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:49:36,071 DEV : loss 0.897527813911438 - f1-score (micro avg)  0.684\n",
      "2022-08-30 16:49:36,091 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:49:36,092 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:49:36,781 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:49:40,818 epoch 10 - iter 11/111 - loss 1.08858744 - samples/sec: 81.78 - lr: 0.001000\n",
      "2022-08-30 16:49:44,930 epoch 10 - iter 22/111 - loss 1.06677451 - samples/sec: 81.44 - lr: 0.001000\n",
      "2022-08-30 16:49:48,808 epoch 10 - iter 33/111 - loss 1.05949468 - samples/sec: 86.39 - lr: 0.001000\n",
      "2022-08-30 16:49:52,887 epoch 10 - iter 44/111 - loss 1.05980668 - samples/sec: 82.11 - lr: 0.001000\n",
      "2022-08-30 16:49:56,900 epoch 10 - iter 55/111 - loss 1.05785312 - samples/sec: 83.42 - lr: 0.001000\n",
      "2022-08-30 16:50:00,868 epoch 10 - iter 66/111 - loss 1.05650259 - samples/sec: 84.44 - lr: 0.001000\n",
      "2022-08-30 16:50:04,954 epoch 10 - iter 77/111 - loss 1.05561950 - samples/sec: 82.13 - lr: 0.001000\n",
      "2022-08-30 16:50:08,860 epoch 10 - iter 88/111 - loss 1.05607471 - samples/sec: 85.76 - lr: 0.001000\n",
      "2022-08-30 16:50:12,892 epoch 10 - iter 99/111 - loss 1.05653278 - samples/sec: 83.04 - lr: 0.001000\n",
      "2022-08-30 16:50:17,110 epoch 10 - iter 110/111 - loss 1.05538260 - samples/sec: 79.42 - lr: 0.001000\n",
      "2022-08-30 16:50:17,585 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:50:17,586 EPOCH 10 done: loss 1.0556 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:50:18,457 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:50:18,488 DEV : loss 0.8928162455558777 - f1-score (micro avg)  0.6862\n",
      "2022-08-30 16:50:18,504 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:50:18,505 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:50:19,205 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:50:23,109 epoch 11 - iter 11/111 - loss 1.04489360 - samples/sec: 84.57 - lr: 0.001000\n",
      "2022-08-30 16:50:27,157 epoch 11 - iter 22/111 - loss 1.04445008 - samples/sec: 82.81 - lr: 0.001000\n",
      "2022-08-30 16:50:31,295 epoch 11 - iter 33/111 - loss 1.04640920 - samples/sec: 80.92 - lr: 0.001000\n",
      "2022-08-30 16:50:35,326 epoch 11 - iter 44/111 - loss 1.04253239 - samples/sec: 83.10 - lr: 0.001000\n",
      "2022-08-30 16:50:39,239 epoch 11 - iter 55/111 - loss 1.04607229 - samples/sec: 85.89 - lr: 0.001000\n",
      "2022-08-30 16:50:43,302 epoch 11 - iter 66/111 - loss 1.04997928 - samples/sec: 82.44 - lr: 0.001000\n",
      "2022-08-30 16:50:47,139 epoch 11 - iter 77/111 - loss 1.04860453 - samples/sec: 87.28 - lr: 0.001000\n",
      "2022-08-30 16:50:50,995 epoch 11 - iter 88/111 - loss 1.04950718 - samples/sec: 86.84 - lr: 0.001000\n",
      "2022-08-30 16:50:55,365 epoch 11 - iter 99/111 - loss 1.05117717 - samples/sec: 76.66 - lr: 0.001000\n",
      "2022-08-30 16:50:59,667 epoch 11 - iter 110/111 - loss 1.05311218 - samples/sec: 78.05 - lr: 0.001000\n",
      "2022-08-30 16:51:00,053 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:51:00,054 EPOCH 11 done: loss 1.0537 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:51:00,974 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:51:01,000 DEV : loss 0.8900983929634094 - f1-score (micro avg)  0.6878\n",
      "2022-08-30 16:51:01,020 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:51:01,022 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:51:02,930 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:51:02,931 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 16:51:03,108 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:51:04,571 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:51:04,598 0.6989\t0.6989\t0.6989\t0.6989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:51:04,599 \n",
      "Results:\n",
      "- F-score (micro) 0.6989\n",
      "- F-score (macro) 0.5345\n",
      "- Accuracy 0.6989\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6150    0.7391    0.6714      1353\n",
      "         ADJ     0.4813    0.6696    0.5600       672\n",
      "       PUNCT     0.9776    0.9909    0.9842       660\n",
      "         ADP     0.8542    0.9008    0.8769       514\n",
      "        VERB     0.5639    0.5011    0.5307       449\n",
      "         AUX     0.8754    0.7970    0.8344       335\n",
      "       PROPN     0.7834    0.3211    0.4556       383\n",
      "       CCONJ     0.9788    0.9635    0.9711       192\n",
      "       SCONJ     0.8729    0.8587    0.8658       184\n",
      "         DET     0.5051    0.3106    0.3846       161\n",
      "        PRON     0.8913    0.7130    0.7923       115\n",
      "         ADV     0.2037    0.0728    0.1073       151\n",
      "         NUM     0.6000    0.0845    0.1481        71\n",
      "        PART     0.8333    0.2381    0.3704        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6989      5264\n",
      "   macro avg     0.6273    0.5101    0.5345      5264\n",
      "weighted avg     0.7047    0.6989    0.6859      5264\n",
      "\n",
      "2022-08-30 16:51:04,600 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:51:04,601 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 16:51:05,074 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 16:53:17,391 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:53:17,392 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 16:53:17,392 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:53:17,393 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 16:53:17,393 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:53:17,394 Parameters:\n",
      "2022-08-30 16:53:17,395  - learning_rate: \"0.001000\"\n",
      "2022-08-30 16:53:17,395  - mini_batch_size: \"30\"\n",
      "2022-08-30 16:53:17,395  - patience: \"3\"\n",
      "2022-08-30 16:53:17,396  - anneal_factor: \"0.5\"\n",
      "2022-08-30 16:53:17,396  - max_epochs: \"12\"\n",
      "2022-08-30 16:53:17,397  - shuffle: \"True\"\n",
      "2022-08-30 16:53:17,397  - train_with_dev: \"False\"\n",
      "2022-08-30 16:53:17,398  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 16:53:17,398 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:53:17,399 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 16:53:17,399 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:53:17,400 Device: cpu\n",
      "2022-08-30 16:53:17,401 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:53:17,402 Embeddings storage mode: cpu\n",
      "2022-08-30 16:53:17,402 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:53:21,432 epoch 1 - iter 11/111 - loss 1.02202448 - samples/sec: 81.93 - lr: 0.001000\n",
      "2022-08-30 16:53:25,580 epoch 1 - iter 22/111 - loss 1.02055416 - samples/sec: 81.04 - lr: 0.001000\n",
      "2022-08-30 16:53:29,155 epoch 1 - iter 33/111 - loss 1.01380745 - samples/sec: 93.80 - lr: 0.001000\n",
      "2022-08-30 16:53:32,899 epoch 1 - iter 44/111 - loss 1.01982110 - samples/sec: 89.58 - lr: 0.001000\n",
      "2022-08-30 16:53:37,131 epoch 1 - iter 55/111 - loss 1.02431787 - samples/sec: 79.19 - lr: 0.001000\n",
      "2022-08-30 16:53:40,880 epoch 1 - iter 66/111 - loss 1.01926463 - samples/sec: 89.55 - lr: 0.001000\n",
      "2022-08-30 16:53:44,977 epoch 1 - iter 77/111 - loss 1.02355137 - samples/sec: 81.66 - lr: 0.001000\n",
      "2022-08-30 16:53:48,646 epoch 1 - iter 88/111 - loss 1.02205873 - samples/sec: 91.54 - lr: 0.001000\n",
      "2022-08-30 16:53:52,617 epoch 1 - iter 99/111 - loss 1.02384352 - samples/sec: 84.53 - lr: 0.001000\n",
      "2022-08-30 16:53:56,912 epoch 1 - iter 110/111 - loss 1.04481899 - samples/sec: 77.87 - lr: 0.001000\n",
      "2022-08-30 16:53:57,368 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:53:57,370 EPOCH 1 done: loss 1.0457 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:53:58,242 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:53:58,273 DEV : loss 0.8928478956222534 - f1-score (micro avg)  0.6896\n",
      "2022-08-30 16:53:58,288 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:53:58,290 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:53:59,204 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:54:03,358 epoch 2 - iter 11/111 - loss 1.05293223 - samples/sec: 79.48 - lr: 0.001000\n",
      "2022-08-30 16:54:07,658 epoch 2 - iter 22/111 - loss 1.04318490 - samples/sec: 78.01 - lr: 0.001000\n",
      "2022-08-30 16:54:11,411 epoch 2 - iter 33/111 - loss 1.05756384 - samples/sec: 89.24 - lr: 0.001000\n",
      "2022-08-30 16:54:15,667 epoch 2 - iter 44/111 - loss 1.05382229 - samples/sec: 78.87 - lr: 0.001000\n",
      "2022-08-30 16:54:19,971 epoch 2 - iter 55/111 - loss 1.05254440 - samples/sec: 77.85 - lr: 0.001000\n",
      "2022-08-30 16:54:24,277 epoch 2 - iter 66/111 - loss 1.05136139 - samples/sec: 77.85 - lr: 0.001000\n",
      "2022-08-30 16:54:28,177 epoch 2 - iter 77/111 - loss 1.05170349 - samples/sec: 85.89 - lr: 0.001000\n",
      "2022-08-30 16:54:31,989 epoch 2 - iter 88/111 - loss 1.04947556 - samples/sec: 87.88 - lr: 0.001000\n",
      "2022-08-30 16:54:35,791 epoch 2 - iter 99/111 - loss 1.04878483 - samples/sec: 88.24 - lr: 0.001000\n",
      "2022-08-30 16:54:39,892 epoch 2 - iter 110/111 - loss 1.04932704 - samples/sec: 81.62 - lr: 0.001000\n",
      "2022-08-30 16:54:40,276 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:54:40,276 EPOCH 2 done: loss 1.0493 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:54:41,127 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:54:41,158 DEV : loss 0.8824746012687683 - f1-score (micro avg)  0.6894\n",
      "2022-08-30 16:54:41,174 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 16:54:41,175 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:54:45,285 epoch 3 - iter 11/111 - loss 1.06565820 - samples/sec: 80.35 - lr: 0.001000\n",
      "2022-08-30 16:54:49,093 epoch 3 - iter 22/111 - loss 1.06111092 - samples/sec: 88.00 - lr: 0.001000\n",
      "2022-08-30 16:54:53,071 epoch 3 - iter 33/111 - loss 1.05611589 - samples/sec: 84.38 - lr: 0.001000\n",
      "2022-08-30 16:54:57,198 epoch 3 - iter 44/111 - loss 1.04660642 - samples/sec: 81.18 - lr: 0.001000\n",
      "2022-08-30 16:55:01,268 epoch 3 - iter 55/111 - loss 1.04756320 - samples/sec: 82.29 - lr: 0.001000\n",
      "2022-08-30 16:55:05,167 epoch 3 - iter 66/111 - loss 1.04815732 - samples/sec: 85.87 - lr: 0.001000\n",
      "2022-08-30 16:55:09,354 epoch 3 - iter 77/111 - loss 1.04498046 - samples/sec: 79.92 - lr: 0.001000\n",
      "2022-08-30 16:55:13,271 epoch 3 - iter 88/111 - loss 1.04453885 - samples/sec: 85.96 - lr: 0.001000\n",
      "2022-08-30 16:55:17,337 epoch 3 - iter 99/111 - loss 1.04298551 - samples/sec: 82.42 - lr: 0.001000\n",
      "2022-08-30 16:55:21,685 epoch 3 - iter 110/111 - loss 1.04216407 - samples/sec: 77.17 - lr: 0.001000\n",
      "2022-08-30 16:55:22,002 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:55:22,002 EPOCH 3 done: loss 1.0422 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:55:22,900 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:55:22,931 DEV : loss 0.8790136575698853 - f1-score (micro avg)  0.692\n",
      "2022-08-30 16:55:22,946 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:55:22,947 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:55:23,636 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:55:27,517 epoch 4 - iter 11/111 - loss 1.05690894 - samples/sec: 85.12 - lr: 0.001000\n",
      "2022-08-30 16:55:31,701 epoch 4 - iter 22/111 - loss 1.06357098 - samples/sec: 80.02 - lr: 0.001000\n",
      "2022-08-30 16:55:35,684 epoch 4 - iter 33/111 - loss 1.05915558 - samples/sec: 84.36 - lr: 0.001000\n",
      "2022-08-30 16:55:39,640 epoch 4 - iter 44/111 - loss 1.04751595 - samples/sec: 84.81 - lr: 0.001000\n",
      "2022-08-30 16:55:43,719 epoch 4 - iter 55/111 - loss 1.04931537 - samples/sec: 82.21 - lr: 0.001000\n",
      "2022-08-30 16:55:48,237 epoch 4 - iter 66/111 - loss 1.04860701 - samples/sec: 74.02 - lr: 0.001000\n",
      "2022-08-30 16:55:52,511 epoch 4 - iter 77/111 - loss 1.04572446 - samples/sec: 78.25 - lr: 0.001000\n",
      "2022-08-30 16:55:56,356 epoch 4 - iter 88/111 - loss 1.04567637 - samples/sec: 87.26 - lr: 0.001000\n",
      "2022-08-30 16:56:00,312 epoch 4 - iter 99/111 - loss 1.04423924 - samples/sec: 84.94 - lr: 0.001000\n",
      "2022-08-30 16:56:04,224 epoch 4 - iter 110/111 - loss 1.04305380 - samples/sec: 85.67 - lr: 0.001000\n",
      "2022-08-30 16:56:04,658 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:56:04,659 EPOCH 4 done: loss 1.0429 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:56:05,540 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:56:05,569 DEV : loss 0.8759079575538635 - f1-score (micro avg)  0.6922\n",
      "2022-08-30 16:56:05,585 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:56:05,586 saving best model\n",
      "2022-08-30 16:56:06,370 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:56:10,462 epoch 5 - iter 11/111 - loss 1.03297059 - samples/sec: 80.68 - lr: 0.001000\n",
      "2022-08-30 16:56:14,285 epoch 5 - iter 22/111 - loss 1.05376574 - samples/sec: 87.72 - lr: 0.001000\n",
      "2022-08-30 16:56:18,257 epoch 5 - iter 33/111 - loss 1.03777765 - samples/sec: 84.31 - lr: 0.001000\n",
      "2022-08-30 16:56:22,172 epoch 5 - iter 44/111 - loss 1.03092141 - samples/sec: 85.54 - lr: 0.001000\n",
      "2022-08-30 16:56:26,095 epoch 5 - iter 55/111 - loss 1.02003932 - samples/sec: 85.36 - lr: 0.001000\n",
      "2022-08-30 16:56:30,522 epoch 5 - iter 66/111 - loss 1.02295122 - samples/sec: 75.62 - lr: 0.001000\n",
      "2022-08-30 16:56:34,628 epoch 5 - iter 77/111 - loss 1.02704313 - samples/sec: 81.56 - lr: 0.001000\n",
      "2022-08-30 16:56:38,543 epoch 5 - iter 88/111 - loss 1.03093871 - samples/sec: 85.89 - lr: 0.001000\n",
      "2022-08-30 16:56:42,799 epoch 5 - iter 99/111 - loss 1.03372451 - samples/sec: 78.93 - lr: 0.001000\n",
      "2022-08-30 16:56:46,689 epoch 5 - iter 110/111 - loss 1.03475499 - samples/sec: 86.18 - lr: 0.001000\n",
      "2022-08-30 16:56:47,077 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:56:47,078 EPOCH 5 done: loss 1.0353 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:56:47,948 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:56:47,980 DEV : loss 0.871025562286377 - f1-score (micro avg)  0.6944\n",
      "2022-08-30 16:56:47,995 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:56:47,996 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:56:48,774 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:56:53,156 epoch 6 - iter 11/111 - loss 1.02708700 - samples/sec: 75.34 - lr: 0.001000\n",
      "2022-08-30 16:56:57,293 epoch 6 - iter 22/111 - loss 1.02872483 - samples/sec: 80.84 - lr: 0.001000\n",
      "2022-08-30 16:57:01,319 epoch 6 - iter 33/111 - loss 1.03336857 - samples/sec: 83.33 - lr: 0.001000\n",
      "2022-08-30 16:57:05,366 epoch 6 - iter 44/111 - loss 1.03841235 - samples/sec: 82.79 - lr: 0.001000\n",
      "2022-08-30 16:57:09,404 epoch 6 - iter 55/111 - loss 1.04257108 - samples/sec: 83.14 - lr: 0.001000\n",
      "2022-08-30 16:57:13,292 epoch 6 - iter 66/111 - loss 1.03946724 - samples/sec: 86.46 - lr: 0.001000\n",
      "2022-08-30 16:57:17,337 epoch 6 - iter 77/111 - loss 1.03670495 - samples/sec: 82.77 - lr: 0.001000\n",
      "2022-08-30 16:57:21,282 epoch 6 - iter 88/111 - loss 1.03498604 - samples/sec: 85.18 - lr: 0.001000\n",
      "2022-08-30 16:57:25,175 epoch 6 - iter 99/111 - loss 1.03534980 - samples/sec: 86.03 - lr: 0.001000\n",
      "2022-08-30 16:57:28,900 epoch 6 - iter 110/111 - loss 1.03424056 - samples/sec: 89.89 - lr: 0.001000\n",
      "2022-08-30 16:57:29,298 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:57:29,299 EPOCH 6 done: loss 1.0343 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:57:30,182 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:57:30,213 DEV : loss 0.8699459433555603 - f1-score (micro avg)  0.6948\n",
      "2022-08-30 16:57:30,228 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:57:30,229 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:57:30,917 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:57:35,051 epoch 7 - iter 11/111 - loss 1.04714421 - samples/sec: 79.86 - lr: 0.001000\n",
      "2022-08-30 16:57:39,204 epoch 7 - iter 22/111 - loss 1.02642330 - samples/sec: 80.82 - lr: 0.001000\n",
      "2022-08-30 16:57:43,126 epoch 7 - iter 33/111 - loss 1.03968982 - samples/sec: 85.32 - lr: 0.001000\n",
      "2022-08-30 16:57:46,927 epoch 7 - iter 44/111 - loss 1.04059287 - samples/sec: 88.19 - lr: 0.001000\n",
      "2022-08-30 16:57:51,229 epoch 7 - iter 55/111 - loss 1.02998508 - samples/sec: 77.87 - lr: 0.001000\n",
      "2022-08-30 16:57:55,186 epoch 7 - iter 66/111 - loss 1.03020408 - samples/sec: 84.64 - lr: 0.001000\n",
      "2022-08-30 16:57:59,442 epoch 7 - iter 77/111 - loss 1.02885159 - samples/sec: 78.59 - lr: 0.001000\n",
      "2022-08-30 16:58:03,229 epoch 7 - iter 88/111 - loss 1.02983085 - samples/sec: 88.73 - lr: 0.001000\n",
      "2022-08-30 16:58:07,193 epoch 7 - iter 99/111 - loss 1.03007864 - samples/sec: 84.59 - lr: 0.001000\n",
      "2022-08-30 16:58:11,356 epoch 7 - iter 110/111 - loss 1.03053760 - samples/sec: 80.35 - lr: 0.001000\n",
      "2022-08-30 16:58:11,761 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:58:11,762 EPOCH 7 done: loss 1.0304 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:58:12,630 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:58:12,663 DEV : loss 0.8661377429962158 - f1-score (micro avg)  0.6951\n",
      "2022-08-30 16:58:12,678 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 16:58:12,679 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:58:13,369 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:58:17,130 epoch 8 - iter 11/111 - loss 1.03243000 - samples/sec: 87.77 - lr: 0.001000\n",
      "2022-08-30 16:58:21,246 epoch 8 - iter 22/111 - loss 1.04676000 - samples/sec: 81.36 - lr: 0.001000\n",
      "2022-08-30 16:58:25,156 epoch 8 - iter 33/111 - loss 1.03439738 - samples/sec: 85.65 - lr: 0.001000\n",
      "2022-08-30 16:58:29,118 epoch 8 - iter 44/111 - loss 1.02990008 - samples/sec: 84.70 - lr: 0.001000\n",
      "2022-08-30 16:58:33,259 epoch 8 - iter 55/111 - loss 1.02213321 - samples/sec: 80.86 - lr: 0.001000\n",
      "2022-08-30 16:58:37,492 epoch 8 - iter 66/111 - loss 1.02652203 - samples/sec: 79.10 - lr: 0.001000\n",
      "2022-08-30 16:58:41,749 epoch 8 - iter 77/111 - loss 1.02874646 - samples/sec: 79.06 - lr: 0.001000\n",
      "2022-08-30 16:58:45,801 epoch 8 - iter 88/111 - loss 1.02739203 - samples/sec: 82.67 - lr: 0.001000\n",
      "2022-08-30 16:58:49,744 epoch 8 - iter 99/111 - loss 1.02301924 - samples/sec: 84.94 - lr: 0.001000\n",
      "2022-08-30 16:58:53,680 epoch 8 - iter 110/111 - loss 1.02344971 - samples/sec: 85.21 - lr: 0.001000\n",
      "2022-08-30 16:58:54,205 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:58:54,205 EPOCH 8 done: loss 1.0238 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:58:55,094 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:58:55,126 DEV : loss 0.8616687059402466 - f1-score (micro avg)  0.6985\n",
      "2022-08-30 16:58:55,146 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:58:55,148 saving best model\n",
      "2022-08-30 16:58:56,065 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:59:00,029 epoch 9 - iter 11/111 - loss 0.99380864 - samples/sec: 83.29 - lr: 0.001000\n",
      "2022-08-30 16:59:04,000 epoch 9 - iter 22/111 - loss 1.00421888 - samples/sec: 84.38 - lr: 0.001000\n",
      "2022-08-30 16:59:08,561 epoch 9 - iter 33/111 - loss 1.01467353 - samples/sec: 73.40 - lr: 0.001000\n",
      "2022-08-30 16:59:12,559 epoch 9 - iter 44/111 - loss 1.02150552 - samples/sec: 83.88 - lr: 0.001000\n",
      "2022-08-30 16:59:16,577 epoch 9 - iter 55/111 - loss 1.02439345 - samples/sec: 83.50 - lr: 0.001000\n",
      "2022-08-30 16:59:20,467 epoch 9 - iter 66/111 - loss 1.03418161 - samples/sec: 86.21 - lr: 0.001000\n",
      "2022-08-30 16:59:24,575 epoch 9 - iter 77/111 - loss 1.03450490 - samples/sec: 81.54 - lr: 0.001000\n",
      "2022-08-30 16:59:28,668 epoch 9 - iter 88/111 - loss 1.03259096 - samples/sec: 81.78 - lr: 0.001000\n",
      "2022-08-30 16:59:32,459 epoch 9 - iter 99/111 - loss 1.02974051 - samples/sec: 88.40 - lr: 0.001000\n",
      "2022-08-30 16:59:36,625 epoch 9 - iter 110/111 - loss 1.02555247 - samples/sec: 80.43 - lr: 0.001000\n",
      "2022-08-30 16:59:37,019 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 16:59:37,020 EPOCH 9 done: loss 1.0255 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:59:37,886 Evaluating as a multi-label problem: False\n",
      "2022-08-30 16:59:37,915 DEV : loss 0.8595040440559387 - f1-score (micro avg)  0.6979\n",
      "2022-08-30 16:59:37,930 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 16:59:37,931 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:59:41,763 epoch 10 - iter 11/111 - loss 0.99936792 - samples/sec: 86.16 - lr: 0.001000\n",
      "2022-08-30 16:59:45,921 epoch 10 - iter 22/111 - loss 1.00088234 - samples/sec: 80.55 - lr: 0.001000\n",
      "2022-08-30 16:59:49,789 epoch 10 - iter 33/111 - loss 1.02424556 - samples/sec: 86.66 - lr: 0.001000\n",
      "2022-08-30 16:59:53,864 epoch 10 - iter 44/111 - loss 1.02461968 - samples/sec: 82.23 - lr: 0.001000\n",
      "2022-08-30 16:59:58,297 epoch 10 - iter 55/111 - loss 1.02724992 - samples/sec: 75.46 - lr: 0.001000\n",
      "2022-08-30 17:00:02,166 epoch 10 - iter 66/111 - loss 1.02273181 - samples/sec: 86.77 - lr: 0.001000\n",
      "2022-08-30 17:00:06,385 epoch 10 - iter 77/111 - loss 1.02115921 - samples/sec: 79.37 - lr: 0.001000\n",
      "2022-08-30 17:00:10,437 epoch 10 - iter 88/111 - loss 1.02190338 - samples/sec: 82.96 - lr: 0.001000\n",
      "2022-08-30 17:00:14,324 epoch 10 - iter 99/111 - loss 1.02345904 - samples/sec: 86.64 - lr: 0.001000\n",
      "2022-08-30 17:00:18,531 epoch 10 - iter 110/111 - loss 1.02203988 - samples/sec: 79.54 - lr: 0.001000\n",
      "2022-08-30 17:00:18,904 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:00:18,905 EPOCH 10 done: loss 1.0222 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:00:20,998 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:00:21,032 DEV : loss 0.8553680181503296 - f1-score (micro avg)  0.6993\n",
      "2022-08-30 17:00:21,048 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:00:21,049 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:00:22,039 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:00:25,959 epoch 11 - iter 11/111 - loss 1.02163009 - samples/sec: 84.25 - lr: 0.001000\n",
      "2022-08-30 17:00:29,934 epoch 11 - iter 22/111 - loss 1.00478433 - samples/sec: 84.36 - lr: 0.001000\n",
      "2022-08-30 17:00:34,060 epoch 11 - iter 33/111 - loss 0.99820126 - samples/sec: 81.20 - lr: 0.001000\n",
      "2022-08-30 17:00:38,008 epoch 11 - iter 44/111 - loss 1.00444089 - samples/sec: 84.90 - lr: 0.001000\n",
      "2022-08-30 17:00:41,696 epoch 11 - iter 55/111 - loss 1.00900946 - samples/sec: 91.01 - lr: 0.001000\n",
      "2022-08-30 17:00:45,315 epoch 11 - iter 66/111 - loss 1.01534597 - samples/sec: 92.62 - lr: 0.001000\n",
      "2022-08-30 17:00:49,600 epoch 11 - iter 77/111 - loss 1.01554635 - samples/sec: 78.27 - lr: 0.001000\n",
      "2022-08-30 17:00:54,057 epoch 11 - iter 88/111 - loss 1.01731831 - samples/sec: 75.05 - lr: 0.001000\n",
      "2022-08-30 17:00:58,253 epoch 11 - iter 99/111 - loss 1.02251716 - samples/sec: 79.81 - lr: 0.001000\n",
      "2022-08-30 17:01:02,419 epoch 11 - iter 110/111 - loss 1.02334898 - samples/sec: 80.31 - lr: 0.001000\n",
      "2022-08-30 17:01:02,807 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:01:02,807 EPOCH 11 done: loss 1.0239 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:01:03,678 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:01:03,707 DEV : loss 0.8532406091690063 - f1-score (micro avg)  0.6995\n",
      "2022-08-30 17:01:03,728 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:01:03,729 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:01:04,409 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:01:08,916 epoch 12 - iter 11/111 - loss 0.98084907 - samples/sec: 73.24 - lr: 0.001000\n",
      "2022-08-30 17:01:12,889 epoch 12 - iter 22/111 - loss 0.99016699 - samples/sec: 84.33 - lr: 0.001000\n",
      "2022-08-30 17:01:16,749 epoch 12 - iter 33/111 - loss 0.99992028 - samples/sec: 86.77 - lr: 0.001000\n",
      "2022-08-30 17:01:20,843 epoch 12 - iter 44/111 - loss 1.00730436 - samples/sec: 81.85 - lr: 0.001000\n",
      "2022-08-30 17:01:24,852 epoch 12 - iter 55/111 - loss 1.00659246 - samples/sec: 83.46 - lr: 0.001000\n",
      "2022-08-30 17:01:28,506 epoch 12 - iter 66/111 - loss 1.00860942 - samples/sec: 91.87 - lr: 0.001000\n",
      "2022-08-30 17:01:32,883 epoch 12 - iter 77/111 - loss 1.00801405 - samples/sec: 76.58 - lr: 0.001000\n",
      "2022-08-30 17:01:36,744 epoch 12 - iter 88/111 - loss 1.00759020 - samples/sec: 86.80 - lr: 0.001000\n",
      "2022-08-30 17:01:40,754 epoch 12 - iter 99/111 - loss 1.01192108 - samples/sec: 83.44 - lr: 0.001000\n",
      "2022-08-30 17:01:44,718 epoch 12 - iter 110/111 - loss 1.01380939 - samples/sec: 84.57 - lr: 0.001000\n",
      "2022-08-30 17:01:45,099 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:01:45,100 EPOCH 12 done: loss 1.0130 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:01:45,970 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:01:46,002 DEV : loss 0.8500238060951233 - f1-score (micro avg)  0.7026\n",
      "2022-08-30 17:01:46,024 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:01:46,026 saving best model\n",
      "2022-08-30 17:01:47,518 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:01:47,519 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 17:01:47,695 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:01:49,117 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:01:49,142 0.7107\t0.7107\t0.7107\t0.7107\n",
      "2022-08-30 17:01:49,143 \n",
      "Results:\n",
      "- F-score (micro) 0.7107\n",
      "- F-score (macro) 0.5455\n",
      "- Accuracy 0.7107\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6253    0.7524    0.6830      1353\n",
      "         ADJ     0.4994    0.6741    0.5738       672\n",
      "       PUNCT     0.9776    0.9909    0.9842       660\n",
      "         ADP     0.8614    0.9066    0.8834       514\n",
      "        VERB     0.6000    0.5345    0.5654       449\n",
      "         AUX     0.8770    0.8090    0.8416       335\n",
      "       PROPN     0.7584    0.3525    0.4813       383\n",
      "       CCONJ     0.9843    0.9792    0.9817       192\n",
      "       SCONJ     0.8791    0.8696    0.8743       184\n",
      "         DET     0.5426    0.3168    0.4000       161\n",
      "         ADV     0.2000    0.0728    0.1068       151\n",
      "        PRON     0.8889    0.6957    0.7805       115\n",
      "         NUM     0.6923    0.1268    0.2143        71\n",
      "        PART     0.7143    0.2381    0.3571        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7107      5264\n",
      "   macro avg     0.6313    0.5199    0.5455      5264\n",
      "weighted avg     0.7139    0.7107    0.6983      5264\n",
      "\n",
      "2022-08-30 17:01:49,144 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:01:49,145 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 17:01:49,640 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 3 #######################\n",
      "#######################################################\n",
      "2022-08-30 17:04:02,834 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:04:02,834 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 17:04:02,835 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:04:02,835 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 17:04:02,836 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:04:02,837 Parameters:\n",
      "2022-08-30 17:04:02,837  - learning_rate: \"0.001000\"\n",
      "2022-08-30 17:04:02,838  - mini_batch_size: \"50\"\n",
      "2022-08-30 17:04:02,838  - patience: \"3\"\n",
      "2022-08-30 17:04:02,839  - anneal_factor: \"0.5\"\n",
      "2022-08-30 17:04:02,840  - max_epochs: \"10\"\n",
      "2022-08-30 17:04:02,841  - shuffle: \"True\"\n",
      "2022-08-30 17:04:02,841  - train_with_dev: \"False\"\n",
      "2022-08-30 17:04:02,842  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 17:04:02,842 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:04:02,843 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 17:04:02,844 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:04:02,844 Device: cpu\n",
      "2022-08-30 17:04:02,845 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:04:02,845 Embeddings storage mode: cpu\n",
      "2022-08-30 17:04:02,846 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:04:05,668 epoch 1 - iter 6/67 - loss 1.00510587 - samples/sec: 106.38 - lr: 0.001000\n",
      "2022-08-30 17:04:08,918 epoch 1 - iter 12/67 - loss 0.97332303 - samples/sec: 94.22 - lr: 0.001000\n",
      "2022-08-30 17:04:11,754 epoch 1 - iter 18/67 - loss 0.96904829 - samples/sec: 107.95 - lr: 0.001000\n",
      "2022-08-30 17:04:14,505 epoch 1 - iter 24/67 - loss 0.98504951 - samples/sec: 111.61 - lr: 0.001000\n",
      "2022-08-30 17:04:17,505 epoch 1 - iter 30/67 - loss 0.98105107 - samples/sec: 102.18 - lr: 0.001000\n",
      "2022-08-30 17:04:20,579 epoch 1 - iter 36/67 - loss 0.98141833 - samples/sec: 99.87 - lr: 0.001000\n",
      "2022-08-30 17:04:23,540 epoch 1 - iter 42/67 - loss 0.98419214 - samples/sec: 103.38 - lr: 0.001000\n",
      "2022-08-30 17:04:26,323 epoch 1 - iter 48/67 - loss 0.98364869 - samples/sec: 110.62 - lr: 0.001000\n",
      "2022-08-30 17:04:29,054 epoch 1 - iter 54/67 - loss 0.98347056 - samples/sec: 113.42 - lr: 0.001000\n",
      "2022-08-30 17:04:32,179 epoch 1 - iter 60/67 - loss 0.98880473 - samples/sec: 97.75 - lr: 0.001000\n",
      "2022-08-30 17:04:35,583 epoch 1 - iter 66/67 - loss 1.00781260 - samples/sec: 89.79 - lr: 0.001000\n",
      "2022-08-30 17:04:36,025 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:04:36,026 EPOCH 1 done: loss 1.0087 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:04:36,868 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:04:36,898 DEV : loss 0.8522018790245056 - f1-score (micro avg)  0.7016\n",
      "2022-08-30 17:04:36,913 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:04:36,914 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:04:37,588 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:04:40,783 epoch 2 - iter 6/67 - loss 1.02805495 - samples/sec: 93.96 - lr: 0.001000\n",
      "2022-08-30 17:04:43,744 epoch 2 - iter 12/67 - loss 1.02906701 - samples/sec: 104.13 - lr: 0.001000\n",
      "2022-08-30 17:04:46,900 epoch 2 - iter 18/67 - loss 1.02979796 - samples/sec: 96.96 - lr: 0.001000\n",
      "2022-08-30 17:04:49,811 epoch 2 - iter 24/67 - loss 1.03186073 - samples/sec: 105.23 - lr: 0.001000\n",
      "2022-08-30 17:04:52,916 epoch 2 - iter 30/67 - loss 1.02394687 - samples/sec: 98.49 - lr: 0.001000\n",
      "2022-08-30 17:04:55,839 epoch 2 - iter 36/67 - loss 1.01900880 - samples/sec: 104.57 - lr: 0.001000\n",
      "2022-08-30 17:04:58,820 epoch 2 - iter 42/67 - loss 1.01378573 - samples/sec: 102.81 - lr: 0.001000\n",
      "2022-08-30 17:05:01,826 epoch 2 - iter 48/67 - loss 1.01289518 - samples/sec: 102.35 - lr: 0.001000\n",
      "2022-08-30 17:05:04,827 epoch 2 - iter 54/67 - loss 1.01327747 - samples/sec: 102.15 - lr: 0.001000\n",
      "2022-08-30 17:05:07,870 epoch 2 - iter 60/67 - loss 1.01190258 - samples/sec: 100.47 - lr: 0.001000\n",
      "2022-08-30 17:05:10,760 epoch 2 - iter 66/67 - loss 1.00980229 - samples/sec: 105.78 - lr: 0.001000\n",
      "2022-08-30 17:05:11,301 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:05:11,302 EPOCH 2 done: loss 1.0098 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:05:12,124 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:05:12,154 DEV : loss 0.8449021577835083 - f1-score (micro avg)  0.7024\n",
      "2022-08-30 17:05:12,173 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:05:12,174 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:05:12,872 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:05:16,185 epoch 3 - iter 6/67 - loss 0.99916579 - samples/sec: 90.58 - lr: 0.001000\n",
      "2022-08-30 17:05:19,015 epoch 3 - iter 12/67 - loss 1.00448526 - samples/sec: 108.77 - lr: 0.001000\n",
      "2022-08-30 17:05:22,060 epoch 3 - iter 18/67 - loss 1.00246675 - samples/sec: 100.60 - lr: 0.001000\n",
      "2022-08-30 17:05:25,448 epoch 3 - iter 24/67 - loss 1.01612921 - samples/sec: 89.96 - lr: 0.001000\n",
      "2022-08-30 17:05:28,589 epoch 3 - iter 30/67 - loss 1.01519091 - samples/sec: 98.07 - lr: 0.001000\n",
      "2022-08-30 17:05:31,702 epoch 3 - iter 36/67 - loss 1.01425275 - samples/sec: 99.04 - lr: 0.001000\n",
      "2022-08-30 17:05:34,869 epoch 3 - iter 42/67 - loss 1.01482957 - samples/sec: 96.93 - lr: 0.001000\n",
      "2022-08-30 17:05:37,861 epoch 3 - iter 48/67 - loss 1.01338848 - samples/sec: 102.21 - lr: 0.001000\n",
      "2022-08-30 17:05:40,666 epoch 3 - iter 54/67 - loss 1.01216759 - samples/sec: 109.17 - lr: 0.001000\n",
      "2022-08-30 17:05:43,412 epoch 3 - iter 60/67 - loss 1.01040913 - samples/sec: 111.69 - lr: 0.001000\n",
      "2022-08-30 17:05:46,461 epoch 3 - iter 66/67 - loss 1.01172396 - samples/sec: 100.81 - lr: 0.001000\n",
      "2022-08-30 17:05:47,026 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:05:47,027 EPOCH 3 done: loss 1.0127 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:05:47,881 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:05:47,912 DEV : loss 0.8430424332618713 - f1-score (micro avg)  0.7024\n",
      "2022-08-30 17:05:47,929 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:05:47,930 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:05:50,674 epoch 4 - iter 6/67 - loss 0.98639101 - samples/sec: 109.37 - lr: 0.001000\n",
      "2022-08-30 17:05:53,829 epoch 4 - iter 12/67 - loss 0.98711109 - samples/sec: 96.99 - lr: 0.001000\n",
      "2022-08-30 17:05:57,291 epoch 4 - iter 18/67 - loss 0.99838659 - samples/sec: 88.03 - lr: 0.001000\n",
      "2022-08-30 17:06:00,327 epoch 4 - iter 24/67 - loss 1.00424739 - samples/sec: 100.60 - lr: 0.001000\n",
      "2022-08-30 17:06:03,399 epoch 4 - iter 30/67 - loss 1.00386255 - samples/sec: 100.00 - lr: 0.001000\n",
      "2022-08-30 17:06:06,380 epoch 4 - iter 36/67 - loss 1.00577719 - samples/sec: 102.95 - lr: 0.001000\n",
      "2022-08-30 17:06:09,669 epoch 4 - iter 42/67 - loss 1.00842464 - samples/sec: 93.46 - lr: 0.001000\n",
      "2022-08-30 17:06:12,838 epoch 4 - iter 48/67 - loss 1.00470952 - samples/sec: 96.34 - lr: 0.001000\n",
      "2022-08-30 17:06:15,673 epoch 4 - iter 54/67 - loss 1.00415691 - samples/sec: 107.99 - lr: 0.001000\n",
      "2022-08-30 17:06:18,575 epoch 4 - iter 60/67 - loss 1.00795727 - samples/sec: 105.45 - lr: 0.001000\n",
      "2022-08-30 17:06:21,757 epoch 4 - iter 66/67 - loss 1.00876959 - samples/sec: 97.02 - lr: 0.001000\n",
      "2022-08-30 17:06:22,181 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:06:22,182 EPOCH 4 done: loss 1.0088 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:06:23,049 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:06:23,082 DEV : loss 0.8402969837188721 - f1-score (micro avg)  0.7042\n",
      "2022-08-30 17:06:23,096 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:06:23,097 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:06:24,296 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:06:27,231 epoch 5 - iter 6/67 - loss 1.02965643 - samples/sec: 102.25 - lr: 0.001000\n",
      "2022-08-30 17:06:30,554 epoch 5 - iter 12/67 - loss 1.02329045 - samples/sec: 91.94 - lr: 0.001000\n",
      "2022-08-30 17:06:33,311 epoch 5 - iter 18/67 - loss 1.02154325 - samples/sec: 111.15 - lr: 0.001000\n",
      "2022-08-30 17:06:36,536 epoch 5 - iter 24/67 - loss 1.02511708 - samples/sec: 94.88 - lr: 0.001000\n",
      "2022-08-30 17:06:39,504 epoch 5 - iter 30/67 - loss 1.02010617 - samples/sec: 103.16 - lr: 0.001000\n",
      "2022-08-30 17:06:42,735 epoch 5 - iter 36/67 - loss 1.01817406 - samples/sec: 94.97 - lr: 0.001000\n",
      "2022-08-30 17:06:45,797 epoch 5 - iter 42/67 - loss 1.01415631 - samples/sec: 99.93 - lr: 0.001000\n",
      "2022-08-30 17:06:48,920 epoch 5 - iter 48/67 - loss 1.01254505 - samples/sec: 97.82 - lr: 0.001000\n",
      "2022-08-30 17:06:51,556 epoch 5 - iter 54/67 - loss 1.01058282 - samples/sec: 117.14 - lr: 0.001000\n",
      "2022-08-30 17:06:54,671 epoch 5 - iter 60/67 - loss 1.01176457 - samples/sec: 98.36 - lr: 0.001000\n",
      "2022-08-30 17:06:57,748 epoch 5 - iter 66/67 - loss 1.01284967 - samples/sec: 99.50 - lr: 0.001000\n",
      "2022-08-30 17:06:58,234 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:06:58,234 EPOCH 5 done: loss 1.0123 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:06:59,081 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:06:59,108 DEV : loss 0.8383892178535461 - f1-score (micro avg)  0.7057\n",
      "2022-08-30 17:06:59,128 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:06:59,129 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:06:59,817 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:07:02,704 epoch 6 - iter 6/67 - loss 1.01462448 - samples/sec: 103.99 - lr: 0.001000\n",
      "2022-08-30 17:07:05,738 epoch 6 - iter 12/67 - loss 1.02013655 - samples/sec: 100.87 - lr: 0.001000\n",
      "2022-08-30 17:07:08,986 epoch 6 - iter 18/67 - loss 1.01238958 - samples/sec: 94.22 - lr: 0.001000\n",
      "2022-08-30 17:07:11,823 epoch 6 - iter 24/67 - loss 1.00756610 - samples/sec: 107.95 - lr: 0.001000\n",
      "2022-08-30 17:07:15,132 epoch 6 - iter 30/67 - loss 1.00528347 - samples/sec: 92.28 - lr: 0.001000\n",
      "2022-08-30 17:07:17,920 epoch 6 - iter 36/67 - loss 1.00930457 - samples/sec: 109.97 - lr: 0.001000\n",
      "2022-08-30 17:07:21,373 epoch 6 - iter 42/67 - loss 1.00795075 - samples/sec: 88.29 - lr: 0.001000\n",
      "2022-08-30 17:07:24,453 epoch 6 - iter 48/67 - loss 1.00614269 - samples/sec: 99.87 - lr: 0.001000\n",
      "2022-08-30 17:07:27,523 epoch 6 - iter 54/67 - loss 1.00760012 - samples/sec: 100.00 - lr: 0.001000\n",
      "2022-08-30 17:07:30,403 epoch 6 - iter 60/67 - loss 1.00998571 - samples/sec: 106.88 - lr: 0.001000\n",
      "2022-08-30 17:07:33,595 epoch 6 - iter 66/67 - loss 1.00790163 - samples/sec: 96.09 - lr: 0.001000\n",
      "2022-08-30 17:07:33,948 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:07:33,948 EPOCH 6 done: loss 1.0079 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:07:34,807 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:07:34,837 DEV : loss 0.8364516496658325 - f1-score (micro avg)  0.7037\n",
      "2022-08-30 17:07:34,852 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:07:34,853 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:07:37,732 epoch 7 - iter 6/67 - loss 1.01539054 - samples/sec: 104.31 - lr: 0.001000\n",
      "2022-08-30 17:07:40,743 epoch 7 - iter 12/67 - loss 1.00112108 - samples/sec: 101.63 - lr: 0.001000\n",
      "2022-08-30 17:07:43,695 epoch 7 - iter 18/67 - loss 1.01514523 - samples/sec: 103.77 - lr: 0.001000\n",
      "2022-08-30 17:07:46,677 epoch 7 - iter 24/67 - loss 1.01022654 - samples/sec: 102.78 - lr: 0.001000\n",
      "2022-08-30 17:07:49,567 epoch 7 - iter 30/67 - loss 1.00881290 - samples/sec: 105.89 - lr: 0.001000\n",
      "2022-08-30 17:07:52,632 epoch 7 - iter 36/67 - loss 1.00420925 - samples/sec: 100.03 - lr: 0.001000\n",
      "2022-08-30 17:07:56,142 epoch 7 - iter 42/67 - loss 1.00278497 - samples/sec: 87.23 - lr: 0.001000\n",
      "2022-08-30 17:07:59,109 epoch 7 - iter 48/67 - loss 1.00201289 - samples/sec: 103.09 - lr: 0.001000\n",
      "2022-08-30 17:08:01,940 epoch 7 - iter 54/67 - loss 1.00615396 - samples/sec: 108.30 - lr: 0.001000\n",
      "2022-08-30 17:08:05,326 epoch 7 - iter 60/67 - loss 1.00361453 - samples/sec: 90.17 - lr: 0.001000\n",
      "2022-08-30 17:08:08,341 epoch 7 - iter 66/67 - loss 1.00230602 - samples/sec: 102.77 - lr: 0.001000\n",
      "2022-08-30 17:08:08,700 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:08:08,701 EPOCH 7 done: loss 1.0028 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:08:09,521 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:08:09,558 DEV : loss 0.8336828351020813 - f1-score (micro avg)  0.7034\n",
      "2022-08-30 17:08:09,576 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 17:08:09,577 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:08:12,799 epoch 8 - iter 6/67 - loss 1.00170734 - samples/sec: 93.17 - lr: 0.001000\n",
      "2022-08-30 17:08:15,869 epoch 8 - iter 12/67 - loss 1.01536802 - samples/sec: 99.70 - lr: 0.001000\n",
      "2022-08-30 17:08:19,106 epoch 8 - iter 18/67 - loss 1.00126106 - samples/sec: 94.46 - lr: 0.001000\n",
      "2022-08-30 17:08:22,126 epoch 8 - iter 24/67 - loss 1.00925376 - samples/sec: 101.32 - lr: 0.001000\n",
      "2022-08-30 17:08:24,975 epoch 8 - iter 30/67 - loss 1.01159079 - samples/sec: 107.41 - lr: 0.001000\n",
      "2022-08-30 17:08:27,932 epoch 8 - iter 36/67 - loss 1.00683309 - samples/sec: 103.66 - lr: 0.001000\n",
      "2022-08-30 17:08:31,038 epoch 8 - iter 42/67 - loss 1.00954510 - samples/sec: 98.36 - lr: 0.001000\n",
      "2022-08-30 17:08:34,030 epoch 8 - iter 48/67 - loss 1.00787623 - samples/sec: 102.28 - lr: 0.001000\n",
      "2022-08-30 17:08:37,053 epoch 8 - iter 54/67 - loss 1.00697126 - samples/sec: 101.28 - lr: 0.001000\n",
      "2022-08-30 17:08:40,198 epoch 8 - iter 60/67 - loss 1.00650606 - samples/sec: 97.06 - lr: 0.001000\n",
      "2022-08-30 17:08:43,200 epoch 8 - iter 66/67 - loss 1.00495732 - samples/sec: 102.08 - lr: 0.001000\n",
      "2022-08-30 17:08:43,628 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:08:43,628 EPOCH 8 done: loss 1.0054 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:08:44,450 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:08:44,478 DEV : loss 0.8320233821868896 - f1-score (micro avg)  0.7055\n",
      "2022-08-30 17:08:44,494 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 17:08:44,495 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:08:47,347 epoch 9 - iter 6/67 - loss 1.03395450 - samples/sec: 105.26 - lr: 0.001000\n",
      "2022-08-30 17:08:50,623 epoch 9 - iter 12/67 - loss 1.02378799 - samples/sec: 94.67 - lr: 0.001000\n",
      "2022-08-30 17:08:54,061 epoch 9 - iter 18/67 - loss 1.00345003 - samples/sec: 88.78 - lr: 0.001000\n",
      "2022-08-30 17:08:57,019 epoch 9 - iter 24/67 - loss 1.00368407 - samples/sec: 103.31 - lr: 0.001000\n",
      "2022-08-30 17:08:59,953 epoch 9 - iter 30/67 - loss 0.99946535 - samples/sec: 104.49 - lr: 0.001000\n",
      "2022-08-30 17:09:03,106 epoch 9 - iter 36/67 - loss 0.99816859 - samples/sec: 97.12 - lr: 0.001000\n",
      "2022-08-30 17:09:06,156 epoch 9 - iter 42/67 - loss 0.99564955 - samples/sec: 100.33 - lr: 0.001000\n",
      "2022-08-30 17:09:09,294 epoch 9 - iter 48/67 - loss 0.99952991 - samples/sec: 97.31 - lr: 0.001000\n",
      "2022-08-30 17:09:12,121 epoch 9 - iter 54/67 - loss 0.99811121 - samples/sec: 108.26 - lr: 0.001000\n",
      "2022-08-30 17:09:15,405 epoch 9 - iter 60/67 - loss 1.00018576 - samples/sec: 92.88 - lr: 0.001000\n",
      "2022-08-30 17:09:18,346 epoch 9 - iter 66/67 - loss 0.99876859 - samples/sec: 104.82 - lr: 0.001000\n",
      "2022-08-30 17:09:18,766 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:09:18,766 EPOCH 9 done: loss 0.9987 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:09:19,591 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:09:19,619 DEV : loss 0.8303889036178589 - f1-score (micro avg)  0.7079\n",
      "2022-08-30 17:09:19,635 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:09:19,636 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:09:20,312 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:09:23,134 epoch 10 - iter 6/67 - loss 0.98203378 - samples/sec: 106.35 - lr: 0.001000\n",
      "2022-08-30 17:09:26,192 epoch 10 - iter 12/67 - loss 0.98580468 - samples/sec: 100.03 - lr: 0.001000\n",
      "2022-08-30 17:09:29,339 epoch 10 - iter 18/67 - loss 0.99501569 - samples/sec: 97.09 - lr: 0.001000\n",
      "2022-08-30 17:09:32,737 epoch 10 - iter 24/67 - loss 0.99454182 - samples/sec: 90.20 - lr: 0.001000\n",
      "2022-08-30 17:09:35,659 epoch 10 - iter 30/67 - loss 0.98941669 - samples/sec: 104.68 - lr: 0.001000\n",
      "2022-08-30 17:09:38,856 epoch 10 - iter 36/67 - loss 0.99150791 - samples/sec: 95.54 - lr: 0.001000\n",
      "2022-08-30 17:09:41,889 epoch 10 - iter 42/67 - loss 0.99213533 - samples/sec: 100.81 - lr: 0.001000\n",
      "2022-08-30 17:09:44,829 epoch 10 - iter 48/67 - loss 0.99326108 - samples/sec: 104.02 - lr: 0.001000\n",
      "2022-08-30 17:09:47,925 epoch 10 - iter 54/67 - loss 0.99317254 - samples/sec: 98.81 - lr: 0.001000\n",
      "2022-08-30 17:09:51,034 epoch 10 - iter 60/67 - loss 0.99249157 - samples/sec: 98.30 - lr: 0.001000\n",
      "2022-08-30 17:09:54,098 epoch 10 - iter 66/67 - loss 0.99406749 - samples/sec: 99.90 - lr: 0.001000\n",
      "2022-08-30 17:09:54,485 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:09:54,486 EPOCH 10 done: loss 0.9942 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:09:55,289 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:09:55,315 DEV : loss 0.8274317383766174 - f1-score (micro avg)  0.7078\n",
      "2022-08-30 17:09:55,330 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:09:56,029 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:09:56,030 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 17:09:56,199 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:09:57,576 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:09:57,599 0.7192\t0.7192\t0.7192\t0.7192\n",
      "2022-08-30 17:09:57,599 \n",
      "Results:\n",
      "- F-score (micro) 0.7192\n",
      "- F-score (macro) 0.5537\n",
      "- Accuracy 0.7192\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6368    0.7568    0.6917      1353\n",
      "         ADJ     0.5172    0.6949    0.5930       672\n",
      "       PUNCT     0.9805    0.9924    0.9864       660\n",
      "         ADP     0.8696    0.9086    0.8887       514\n",
      "        VERB     0.5947    0.5523    0.5727       449\n",
      "         AUX     0.8860    0.8119    0.8474       335\n",
      "       PROPN     0.7692    0.3655    0.4956       383\n",
      "       CCONJ     0.9843    0.9792    0.9817       192\n",
      "       SCONJ     0.8750    0.8750    0.8750       184\n",
      "         DET     0.5600    0.3478    0.4291       161\n",
      "         ADV     0.2143    0.0795    0.1159       151\n",
      "        PRON     0.9000    0.7043    0.7902       115\n",
      "         NUM     0.7143    0.1408    0.2353        71\n",
      "        PART     0.7143    0.2381    0.3571        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7192      5264\n",
      "   macro avg     0.6385    0.5280    0.5537      5264\n",
      "weighted avg     0.7225    0.7192    0.7075      5264\n",
      "\n",
      "2022-08-30 17:09:57,600 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:09:57,602 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:09:58,094 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 17:12:19,706 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:12:19,707 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 17:12:19,707 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:12:19,708 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 17:12:19,709 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:12:19,709 Parameters:\n",
      "2022-08-30 17:12:19,710  - learning_rate: \"0.001000\"\n",
      "2022-08-30 17:12:19,710  - mini_batch_size: \"50\"\n",
      "2022-08-30 17:12:19,711  - patience: \"3\"\n",
      "2022-08-30 17:12:19,711  - anneal_factor: \"0.5\"\n",
      "2022-08-30 17:12:19,712  - max_epochs: \"11\"\n",
      "2022-08-30 17:12:19,712  - shuffle: \"True\"\n",
      "2022-08-30 17:12:19,713  - train_with_dev: \"False\"\n",
      "2022-08-30 17:12:19,713  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 17:12:19,713 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:12:19,714 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 17:12:19,715 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:12:19,715 Device: cpu\n",
      "2022-08-30 17:12:19,716 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:12:19,716 Embeddings storage mode: cpu\n",
      "2022-08-30 17:12:19,717 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:12:22,558 epoch 1 - iter 6/67 - loss 0.98216827 - samples/sec: 105.60 - lr: 0.001000\n",
      "2022-08-30 17:12:25,776 epoch 1 - iter 12/67 - loss 0.97352504 - samples/sec: 95.36 - lr: 0.001000\n",
      "2022-08-30 17:12:28,552 epoch 1 - iter 18/67 - loss 0.96315775 - samples/sec: 110.50 - lr: 0.001000\n",
      "2022-08-30 17:12:31,258 epoch 1 - iter 24/67 - loss 0.97692664 - samples/sec: 113.64 - lr: 0.001000\n",
      "2022-08-30 17:12:34,266 epoch 1 - iter 30/67 - loss 0.97548293 - samples/sec: 101.52 - lr: 0.001000\n",
      "2022-08-30 17:12:37,266 epoch 1 - iter 36/67 - loss 0.97478493 - samples/sec: 102.21 - lr: 0.001000\n",
      "2022-08-30 17:12:40,248 epoch 1 - iter 42/67 - loss 0.97496928 - samples/sec: 102.85 - lr: 0.001000\n",
      "2022-08-30 17:12:43,091 epoch 1 - iter 48/67 - loss 0.97369319 - samples/sec: 107.60 - lr: 0.001000\n",
      "2022-08-30 17:12:45,839 epoch 1 - iter 54/67 - loss 0.97416221 - samples/sec: 111.57 - lr: 0.001000\n",
      "2022-08-30 17:12:48,976 epoch 1 - iter 60/67 - loss 0.97850343 - samples/sec: 97.53 - lr: 0.001000\n",
      "2022-08-30 17:12:52,312 epoch 1 - iter 66/67 - loss 0.99699453 - samples/sec: 91.60 - lr: 0.001000\n",
      "2022-08-30 17:12:52,852 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:12:52,853 EPOCH 1 done: loss 0.9979 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:12:53,675 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:12:53,701 DEV : loss 0.8345589637756348 - f1-score (micro avg)  0.7089\n",
      "2022-08-30 17:12:53,722 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:12:53,723 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:12:54,436 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:12:57,710 epoch 2 - iter 6/67 - loss 1.01596162 - samples/sec: 91.66 - lr: 0.001000\n",
      "2022-08-30 17:13:00,580 epoch 2 - iter 12/67 - loss 1.00929848 - samples/sec: 107.22 - lr: 0.001000\n",
      "2022-08-30 17:13:03,961 epoch 2 - iter 18/67 - loss 1.00906803 - samples/sec: 90.50 - lr: 0.001000\n",
      "2022-08-30 17:13:07,162 epoch 2 - iter 24/67 - loss 1.01425061 - samples/sec: 95.48 - lr: 0.001000\n",
      "2022-08-30 17:13:09,925 epoch 2 - iter 30/67 - loss 1.00722746 - samples/sec: 111.07 - lr: 0.001000\n",
      "2022-08-30 17:13:12,742 epoch 2 - iter 36/67 - loss 1.00694887 - samples/sec: 108.73 - lr: 0.001000\n",
      "2022-08-30 17:13:15,913 epoch 2 - iter 42/67 - loss 1.00531669 - samples/sec: 96.34 - lr: 0.001000\n",
      "2022-08-30 17:13:19,053 epoch 2 - iter 48/67 - loss 0.99956895 - samples/sec: 97.43 - lr: 0.001000\n",
      "2022-08-30 17:13:21,715 epoch 2 - iter 54/67 - loss 1.00232668 - samples/sec: 115.12 - lr: 0.001000\n",
      "2022-08-30 17:13:24,584 epoch 2 - iter 60/67 - loss 0.99955867 - samples/sec: 106.69 - lr: 0.001000\n",
      "2022-08-30 17:13:27,973 epoch 2 - iter 66/67 - loss 0.99999849 - samples/sec: 90.17 - lr: 0.001000\n",
      "2022-08-30 17:13:28,418 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:13:28,419 EPOCH 2 done: loss 0.9998 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:13:29,264 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:13:29,300 DEV : loss 0.8264605402946472 - f1-score (micro avg)  0.7076\n",
      "2022-08-30 17:13:29,319 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:13:29,320 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:13:32,212 epoch 3 - iter 6/67 - loss 0.97927343 - samples/sec: 103.81 - lr: 0.001000\n",
      "2022-08-30 17:13:34,996 epoch 3 - iter 12/67 - loss 0.97869176 - samples/sec: 110.09 - lr: 0.001000\n",
      "2022-08-30 17:13:38,126 epoch 3 - iter 18/67 - loss 0.98483917 - samples/sec: 97.72 - lr: 0.001000\n",
      "2022-08-30 17:13:41,083 epoch 3 - iter 24/67 - loss 0.98089841 - samples/sec: 103.38 - lr: 0.001000\n",
      "2022-08-30 17:13:44,553 epoch 3 - iter 30/67 - loss 0.98641136 - samples/sec: 87.87 - lr: 0.001000\n",
      "2022-08-30 17:13:47,368 epoch 3 - iter 36/67 - loss 0.98990441 - samples/sec: 108.77 - lr: 0.001000\n",
      "2022-08-30 17:13:50,321 epoch 3 - iter 42/67 - loss 0.99457723 - samples/sec: 104.09 - lr: 0.001000\n",
      "2022-08-30 17:13:53,215 epoch 3 - iter 48/67 - loss 0.99319683 - samples/sec: 106.16 - lr: 0.001000\n",
      "2022-08-30 17:13:56,592 epoch 3 - iter 54/67 - loss 0.99444302 - samples/sec: 90.44 - lr: 0.001000\n",
      "2022-08-30 17:13:59,827 epoch 3 - iter 60/67 - loss 0.99542409 - samples/sec: 94.34 - lr: 0.001000\n",
      "2022-08-30 17:14:02,956 epoch 3 - iter 66/67 - loss 0.99650473 - samples/sec: 97.72 - lr: 0.001000\n",
      "2022-08-30 17:14:03,357 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:14:03,358 EPOCH 3 done: loss 0.9961 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:14:05,502 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:14:05,537 DEV : loss 0.8241419792175293 - f1-score (micro avg)  0.7086\n",
      "2022-08-30 17:14:05,556 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 17:14:05,558 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:14:08,751 epoch 4 - iter 6/67 - loss 1.00756285 - samples/sec: 93.98 - lr: 0.001000\n",
      "2022-08-30 17:14:11,989 epoch 4 - iter 12/67 - loss 1.00228933 - samples/sec: 94.46 - lr: 0.001000\n",
      "2022-08-30 17:14:15,152 epoch 4 - iter 18/67 - loss 1.00043078 - samples/sec: 96.77 - lr: 0.001000\n",
      "2022-08-30 17:14:18,257 epoch 4 - iter 24/67 - loss 1.00372413 - samples/sec: 98.78 - lr: 0.001000\n",
      "2022-08-30 17:14:21,336 epoch 4 - iter 30/67 - loss 1.00410227 - samples/sec: 99.44 - lr: 0.001000\n",
      "2022-08-30 17:14:24,346 epoch 4 - iter 36/67 - loss 0.99726980 - samples/sec: 102.49 - lr: 0.001000\n",
      "2022-08-30 17:14:27,637 epoch 4 - iter 42/67 - loss 1.00007775 - samples/sec: 94.76 - lr: 0.001000\n",
      "2022-08-30 17:14:30,291 epoch 4 - iter 48/67 - loss 0.99493347 - samples/sec: 115.79 - lr: 0.001000\n",
      "2022-08-30 17:14:33,148 epoch 4 - iter 54/67 - loss 0.99320504 - samples/sec: 107.30 - lr: 0.001000\n",
      "2022-08-30 17:14:36,205 epoch 4 - iter 60/67 - loss 0.99346780 - samples/sec: 99.93 - lr: 0.001000\n",
      "2022-08-30 17:14:39,069 epoch 4 - iter 66/67 - loss 0.99458471 - samples/sec: 106.84 - lr: 0.001000\n",
      "2022-08-30 17:14:39,531 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:14:39,532 EPOCH 4 done: loss 0.9946 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:14:40,358 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:14:40,394 DEV : loss 0.822037398815155 - f1-score (micro avg)  0.7099\n",
      "2022-08-30 17:14:40,410 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:14:40,411 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:14:41,091 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:14:44,063 epoch 5 - iter 6/67 - loss 1.01152737 - samples/sec: 100.98 - lr: 0.001000\n",
      "2022-08-30 17:14:47,057 epoch 5 - iter 12/67 - loss 0.98815195 - samples/sec: 102.25 - lr: 0.001000\n",
      "2022-08-30 17:14:49,948 epoch 5 - iter 18/67 - loss 0.99659635 - samples/sec: 106.01 - lr: 0.001000\n",
      "2022-08-30 17:14:53,003 epoch 5 - iter 24/67 - loss 0.99510232 - samples/sec: 100.17 - lr: 0.001000\n",
      "2022-08-30 17:14:55,979 epoch 5 - iter 30/67 - loss 0.99789319 - samples/sec: 103.09 - lr: 0.001000\n",
      "2022-08-30 17:14:58,834 epoch 5 - iter 36/67 - loss 0.99765069 - samples/sec: 107.37 - lr: 0.001000\n",
      "2022-08-30 17:15:01,789 epoch 5 - iter 42/67 - loss 0.99395512 - samples/sec: 103.52 - lr: 0.001000\n",
      "2022-08-30 17:15:04,626 epoch 5 - iter 48/67 - loss 0.98995409 - samples/sec: 108.15 - lr: 0.001000\n",
      "2022-08-30 17:15:07,497 epoch 5 - iter 54/67 - loss 0.98817147 - samples/sec: 107.33 - lr: 0.001000\n",
      "2022-08-30 17:15:11,313 epoch 5 - iter 60/67 - loss 0.99167393 - samples/sec: 80.09 - lr: 0.001000\n",
      "2022-08-30 17:15:14,258 epoch 5 - iter 66/67 - loss 0.99065290 - samples/sec: 104.28 - lr: 0.001000\n",
      "2022-08-30 17:15:14,668 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:15:14,669 EPOCH 5 done: loss 0.9908 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:15:15,484 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:15:15,514 DEV : loss 0.8214399218559265 - f1-score (micro avg)  0.7099\n",
      "2022-08-30 17:15:15,529 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:15:15,530 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:15:18,467 epoch 6 - iter 6/67 - loss 0.98927792 - samples/sec: 102.18 - lr: 0.001000\n",
      "2022-08-30 17:15:21,250 epoch 6 - iter 12/67 - loss 0.98391724 - samples/sec: 110.58 - lr: 0.001000\n",
      "2022-08-30 17:15:24,984 epoch 6 - iter 18/67 - loss 0.99258357 - samples/sec: 81.79 - lr: 0.001000\n",
      "2022-08-30 17:15:28,167 epoch 6 - iter 24/67 - loss 0.98711689 - samples/sec: 96.06 - lr: 0.001000\n",
      "2022-08-30 17:15:31,134 epoch 6 - iter 30/67 - loss 0.98930449 - samples/sec: 103.23 - lr: 0.001000\n",
      "2022-08-30 17:15:34,133 epoch 6 - iter 36/67 - loss 0.98923555 - samples/sec: 102.08 - lr: 0.001000\n",
      "2022-08-30 17:15:36,857 epoch 6 - iter 42/67 - loss 0.99085713 - samples/sec: 112.53 - lr: 0.001000\n",
      "2022-08-30 17:15:39,843 epoch 6 - iter 48/67 - loss 0.99171653 - samples/sec: 102.63 - lr: 0.001000\n",
      "2022-08-30 17:15:43,120 epoch 6 - iter 54/67 - loss 0.99251793 - samples/sec: 93.20 - lr: 0.001000\n",
      "2022-08-30 17:15:45,984 epoch 6 - iter 60/67 - loss 0.99331964 - samples/sec: 106.91 - lr: 0.001000\n",
      "2022-08-30 17:15:49,057 epoch 6 - iter 66/67 - loss 0.99040542 - samples/sec: 99.60 - lr: 0.001000\n",
      "2022-08-30 17:15:49,400 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:15:49,400 EPOCH 6 done: loss 0.9906 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:15:50,216 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:15:50,246 DEV : loss 0.8176887631416321 - f1-score (micro avg)  0.7091\n",
      "2022-08-30 17:15:50,265 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:15:50,266 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:15:53,630 epoch 7 - iter 6/67 - loss 0.99146385 - samples/sec: 89.23 - lr: 0.001000\n",
      "2022-08-30 17:15:56,475 epoch 7 - iter 12/67 - loss 0.97881519 - samples/sec: 107.84 - lr: 0.001000\n",
      "2022-08-30 17:15:59,557 epoch 7 - iter 18/67 - loss 0.97979122 - samples/sec: 99.73 - lr: 0.001000\n",
      "2022-08-30 17:16:02,367 epoch 7 - iter 24/67 - loss 0.98040921 - samples/sec: 110.05 - lr: 0.001000\n",
      "2022-08-30 17:16:05,785 epoch 7 - iter 30/67 - loss 0.97680248 - samples/sec: 90.66 - lr: 0.001000\n",
      "2022-08-30 17:16:08,784 epoch 7 - iter 36/67 - loss 0.98210198 - samples/sec: 102.35 - lr: 0.001000\n",
      "2022-08-30 17:16:11,705 epoch 7 - iter 42/67 - loss 0.98112931 - samples/sec: 104.75 - lr: 0.001000\n",
      "2022-08-30 17:16:14,550 epoch 7 - iter 48/67 - loss 0.98119782 - samples/sec: 107.72 - lr: 0.001000\n",
      "2022-08-30 17:16:17,650 epoch 7 - iter 54/67 - loss 0.98028353 - samples/sec: 98.65 - lr: 0.001000\n",
      "2022-08-30 17:16:20,672 epoch 7 - iter 60/67 - loss 0.98391043 - samples/sec: 101.45 - lr: 0.001000\n",
      "2022-08-30 17:16:23,951 epoch 7 - iter 66/67 - loss 0.98377162 - samples/sec: 93.20 - lr: 0.001000\n",
      "2022-08-30 17:16:24,426 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:16:24,427 EPOCH 7 done: loss 0.9836 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:16:25,297 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:16:25,333 DEV : loss 0.8166335821151733 - f1-score (micro avg)  0.7122\n",
      "2022-08-30 17:16:25,349 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:16:25,351 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:16:26,247 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:16:29,109 epoch 8 - iter 6/67 - loss 0.98656940 - samples/sec: 104.90 - lr: 0.001000\n",
      "2022-08-30 17:16:32,334 epoch 8 - iter 12/67 - loss 0.97948606 - samples/sec: 94.73 - lr: 0.001000\n",
      "2022-08-30 17:16:35,334 epoch 8 - iter 18/67 - loss 0.97553821 - samples/sec: 102.53 - lr: 0.001000\n",
      "2022-08-30 17:16:38,380 epoch 8 - iter 24/67 - loss 0.98308213 - samples/sec: 100.77 - lr: 0.001000\n",
      "2022-08-30 17:16:41,590 epoch 8 - iter 30/67 - loss 0.98520030 - samples/sec: 96.09 - lr: 0.001000\n",
      "2022-08-30 17:16:44,988 epoch 8 - iter 36/67 - loss 0.98150483 - samples/sec: 89.96 - lr: 0.001000\n",
      "2022-08-30 17:16:48,023 epoch 8 - iter 42/67 - loss 0.97995294 - samples/sec: 100.91 - lr: 0.001000\n",
      "2022-08-30 17:16:50,945 epoch 8 - iter 48/67 - loss 0.98044730 - samples/sec: 104.86 - lr: 0.001000\n",
      "2022-08-30 17:16:53,961 epoch 8 - iter 54/67 - loss 0.97849924 - samples/sec: 101.35 - lr: 0.001000\n",
      "2022-08-30 17:16:56,856 epoch 8 - iter 60/67 - loss 0.97936307 - samples/sec: 105.71 - lr: 0.001000\n",
      "2022-08-30 17:17:00,081 epoch 8 - iter 66/67 - loss 0.97900103 - samples/sec: 94.64 - lr: 0.001000\n",
      "2022-08-30 17:17:00,515 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:17:00,515 EPOCH 8 done: loss 0.9788 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:17:01,344 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:17:01,383 DEV : loss 0.8153910040855408 - f1-score (micro avg)  0.7113\n",
      "2022-08-30 17:17:01,402 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:17:01,404 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:17:04,221 epoch 9 - iter 6/67 - loss 0.99943963 - samples/sec: 106.57 - lr: 0.001000\n",
      "2022-08-30 17:17:07,316 epoch 9 - iter 12/67 - loss 0.98686721 - samples/sec: 98.85 - lr: 0.001000\n",
      "2022-08-30 17:17:10,177 epoch 9 - iter 18/67 - loss 0.99161784 - samples/sec: 107.60 - lr: 0.001000\n",
      "2022-08-30 17:17:13,561 epoch 9 - iter 24/67 - loss 0.98360245 - samples/sec: 90.25 - lr: 0.001000\n",
      "2022-08-30 17:17:16,758 epoch 9 - iter 30/67 - loss 0.98266074 - samples/sec: 95.66 - lr: 0.001000\n",
      "2022-08-30 17:17:19,982 epoch 9 - iter 36/67 - loss 0.98044010 - samples/sec: 94.64 - lr: 0.001000\n",
      "2022-08-30 17:17:22,871 epoch 9 - iter 42/67 - loss 0.98150568 - samples/sec: 106.23 - lr: 0.001000\n",
      "2022-08-30 17:17:25,987 epoch 9 - iter 48/67 - loss 0.98205596 - samples/sec: 98.17 - lr: 0.001000\n",
      "2022-08-30 17:17:28,904 epoch 9 - iter 54/67 - loss 0.98207776 - samples/sec: 104.90 - lr: 0.001000\n",
      "2022-08-30 17:17:31,987 epoch 9 - iter 60/67 - loss 0.98380884 - samples/sec: 99.11 - lr: 0.001000\n",
      "2022-08-30 17:17:34,917 epoch 9 - iter 66/67 - loss 0.98537798 - samples/sec: 104.42 - lr: 0.001000\n",
      "2022-08-30 17:17:35,289 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:17:35,289 EPOCH 9 done: loss 0.9866 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:17:36,144 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:17:36,180 DEV : loss 0.813431441783905 - f1-score (micro avg)  0.7135\n",
      "2022-08-30 17:17:36,200 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:17:36,201 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:17:36,914 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:17:39,780 epoch 10 - iter 6/67 - loss 0.97656933 - samples/sec: 104.75 - lr: 0.001000\n",
      "2022-08-30 17:17:42,892 epoch 10 - iter 12/67 - loss 0.97197351 - samples/sec: 98.26 - lr: 0.001000\n",
      "2022-08-30 17:17:45,868 epoch 10 - iter 18/67 - loss 0.98456309 - samples/sec: 102.92 - lr: 0.001000\n",
      "2022-08-30 17:17:49,126 epoch 10 - iter 24/67 - loss 0.98113498 - samples/sec: 93.81 - lr: 0.001000\n",
      "2022-08-30 17:17:52,205 epoch 10 - iter 30/67 - loss 0.98146365 - samples/sec: 99.47 - lr: 0.001000\n",
      "2022-08-30 17:17:55,249 epoch 10 - iter 36/67 - loss 0.98097475 - samples/sec: 100.40 - lr: 0.001000\n",
      "2022-08-30 17:17:57,954 epoch 10 - iter 42/67 - loss 0.97795407 - samples/sec: 113.25 - lr: 0.001000\n",
      "2022-08-30 17:18:01,102 epoch 10 - iter 48/67 - loss 0.97826148 - samples/sec: 97.21 - lr: 0.001000\n",
      "2022-08-30 17:18:04,044 epoch 10 - iter 54/67 - loss 0.98084177 - samples/sec: 104.09 - lr: 0.001000\n",
      "2022-08-30 17:18:07,141 epoch 10 - iter 60/67 - loss 0.98052992 - samples/sec: 98.72 - lr: 0.001000\n",
      "2022-08-30 17:18:10,158 epoch 10 - iter 66/67 - loss 0.98189009 - samples/sec: 101.45 - lr: 0.001000\n",
      "2022-08-30 17:18:10,629 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:18:10,630 EPOCH 10 done: loss 0.9822 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:18:11,441 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:18:11,474 DEV : loss 0.811368465423584 - f1-score (micro avg)  0.7138\n",
      "2022-08-30 17:18:11,490 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:18:11,491 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:18:12,188 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:18:15,442 epoch 11 - iter 6/67 - loss 0.99373377 - samples/sec: 92.22 - lr: 0.001000\n",
      "2022-08-30 17:18:18,332 epoch 11 - iter 12/67 - loss 0.97627408 - samples/sec: 106.42 - lr: 0.001000\n",
      "2022-08-30 17:18:21,243 epoch 11 - iter 18/67 - loss 0.98798152 - samples/sec: 105.71 - lr: 0.001000\n",
      "2022-08-30 17:18:24,165 epoch 11 - iter 24/67 - loss 0.99521859 - samples/sec: 104.86 - lr: 0.001000\n",
      "2022-08-30 17:18:27,104 epoch 11 - iter 30/67 - loss 0.99026645 - samples/sec: 104.24 - lr: 0.001000\n",
      "2022-08-30 17:18:30,577 epoch 11 - iter 36/67 - loss 0.98666075 - samples/sec: 87.87 - lr: 0.001000\n",
      "2022-08-30 17:18:33,481 epoch 11 - iter 42/67 - loss 0.98466264 - samples/sec: 105.41 - lr: 0.001000\n",
      "2022-08-30 17:18:36,449 epoch 11 - iter 48/67 - loss 0.98411697 - samples/sec: 103.31 - lr: 0.001000\n",
      "2022-08-30 17:18:39,349 epoch 11 - iter 54/67 - loss 0.98599490 - samples/sec: 105.97 - lr: 0.001000\n",
      "2022-08-30 17:18:42,657 epoch 11 - iter 60/67 - loss 0.98651338 - samples/sec: 93.57 - lr: 0.001000\n",
      "2022-08-30 17:18:45,820 epoch 11 - iter 66/67 - loss 0.98448229 - samples/sec: 96.93 - lr: 0.001000\n",
      "2022-08-30 17:18:46,190 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:18:46,190 EPOCH 11 done: loss 0.9843 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:18:47,040 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:18:47,071 DEV : loss 0.8094101548194885 - f1-score (micro avg)  0.7141\n",
      "2022-08-30 17:18:47,085 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:18:47,086 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:18:48,543 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:18:48,544 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 17:18:48,725 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:18:50,122 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:18:50,148 0.724\t0.724\t0.724\t0.724\n",
      "2022-08-30 17:18:50,149 \n",
      "Results:\n",
      "- F-score (micro) 0.724\n",
      "- F-score (macro) 0.5684\n",
      "- Accuracy 0.724\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6419    0.7524    0.6928      1353\n",
      "         ADJ     0.5176    0.7009    0.5954       672\n",
      "       PUNCT     0.9820    0.9924    0.9872       660\n",
      "         ADP     0.8755    0.9163    0.8954       514\n",
      "        VERB     0.6103    0.5546    0.5811       449\n",
      "         AUX     0.8871    0.8209    0.8527       335\n",
      "       PROPN     0.7730    0.3734    0.5035       383\n",
      "       CCONJ     0.9895    0.9844    0.9869       192\n",
      "       SCONJ     0.8895    0.8750    0.8822       184\n",
      "         DET     0.5888    0.3913    0.4701       161\n",
      "         ADV     0.2273    0.0993    0.1382       151\n",
      "        PRON     0.9011    0.7130    0.7961       115\n",
      "         NUM     0.8125    0.1831    0.2989        71\n",
      "        PART     0.7500    0.2857    0.4138        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7240      5264\n",
      "   macro avg     0.6529    0.5402    0.5684      5264\n",
      "weighted avg     0.7298    0.7240    0.7140      5264\n",
      "\n",
      "2022-08-30 17:18:50,149 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:18:50,154 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:18:50,659 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 17:21:06,425 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:21:06,426 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 17:21:06,426 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:21:06,427 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 17:21:06,427 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:21:06,427 Parameters:\n",
      "2022-08-30 17:21:06,428  - learning_rate: \"0.001000\"\n",
      "2022-08-30 17:21:06,429  - mini_batch_size: \"50\"\n",
      "2022-08-30 17:21:06,429  - patience: \"3\"\n",
      "2022-08-30 17:21:06,430  - anneal_factor: \"0.5\"\n",
      "2022-08-30 17:21:06,430  - max_epochs: \"12\"\n",
      "2022-08-30 17:21:06,431  - shuffle: \"True\"\n",
      "2022-08-30 17:21:06,431  - train_with_dev: \"False\"\n",
      "2022-08-30 17:21:06,431  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 17:21:06,432 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:21:06,433 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 17:21:06,433 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:21:06,434 Device: cpu\n",
      "2022-08-30 17:21:06,434 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:21:06,435 Embeddings storage mode: cpu\n",
      "2022-08-30 17:21:06,435 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:21:09,255 epoch 1 - iter 6/67 - loss 0.95099977 - samples/sec: 106.42 - lr: 0.001000\n",
      "2022-08-30 17:21:12,436 epoch 1 - iter 12/67 - loss 0.94258593 - samples/sec: 96.12 - lr: 0.001000\n",
      "2022-08-30 17:21:15,243 epoch 1 - iter 18/67 - loss 0.94102070 - samples/sec: 109.65 - lr: 0.001000\n",
      "2022-08-30 17:21:17,992 epoch 1 - iter 24/67 - loss 0.95671913 - samples/sec: 111.40 - lr: 0.001000\n",
      "2022-08-30 17:21:21,023 epoch 1 - iter 30/67 - loss 0.95210858 - samples/sec: 101.04 - lr: 0.001000\n",
      "2022-08-30 17:21:24,055 epoch 1 - iter 36/67 - loss 0.95239393 - samples/sec: 100.94 - lr: 0.001000\n",
      "2022-08-30 17:21:26,979 epoch 1 - iter 42/67 - loss 0.95352100 - samples/sec: 104.82 - lr: 0.001000\n",
      "2022-08-30 17:21:29,793 epoch 1 - iter 48/67 - loss 0.95452630 - samples/sec: 110.09 - lr: 0.001000\n",
      "2022-08-30 17:21:32,519 epoch 1 - iter 54/67 - loss 0.95508169 - samples/sec: 112.53 - lr: 0.001000\n",
      "2022-08-30 17:21:35,669 epoch 1 - iter 60/67 - loss 0.96051544 - samples/sec: 97.69 - lr: 0.001000\n",
      "2022-08-30 17:21:39,023 epoch 1 - iter 66/67 - loss 0.97894074 - samples/sec: 91.16 - lr: 0.001000\n",
      "2022-08-30 17:21:39,498 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:21:39,498 EPOCH 1 done: loss 0.9798 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:21:40,302 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:21:40,332 DEV : loss 0.813499391078949 - f1-score (micro avg)  0.7156\n",
      "2022-08-30 17:21:40,348 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:21:40,349 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:21:41,130 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:21:44,279 epoch 2 - iter 6/67 - loss 0.98420414 - samples/sec: 95.36 - lr: 0.001000\n",
      "2022-08-30 17:21:47,478 epoch 2 - iter 12/67 - loss 0.98892575 - samples/sec: 95.42 - lr: 0.001000\n",
      "2022-08-30 17:21:50,936 epoch 2 - iter 18/67 - loss 0.99002689 - samples/sec: 88.42 - lr: 0.001000\n",
      "2022-08-30 17:21:53,675 epoch 2 - iter 24/67 - loss 0.98430050 - samples/sec: 111.77 - lr: 0.001000\n",
      "2022-08-30 17:21:56,784 epoch 2 - iter 30/67 - loss 0.98280762 - samples/sec: 98.43 - lr: 0.001000\n",
      "2022-08-30 17:21:59,890 epoch 2 - iter 36/67 - loss 0.97848505 - samples/sec: 98.49 - lr: 0.001000\n",
      "2022-08-30 17:22:03,308 epoch 2 - iter 42/67 - loss 0.98112970 - samples/sec: 89.29 - lr: 0.001000\n",
      "2022-08-30 17:22:06,251 epoch 2 - iter 48/67 - loss 0.98168718 - samples/sec: 104.24 - lr: 0.001000\n",
      "2022-08-30 17:22:09,210 epoch 2 - iter 54/67 - loss 0.97961190 - samples/sec: 103.45 - lr: 0.001000\n",
      "2022-08-30 17:22:12,321 epoch 2 - iter 60/67 - loss 0.98037183 - samples/sec: 98.26 - lr: 0.001000\n",
      "2022-08-30 17:22:15,328 epoch 2 - iter 66/67 - loss 0.98347754 - samples/sec: 102.08 - lr: 0.001000\n",
      "2022-08-30 17:22:15,738 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:22:15,739 EPOCH 2 done: loss 0.9835 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:22:16,562 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:22:16,597 DEV : loss 0.8059108853340149 - f1-score (micro avg)  0.7147\n",
      "2022-08-30 17:22:16,618 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:22:16,619 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:22:19,557 epoch 3 - iter 6/67 - loss 0.99765475 - samples/sec: 102.18 - lr: 0.001000\n",
      "2022-08-30 17:22:22,714 epoch 3 - iter 12/67 - loss 1.01142717 - samples/sec: 97.15 - lr: 0.001000\n",
      "2022-08-30 17:22:25,560 epoch 3 - iter 18/67 - loss 1.00487764 - samples/sec: 107.72 - lr: 0.001000\n",
      "2022-08-30 17:22:28,661 epoch 3 - iter 24/67 - loss 0.99988114 - samples/sec: 98.62 - lr: 0.001000\n",
      "2022-08-30 17:22:31,617 epoch 3 - iter 30/67 - loss 0.98793066 - samples/sec: 103.56 - lr: 0.001000\n",
      "2022-08-30 17:22:34,475 epoch 3 - iter 36/67 - loss 0.98682080 - samples/sec: 107.30 - lr: 0.001000\n",
      "2022-08-30 17:22:37,782 epoch 3 - iter 42/67 - loss 0.99020667 - samples/sec: 92.31 - lr: 0.001000\n",
      "2022-08-30 17:22:40,803 epoch 3 - iter 48/67 - loss 0.98770894 - samples/sec: 101.42 - lr: 0.001000\n",
      "2022-08-30 17:22:44,259 epoch 3 - iter 54/67 - loss 0.98569122 - samples/sec: 88.68 - lr: 0.001000\n",
      "2022-08-30 17:22:47,161 epoch 3 - iter 60/67 - loss 0.97956734 - samples/sec: 105.52 - lr: 0.001000\n",
      "2022-08-30 17:22:50,248 epoch 3 - iter 66/67 - loss 0.97940027 - samples/sec: 99.11 - lr: 0.001000\n",
      "2022-08-30 17:22:50,714 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:22:50,715 EPOCH 3 done: loss 0.9800 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:22:51,562 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:22:51,589 DEV : loss 0.8051793575286865 - f1-score (micro avg)  0.7149\n",
      "2022-08-30 17:22:51,607 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 17:22:51,608 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:22:54,710 epoch 4 - iter 6/67 - loss 0.98093923 - samples/sec: 96.77 - lr: 0.001000\n",
      "2022-08-30 17:22:57,642 epoch 4 - iter 12/67 - loss 0.97391164 - samples/sec: 104.46 - lr: 0.001000\n",
      "2022-08-30 17:23:00,795 epoch 4 - iter 18/67 - loss 0.97539831 - samples/sec: 97.02 - lr: 0.001000\n",
      "2022-08-30 17:23:03,958 epoch 4 - iter 24/67 - loss 0.97239566 - samples/sec: 96.77 - lr: 0.001000\n",
      "2022-08-30 17:23:07,090 epoch 4 - iter 30/67 - loss 0.96962103 - samples/sec: 97.72 - lr: 0.001000\n",
      "2022-08-30 17:23:09,931 epoch 4 - iter 36/67 - loss 0.97113345 - samples/sec: 107.76 - lr: 0.001000\n",
      "2022-08-30 17:23:13,229 epoch 4 - iter 42/67 - loss 0.97055358 - samples/sec: 92.71 - lr: 0.001000\n",
      "2022-08-30 17:23:16,052 epoch 4 - iter 48/67 - loss 0.96940098 - samples/sec: 108.38 - lr: 0.001000\n",
      "2022-08-30 17:23:19,381 epoch 4 - iter 54/67 - loss 0.97327702 - samples/sec: 91.74 - lr: 0.001000\n",
      "2022-08-30 17:23:22,101 epoch 4 - iter 60/67 - loss 0.97470390 - samples/sec: 113.55 - lr: 0.001000\n",
      "2022-08-30 17:23:25,447 epoch 4 - iter 66/67 - loss 0.97287611 - samples/sec: 91.40 - lr: 0.001000\n",
      "2022-08-30 17:23:25,980 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:23:25,981 EPOCH 4 done: loss 0.9727 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:23:26,829 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:23:26,858 DEV : loss 0.8036124110221863 - f1-score (micro avg)  0.7165\n",
      "2022-08-30 17:23:26,873 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:23:26,874 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:23:27,588 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:23:30,281 epoch 5 - iter 6/67 - loss 0.99898524 - samples/sec: 111.44 - lr: 0.001000\n",
      "2022-08-30 17:23:33,646 epoch 5 - iter 12/67 - loss 0.97868347 - samples/sec: 90.80 - lr: 0.001000\n",
      "2022-08-30 17:23:36,483 epoch 5 - iter 18/67 - loss 0.97759145 - samples/sec: 108.23 - lr: 0.001000\n",
      "2022-08-30 17:23:39,547 epoch 5 - iter 24/67 - loss 0.97542794 - samples/sec: 100.07 - lr: 0.001000\n",
      "2022-08-30 17:23:42,404 epoch 5 - iter 30/67 - loss 0.97415963 - samples/sec: 107.49 - lr: 0.001000\n",
      "2022-08-30 17:23:45,549 epoch 5 - iter 36/67 - loss 0.97100704 - samples/sec: 97.50 - lr: 0.001000\n",
      "2022-08-30 17:23:49,053 epoch 5 - iter 42/67 - loss 0.97290887 - samples/sec: 87.08 - lr: 0.001000\n",
      "2022-08-30 17:23:52,278 epoch 5 - iter 48/67 - loss 0.97295022 - samples/sec: 94.79 - lr: 0.001000\n",
      "2022-08-30 17:23:55,328 epoch 5 - iter 54/67 - loss 0.97334175 - samples/sec: 100.30 - lr: 0.001000\n",
      "2022-08-30 17:23:58,518 epoch 5 - iter 60/67 - loss 0.97150355 - samples/sec: 96.06 - lr: 0.001000\n",
      "2022-08-30 17:24:01,583 epoch 5 - iter 66/67 - loss 0.97337134 - samples/sec: 100.23 - lr: 0.001000\n",
      "2022-08-30 17:24:01,952 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:24:01,953 EPOCH 5 done: loss 0.9733 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:24:02,783 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:24:02,815 DEV : loss 0.8021631240844727 - f1-score (micro avg)  0.7175\n",
      "2022-08-30 17:24:02,830 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:24:02,831 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:24:03,601 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:24:06,450 epoch 6 - iter 6/67 - loss 0.97813898 - samples/sec: 105.34 - lr: 0.001000\n",
      "2022-08-30 17:24:09,359 epoch 6 - iter 12/67 - loss 0.97230746 - samples/sec: 105.37 - lr: 0.001000\n",
      "2022-08-30 17:24:12,299 epoch 6 - iter 18/67 - loss 0.97053134 - samples/sec: 104.38 - lr: 0.001000\n",
      "2022-08-30 17:24:15,492 epoch 6 - iter 24/67 - loss 0.97497174 - samples/sec: 96.18 - lr: 0.001000\n",
      "2022-08-30 17:24:18,313 epoch 6 - iter 30/67 - loss 0.97758402 - samples/sec: 109.17 - lr: 0.001000\n",
      "2022-08-30 17:24:21,625 epoch 6 - iter 36/67 - loss 0.97883143 - samples/sec: 92.59 - lr: 0.001000\n",
      "2022-08-30 17:24:24,652 epoch 6 - iter 42/67 - loss 0.98002534 - samples/sec: 101.21 - lr: 0.001000\n",
      "2022-08-30 17:24:27,564 epoch 6 - iter 48/67 - loss 0.97590411 - samples/sec: 105.49 - lr: 0.001000\n",
      "2022-08-30 17:24:30,593 epoch 6 - iter 54/67 - loss 0.97445308 - samples/sec: 101.21 - lr: 0.001000\n",
      "2022-08-30 17:24:33,680 epoch 6 - iter 60/67 - loss 0.97522428 - samples/sec: 99.27 - lr: 0.001000\n",
      "2022-08-30 17:24:36,955 epoch 6 - iter 66/67 - loss 0.97554663 - samples/sec: 93.25 - lr: 0.001000\n",
      "2022-08-30 17:24:37,511 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:24:37,513 EPOCH 6 done: loss 0.9750 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:24:38,366 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:24:38,396 DEV : loss 0.8006525039672852 - f1-score (micro avg)  0.7182\n",
      "2022-08-30 17:24:38,412 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:24:38,413 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:24:39,098 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:24:41,959 epoch 7 - iter 6/67 - loss 0.98643671 - samples/sec: 104.93 - lr: 0.001000\n",
      "2022-08-30 17:24:44,961 epoch 7 - iter 12/67 - loss 0.97424950 - samples/sec: 101.97 - lr: 0.001000\n",
      "2022-08-30 17:24:48,035 epoch 7 - iter 18/67 - loss 0.97124659 - samples/sec: 99.63 - lr: 0.001000\n",
      "2022-08-30 17:24:51,332 epoch 7 - iter 24/67 - loss 0.96897881 - samples/sec: 92.71 - lr: 0.001000\n",
      "2022-08-30 17:24:54,716 epoch 7 - iter 30/67 - loss 0.96763487 - samples/sec: 90.44 - lr: 0.001000\n",
      "2022-08-30 17:24:57,740 epoch 7 - iter 36/67 - loss 0.97100699 - samples/sec: 101.94 - lr: 0.001000\n",
      "2022-08-30 17:25:00,568 epoch 7 - iter 42/67 - loss 0.96939127 - samples/sec: 108.50 - lr: 0.001000\n",
      "2022-08-30 17:25:03,604 epoch 7 - iter 48/67 - loss 0.96980334 - samples/sec: 102.25 - lr: 0.001000\n",
      "2022-08-30 17:25:06,625 epoch 7 - iter 54/67 - loss 0.96707186 - samples/sec: 101.76 - lr: 0.001000\n",
      "2022-08-30 17:25:09,978 epoch 7 - iter 60/67 - loss 0.96815578 - samples/sec: 91.19 - lr: 0.001000\n",
      "2022-08-30 17:25:12,853 epoch 7 - iter 66/67 - loss 0.96696632 - samples/sec: 106.72 - lr: 0.001000\n",
      "2022-08-30 17:25:13,223 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:25:13,223 EPOCH 7 done: loss 0.9676 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:25:14,078 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:25:14,111 DEV : loss 0.7984767556190491 - f1-score (micro avg)  0.7177\n",
      "2022-08-30 17:25:14,130 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:25:14,131 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:25:17,268 epoch 8 - iter 6/67 - loss 0.94952021 - samples/sec: 95.66 - lr: 0.001000\n",
      "2022-08-30 17:25:20,677 epoch 8 - iter 12/67 - loss 0.96081528 - samples/sec: 89.55 - lr: 0.001000\n",
      "2022-08-30 17:25:23,528 epoch 8 - iter 18/67 - loss 0.96102337 - samples/sec: 107.41 - lr: 0.001000\n",
      "2022-08-30 17:25:26,341 epoch 8 - iter 24/67 - loss 0.96030684 - samples/sec: 108.97 - lr: 0.001000\n",
      "2022-08-30 17:25:29,593 epoch 8 - iter 30/67 - loss 0.96270866 - samples/sec: 95.39 - lr: 0.001000\n",
      "2022-08-30 17:25:32,752 epoch 8 - iter 36/67 - loss 0.96197118 - samples/sec: 96.62 - lr: 0.001000\n",
      "2022-08-30 17:25:35,944 epoch 8 - iter 42/67 - loss 0.96184940 - samples/sec: 95.60 - lr: 0.001000\n",
      "2022-08-30 17:25:38,945 epoch 8 - iter 48/67 - loss 0.96630692 - samples/sec: 101.94 - lr: 0.001000\n",
      "2022-08-30 17:25:41,821 epoch 8 - iter 54/67 - loss 0.96519173 - samples/sec: 106.35 - lr: 0.001000\n",
      "2022-08-30 17:25:45,070 epoch 8 - iter 60/67 - loss 0.96676138 - samples/sec: 94.43 - lr: 0.001000\n",
      "2022-08-30 17:25:48,143 epoch 8 - iter 66/67 - loss 0.96726202 - samples/sec: 100.03 - lr: 0.001000\n",
      "2022-08-30 17:25:48,607 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:25:48,608 EPOCH 8 done: loss 0.9668 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:25:50,802 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:25:50,835 DEV : loss 0.7968918085098267 - f1-score (micro avg)  0.7191\n",
      "2022-08-30 17:25:50,852 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:25:50,853 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:25:51,682 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:25:54,510 epoch 9 - iter 6/67 - loss 0.94784432 - samples/sec: 106.16 - lr: 0.001000\n",
      "2022-08-30 17:25:57,685 epoch 9 - iter 12/67 - loss 0.94152568 - samples/sec: 96.46 - lr: 0.001000\n",
      "2022-08-30 17:26:00,738 epoch 9 - iter 18/67 - loss 0.95653832 - samples/sec: 100.30 - lr: 0.001000\n",
      "2022-08-30 17:26:03,750 epoch 9 - iter 24/67 - loss 0.96200465 - samples/sec: 101.97 - lr: 0.001000\n",
      "2022-08-30 17:26:06,871 epoch 9 - iter 30/67 - loss 0.96349840 - samples/sec: 98.17 - lr: 0.001000\n",
      "2022-08-30 17:26:10,098 epoch 9 - iter 36/67 - loss 0.96930557 - samples/sec: 94.97 - lr: 0.001000\n",
      "2022-08-30 17:26:13,171 epoch 9 - iter 42/67 - loss 0.96543620 - samples/sec: 99.70 - lr: 0.001000\n",
      "2022-08-30 17:26:16,307 epoch 9 - iter 48/67 - loss 0.96479108 - samples/sec: 97.43 - lr: 0.001000\n",
      "2022-08-30 17:26:19,262 epoch 9 - iter 54/67 - loss 0.96310751 - samples/sec: 103.73 - lr: 0.001000\n",
      "2022-08-30 17:26:22,853 epoch 9 - iter 60/67 - loss 0.96499292 - samples/sec: 85.06 - lr: 0.001000\n",
      "2022-08-30 17:26:26,048 epoch 9 - iter 66/67 - loss 0.96436630 - samples/sec: 96.18 - lr: 0.001000\n",
      "2022-08-30 17:26:26,451 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:26:26,452 EPOCH 9 done: loss 0.9644 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:26:27,399 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:26:27,433 DEV : loss 0.7948141694068909 - f1-score (micro avg)  0.719\n",
      "2022-08-30 17:26:27,455 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:26:27,456 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:26:30,363 epoch 10 - iter 6/67 - loss 0.94281605 - samples/sec: 103.23 - lr: 0.001000\n",
      "2022-08-30 17:26:33,419 epoch 10 - iter 12/67 - loss 0.95192636 - samples/sec: 100.57 - lr: 0.001000\n",
      "2022-08-30 17:26:36,517 epoch 10 - iter 18/67 - loss 0.95719969 - samples/sec: 99.40 - lr: 0.001000\n",
      "2022-08-30 17:26:39,794 epoch 10 - iter 24/67 - loss 0.96181882 - samples/sec: 93.60 - lr: 0.001000\n",
      "2022-08-30 17:26:42,995 epoch 10 - iter 30/67 - loss 0.96296780 - samples/sec: 95.72 - lr: 0.001000\n",
      "2022-08-30 17:26:46,116 epoch 10 - iter 36/67 - loss 0.96148484 - samples/sec: 98.49 - lr: 0.001000\n",
      "2022-08-30 17:26:49,041 epoch 10 - iter 42/67 - loss 0.96168098 - samples/sec: 104.64 - lr: 0.001000\n",
      "2022-08-30 17:26:52,058 epoch 10 - iter 48/67 - loss 0.96500836 - samples/sec: 101.63 - lr: 0.001000\n",
      "2022-08-30 17:26:55,262 epoch 10 - iter 54/67 - loss 0.96710201 - samples/sec: 95.45 - lr: 0.001000\n",
      "2022-08-30 17:26:58,341 epoch 10 - iter 60/67 - loss 0.96820058 - samples/sec: 99.50 - lr: 0.001000\n",
      "2022-08-30 17:27:01,929 epoch 10 - iter 66/67 - loss 0.96567639 - samples/sec: 85.20 - lr: 0.001000\n",
      "2022-08-30 17:27:02,322 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:27:02,323 EPOCH 10 done: loss 0.9655 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:27:03,206 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:27:03,235 DEV : loss 0.7924354076385498 - f1-score (micro avg)  0.7188\n",
      "2022-08-30 17:27:03,252 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 17:27:03,254 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:27:06,430 epoch 11 - iter 6/67 - loss 0.96269414 - samples/sec: 94.49 - lr: 0.001000\n",
      "2022-08-30 17:27:09,535 epoch 11 - iter 12/67 - loss 0.96794938 - samples/sec: 99.44 - lr: 0.001000\n",
      "2022-08-30 17:27:12,709 epoch 11 - iter 18/67 - loss 0.96837075 - samples/sec: 96.46 - lr: 0.001000\n",
      "2022-08-30 17:27:15,753 epoch 11 - iter 24/67 - loss 0.96720459 - samples/sec: 100.60 - lr: 0.001000\n",
      "2022-08-30 17:27:18,995 epoch 11 - iter 30/67 - loss 0.96578099 - samples/sec: 94.19 - lr: 0.001000\n",
      "2022-08-30 17:27:21,897 epoch 11 - iter 36/67 - loss 0.96880881 - samples/sec: 105.78 - lr: 0.001000\n",
      "2022-08-30 17:27:24,735 epoch 11 - iter 42/67 - loss 0.96845310 - samples/sec: 107.84 - lr: 0.001000\n",
      "2022-08-30 17:27:27,986 epoch 11 - iter 48/67 - loss 0.96933849 - samples/sec: 93.96 - lr: 0.001000\n",
      "2022-08-30 17:27:31,017 epoch 11 - iter 54/67 - loss 0.96894787 - samples/sec: 101.45 - lr: 0.001000\n",
      "2022-08-30 17:27:34,165 epoch 11 - iter 60/67 - loss 0.96570510 - samples/sec: 97.24 - lr: 0.001000\n",
      "2022-08-30 17:27:37,376 epoch 11 - iter 66/67 - loss 0.96484500 - samples/sec: 95.06 - lr: 0.001000\n",
      "2022-08-30 17:27:37,802 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:27:37,803 EPOCH 11 done: loss 0.9654 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:27:38,646 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:27:38,679 DEV : loss 0.7910969853401184 - f1-score (micro avg)  0.7182\n",
      "2022-08-30 17:27:38,695 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 17:27:38,696 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:27:41,998 epoch 12 - iter 6/67 - loss 0.97147475 - samples/sec: 90.88 - lr: 0.001000\n",
      "2022-08-30 17:27:45,265 epoch 12 - iter 12/67 - loss 0.96737841 - samples/sec: 93.72 - lr: 0.001000\n",
      "2022-08-30 17:27:48,074 epoch 12 - iter 18/67 - loss 0.96445862 - samples/sec: 109.25 - lr: 0.001000\n",
      "2022-08-30 17:27:50,913 epoch 12 - iter 24/67 - loss 0.96702281 - samples/sec: 108.07 - lr: 0.001000\n",
      "2022-08-30 17:27:53,718 epoch 12 - iter 30/67 - loss 0.96697557 - samples/sec: 110.54 - lr: 0.001000\n",
      "2022-08-30 17:27:56,788 epoch 12 - iter 36/67 - loss 0.97021254 - samples/sec: 99.63 - lr: 0.001000\n",
      "2022-08-30 17:28:00,103 epoch 12 - iter 42/67 - loss 0.96722146 - samples/sec: 92.19 - lr: 0.001000\n",
      "2022-08-30 17:28:03,067 epoch 12 - iter 48/67 - loss 0.96992176 - samples/sec: 103.56 - lr: 0.001000\n",
      "2022-08-30 17:28:05,996 epoch 12 - iter 54/67 - loss 0.96978708 - samples/sec: 104.82 - lr: 0.001000\n",
      "2022-08-30 17:28:09,083 epoch 12 - iter 60/67 - loss 0.97117641 - samples/sec: 99.37 - lr: 0.001000\n",
      "2022-08-30 17:28:12,291 epoch 12 - iter 66/67 - loss 0.96904645 - samples/sec: 95.27 - lr: 0.001000\n",
      "2022-08-30 17:28:12,720 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:28:12,721 EPOCH 12 done: loss 0.9689 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:28:13,537 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:28:13,568 DEV : loss 0.7909784913063049 - f1-score (micro avg)  0.7201\n",
      "2022-08-30 17:28:13,589 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:28:13,591 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:28:14,991 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:28:14,992 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 17:28:15,168 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:28:16,560 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:28:16,584 0.7352\t0.7352\t0.7352\t0.7352\n",
      "2022-08-30 17:28:16,585 \n",
      "Results:\n",
      "- F-score (micro) 0.7352\n",
      "- F-score (macro) 0.5793\n",
      "- Accuracy 0.7352\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6472    0.7783    0.7067      1353\n",
      "         ADJ     0.5322    0.7009    0.6050       672\n",
      "       PUNCT     0.9821    0.9955    0.9887       660\n",
      "         ADP     0.8787    0.9163    0.8971       514\n",
      "        VERB     0.6283    0.5835    0.6051       449\n",
      "         AUX     0.9142    0.8269    0.8683       335\n",
      "       PROPN     0.7838    0.3786    0.5106       383\n",
      "       CCONJ     0.9895    0.9844    0.9869       192\n",
      "       SCONJ     0.9061    0.8913    0.8986       184\n",
      "         DET     0.6364    0.3913    0.4846       161\n",
      "         ADV     0.2909    0.1060    0.1553       151\n",
      "        PRON     0.9011    0.7130    0.7961       115\n",
      "         NUM     0.8125    0.1831    0.2989        71\n",
      "        PART     0.7778    0.3333    0.4667        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7352      5264\n",
      "   macro avg     0.6675    0.5489    0.5793      5264\n",
      "weighted avg     0.7413    0.7352    0.7244      5264\n",
      "\n",
      "2022-08-30 17:28:16,585 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:28:16,587 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:28:17,070 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 17:30:39,968 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:30:39,969 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 17:30:39,969 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:30:39,970 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 17:30:39,971 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:30:39,971 Parameters:\n",
      "2022-08-30 17:30:39,972  - learning_rate: \"0.001000\"\n",
      "2022-08-30 17:30:39,972  - mini_batch_size: \"70\"\n",
      "2022-08-30 17:30:39,973  - patience: \"3\"\n",
      "2022-08-30 17:30:39,973  - anneal_factor: \"0.5\"\n",
      "2022-08-30 17:30:39,973  - max_epochs: \"10\"\n",
      "2022-08-30 17:30:39,974  - shuffle: \"True\"\n",
      "2022-08-30 17:30:39,974  - train_with_dev: \"False\"\n",
      "2022-08-30 17:30:39,975  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 17:30:39,975 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:30:39,975 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 17:30:39,976 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:30:39,976 Device: cpu\n",
      "2022-08-30 17:30:39,977 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:30:39,978 Embeddings storage mode: cpu\n",
      "2022-08-30 17:30:39,978 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:30:42,364 epoch 1 - iter 4/48 - loss 0.99402402 - samples/sec: 117.40 - lr: 0.001000\n",
      "2022-08-30 17:30:45,285 epoch 1 - iter 8/48 - loss 0.94797564 - samples/sec: 98.73 - lr: 0.001000\n",
      "2022-08-30 17:30:47,618 epoch 1 - iter 12/48 - loss 0.94554321 - samples/sec: 122.97 - lr: 0.001000\n",
      "2022-08-30 17:30:50,156 epoch 1 - iter 16/48 - loss 0.95078863 - samples/sec: 115.27 - lr: 0.001000\n",
      "2022-08-30 17:30:52,731 epoch 1 - iter 20/48 - loss 0.94148265 - samples/sec: 111.29 - lr: 0.001000\n",
      "2022-08-30 17:30:55,427 epoch 1 - iter 24/48 - loss 0.94105973 - samples/sec: 106.02 - lr: 0.001000\n",
      "2022-08-30 17:30:57,844 epoch 1 - iter 28/48 - loss 0.93884966 - samples/sec: 119.66 - lr: 0.001000\n",
      "2022-08-30 17:31:00,469 epoch 1 - iter 32/48 - loss 0.94038596 - samples/sec: 108.99 - lr: 0.001000\n",
      "2022-08-30 17:31:02,842 epoch 1 - iter 36/48 - loss 0.94125124 - samples/sec: 121.37 - lr: 0.001000\n",
      "2022-08-30 17:31:05,408 epoch 1 - iter 40/48 - loss 0.93846381 - samples/sec: 111.69 - lr: 0.001000\n",
      "2022-08-30 17:31:07,898 epoch 1 - iter 44/48 - loss 0.94541269 - samples/sec: 115.27 - lr: 0.001000\n",
      "2022-08-30 17:31:10,879 epoch 1 - iter 48/48 - loss 0.96409449 - samples/sec: 95.76 - lr: 0.001000\n",
      "2022-08-30 17:31:10,941 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:31:10,942 EPOCH 1 done: loss 0.9641 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:31:11,781 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:31:11,810 DEV : loss 0.7926454544067383 - f1-score (micro avg)  0.7225\n",
      "2022-08-30 17:31:11,825 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:31:11,826 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:31:12,841 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:31:15,587 epoch 2 - iter 4/48 - loss 0.94023360 - samples/sec: 102.00 - lr: 0.001000\n",
      "2022-08-30 17:31:18,077 epoch 2 - iter 8/48 - loss 0.95199152 - samples/sec: 115.85 - lr: 0.001000\n",
      "2022-08-30 17:31:21,122 epoch 2 - iter 12/48 - loss 0.94910691 - samples/sec: 93.68 - lr: 0.001000\n",
      "2022-08-30 17:31:24,111 epoch 2 - iter 16/48 - loss 0.95838387 - samples/sec: 95.56 - lr: 0.001000\n",
      "2022-08-30 17:31:26,670 epoch 2 - iter 20/48 - loss 0.94934206 - samples/sec: 111.78 - lr: 0.001000\n",
      "2022-08-30 17:31:29,312 epoch 2 - iter 24/48 - loss 0.95278450 - samples/sec: 108.91 - lr: 0.001000\n",
      "2022-08-30 17:31:31,741 epoch 2 - iter 28/48 - loss 0.95117443 - samples/sec: 120.12 - lr: 0.001000\n",
      "2022-08-30 17:31:34,214 epoch 2 - iter 32/48 - loss 0.95292661 - samples/sec: 115.80 - lr: 0.001000\n",
      "2022-08-30 17:31:36,754 epoch 2 - iter 36/48 - loss 0.95510068 - samples/sec: 112.81 - lr: 0.001000\n",
      "2022-08-30 17:31:39,135 epoch 2 - iter 40/48 - loss 0.95750993 - samples/sec: 120.59 - lr: 0.001000\n",
      "2022-08-30 17:31:41,878 epoch 2 - iter 44/48 - loss 0.95712481 - samples/sec: 104.24 - lr: 0.001000\n",
      "2022-08-30 17:31:44,686 epoch 2 - iter 48/48 - loss 0.95861828 - samples/sec: 102.00 - lr: 0.001000\n",
      "2022-08-30 17:31:44,756 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:31:44,757 EPOCH 2 done: loss 0.9586 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:31:45,554 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:31:45,584 DEV : loss 0.7874074578285217 - f1-score (micro avg)  0.7203\n",
      "2022-08-30 17:31:45,599 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:31:45,600 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:31:48,358 epoch 3 - iter 4/48 - loss 0.94688567 - samples/sec: 101.63 - lr: 0.001000\n",
      "2022-08-30 17:31:50,942 epoch 3 - iter 8/48 - loss 0.94972566 - samples/sec: 112.13 - lr: 0.001000\n",
      "2022-08-30 17:31:53,369 epoch 3 - iter 12/48 - loss 0.95378015 - samples/sec: 118.39 - lr: 0.001000\n",
      "2022-08-30 17:31:56,535 epoch 3 - iter 16/48 - loss 0.96335614 - samples/sec: 90.56 - lr: 0.001000\n",
      "2022-08-30 17:31:59,267 epoch 3 - iter 20/48 - loss 0.95626385 - samples/sec: 104.83 - lr: 0.001000\n",
      "2022-08-30 17:32:02,001 epoch 3 - iter 24/48 - loss 0.96088388 - samples/sec: 104.56 - lr: 0.001000\n",
      "2022-08-30 17:32:04,427 epoch 3 - iter 28/48 - loss 0.96322482 - samples/sec: 118.64 - lr: 0.001000\n",
      "2022-08-30 17:32:07,003 epoch 3 - iter 32/48 - loss 0.96347050 - samples/sec: 111.42 - lr: 0.001000\n",
      "2022-08-30 17:32:09,512 epoch 3 - iter 36/48 - loss 0.96417150 - samples/sec: 114.66 - lr: 0.001000\n",
      "2022-08-30 17:32:11,938 epoch 3 - iter 40/48 - loss 0.96152797 - samples/sec: 118.64 - lr: 0.001000\n",
      "2022-08-30 17:32:14,529 epoch 3 - iter 44/48 - loss 0.96147885 - samples/sec: 110.67 - lr: 0.001000\n",
      "2022-08-30 17:32:17,181 epoch 3 - iter 48/48 - loss 0.96167728 - samples/sec: 108.49 - lr: 0.001000\n",
      "2022-08-30 17:32:17,239 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:32:17,240 EPOCH 3 done: loss 0.9617 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:32:18,052 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:32:18,078 DEV : loss 0.7860589027404785 - f1-score (micro avg)  0.7222\n",
      "2022-08-30 17:32:18,096 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 17:32:18,097 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:32:20,402 epoch 4 - iter 4/48 - loss 0.99481872 - samples/sec: 121.53 - lr: 0.001000\n",
      "2022-08-30 17:32:23,075 epoch 4 - iter 8/48 - loss 0.96376346 - samples/sec: 107.12 - lr: 0.001000\n",
      "2022-08-30 17:32:26,070 epoch 4 - iter 12/48 - loss 0.97051201 - samples/sec: 95.24 - lr: 0.001000\n",
      "2022-08-30 17:32:28,601 epoch 4 - iter 16/48 - loss 0.96506373 - samples/sec: 113.18 - lr: 0.001000\n",
      "2022-08-30 17:32:31,479 epoch 4 - iter 20/48 - loss 0.96914042 - samples/sec: 99.43 - lr: 0.001000\n",
      "2022-08-30 17:32:34,345 epoch 4 - iter 24/48 - loss 0.97045964 - samples/sec: 100.21 - lr: 0.001000\n",
      "2022-08-30 17:32:37,068 epoch 4 - iter 28/48 - loss 0.96709702 - samples/sec: 107.24 - lr: 0.001000\n",
      "2022-08-30 17:32:39,810 epoch 4 - iter 32/48 - loss 0.96541232 - samples/sec: 104.40 - lr: 0.001000\n",
      "2022-08-30 17:32:42,280 epoch 4 - iter 36/48 - loss 0.96898977 - samples/sec: 115.99 - lr: 0.001000\n",
      "2022-08-30 17:32:44,749 epoch 4 - iter 40/48 - loss 0.96757652 - samples/sec: 116.13 - lr: 0.001000\n",
      "2022-08-30 17:32:47,208 epoch 4 - iter 44/48 - loss 0.96383141 - samples/sec: 116.42 - lr: 0.001000\n",
      "2022-08-30 17:32:49,534 epoch 4 - iter 48/48 - loss 0.96275564 - samples/sec: 123.46 - lr: 0.001000\n",
      "2022-08-30 17:32:49,603 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:32:49,604 EPOCH 4 done: loss 0.9628 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:32:50,428 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:32:50,456 DEV : loss 0.7852287292480469 - f1-score (micro avg)  0.7247\n",
      "2022-08-30 17:32:50,477 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:32:50,478 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:32:51,215 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:32:53,774 epoch 5 - iter 4/48 - loss 0.95584978 - samples/sec: 109.50 - lr: 0.001000\n",
      "2022-08-30 17:32:56,302 epoch 5 - iter 8/48 - loss 0.96263463 - samples/sec: 113.22 - lr: 0.001000\n",
      "2022-08-30 17:32:58,898 epoch 5 - iter 12/48 - loss 0.96287422 - samples/sec: 110.58 - lr: 0.001000\n",
      "2022-08-30 17:33:01,508 epoch 5 - iter 16/48 - loss 0.96326521 - samples/sec: 109.59 - lr: 0.001000\n",
      "2022-08-30 17:33:04,014 epoch 5 - iter 20/48 - loss 0.95701010 - samples/sec: 114.43 - lr: 0.001000\n",
      "2022-08-30 17:33:06,906 epoch 5 - iter 24/48 - loss 0.95887725 - samples/sec: 98.91 - lr: 0.001000\n",
      "2022-08-30 17:33:09,714 epoch 5 - iter 28/48 - loss 0.95587540 - samples/sec: 101.82 - lr: 0.001000\n",
      "2022-08-30 17:33:12,275 epoch 5 - iter 32/48 - loss 0.95678721 - samples/sec: 112.04 - lr: 0.001000\n",
      "2022-08-30 17:33:15,200 epoch 5 - iter 36/48 - loss 0.95756096 - samples/sec: 97.53 - lr: 0.001000\n",
      "2022-08-30 17:33:17,625 epoch 5 - iter 40/48 - loss 0.95515549 - samples/sec: 118.24 - lr: 0.001000\n",
      "2022-08-30 17:33:20,296 epoch 5 - iter 44/48 - loss 0.95959478 - samples/sec: 107.07 - lr: 0.001000\n",
      "2022-08-30 17:33:22,731 epoch 5 - iter 48/48 - loss 0.96012067 - samples/sec: 117.80 - lr: 0.001000\n",
      "2022-08-30 17:33:22,791 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:33:22,792 EPOCH 5 done: loss 0.9601 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:33:23,596 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:33:23,628 DEV : loss 0.7835838794708252 - f1-score (micro avg)  0.7245\n",
      "2022-08-30 17:33:23,646 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:33:23,647 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:33:26,096 epoch 6 - iter 4/48 - loss 0.93544172 - samples/sec: 114.38 - lr: 0.001000\n",
      "2022-08-30 17:33:28,609 epoch 6 - iter 8/48 - loss 0.93998463 - samples/sec: 114.01 - lr: 0.001000\n",
      "2022-08-30 17:33:31,329 epoch 6 - iter 12/48 - loss 0.96052687 - samples/sec: 105.42 - lr: 0.001000\n",
      "2022-08-30 17:33:33,931 epoch 6 - iter 16/48 - loss 0.96274179 - samples/sec: 110.50 - lr: 0.001000\n",
      "2022-08-30 17:33:36,454 epoch 6 - iter 20/48 - loss 0.96544116 - samples/sec: 113.59 - lr: 0.001000\n",
      "2022-08-30 17:33:39,146 epoch 6 - iter 24/48 - loss 0.96533513 - samples/sec: 107.44 - lr: 0.001000\n",
      "2022-08-30 17:33:42,015 epoch 6 - iter 28/48 - loss 0.96699289 - samples/sec: 99.72 - lr: 0.001000\n",
      "2022-08-30 17:33:44,843 epoch 6 - iter 32/48 - loss 0.96556126 - samples/sec: 101.30 - lr: 0.001000\n",
      "2022-08-30 17:33:47,229 epoch 6 - iter 36/48 - loss 0.96774746 - samples/sec: 120.48 - lr: 0.001000\n",
      "2022-08-30 17:33:49,823 epoch 6 - iter 40/48 - loss 0.96505396 - samples/sec: 110.50 - lr: 0.001000\n",
      "2022-08-30 17:33:52,560 epoch 6 - iter 44/48 - loss 0.95976590 - samples/sec: 104.75 - lr: 0.001000\n",
      "2022-08-30 17:33:55,260 epoch 6 - iter 48/48 - loss 0.95962162 - samples/sec: 106.30 - lr: 0.001000\n",
      "2022-08-30 17:33:55,319 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:33:55,320 EPOCH 6 done: loss 0.9596 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:33:56,156 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:33:56,190 DEV : loss 0.7813466191291809 - f1-score (micro avg)  0.7245\n",
      "2022-08-30 17:33:56,208 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 17:33:56,209 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:33:58,929 epoch 7 - iter 4/48 - loss 0.98194620 - samples/sec: 102.98 - lr: 0.001000\n",
      "2022-08-30 17:34:01,467 epoch 7 - iter 8/48 - loss 0.97447787 - samples/sec: 112.90 - lr: 0.001000\n",
      "2022-08-30 17:34:03,726 epoch 7 - iter 12/48 - loss 0.95841579 - samples/sec: 127.27 - lr: 0.001000\n",
      "2022-08-30 17:34:06,605 epoch 7 - iter 16/48 - loss 0.95283440 - samples/sec: 99.19 - lr: 0.001000\n",
      "2022-08-30 17:34:09,667 epoch 7 - iter 20/48 - loss 0.95514852 - samples/sec: 93.27 - lr: 0.001000\n",
      "2022-08-30 17:34:12,101 epoch 7 - iter 24/48 - loss 0.95537074 - samples/sec: 118.19 - lr: 0.001000\n",
      "2022-08-30 17:34:14,917 epoch 7 - iter 28/48 - loss 0.95611098 - samples/sec: 101.38 - lr: 0.001000\n",
      "2022-08-30 17:34:17,546 epoch 7 - iter 32/48 - loss 0.95688453 - samples/sec: 108.82 - lr: 0.001000\n",
      "2022-08-30 17:34:20,513 epoch 7 - iter 36/48 - loss 0.95618407 - samples/sec: 97.12 - lr: 0.001000\n",
      "2022-08-30 17:34:22,983 epoch 7 - iter 40/48 - loss 0.95639767 - samples/sec: 116.76 - lr: 0.001000\n",
      "2022-08-30 17:34:25,217 epoch 7 - iter 44/48 - loss 0.95360174 - samples/sec: 128.91 - lr: 0.001000\n",
      "2022-08-30 17:34:27,848 epoch 7 - iter 48/48 - loss 0.95363116 - samples/sec: 109.08 - lr: 0.001000\n",
      "2022-08-30 17:34:27,904 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:34:27,905 EPOCH 7 done: loss 0.9536 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:34:28,732 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:34:28,764 DEV : loss 0.780739963054657 - f1-score (micro avg)  0.7253\n",
      "2022-08-30 17:34:28,780 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:34:28,782 saving best model\n",
      "2022-08-30 17:34:29,483 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:34:31,744 epoch 8 - iter 4/48 - loss 0.98139005 - samples/sec: 123.92 - lr: 0.001000\n",
      "2022-08-30 17:34:34,179 epoch 8 - iter 8/48 - loss 0.96602718 - samples/sec: 117.65 - lr: 0.001000\n",
      "2022-08-30 17:34:36,695 epoch 8 - iter 12/48 - loss 0.95547242 - samples/sec: 113.77 - lr: 0.001000\n",
      "2022-08-30 17:34:39,144 epoch 8 - iter 16/48 - loss 0.95985212 - samples/sec: 117.11 - lr: 0.001000\n",
      "2022-08-30 17:34:41,655 epoch 8 - iter 20/48 - loss 0.95652744 - samples/sec: 114.15 - lr: 0.001000\n",
      "2022-08-30 17:34:44,215 epoch 8 - iter 24/48 - loss 0.96127221 - samples/sec: 111.78 - lr: 0.001000\n",
      "2022-08-30 17:34:46,738 epoch 8 - iter 28/48 - loss 0.96206111 - samples/sec: 113.54 - lr: 0.001000\n",
      "2022-08-30 17:34:49,468 epoch 8 - iter 32/48 - loss 0.96171732 - samples/sec: 104.71 - lr: 0.001000\n",
      "2022-08-30 17:34:52,224 epoch 8 - iter 36/48 - loss 0.95656402 - samples/sec: 103.78 - lr: 0.001000\n",
      "2022-08-30 17:34:55,220 epoch 8 - iter 40/48 - loss 0.95438366 - samples/sec: 96.35 - lr: 0.001000\n",
      "2022-08-30 17:34:57,937 epoch 8 - iter 44/48 - loss 0.95680694 - samples/sec: 105.38 - lr: 0.001000\n",
      "2022-08-30 17:35:00,580 epoch 8 - iter 48/48 - loss 0.95631029 - samples/sec: 108.53 - lr: 0.001000\n",
      "2022-08-30 17:35:00,653 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:35:00,653 EPOCH 8 done: loss 0.9563 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:35:01,493 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:35:01,528 DEV : loss 0.7799185514450073 - f1-score (micro avg)  0.7248\n",
      "2022-08-30 17:35:01,550 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:35:01,551 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:35:04,141 epoch 9 - iter 4/48 - loss 0.94009752 - samples/sec: 108.19 - lr: 0.001000\n",
      "2022-08-30 17:35:06,848 epoch 9 - iter 8/48 - loss 0.95421414 - samples/sec: 105.70 - lr: 0.001000\n",
      "2022-08-30 17:35:09,610 epoch 9 - iter 12/48 - loss 0.95193756 - samples/sec: 103.63 - lr: 0.001000\n",
      "2022-08-30 17:35:12,201 epoch 9 - iter 16/48 - loss 0.96203592 - samples/sec: 110.80 - lr: 0.001000\n",
      "2022-08-30 17:35:14,609 epoch 9 - iter 20/48 - loss 0.96552066 - samples/sec: 119.05 - lr: 0.001000\n",
      "2022-08-30 17:35:17,059 epoch 9 - iter 24/48 - loss 0.96365849 - samples/sec: 117.70 - lr: 0.001000\n",
      "2022-08-30 17:35:19,641 epoch 9 - iter 28/48 - loss 0.96542842 - samples/sec: 111.02 - lr: 0.001000\n",
      "2022-08-30 17:35:22,213 epoch 9 - iter 32/48 - loss 0.95992514 - samples/sec: 111.29 - lr: 0.001000\n",
      "2022-08-30 17:35:24,945 epoch 9 - iter 36/48 - loss 0.95787762 - samples/sec: 104.71 - lr: 0.001000\n",
      "2022-08-30 17:35:27,415 epoch 9 - iter 40/48 - loss 0.95709284 - samples/sec: 116.28 - lr: 0.001000\n",
      "2022-08-30 17:35:29,873 epoch 9 - iter 44/48 - loss 0.95494241 - samples/sec: 116.96 - lr: 0.001000\n",
      "2022-08-30 17:35:32,796 epoch 9 - iter 48/48 - loss 0.95432456 - samples/sec: 97.87 - lr: 0.001000\n",
      "2022-08-30 17:35:32,853 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:35:32,853 EPOCH 9 done: loss 0.9543 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:35:33,669 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:35:33,699 DEV : loss 0.7786158323287964 - f1-score (micro avg)  0.7256\n",
      "2022-08-30 17:35:33,715 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:35:33,716 saving best model\n",
      "2022-08-30 17:35:34,408 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:35:37,243 epoch 10 - iter 4/48 - loss 0.95824473 - samples/sec: 98.84 - lr: 0.001000\n",
      "2022-08-30 17:35:39,692 epoch 10 - iter 8/48 - loss 0.95002396 - samples/sec: 116.91 - lr: 0.001000\n",
      "2022-08-30 17:35:42,875 epoch 10 - iter 12/48 - loss 0.94367728 - samples/sec: 89.57 - lr: 0.001000\n",
      "2022-08-30 17:35:45,492 epoch 10 - iter 16/48 - loss 0.94432487 - samples/sec: 109.42 - lr: 0.001000\n",
      "2022-08-30 17:35:48,150 epoch 10 - iter 20/48 - loss 0.94916518 - samples/sec: 108.86 - lr: 0.001000\n",
      "2022-08-30 17:35:50,722 epoch 10 - iter 24/48 - loss 0.94904210 - samples/sec: 111.24 - lr: 0.001000\n",
      "2022-08-30 17:35:53,289 epoch 10 - iter 28/48 - loss 0.94960609 - samples/sec: 111.73 - lr: 0.001000\n",
      "2022-08-30 17:35:55,781 epoch 10 - iter 32/48 - loss 0.94658242 - samples/sec: 115.08 - lr: 0.001000\n",
      "2022-08-30 17:35:58,633 epoch 10 - iter 36/48 - loss 0.94587368 - samples/sec: 100.29 - lr: 0.001000\n",
      "2022-08-30 17:36:01,145 epoch 10 - iter 40/48 - loss 0.94884384 - samples/sec: 114.33 - lr: 0.001000\n",
      "2022-08-30 17:36:03,533 epoch 10 - iter 44/48 - loss 0.94791603 - samples/sec: 120.33 - lr: 0.001000\n",
      "2022-08-30 17:36:05,894 epoch 10 - iter 48/48 - loss 0.94767801 - samples/sec: 122.65 - lr: 0.001000\n",
      "2022-08-30 17:36:05,956 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:36:05,957 EPOCH 10 done: loss 0.9477 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:36:06,753 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:36:06,786 DEV : loss 0.7768062949180603 - f1-score (micro avg)  0.7261\n",
      "2022-08-30 17:36:06,801 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:36:06,802 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:36:08,762 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:36:08,763 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 17:36:08,948 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:36:10,277 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:36:10,300 0.7392\t0.7392\t0.7392\t0.7392\n",
      "2022-08-30 17:36:10,301 \n",
      "Results:\n",
      "- F-score (micro) 0.7392\n",
      "- F-score (macro) 0.5868\n",
      "- Accuracy 0.7392\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6558    0.7761    0.7109      1353\n",
      "         ADJ     0.5364    0.7024    0.6082       672\n",
      "       PUNCT     0.9835    0.9955    0.9895       660\n",
      "         ADP     0.8790    0.9183    0.8982       514\n",
      "        VERB     0.6303    0.5924    0.6108       449\n",
      "         AUX     0.9082    0.8269    0.8656       335\n",
      "       PROPN     0.7897    0.4021    0.5329       383\n",
      "       CCONJ     0.9895    0.9844    0.9869       192\n",
      "       SCONJ     0.9066    0.8967    0.9016       184\n",
      "         DET     0.6262    0.4161    0.5000       161\n",
      "         ADV     0.2931    0.1126    0.1627       151\n",
      "        PRON     0.9022    0.7217    0.8019       115\n",
      "         NUM     0.8333    0.2113    0.3371        71\n",
      "        PART     0.8750    0.3333    0.4828        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7392      5264\n",
      "   macro avg     0.6756    0.5556    0.5868      5264\n",
      "weighted avg     0.7450    0.7392    0.7296      5264\n",
      "\n",
      "2022-08-30 17:36:10,301 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:36:10,303 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:36:10,811 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 17:38:29,679 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:38:29,679 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 17:38:29,680 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:38:29,681 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 17:38:29,681 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:38:29,682 Parameters:\n",
      "2022-08-30 17:38:29,682  - learning_rate: \"0.001000\"\n",
      "2022-08-30 17:38:29,683  - mini_batch_size: \"70\"\n",
      "2022-08-30 17:38:29,683  - patience: \"3\"\n",
      "2022-08-30 17:38:29,684  - anneal_factor: \"0.5\"\n",
      "2022-08-30 17:38:29,684  - max_epochs: \"11\"\n",
      "2022-08-30 17:38:29,685  - shuffle: \"True\"\n",
      "2022-08-30 17:38:29,685  - train_with_dev: \"False\"\n",
      "2022-08-30 17:38:29,686  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 17:38:29,686 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:38:29,687 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 17:38:29,687 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:38:29,687 Device: cpu\n",
      "2022-08-30 17:38:29,688 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:38:29,688 Embeddings storage mode: cpu\n",
      "2022-08-30 17:38:29,689 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:38:32,149 epoch 1 - iter 4/48 - loss 0.93973866 - samples/sec: 113.91 - lr: 0.001000\n",
      "2022-08-30 17:38:35,109 epoch 1 - iter 8/48 - loss 0.92088003 - samples/sec: 96.62 - lr: 0.001000\n",
      "2022-08-30 17:38:37,396 epoch 1 - iter 12/48 - loss 0.92189310 - samples/sec: 125.62 - lr: 0.001000\n",
      "2022-08-30 17:38:39,901 epoch 1 - iter 16/48 - loss 0.92828837 - samples/sec: 115.18 - lr: 0.001000\n",
      "2022-08-30 17:38:42,374 epoch 1 - iter 20/48 - loss 0.92643429 - samples/sec: 115.80 - lr: 0.001000\n",
      "2022-08-30 17:38:45,108 epoch 1 - iter 24/48 - loss 0.92953979 - samples/sec: 105.03 - lr: 0.001000\n",
      "2022-08-30 17:38:47,516 epoch 1 - iter 28/48 - loss 0.92705002 - samples/sec: 119.00 - lr: 0.001000\n",
      "2022-08-30 17:38:50,133 epoch 1 - iter 32/48 - loss 0.92853386 - samples/sec: 109.98 - lr: 0.001000\n",
      "2022-08-30 17:38:52,500 epoch 1 - iter 36/48 - loss 0.93088792 - samples/sec: 121.42 - lr: 0.001000\n",
      "2022-08-30 17:38:55,089 epoch 1 - iter 40/48 - loss 0.92758360 - samples/sec: 111.73 - lr: 0.001000\n",
      "2022-08-30 17:38:57,666 epoch 1 - iter 44/48 - loss 0.93399491 - samples/sec: 111.24 - lr: 0.001000\n",
      "2022-08-30 17:39:00,607 epoch 1 - iter 48/48 - loss 0.95343104 - samples/sec: 97.22 - lr: 0.001000\n",
      "2022-08-30 17:39:00,661 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:39:00,661 EPOCH 1 done: loss 0.9534 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:39:02,720 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:39:02,749 DEV : loss 0.7810553312301636 - f1-score (micro avg)  0.7266\n",
      "2022-08-30 17:39:02,769 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:39:02,771 saving best model\n",
      "2022-08-30 17:39:03,447 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:39:06,175 epoch 2 - iter 4/48 - loss 0.97593098 - samples/sec: 102.68 - lr: 0.001000\n",
      "2022-08-30 17:39:09,029 epoch 2 - iter 8/48 - loss 0.96270356 - samples/sec: 100.11 - lr: 0.001000\n",
      "2022-08-30 17:39:11,606 epoch 2 - iter 12/48 - loss 0.96013178 - samples/sec: 111.16 - lr: 0.001000\n",
      "2022-08-30 17:39:14,238 epoch 2 - iter 16/48 - loss 0.95454820 - samples/sec: 108.78 - lr: 0.001000\n",
      "2022-08-30 17:39:16,674 epoch 2 - iter 20/48 - loss 0.95382597 - samples/sec: 117.75 - lr: 0.001000\n",
      "2022-08-30 17:39:19,475 epoch 2 - iter 24/48 - loss 0.95577114 - samples/sec: 102.00 - lr: 0.001000\n",
      "2022-08-30 17:39:22,468 epoch 2 - iter 28/48 - loss 0.95732393 - samples/sec: 95.69 - lr: 0.001000\n",
      "2022-08-30 17:39:25,222 epoch 2 - iter 32/48 - loss 0.95448548 - samples/sec: 106.02 - lr: 0.001000\n",
      "2022-08-30 17:39:27,865 epoch 2 - iter 36/48 - loss 0.95390246 - samples/sec: 108.27 - lr: 0.001000\n",
      "2022-08-30 17:39:30,281 epoch 2 - iter 40/48 - loss 0.95421010 - samples/sec: 118.95 - lr: 0.001000\n",
      "2022-08-30 17:39:32,956 epoch 2 - iter 44/48 - loss 0.95324233 - samples/sec: 107.28 - lr: 0.001000\n",
      "2022-08-30 17:39:35,170 epoch 2 - iter 48/48 - loss 0.95255824 - samples/sec: 129.99 - lr: 0.001000\n",
      "2022-08-30 17:39:35,226 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:39:35,227 EPOCH 2 done: loss 0.9526 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:39:36,159 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:39:36,193 DEV : loss 0.7755822539329529 - f1-score (micro avg)  0.7264\n",
      "2022-08-30 17:39:36,211 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:39:36,213 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:39:38,814 epoch 3 - iter 4/48 - loss 0.94879925 - samples/sec: 107.69 - lr: 0.001000\n",
      "2022-08-30 17:39:41,700 epoch 3 - iter 8/48 - loss 0.95689884 - samples/sec: 99.57 - lr: 0.001000\n",
      "2022-08-30 17:39:44,206 epoch 3 - iter 12/48 - loss 0.95146630 - samples/sec: 114.47 - lr: 0.001000\n",
      "2022-08-30 17:39:46,953 epoch 3 - iter 16/48 - loss 0.95538164 - samples/sec: 104.09 - lr: 0.001000\n",
      "2022-08-30 17:39:49,983 epoch 3 - iter 20/48 - loss 0.94794853 - samples/sec: 94.31 - lr: 0.001000\n",
      "2022-08-30 17:39:52,562 epoch 3 - iter 24/48 - loss 0.95232816 - samples/sec: 111.24 - lr: 0.001000\n",
      "2022-08-30 17:39:55,048 epoch 3 - iter 28/48 - loss 0.95325593 - samples/sec: 115.42 - lr: 0.001000\n",
      "2022-08-30 17:39:57,414 epoch 3 - iter 32/48 - loss 0.95092020 - samples/sec: 121.48 - lr: 0.001000\n",
      "2022-08-30 17:40:00,081 epoch 3 - iter 36/48 - loss 0.95083127 - samples/sec: 107.36 - lr: 0.001000\n",
      "2022-08-30 17:40:02,888 epoch 3 - iter 40/48 - loss 0.94626830 - samples/sec: 101.86 - lr: 0.001000\n",
      "2022-08-30 17:40:05,758 epoch 3 - iter 44/48 - loss 0.94885109 - samples/sec: 99.68 - lr: 0.001000\n",
      "2022-08-30 17:40:08,041 epoch 3 - iter 48/48 - loss 0.94867778 - samples/sec: 125.96 - lr: 0.001000\n",
      "2022-08-30 17:40:08,098 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:40:08,098 EPOCH 3 done: loss 0.9487 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:40:08,902 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:40:08,931 DEV : loss 0.7740859985351562 - f1-score (micro avg)  0.7268\n",
      "2022-08-30 17:40:08,952 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:40:08,954 saving best model\n",
      "2022-08-30 17:40:10,182 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:40:12,633 epoch 4 - iter 4/48 - loss 0.95028951 - samples/sec: 114.29 - lr: 0.001000\n",
      "2022-08-30 17:40:15,012 epoch 4 - iter 8/48 - loss 0.93718213 - samples/sec: 120.69 - lr: 0.001000\n",
      "2022-08-30 17:40:17,906 epoch 4 - iter 12/48 - loss 0.94768331 - samples/sec: 98.87 - lr: 0.001000\n",
      "2022-08-30 17:40:20,952 epoch 4 - iter 16/48 - loss 0.93669380 - samples/sec: 93.87 - lr: 0.001000\n",
      "2022-08-30 17:40:23,489 epoch 4 - iter 20/48 - loss 0.93510108 - samples/sec: 113.09 - lr: 0.001000\n",
      "2022-08-30 17:40:26,145 epoch 4 - iter 24/48 - loss 0.93650710 - samples/sec: 107.94 - lr: 0.001000\n",
      "2022-08-30 17:40:28,905 epoch 4 - iter 28/48 - loss 0.94043112 - samples/sec: 103.74 - lr: 0.001000\n",
      "2022-08-30 17:40:31,313 epoch 4 - iter 32/48 - loss 0.94339199 - samples/sec: 119.10 - lr: 0.001000\n",
      "2022-08-30 17:40:33,961 epoch 4 - iter 36/48 - loss 0.94250409 - samples/sec: 109.42 - lr: 0.001000\n",
      "2022-08-30 17:40:36,709 epoch 4 - iter 40/48 - loss 0.94816156 - samples/sec: 104.13 - lr: 0.001000\n",
      "2022-08-30 17:40:39,191 epoch 4 - iter 44/48 - loss 0.94699332 - samples/sec: 115.85 - lr: 0.001000\n",
      "2022-08-30 17:40:41,937 epoch 4 - iter 48/48 - loss 0.94743678 - samples/sec: 104.09 - lr: 0.001000\n",
      "2022-08-30 17:40:41,996 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:40:41,997 EPOCH 4 done: loss 0.9474 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:40:42,826 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:40:42,856 DEV : loss 0.772881805896759 - f1-score (micro avg)  0.7274\n",
      "2022-08-30 17:40:42,874 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:40:42,875 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:40:43,586 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:40:46,130 epoch 5 - iter 4/48 - loss 0.94601149 - samples/sec: 110.15 - lr: 0.001000\n",
      "2022-08-30 17:40:48,726 epoch 5 - iter 8/48 - loss 0.94292098 - samples/sec: 110.41 - lr: 0.001000\n",
      "2022-08-30 17:40:51,124 epoch 5 - iter 12/48 - loss 0.93227145 - samples/sec: 121.16 - lr: 0.001000\n",
      "2022-08-30 17:40:53,693 epoch 5 - iter 16/48 - loss 0.93997860 - samples/sec: 111.73 - lr: 0.001000\n",
      "2022-08-30 17:40:56,316 epoch 5 - iter 20/48 - loss 0.94254014 - samples/sec: 109.50 - lr: 0.001000\n",
      "2022-08-30 17:40:59,002 epoch 5 - iter 24/48 - loss 0.94820737 - samples/sec: 106.71 - lr: 0.001000\n",
      "2022-08-30 17:41:01,773 epoch 5 - iter 28/48 - loss 0.95023546 - samples/sec: 103.44 - lr: 0.001000\n",
      "2022-08-30 17:41:04,251 epoch 5 - iter 32/48 - loss 0.94760155 - samples/sec: 116.23 - lr: 0.001000\n",
      "2022-08-30 17:41:06,931 epoch 5 - iter 36/48 - loss 0.95041423 - samples/sec: 106.87 - lr: 0.001000\n",
      "2022-08-30 17:41:10,012 epoch 5 - iter 40/48 - loss 0.95043046 - samples/sec: 92.99 - lr: 0.001000\n",
      "2022-08-30 17:41:12,777 epoch 5 - iter 44/48 - loss 0.94974020 - samples/sec: 103.74 - lr: 0.001000\n",
      "2022-08-30 17:41:15,079 epoch 5 - iter 48/48 - loss 0.94963497 - samples/sec: 125.00 - lr: 0.001000\n",
      "2022-08-30 17:41:15,135 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:41:15,136 EPOCH 5 done: loss 0.9496 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:41:15,925 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:41:15,956 DEV : loss 0.7723290920257568 - f1-score (micro avg)  0.7268\n",
      "2022-08-30 17:41:15,974 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:41:15,975 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:41:18,274 epoch 6 - iter 4/48 - loss 0.92556918 - samples/sec: 121.90 - lr: 0.001000\n",
      "2022-08-30 17:41:20,803 epoch 6 - iter 8/48 - loss 0.92415636 - samples/sec: 113.22 - lr: 0.001000\n",
      "2022-08-30 17:41:23,540 epoch 6 - iter 12/48 - loss 0.93525577 - samples/sec: 104.44 - lr: 0.001000\n",
      "2022-08-30 17:41:26,098 epoch 6 - iter 16/48 - loss 0.93333281 - samples/sec: 112.27 - lr: 0.001000\n",
      "2022-08-30 17:41:28,879 epoch 6 - iter 20/48 - loss 0.93630023 - samples/sec: 102.83 - lr: 0.001000\n",
      "2022-08-30 17:41:31,868 epoch 6 - iter 24/48 - loss 0.93690041 - samples/sec: 95.37 - lr: 0.001000\n",
      "2022-08-30 17:41:34,323 epoch 6 - iter 28/48 - loss 0.93728210 - samples/sec: 116.76 - lr: 0.001000\n",
      "2022-08-30 17:41:37,311 epoch 6 - iter 32/48 - loss 0.93806113 - samples/sec: 95.66 - lr: 0.001000\n",
      "2022-08-30 17:41:39,968 epoch 6 - iter 36/48 - loss 0.94523931 - samples/sec: 108.82 - lr: 0.001000\n",
      "2022-08-30 17:41:42,466 epoch 6 - iter 40/48 - loss 0.94581395 - samples/sec: 114.90 - lr: 0.001000\n",
      "2022-08-30 17:41:45,104 epoch 6 - iter 44/48 - loss 0.94738034 - samples/sec: 109.85 - lr: 0.001000\n",
      "2022-08-30 17:41:47,580 epoch 6 - iter 48/48 - loss 0.94703240 - samples/sec: 115.94 - lr: 0.001000\n",
      "2022-08-30 17:41:47,655 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:41:47,656 EPOCH 6 done: loss 0.9470 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:41:48,442 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:41:48,479 DEV : loss 0.7694693803787231 - f1-score (micro avg)  0.7279\n",
      "2022-08-30 17:41:48,499 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:41:48,500 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:41:49,195 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:41:51,451 epoch 7 - iter 4/48 - loss 0.93728663 - samples/sec: 124.28 - lr: 0.001000\n",
      "2022-08-30 17:41:54,042 epoch 7 - iter 8/48 - loss 0.93719959 - samples/sec: 110.63 - lr: 0.001000\n",
      "2022-08-30 17:41:56,820 epoch 7 - iter 12/48 - loss 0.94503462 - samples/sec: 102.94 - lr: 0.001000\n",
      "2022-08-30 17:41:59,713 epoch 7 - iter 16/48 - loss 0.95035698 - samples/sec: 98.87 - lr: 0.001000\n",
      "2022-08-30 17:42:02,636 epoch 7 - iter 20/48 - loss 0.94728152 - samples/sec: 97.97 - lr: 0.001000\n",
      "2022-08-30 17:42:05,395 epoch 7 - iter 24/48 - loss 0.94540578 - samples/sec: 103.78 - lr: 0.001000\n",
      "2022-08-30 17:42:08,018 epoch 7 - iter 28/48 - loss 0.94226199 - samples/sec: 109.42 - lr: 0.001000\n",
      "2022-08-30 17:42:10,487 epoch 7 - iter 32/48 - loss 0.94114253 - samples/sec: 116.18 - lr: 0.001000\n",
      "2022-08-30 17:42:12,898 epoch 7 - iter 36/48 - loss 0.94065560 - samples/sec: 119.66 - lr: 0.001000\n",
      "2022-08-30 17:42:15,808 epoch 7 - iter 40/48 - loss 0.94436770 - samples/sec: 98.18 - lr: 0.001000\n",
      "2022-08-30 17:42:18,702 epoch 7 - iter 44/48 - loss 0.94540880 - samples/sec: 98.70 - lr: 0.001000\n",
      "2022-08-30 17:42:20,981 epoch 7 - iter 48/48 - loss 0.94393730 - samples/sec: 126.53 - lr: 0.001000\n",
      "2022-08-30 17:42:21,045 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:42:21,046 EPOCH 7 done: loss 0.9439 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:42:21,857 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:42:21,886 DEV : loss 0.768486499786377 - f1-score (micro avg)  0.7287\n",
      "2022-08-30 17:42:21,903 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:42:21,904 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:42:22,789 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:42:25,523 epoch 8 - iter 4/48 - loss 0.94781568 - samples/sec: 102.53 - lr: 0.001000\n",
      "2022-08-30 17:42:28,422 epoch 8 - iter 8/48 - loss 0.95095662 - samples/sec: 98.73 - lr: 0.001000\n",
      "2022-08-30 17:42:31,220 epoch 8 - iter 12/48 - loss 0.95073059 - samples/sec: 102.68 - lr: 0.001000\n",
      "2022-08-30 17:42:33,905 epoch 8 - iter 16/48 - loss 0.94850125 - samples/sec: 106.75 - lr: 0.001000\n",
      "2022-08-30 17:42:36,426 epoch 8 - iter 20/48 - loss 0.94872186 - samples/sec: 113.59 - lr: 0.001000\n",
      "2022-08-30 17:42:39,078 epoch 8 - iter 24/48 - loss 0.94533409 - samples/sec: 107.82 - lr: 0.001000\n",
      "2022-08-30 17:42:42,000 epoch 8 - iter 28/48 - loss 0.94429830 - samples/sec: 98.25 - lr: 0.001000\n",
      "2022-08-30 17:42:44,610 epoch 8 - iter 32/48 - loss 0.94519849 - samples/sec: 110.11 - lr: 0.001000\n",
      "2022-08-30 17:42:46,973 epoch 8 - iter 36/48 - loss 0.94291976 - samples/sec: 122.38 - lr: 0.001000\n",
      "2022-08-30 17:42:49,671 epoch 8 - iter 40/48 - loss 0.94295872 - samples/sec: 106.02 - lr: 0.001000\n",
      "2022-08-30 17:42:52,369 epoch 8 - iter 44/48 - loss 0.94283505 - samples/sec: 107.78 - lr: 0.001000\n",
      "2022-08-30 17:42:54,709 epoch 8 - iter 48/48 - loss 0.94407660 - samples/sec: 123.57 - lr: 0.001000\n",
      "2022-08-30 17:42:54,770 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:42:54,770 EPOCH 8 done: loss 0.9441 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:42:55,640 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:42:55,667 DEV : loss 0.7688684463500977 - f1-score (micro avg)  0.7289\n",
      "2022-08-30 17:42:55,685 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:42:55,687 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:42:56,607 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:42:59,259 epoch 9 - iter 4/48 - loss 0.90886830 - samples/sec: 105.66 - lr: 0.001000\n",
      "2022-08-30 17:43:01,943 epoch 9 - iter 8/48 - loss 0.92826528 - samples/sec: 106.59 - lr: 0.001000\n",
      "2022-08-30 17:43:04,445 epoch 9 - iter 12/48 - loss 0.93385596 - samples/sec: 114.66 - lr: 0.001000\n",
      "2022-08-30 17:43:07,239 epoch 9 - iter 16/48 - loss 0.93495053 - samples/sec: 103.51 - lr: 0.001000\n",
      "2022-08-30 17:43:09,843 epoch 9 - iter 20/48 - loss 0.93619630 - samples/sec: 109.85 - lr: 0.001000\n",
      "2022-08-30 17:43:12,411 epoch 9 - iter 24/48 - loss 0.93639624 - samples/sec: 111.46 - lr: 0.001000\n",
      "2022-08-30 17:43:15,084 epoch 9 - iter 28/48 - loss 0.94072086 - samples/sec: 108.28 - lr: 0.001000\n",
      "2022-08-30 17:43:17,675 epoch 9 - iter 32/48 - loss 0.94124135 - samples/sec: 110.85 - lr: 0.001000\n",
      "2022-08-30 17:43:20,545 epoch 9 - iter 36/48 - loss 0.94322343 - samples/sec: 99.57 - lr: 0.001000\n",
      "2022-08-30 17:43:23,266 epoch 9 - iter 40/48 - loss 0.94310012 - samples/sec: 105.58 - lr: 0.001000\n",
      "2022-08-30 17:43:25,925 epoch 9 - iter 44/48 - loss 0.93991279 - samples/sec: 107.90 - lr: 0.001000\n",
      "2022-08-30 17:43:28,047 epoch 9 - iter 48/48 - loss 0.94254142 - samples/sec: 135.46 - lr: 0.001000\n",
      "2022-08-30 17:43:28,103 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:43:28,104 EPOCH 9 done: loss 0.9425 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:43:28,913 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:43:28,944 DEV : loss 0.7664691209793091 - f1-score (micro avg)  0.7294\n",
      "2022-08-30 17:43:28,959 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:43:28,960 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:43:29,666 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:43:32,409 epoch 10 - iter 4/48 - loss 0.95079644 - samples/sec: 102.12 - lr: 0.001000\n",
      "2022-08-30 17:43:35,127 epoch 10 - iter 8/48 - loss 0.94337708 - samples/sec: 106.50 - lr: 0.001000\n",
      "2022-08-30 17:43:37,543 epoch 10 - iter 12/48 - loss 0.94840157 - samples/sec: 118.74 - lr: 0.001000\n",
      "2022-08-30 17:43:40,145 epoch 10 - iter 16/48 - loss 0.94927479 - samples/sec: 110.28 - lr: 0.001000\n",
      "2022-08-30 17:43:42,764 epoch 10 - iter 20/48 - loss 0.94840280 - samples/sec: 109.50 - lr: 0.001000\n",
      "2022-08-30 17:43:45,194 epoch 10 - iter 24/48 - loss 0.95010710 - samples/sec: 117.99 - lr: 0.001000\n",
      "2022-08-30 17:43:48,079 epoch 10 - iter 28/48 - loss 0.94947753 - samples/sec: 98.98 - lr: 0.001000\n",
      "2022-08-30 17:43:51,080 epoch 10 - iter 32/48 - loss 0.95067505 - samples/sec: 95.11 - lr: 0.001000\n",
      "2022-08-30 17:43:53,838 epoch 10 - iter 36/48 - loss 0.95070470 - samples/sec: 103.74 - lr: 0.001000\n",
      "2022-08-30 17:43:56,298 epoch 10 - iter 40/48 - loss 0.94625214 - samples/sec: 116.52 - lr: 0.001000\n",
      "2022-08-30 17:43:59,016 epoch 10 - iter 44/48 - loss 0.94828460 - samples/sec: 105.74 - lr: 0.001000\n",
      "2022-08-30 17:44:01,486 epoch 10 - iter 48/48 - loss 0.94555526 - samples/sec: 116.62 - lr: 0.001000\n",
      "2022-08-30 17:44:01,561 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:44:01,562 EPOCH 10 done: loss 0.9456 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:44:02,337 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:44:02,371 DEV : loss 0.7662568688392639 - f1-score (micro avg)  0.7297\n",
      "2022-08-30 17:44:02,386 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:44:02,387 saving best model\n",
      "2022-08-30 17:44:03,090 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:44:05,519 epoch 11 - iter 4/48 - loss 0.94910962 - samples/sec: 115.32 - lr: 0.001000\n",
      "2022-08-30 17:44:08,113 epoch 11 - iter 8/48 - loss 0.94499548 - samples/sec: 110.50 - lr: 0.001000\n",
      "2022-08-30 17:44:10,692 epoch 11 - iter 12/48 - loss 0.93711731 - samples/sec: 111.16 - lr: 0.001000\n",
      "2022-08-30 17:44:13,087 epoch 11 - iter 16/48 - loss 0.93539292 - samples/sec: 120.90 - lr: 0.001000\n",
      "2022-08-30 17:44:15,954 epoch 11 - iter 20/48 - loss 0.94145766 - samples/sec: 99.61 - lr: 0.001000\n",
      "2022-08-30 17:44:18,674 epoch 11 - iter 24/48 - loss 0.94281132 - samples/sec: 105.14 - lr: 0.001000\n",
      "2022-08-30 17:44:21,474 epoch 11 - iter 28/48 - loss 0.94172808 - samples/sec: 102.19 - lr: 0.001000\n",
      "2022-08-30 17:44:23,788 epoch 11 - iter 32/48 - loss 0.94461218 - samples/sec: 125.50 - lr: 0.001000\n",
      "2022-08-30 17:44:26,516 epoch 11 - iter 36/48 - loss 0.94764170 - samples/sec: 104.83 - lr: 0.001000\n",
      "2022-08-30 17:44:29,442 epoch 11 - iter 40/48 - loss 0.94533340 - samples/sec: 97.53 - lr: 0.001000\n",
      "2022-08-30 17:44:32,032 epoch 11 - iter 44/48 - loss 0.94480442 - samples/sec: 111.11 - lr: 0.001000\n",
      "2022-08-30 17:44:34,263 epoch 11 - iter 48/48 - loss 0.94426827 - samples/sec: 129.27 - lr: 0.001000\n",
      "2022-08-30 17:44:34,321 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:44:34,321 EPOCH 11 done: loss 0.9443 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:44:35,169 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:44:35,200 DEV : loss 0.7652614116668701 - f1-score (micro avg)  0.7308\n",
      "2022-08-30 17:44:35,216 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:44:35,217 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:44:36,759 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:44:36,760 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 17:44:36,937 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:44:38,291 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:44:38,314 0.7458\t0.7458\t0.7458\t0.7458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:44:38,314 \n",
      "Results:\n",
      "- F-score (micro) 0.7458\n",
      "- F-score (macro) 0.5972\n",
      "- Accuracy 0.7458\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6609    0.7849    0.7176      1353\n",
      "         ADJ     0.5540    0.7098    0.6223       672\n",
      "       PUNCT     0.9850    0.9970    0.9910       660\n",
      "         ADP     0.8870    0.9163    0.9014       514\n",
      "        VERB     0.6307    0.6125    0.6215       449\n",
      "         AUX     0.9205    0.8299    0.8728       335\n",
      "       PROPN     0.8128    0.3969    0.5333       383\n",
      "       CCONJ     0.9895    0.9844    0.9869       192\n",
      "       SCONJ     0.9027    0.9076    0.9051       184\n",
      "         DET     0.6126    0.4224    0.5000       161\n",
      "         ADV     0.3016    0.1258    0.1776       151\n",
      "        PRON     0.9053    0.7478    0.8190       115\n",
      "         NUM     0.8421    0.2254    0.3556        71\n",
      "        PART     1.0000    0.3810    0.5517        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7458      5264\n",
      "   macro avg     0.6878    0.5651    0.5972      5264\n",
      "weighted avg     0.7524    0.7458    0.7364      5264\n",
      "\n",
      "2022-08-30 17:44:38,315 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:44:38,317 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 17:44:38,801 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 17:46:55,583 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:46:55,584 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 17:46:55,584 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:46:55,585 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 17:46:55,586 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:46:55,586 Parameters:\n",
      "2022-08-30 17:46:55,587  - learning_rate: \"0.001000\"\n",
      "2022-08-30 17:46:55,587  - mini_batch_size: \"70\"\n",
      "2022-08-30 17:46:55,587  - patience: \"3\"\n",
      "2022-08-30 17:46:55,588  - anneal_factor: \"0.5\"\n",
      "2022-08-30 17:46:55,589  - max_epochs: \"12\"\n",
      "2022-08-30 17:46:55,590  - shuffle: \"True\"\n",
      "2022-08-30 17:46:55,590  - train_with_dev: \"False\"\n",
      "2022-08-30 17:46:55,591  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 17:46:55,591 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:46:55,592 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 17:46:55,592 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:46:55,593 Device: cpu\n",
      "2022-08-30 17:46:55,594 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:46:55,594 Embeddings storage mode: cpu\n",
      "2022-08-30 17:46:55,594 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:46:57,948 epoch 1 - iter 4/48 - loss 0.93817942 - samples/sec: 119.05 - lr: 0.001000\n",
      "2022-08-30 17:47:00,828 epoch 1 - iter 8/48 - loss 0.90875910 - samples/sec: 99.22 - lr: 0.001000\n",
      "2022-08-30 17:47:03,060 epoch 1 - iter 12/48 - loss 0.91548799 - samples/sec: 128.79 - lr: 0.001000\n",
      "2022-08-30 17:47:05,542 epoch 1 - iter 16/48 - loss 0.91432333 - samples/sec: 115.23 - lr: 0.001000\n",
      "2022-08-30 17:47:08,296 epoch 1 - iter 20/48 - loss 0.90914878 - samples/sec: 106.02 - lr: 0.001000\n",
      "2022-08-30 17:47:11,134 epoch 1 - iter 24/48 - loss 0.91037125 - samples/sec: 100.79 - lr: 0.001000\n",
      "2022-08-30 17:47:13,641 epoch 1 - iter 28/48 - loss 0.91031832 - samples/sec: 114.52 - lr: 0.001000\n",
      "2022-08-30 17:47:16,314 epoch 1 - iter 32/48 - loss 0.91296708 - samples/sec: 107.03 - lr: 0.001000\n",
      "2022-08-30 17:47:18,817 epoch 1 - iter 36/48 - loss 0.91443606 - samples/sec: 115.04 - lr: 0.001000\n",
      "2022-08-30 17:47:21,577 epoch 1 - iter 40/48 - loss 0.90971193 - samples/sec: 103.67 - lr: 0.001000\n",
      "2022-08-30 17:47:24,334 epoch 1 - iter 44/48 - loss 0.91654952 - samples/sec: 104.52 - lr: 0.001000\n",
      "2022-08-30 17:47:27,323 epoch 1 - iter 48/48 - loss 0.93608304 - samples/sec: 96.85 - lr: 0.001000\n",
      "2022-08-30 17:47:27,391 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:47:27,392 EPOCH 1 done: loss 0.9361 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:47:28,202 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:47:28,233 DEV : loss 0.769015371799469 - f1-score (micro avg)  0.7313\n",
      "2022-08-30 17:47:28,255 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:47:28,256 saving best model\n",
      "2022-08-30 17:47:28,941 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:47:31,328 epoch 2 - iter 4/48 - loss 0.96236363 - samples/sec: 117.35 - lr: 0.001000\n",
      "2022-08-30 17:47:34,024 epoch 2 - iter 8/48 - loss 0.95170595 - samples/sec: 106.63 - lr: 0.001000\n",
      "2022-08-30 17:47:36,785 epoch 2 - iter 12/48 - loss 0.94860720 - samples/sec: 103.51 - lr: 0.001000\n",
      "2022-08-30 17:47:39,421 epoch 2 - iter 16/48 - loss 0.94055797 - samples/sec: 108.78 - lr: 0.001000\n",
      "2022-08-30 17:47:42,899 epoch 2 - iter 20/48 - loss 0.94485177 - samples/sec: 83.36 - lr: 0.001000\n",
      "2022-08-30 17:47:45,306 epoch 2 - iter 24/48 - loss 0.93700715 - samples/sec: 119.56 - lr: 0.001000\n",
      "2022-08-30 17:47:47,993 epoch 2 - iter 28/48 - loss 0.93848564 - samples/sec: 107.12 - lr: 0.001000\n",
      "2022-08-30 17:47:50,579 epoch 2 - iter 32/48 - loss 0.94054735 - samples/sec: 111.02 - lr: 0.001000\n",
      "2022-08-30 17:47:52,967 epoch 2 - iter 36/48 - loss 0.93827844 - samples/sec: 121.74 - lr: 0.001000\n",
      "2022-08-30 17:47:55,519 epoch 2 - iter 40/48 - loss 0.94025963 - samples/sec: 112.09 - lr: 0.001000\n",
      "2022-08-30 17:47:58,195 epoch 2 - iter 44/48 - loss 0.93822077 - samples/sec: 107.24 - lr: 0.001000\n",
      "2022-08-30 17:48:00,743 epoch 2 - iter 48/48 - loss 0.93827229 - samples/sec: 112.36 - lr: 0.001000\n",
      "2022-08-30 17:48:00,797 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:48:00,798 EPOCH 2 done: loss 0.9383 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:48:01,616 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:48:01,654 DEV : loss 0.762510359287262 - f1-score (micro avg)  0.7307\n",
      "2022-08-30 17:48:01,672 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:48:01,673 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:48:04,436 epoch 3 - iter 4/48 - loss 0.92734809 - samples/sec: 101.45 - lr: 0.001000\n",
      "2022-08-30 17:48:07,005 epoch 3 - iter 8/48 - loss 0.92172508 - samples/sec: 112.31 - lr: 0.001000\n",
      "2022-08-30 17:48:10,221 epoch 3 - iter 12/48 - loss 0.92793825 - samples/sec: 88.86 - lr: 0.001000\n",
      "2022-08-30 17:48:12,714 epoch 3 - iter 16/48 - loss 0.92581704 - samples/sec: 114.85 - lr: 0.001000\n",
      "2022-08-30 17:48:15,170 epoch 3 - iter 20/48 - loss 0.92860495 - samples/sec: 116.81 - lr: 0.001000\n",
      "2022-08-30 17:48:17,769 epoch 3 - iter 24/48 - loss 0.92944783 - samples/sec: 110.32 - lr: 0.001000\n",
      "2022-08-30 17:48:20,675 epoch 3 - iter 28/48 - loss 0.93142059 - samples/sec: 98.45 - lr: 0.001000\n",
      "2022-08-30 17:48:23,157 epoch 3 - iter 32/48 - loss 0.93400322 - samples/sec: 115.46 - lr: 0.001000\n",
      "2022-08-30 17:48:25,809 epoch 3 - iter 36/48 - loss 0.93615361 - samples/sec: 107.90 - lr: 0.001000\n",
      "2022-08-30 17:48:28,631 epoch 3 - iter 40/48 - loss 0.93740018 - samples/sec: 101.23 - lr: 0.001000\n",
      "2022-08-30 17:48:30,922 epoch 3 - iter 44/48 - loss 0.93867323 - samples/sec: 126.30 - lr: 0.001000\n",
      "2022-08-30 17:48:33,099 epoch 3 - iter 48/48 - loss 0.93802208 - samples/sec: 132.08 - lr: 0.001000\n",
      "2022-08-30 17:48:33,157 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:48:33,158 EPOCH 3 done: loss 0.9380 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:48:33,933 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:48:33,962 DEV : loss 0.7620362043380737 - f1-score (micro avg)  0.7325\n",
      "2022-08-30 17:48:33,979 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:48:33,980 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:48:34,698 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:48:37,044 epoch 4 - iter 4/48 - loss 0.96184161 - samples/sec: 119.40 - lr: 0.001000\n",
      "2022-08-30 17:48:39,641 epoch 4 - iter 8/48 - loss 0.94108296 - samples/sec: 110.45 - lr: 0.001000\n",
      "2022-08-30 17:48:42,164 epoch 4 - iter 12/48 - loss 0.93922339 - samples/sec: 115.23 - lr: 0.001000\n",
      "2022-08-30 17:48:44,715 epoch 4 - iter 16/48 - loss 0.93838448 - samples/sec: 112.09 - lr: 0.001000\n",
      "2022-08-30 17:48:47,146 epoch 4 - iter 20/48 - loss 0.93763361 - samples/sec: 117.99 - lr: 0.001000\n",
      "2022-08-30 17:48:49,776 epoch 4 - iter 24/48 - loss 0.93577754 - samples/sec: 109.03 - lr: 0.001000\n",
      "2022-08-30 17:48:52,628 epoch 4 - iter 28/48 - loss 0.93418373 - samples/sec: 100.18 - lr: 0.001000\n",
      "2022-08-30 17:48:55,307 epoch 4 - iter 32/48 - loss 0.93102274 - samples/sec: 106.91 - lr: 0.001000\n",
      "2022-08-30 17:48:57,789 epoch 4 - iter 36/48 - loss 0.93171765 - samples/sec: 115.46 - lr: 0.001000\n",
      "2022-08-30 17:49:00,584 epoch 4 - iter 40/48 - loss 0.93365894 - samples/sec: 102.15 - lr: 0.001000\n",
      "2022-08-30 17:49:03,310 epoch 4 - iter 44/48 - loss 0.93644031 - samples/sec: 106.42 - lr: 0.001000\n",
      "2022-08-30 17:49:06,155 epoch 4 - iter 48/48 - loss 0.93560060 - samples/sec: 100.94 - lr: 0.001000\n",
      "2022-08-30 17:49:06,239 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:49:06,240 EPOCH 4 done: loss 0.9356 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:49:07,019 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:49:07,053 DEV : loss 0.7596547603607178 - f1-score (micro avg)  0.7323\n",
      "2022-08-30 17:49:07,067 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:49:07,068 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:49:09,323 epoch 5 - iter 4/48 - loss 0.91710026 - samples/sec: 124.22 - lr: 0.001000\n",
      "2022-08-30 17:49:12,092 epoch 5 - iter 8/48 - loss 0.94111120 - samples/sec: 103.90 - lr: 0.001000\n",
      "2022-08-30 17:49:15,031 epoch 5 - iter 12/48 - loss 0.94723032 - samples/sec: 97.83 - lr: 0.001000\n",
      "2022-08-30 17:49:17,898 epoch 5 - iter 16/48 - loss 0.94473393 - samples/sec: 99.68 - lr: 0.001000\n",
      "2022-08-30 17:49:20,128 epoch 5 - iter 20/48 - loss 0.94086808 - samples/sec: 129.03 - lr: 0.001000\n",
      "2022-08-30 17:49:22,717 epoch 5 - iter 24/48 - loss 0.94466833 - samples/sec: 110.63 - lr: 0.001000\n",
      "2022-08-30 17:49:25,338 epoch 5 - iter 28/48 - loss 0.94196144 - samples/sec: 109.46 - lr: 0.001000\n",
      "2022-08-30 17:49:28,313 epoch 5 - iter 32/48 - loss 0.94051314 - samples/sec: 97.90 - lr: 0.001000\n",
      "2022-08-30 17:49:31,314 epoch 5 - iter 36/48 - loss 0.93509361 - samples/sec: 95.53 - lr: 0.001000\n",
      "2022-08-30 17:49:33,789 epoch 5 - iter 40/48 - loss 0.93339296 - samples/sec: 116.23 - lr: 0.001000\n",
      "2022-08-30 17:49:36,220 epoch 5 - iter 44/48 - loss 0.93326002 - samples/sec: 117.80 - lr: 0.001000\n",
      "2022-08-30 17:49:38,573 epoch 5 - iter 48/48 - loss 0.93347100 - samples/sec: 122.65 - lr: 0.001000\n",
      "2022-08-30 17:49:38,630 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:49:38,631 EPOCH 5 done: loss 0.9335 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:49:40,761 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:49:40,790 DEV : loss 0.7590652704238892 - f1-score (micro avg)  0.7328\n",
      "2022-08-30 17:49:40,807 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:49:40,808 saving best model\n",
      "2022-08-30 17:49:41,596 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:49:44,721 epoch 6 - iter 4/48 - loss 0.93782443 - samples/sec: 89.69 - lr: 0.001000\n",
      "2022-08-30 17:49:47,462 epoch 6 - iter 8/48 - loss 0.92675970 - samples/sec: 104.32 - lr: 0.001000\n",
      "2022-08-30 17:49:50,095 epoch 6 - iter 12/48 - loss 0.92649347 - samples/sec: 110.41 - lr: 0.001000\n",
      "2022-08-30 17:49:52,654 epoch 6 - iter 16/48 - loss 0.92177416 - samples/sec: 111.82 - lr: 0.001000\n",
      "2022-08-30 17:49:55,034 epoch 6 - iter 20/48 - loss 0.92560467 - samples/sec: 120.48 - lr: 0.001000\n",
      "2022-08-30 17:49:57,519 epoch 6 - iter 24/48 - loss 0.92831763 - samples/sec: 115.61 - lr: 0.001000\n",
      "2022-08-30 17:49:59,976 epoch 6 - iter 28/48 - loss 0.92835928 - samples/sec: 117.85 - lr: 0.001000\n",
      "2022-08-30 17:50:02,484 epoch 6 - iter 32/48 - loss 0.93533629 - samples/sec: 114.52 - lr: 0.001000\n",
      "2022-08-30 17:50:05,413 epoch 6 - iter 36/48 - loss 0.93608005 - samples/sec: 97.73 - lr: 0.001000\n",
      "2022-08-30 17:50:08,170 epoch 6 - iter 40/48 - loss 0.93584642 - samples/sec: 104.32 - lr: 0.001000\n",
      "2022-08-30 17:50:11,167 epoch 6 - iter 44/48 - loss 0.93572858 - samples/sec: 95.21 - lr: 0.001000\n",
      "2022-08-30 17:50:13,514 epoch 6 - iter 48/48 - loss 0.93569852 - samples/sec: 122.32 - lr: 0.001000\n",
      "2022-08-30 17:50:13,575 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:50:13,576 EPOCH 6 done: loss 0.9357 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:50:14,362 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:50:14,392 DEV : loss 0.7584441900253296 - f1-score (micro avg)  0.7333\n",
      "2022-08-30 17:50:14,408 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:50:14,408 saving best model\n",
      "2022-08-30 17:50:15,235 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:50:18,194 epoch 7 - iter 4/48 - loss 0.92501000 - samples/sec: 94.72 - lr: 0.001000\n",
      "2022-08-30 17:50:20,846 epoch 7 - iter 8/48 - loss 0.92805127 - samples/sec: 107.90 - lr: 0.001000\n",
      "2022-08-30 17:50:23,634 epoch 7 - iter 12/48 - loss 0.92685836 - samples/sec: 102.49 - lr: 0.001000\n",
      "2022-08-30 17:50:26,492 epoch 7 - iter 16/48 - loss 0.92927996 - samples/sec: 100.54 - lr: 0.001000\n",
      "2022-08-30 17:50:29,349 epoch 7 - iter 20/48 - loss 0.93386644 - samples/sec: 100.47 - lr: 0.001000\n",
      "2022-08-30 17:50:31,797 epoch 7 - iter 24/48 - loss 0.93519480 - samples/sec: 119.00 - lr: 0.001000\n",
      "2022-08-30 17:50:34,264 epoch 7 - iter 28/48 - loss 0.93595828 - samples/sec: 116.33 - lr: 0.001000\n",
      "2022-08-30 17:50:36,960 epoch 7 - iter 32/48 - loss 0.93655752 - samples/sec: 106.02 - lr: 0.001000\n",
      "2022-08-30 17:50:39,629 epoch 7 - iter 36/48 - loss 0.93652142 - samples/sec: 107.78 - lr: 0.001000\n",
      "2022-08-30 17:50:42,227 epoch 7 - iter 40/48 - loss 0.93712247 - samples/sec: 111.20 - lr: 0.001000\n",
      "2022-08-30 17:50:44,609 epoch 7 - iter 44/48 - loss 0.93574043 - samples/sec: 120.59 - lr: 0.001000\n",
      "2022-08-30 17:50:47,071 epoch 7 - iter 48/48 - loss 0.93402423 - samples/sec: 116.47 - lr: 0.001000\n",
      "2022-08-30 17:50:47,133 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:50:47,134 EPOCH 7 done: loss 0.9340 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:50:47,942 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:50:47,971 DEV : loss 0.7573302388191223 - f1-score (micro avg)  0.7323\n",
      "2022-08-30 17:50:47,988 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:50:47,989 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:50:50,465 epoch 8 - iter 4/48 - loss 0.91937387 - samples/sec: 113.13 - lr: 0.001000\n",
      "2022-08-30 17:50:52,974 epoch 8 - iter 8/48 - loss 0.92850892 - samples/sec: 115.04 - lr: 0.001000\n",
      "2022-08-30 17:50:55,758 epoch 8 - iter 12/48 - loss 0.92962270 - samples/sec: 102.71 - lr: 0.001000\n",
      "2022-08-30 17:50:58,441 epoch 8 - iter 16/48 - loss 0.93497307 - samples/sec: 107.07 - lr: 0.001000\n",
      "2022-08-30 17:51:00,840 epoch 8 - iter 20/48 - loss 0.93786114 - samples/sec: 120.74 - lr: 0.001000\n",
      "2022-08-30 17:51:03,589 epoch 8 - iter 24/48 - loss 0.93517852 - samples/sec: 103.93 - lr: 0.001000\n",
      "2022-08-30 17:51:06,575 epoch 8 - iter 28/48 - loss 0.93296104 - samples/sec: 95.69 - lr: 0.001000\n",
      "2022-08-30 17:51:08,908 epoch 8 - iter 32/48 - loss 0.93250163 - samples/sec: 122.91 - lr: 0.001000\n",
      "2022-08-30 17:51:12,000 epoch 8 - iter 36/48 - loss 0.93229490 - samples/sec: 92.26 - lr: 0.001000\n",
      "2022-08-30 17:51:14,758 epoch 8 - iter 40/48 - loss 0.93186645 - samples/sec: 103.90 - lr: 0.001000\n",
      "2022-08-30 17:51:17,240 epoch 8 - iter 44/48 - loss 0.93151806 - samples/sec: 115.89 - lr: 0.001000\n",
      "2022-08-30 17:51:19,846 epoch 8 - iter 48/48 - loss 0.93348053 - samples/sec: 110.02 - lr: 0.001000\n",
      "2022-08-30 17:51:19,906 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:51:19,906 EPOCH 8 done: loss 0.9335 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:51:20,710 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:51:20,740 DEV : loss 0.7562087178230286 - f1-score (micro avg)  0.7336\n",
      "2022-08-30 17:51:20,756 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:51:20,757 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:51:21,431 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:51:24,124 epoch 9 - iter 4/48 - loss 0.91048902 - samples/sec: 104.01 - lr: 0.001000\n",
      "2022-08-30 17:51:26,653 epoch 9 - iter 8/48 - loss 0.94364445 - samples/sec: 113.45 - lr: 0.001000\n",
      "2022-08-30 17:51:29,055 epoch 9 - iter 12/48 - loss 0.93431019 - samples/sec: 119.45 - lr: 0.001000\n",
      "2022-08-30 17:51:31,815 epoch 9 - iter 16/48 - loss 0.93114449 - samples/sec: 103.74 - lr: 0.001000\n",
      "2022-08-30 17:51:34,580 epoch 9 - iter 20/48 - loss 0.93798764 - samples/sec: 103.44 - lr: 0.001000\n",
      "2022-08-30 17:51:37,092 epoch 9 - iter 24/48 - loss 0.93539228 - samples/sec: 114.47 - lr: 0.001000\n",
      "2022-08-30 17:51:39,724 epoch 9 - iter 28/48 - loss 0.93168249 - samples/sec: 108.99 - lr: 0.001000\n",
      "2022-08-30 17:51:42,162 epoch 9 - iter 32/48 - loss 0.93454986 - samples/sec: 117.89 - lr: 0.001000\n",
      "2022-08-30 17:51:45,363 epoch 9 - iter 36/48 - loss 0.93335861 - samples/sec: 89.40 - lr: 0.001000\n",
      "2022-08-30 17:51:48,218 epoch 9 - iter 40/48 - loss 0.93285954 - samples/sec: 100.83 - lr: 0.001000\n",
      "2022-08-30 17:51:50,865 epoch 9 - iter 44/48 - loss 0.93319070 - samples/sec: 108.82 - lr: 0.001000\n",
      "2022-08-30 17:51:53,156 epoch 9 - iter 48/48 - loss 0.93250093 - samples/sec: 125.34 - lr: 0.001000\n",
      "2022-08-30 17:51:53,213 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:51:53,214 EPOCH 9 done: loss 0.9325 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:51:54,053 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:51:54,082 DEV : loss 0.7550098896026611 - f1-score (micro avg)  0.7354\n",
      "2022-08-30 17:51:54,097 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:51:54,099 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:51:54,789 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:51:57,756 epoch 10 - iter 4/48 - loss 0.93268895 - samples/sec: 94.44 - lr: 0.001000\n",
      "2022-08-30 17:52:00,392 epoch 10 - iter 8/48 - loss 0.95065964 - samples/sec: 108.44 - lr: 0.001000\n",
      "2022-08-30 17:52:03,150 epoch 10 - iter 12/48 - loss 0.94069701 - samples/sec: 105.11 - lr: 0.001000\n",
      "2022-08-30 17:52:05,694 epoch 10 - iter 16/48 - loss 0.93875718 - samples/sec: 112.77 - lr: 0.001000\n",
      "2022-08-30 17:52:08,117 epoch 10 - iter 20/48 - loss 0.93965781 - samples/sec: 118.64 - lr: 0.001000\n",
      "2022-08-30 17:52:10,822 epoch 10 - iter 24/48 - loss 0.93368293 - samples/sec: 105.74 - lr: 0.001000\n",
      "2022-08-30 17:52:13,439 epoch 10 - iter 28/48 - loss 0.93283734 - samples/sec: 109.38 - lr: 0.001000\n",
      "2022-08-30 17:52:16,245 epoch 10 - iter 32/48 - loss 0.93422339 - samples/sec: 103.13 - lr: 0.001000\n",
      "2022-08-30 17:52:18,915 epoch 10 - iter 36/48 - loss 0.93441892 - samples/sec: 107.32 - lr: 0.001000\n",
      "2022-08-30 17:52:21,231 epoch 10 - iter 40/48 - loss 0.93599558 - samples/sec: 124.28 - lr: 0.001000\n",
      "2022-08-30 17:52:23,896 epoch 10 - iter 44/48 - loss 0.93576146 - samples/sec: 107.44 - lr: 0.001000\n",
      "2022-08-30 17:52:26,238 epoch 10 - iter 48/48 - loss 0.93367328 - samples/sec: 122.81 - lr: 0.001000\n",
      "2022-08-30 17:52:26,292 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:52:26,293 EPOCH 10 done: loss 0.9337 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:52:27,106 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:52:27,141 DEV : loss 0.7536630630493164 - f1-score (micro avg)  0.7347\n",
      "2022-08-30 17:52:27,156 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:52:27,157 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:52:29,780 epoch 11 - iter 4/48 - loss 0.92689420 - samples/sec: 106.79 - lr: 0.001000\n",
      "2022-08-30 17:52:32,521 epoch 11 - iter 8/48 - loss 0.93000028 - samples/sec: 104.24 - lr: 0.001000\n",
      "2022-08-30 17:52:35,274 epoch 11 - iter 12/48 - loss 0.92867233 - samples/sec: 104.36 - lr: 0.001000\n",
      "2022-08-30 17:52:37,969 epoch 11 - iter 16/48 - loss 0.92471253 - samples/sec: 106.02 - lr: 0.001000\n",
      "2022-08-30 17:52:40,518 epoch 11 - iter 20/48 - loss 0.92053200 - samples/sec: 112.49 - lr: 0.001000\n",
      "2022-08-30 17:52:42,966 epoch 11 - iter 24/48 - loss 0.92502618 - samples/sec: 117.94 - lr: 0.001000\n",
      "2022-08-30 17:52:45,382 epoch 11 - iter 28/48 - loss 0.92495938 - samples/sec: 119.00 - lr: 0.001000\n",
      "2022-08-30 17:52:47,781 epoch 11 - iter 32/48 - loss 0.92760865 - samples/sec: 120.02 - lr: 0.001000\n",
      "2022-08-30 17:52:51,076 epoch 11 - iter 36/48 - loss 0.92740277 - samples/sec: 86.63 - lr: 0.001000\n",
      "2022-08-30 17:52:53,551 epoch 11 - iter 40/48 - loss 0.92788701 - samples/sec: 115.75 - lr: 0.001000\n",
      "2022-08-30 17:52:56,324 epoch 11 - iter 44/48 - loss 0.92914786 - samples/sec: 104.28 - lr: 0.001000\n",
      "2022-08-30 17:52:58,570 epoch 11 - iter 48/48 - loss 0.92844095 - samples/sec: 128.85 - lr: 0.001000\n",
      "2022-08-30 17:52:58,644 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:52:58,645 EPOCH 11 done: loss 0.9284 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:52:59,429 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:52:59,461 DEV : loss 0.7523167133331299 - f1-score (micro avg)  0.7364\n",
      "2022-08-30 17:52:59,479 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:52:59,480 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:53:00,621 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:53:03,281 epoch 12 - iter 4/48 - loss 0.95799703 - samples/sec: 105.34 - lr: 0.001000\n",
      "2022-08-30 17:53:06,024 epoch 12 - iter 8/48 - loss 0.94099687 - samples/sec: 104.40 - lr: 0.001000\n",
      "2022-08-30 17:53:08,660 epoch 12 - iter 12/48 - loss 0.93619373 - samples/sec: 108.86 - lr: 0.001000\n",
      "2022-08-30 17:53:11,338 epoch 12 - iter 16/48 - loss 0.93519108 - samples/sec: 106.95 - lr: 0.001000\n",
      "2022-08-30 17:53:14,180 epoch 12 - iter 20/48 - loss 0.92677125 - samples/sec: 102.90 - lr: 0.001000\n",
      "2022-08-30 17:53:16,979 epoch 12 - iter 24/48 - loss 0.93348332 - samples/sec: 102.12 - lr: 0.001000\n",
      "2022-08-30 17:53:19,308 epoch 12 - iter 28/48 - loss 0.93266481 - samples/sec: 123.46 - lr: 0.001000\n",
      "2022-08-30 17:53:21,870 epoch 12 - iter 32/48 - loss 0.93056905 - samples/sec: 112.00 - lr: 0.001000\n",
      "2022-08-30 17:53:24,286 epoch 12 - iter 36/48 - loss 0.93343110 - samples/sec: 118.59 - lr: 0.001000\n",
      "2022-08-30 17:53:26,957 epoch 12 - iter 40/48 - loss 0.93310023 - samples/sec: 107.12 - lr: 0.001000\n",
      "2022-08-30 17:53:29,633 epoch 12 - iter 44/48 - loss 0.93038575 - samples/sec: 106.99 - lr: 0.001000\n",
      "2022-08-30 17:53:32,298 epoch 12 - iter 48/48 - loss 0.93058408 - samples/sec: 107.57 - lr: 0.001000\n",
      "2022-08-30 17:53:32,365 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:53:32,366 EPOCH 12 done: loss 0.9306 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:53:33,202 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:53:33,233 DEV : loss 0.7527742385864258 - f1-score (micro avg)  0.7364\n",
      "2022-08-30 17:53:33,248 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:53:34,288 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:53:34,289 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 17:53:34,471 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:53:35,800 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:53:35,826 0.7454\t0.7454\t0.7454\t0.7454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:53:35,827 \n",
      "Results:\n",
      "- F-score (micro) 0.7454\n",
      "- F-score (macro) 0.5987\n",
      "- Accuracy 0.7454\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6608    0.7761    0.7138      1353\n",
      "         ADJ     0.5477    0.7173    0.6211       672\n",
      "       PUNCT     0.9850    0.9970    0.9910       660\n",
      "         ADP     0.8870    0.9163    0.9014       514\n",
      "        VERB     0.6430    0.6058    0.6239       449\n",
      "         AUX     0.9175    0.8299    0.8715       335\n",
      "       PROPN     0.7929    0.4099    0.5404       383\n",
      "       CCONJ     0.9895    0.9844    0.9869       192\n",
      "       SCONJ     0.9126    0.9076    0.9101       184\n",
      "         DET     0.6486    0.4472    0.5294       161\n",
      "         ADV     0.2812    0.1192    0.1674       151\n",
      "        PRON     0.9053    0.7478    0.8190       115\n",
      "         NUM     0.8000    0.2254    0.3516        71\n",
      "        PART     1.0000    0.3810    0.5517        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7454      5264\n",
      "   macro avg     0.6857    0.5665    0.5987      5264\n",
      "weighted avg     0.7513    0.7454    0.7367      5264\n",
      "\n",
      "2022-08-30 17:53:35,827 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:53:35,832 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 17:53:36,324 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 17:55:59,790 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:55:59,791 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 17:55:59,791 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:55:59,792 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 17:55:59,792 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:55:59,793 Parameters:\n",
      "2022-08-30 17:55:59,794  - learning_rate: \"0.001000\"\n",
      "2022-08-30 17:55:59,794  - mini_batch_size: \"90\"\n",
      "2022-08-30 17:55:59,795  - patience: \"3\"\n",
      "2022-08-30 17:55:59,796  - anneal_factor: \"0.5\"\n",
      "2022-08-30 17:55:59,796  - max_epochs: \"10\"\n",
      "2022-08-30 17:55:59,797  - shuffle: \"True\"\n",
      "2022-08-30 17:55:59,797  - train_with_dev: \"False\"\n",
      "2022-08-30 17:55:59,798  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 17:55:59,798 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:55:59,799 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 17:55:59,800 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:55:59,800 Device: cpu\n",
      "2022-08-30 17:55:59,801 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:55:59,801 Embeddings storage mode: cpu\n",
      "2022-08-30 17:55:59,802 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:56:02,068 epoch 1 - iter 3/37 - loss 0.93030001 - samples/sec: 119.21 - lr: 0.001000\n",
      "2022-08-30 17:56:04,742 epoch 1 - iter 6/37 - loss 0.89856082 - samples/sec: 103.17 - lr: 0.001000\n",
      "2022-08-30 17:56:06,943 epoch 1 - iter 9/37 - loss 0.89310320 - samples/sec: 125.99 - lr: 0.001000\n",
      "2022-08-30 17:56:09,222 epoch 1 - iter 12/37 - loss 0.89769960 - samples/sec: 122.01 - lr: 0.001000\n",
      "2022-08-30 17:56:11,557 epoch 1 - iter 15/37 - loss 0.90268323 - samples/sec: 118.89 - lr: 0.001000\n",
      "2022-08-30 17:56:13,857 epoch 1 - iter 18/37 - loss 0.89752757 - samples/sec: 120.48 - lr: 0.001000\n",
      "2022-08-30 17:56:16,579 epoch 1 - iter 21/37 - loss 0.90113032 - samples/sec: 101.47 - lr: 0.001000\n",
      "2022-08-30 17:56:18,886 epoch 1 - iter 24/37 - loss 0.90137585 - samples/sec: 119.79 - lr: 0.001000\n",
      "2022-08-30 17:56:21,216 epoch 1 - iter 27/37 - loss 0.90043017 - samples/sec: 119.73 - lr: 0.001000\n",
      "2022-08-30 17:56:23,280 epoch 1 - iter 30/37 - loss 0.90216318 - samples/sec: 134.93 - lr: 0.001000\n",
      "2022-08-30 17:56:25,944 epoch 1 - iter 33/37 - loss 0.90504411 - samples/sec: 103.45 - lr: 0.001000\n",
      "2022-08-30 17:56:28,766 epoch 1 - iter 36/37 - loss 0.92419830 - samples/sec: 97.68 - lr: 0.001000\n",
      "2022-08-30 17:56:29,895 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:56:29,896 EPOCH 1 done: loss 0.9286 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:56:30,676 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:56:30,712 DEV : loss 0.7564184069633484 - f1-score (micro avg)  0.7349\n",
      "2022-08-30 17:56:30,732 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:56:30,733 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:56:31,416 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:56:33,856 epoch 2 - iter 3/37 - loss 0.96090601 - samples/sec: 110.75 - lr: 0.001000\n",
      "2022-08-30 17:56:36,250 epoch 2 - iter 6/37 - loss 0.95059742 - samples/sec: 115.38 - lr: 0.001000\n",
      "2022-08-30 17:56:38,656 epoch 2 - iter 9/37 - loss 0.94645557 - samples/sec: 114.99 - lr: 0.001000\n",
      "2022-08-30 17:56:40,919 epoch 2 - iter 12/37 - loss 0.93792446 - samples/sec: 122.73 - lr: 0.001000\n",
      "2022-08-30 17:56:43,409 epoch 2 - iter 15/37 - loss 0.93416269 - samples/sec: 110.79 - lr: 0.001000\n",
      "2022-08-30 17:56:46,107 epoch 2 - iter 18/37 - loss 0.92921796 - samples/sec: 103.29 - lr: 0.001000\n",
      "2022-08-30 17:56:48,775 epoch 2 - iter 21/37 - loss 0.93095967 - samples/sec: 103.41 - lr: 0.001000\n",
      "2022-08-30 17:56:51,073 epoch 2 - iter 24/37 - loss 0.92702314 - samples/sec: 120.48 - lr: 0.001000\n",
      "2022-08-30 17:56:53,580 epoch 2 - iter 27/37 - loss 0.92784905 - samples/sec: 110.47 - lr: 0.001000\n",
      "2022-08-30 17:56:56,217 epoch 2 - iter 30/37 - loss 0.92699637 - samples/sec: 105.10 - lr: 0.001000\n",
      "2022-08-30 17:56:58,934 epoch 2 - iter 33/37 - loss 0.92565330 - samples/sec: 101.62 - lr: 0.001000\n",
      "2022-08-30 17:57:01,537 epoch 2 - iter 36/37 - loss 0.92447358 - samples/sec: 105.97 - lr: 0.001000\n",
      "2022-08-30 17:57:02,511 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:57:02,516 EPOCH 2 done: loss 0.9233 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:57:03,349 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:57:03,386 DEV : loss 0.7512505054473877 - f1-score (micro avg)  0.7364\n",
      "2022-08-30 17:57:03,410 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:57:03,411 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:57:04,203 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:57:06,414 epoch 3 - iter 3/37 - loss 0.93924262 - samples/sec: 122.23 - lr: 0.001000\n",
      "2022-08-30 17:57:08,816 epoch 3 - iter 6/37 - loss 0.92767557 - samples/sec: 117.09 - lr: 0.001000\n",
      "2022-08-30 17:57:11,039 epoch 3 - iter 9/37 - loss 0.92435547 - samples/sec: 124.88 - lr: 0.001000\n",
      "2022-08-30 17:57:13,469 epoch 3 - iter 12/37 - loss 0.92627774 - samples/sec: 113.83 - lr: 0.001000\n",
      "2022-08-30 17:57:16,113 epoch 3 - iter 15/37 - loss 0.92855023 - samples/sec: 104.65 - lr: 0.001000\n",
      "2022-08-30 17:57:18,601 epoch 3 - iter 18/37 - loss 0.92954357 - samples/sec: 110.93 - lr: 0.001000\n",
      "2022-08-30 17:57:21,157 epoch 3 - iter 21/37 - loss 0.93179096 - samples/sec: 108.83 - lr: 0.001000\n",
      "2022-08-30 17:57:24,138 epoch 3 - iter 24/37 - loss 0.93070426 - samples/sec: 92.50 - lr: 0.001000\n",
      "2022-08-30 17:57:26,713 epoch 3 - iter 27/37 - loss 0.92810503 - samples/sec: 107.57 - lr: 0.001000\n",
      "2022-08-30 17:57:29,152 epoch 3 - iter 30/37 - loss 0.92901241 - samples/sec: 113.49 - lr: 0.001000\n",
      "2022-08-30 17:57:31,563 epoch 3 - iter 33/37 - loss 0.92814687 - samples/sec: 114.70 - lr: 0.001000\n",
      "2022-08-30 17:57:34,011 epoch 3 - iter 36/37 - loss 0.92893428 - samples/sec: 113.30 - lr: 0.001000\n",
      "2022-08-30 17:57:34,946 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:57:34,946 EPOCH 3 done: loss 0.9288 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:57:35,750 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:57:35,782 DEV : loss 0.7501858472824097 - f1-score (micro avg)  0.7357\n",
      "2022-08-30 17:57:35,801 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:57:35,802 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:57:38,422 epoch 4 - iter 3/37 - loss 0.93242576 - samples/sec: 103.09 - lr: 0.001000\n",
      "2022-08-30 17:57:40,644 epoch 4 - iter 6/37 - loss 0.90994221 - samples/sec: 124.83 - lr: 0.001000\n",
      "2022-08-30 17:57:42,937 epoch 4 - iter 9/37 - loss 0.92173457 - samples/sec: 121.02 - lr: 0.001000\n",
      "2022-08-30 17:57:45,110 epoch 4 - iter 12/37 - loss 0.92067959 - samples/sec: 127.60 - lr: 0.001000\n",
      "2022-08-30 17:57:47,821 epoch 4 - iter 15/37 - loss 0.91836677 - samples/sec: 101.89 - lr: 0.001000\n",
      "2022-08-30 17:57:50,398 epoch 4 - iter 18/37 - loss 0.91847387 - samples/sec: 107.14 - lr: 0.001000\n",
      "2022-08-30 17:57:53,400 epoch 4 - iter 21/37 - loss 0.92002779 - samples/sec: 91.99 - lr: 0.001000\n",
      "2022-08-30 17:57:55,679 epoch 4 - iter 24/37 - loss 0.92166669 - samples/sec: 124.65 - lr: 0.001000\n",
      "2022-08-30 17:57:58,136 epoch 4 - iter 27/37 - loss 0.92396905 - samples/sec: 113.11 - lr: 0.001000\n",
      "2022-08-30 17:58:00,729 epoch 4 - iter 30/37 - loss 0.92543528 - samples/sec: 106.72 - lr: 0.001000\n",
      "2022-08-30 17:58:03,454 epoch 4 - iter 33/37 - loss 0.92622309 - samples/sec: 101.05 - lr: 0.001000\n",
      "2022-08-30 17:58:05,965 epoch 4 - iter 36/37 - loss 0.92685408 - samples/sec: 111.02 - lr: 0.001000\n",
      "2022-08-30 17:58:06,743 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:58:06,744 EPOCH 4 done: loss 0.9262 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:58:07,521 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:58:07,548 DEV : loss 0.7494960427284241 - f1-score (micro avg)  0.7368\n",
      "2022-08-30 17:58:07,567 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:58:07,568 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:58:08,380 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:58:10,487 epoch 5 - iter 3/37 - loss 0.94704456 - samples/sec: 128.21 - lr: 0.001000\n",
      "2022-08-30 17:58:12,959 epoch 5 - iter 6/37 - loss 0.93169397 - samples/sec: 112.36 - lr: 0.001000\n",
      "2022-08-30 17:58:15,960 epoch 5 - iter 9/37 - loss 0.92554483 - samples/sec: 91.65 - lr: 0.001000\n",
      "2022-08-30 17:58:18,217 epoch 5 - iter 12/37 - loss 0.92061394 - samples/sec: 122.62 - lr: 0.001000\n",
      "2022-08-30 17:58:21,004 epoch 5 - iter 15/37 - loss 0.92599014 - samples/sec: 98.97 - lr: 0.001000\n",
      "2022-08-30 17:58:23,744 epoch 5 - iter 18/37 - loss 0.92895331 - samples/sec: 100.67 - lr: 0.001000\n",
      "2022-08-30 17:58:26,004 epoch 5 - iter 21/37 - loss 0.93039389 - samples/sec: 122.62 - lr: 0.001000\n",
      "2022-08-30 17:58:28,359 epoch 5 - iter 24/37 - loss 0.92655633 - samples/sec: 119.42 - lr: 0.001000\n",
      "2022-08-30 17:58:30,570 epoch 5 - iter 27/37 - loss 0.92527827 - samples/sec: 125.70 - lr: 0.001000\n",
      "2022-08-30 17:58:32,929 epoch 5 - iter 30/37 - loss 0.92765247 - samples/sec: 117.49 - lr: 0.001000\n",
      "2022-08-30 17:58:35,324 epoch 5 - iter 33/37 - loss 0.92746392 - samples/sec: 115.63 - lr: 0.001000\n",
      "2022-08-30 17:58:38,079 epoch 5 - iter 36/37 - loss 0.92806918 - samples/sec: 101.81 - lr: 0.001000\n",
      "2022-08-30 17:58:38,710 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:58:38,711 EPOCH 5 done: loss 0.9286 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:58:39,536 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:58:39,563 DEV : loss 0.7486994862556458 - f1-score (micro avg)  0.7355\n",
      "2022-08-30 17:58:39,581 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:58:39,582 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:58:41,937 epoch 6 - iter 3/37 - loss 0.89191623 - samples/sec: 114.70 - lr: 0.001000\n",
      "2022-08-30 17:58:44,952 epoch 6 - iter 6/37 - loss 0.91099502 - samples/sec: 91.25 - lr: 0.001000\n",
      "2022-08-30 17:58:47,552 epoch 6 - iter 9/37 - loss 0.91459742 - samples/sec: 106.30 - lr: 0.001000\n",
      "2022-08-30 17:58:49,870 epoch 6 - iter 12/37 - loss 0.92209178 - samples/sec: 120.59 - lr: 0.001000\n",
      "2022-08-30 17:58:52,040 epoch 6 - iter 15/37 - loss 0.92465172 - samples/sec: 128.08 - lr: 0.001000\n",
      "2022-08-30 17:58:54,884 epoch 6 - iter 18/37 - loss 0.92632906 - samples/sec: 96.98 - lr: 0.001000\n",
      "2022-08-30 17:58:57,320 epoch 6 - iter 21/37 - loss 0.92539838 - samples/sec: 113.83 - lr: 0.001000\n",
      "2022-08-30 17:58:59,748 epoch 6 - iter 24/37 - loss 0.92687079 - samples/sec: 116.93 - lr: 0.001000\n",
      "2022-08-30 17:59:02,269 epoch 6 - iter 27/37 - loss 0.92801950 - samples/sec: 109.53 - lr: 0.001000\n",
      "2022-08-30 17:59:04,863 epoch 6 - iter 30/37 - loss 0.92832404 - samples/sec: 106.47 - lr: 0.001000\n",
      "2022-08-30 17:59:07,196 epoch 6 - iter 33/37 - loss 0.92690411 - samples/sec: 119.00 - lr: 0.001000\n",
      "2022-08-30 17:59:09,892 epoch 6 - iter 36/37 - loss 0.92716951 - samples/sec: 102.51 - lr: 0.001000\n",
      "2022-08-30 17:59:10,663 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:59:10,664 EPOCH 6 done: loss 0.9274 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:59:11,551 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:59:11,583 DEV : loss 0.7473501563072205 - f1-score (micro avg)  0.7385\n",
      "2022-08-30 17:59:11,599 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 17:59:11,600 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:59:12,321 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:59:14,666 epoch 7 - iter 3/37 - loss 0.91928145 - samples/sec: 115.24 - lr: 0.001000\n",
      "2022-08-30 17:59:17,249 epoch 7 - iter 6/37 - loss 0.91935027 - samples/sec: 107.44 - lr: 0.001000\n",
      "2022-08-30 17:59:19,533 epoch 7 - iter 9/37 - loss 0.92652608 - samples/sec: 121.51 - lr: 0.001000\n",
      "2022-08-30 17:59:21,938 epoch 7 - iter 12/37 - loss 0.91947739 - samples/sec: 115.83 - lr: 0.001000\n",
      "2022-08-30 17:59:24,546 epoch 7 - iter 15/37 - loss 0.92037229 - samples/sec: 105.80 - lr: 0.001000\n",
      "2022-08-30 17:59:27,625 epoch 7 - iter 18/37 - loss 0.92282037 - samples/sec: 89.88 - lr: 0.001000\n",
      "2022-08-30 17:59:30,679 epoch 7 - iter 21/37 - loss 0.92062757 - samples/sec: 90.39 - lr: 0.001000\n",
      "2022-08-30 17:59:32,847 epoch 7 - iter 24/37 - loss 0.92261729 - samples/sec: 128.39 - lr: 0.001000\n",
      "2022-08-30 17:59:35,197 epoch 7 - iter 27/37 - loss 0.92256937 - samples/sec: 118.06 - lr: 0.001000\n",
      "2022-08-30 17:59:37,497 epoch 7 - iter 30/37 - loss 0.92353497 - samples/sec: 120.32 - lr: 0.001000\n",
      "2022-08-30 17:59:39,839 epoch 7 - iter 33/37 - loss 0.92132084 - samples/sec: 119.57 - lr: 0.001000\n",
      "2022-08-30 17:59:42,325 epoch 7 - iter 36/37 - loss 0.92209947 - samples/sec: 111.11 - lr: 0.001000\n",
      "2022-08-30 17:59:43,093 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 17:59:43,093 EPOCH 7 done: loss 0.9220 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:59:43,871 Evaluating as a multi-label problem: False\n",
      "2022-08-30 17:59:43,903 DEV : loss 0.7477264404296875 - f1-score (micro avg)  0.7372\n",
      "2022-08-30 17:59:43,917 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 17:59:43,918 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:59:46,298 epoch 8 - iter 3/37 - loss 0.97119799 - samples/sec: 113.54 - lr: 0.001000\n",
      "2022-08-30 17:59:48,677 epoch 8 - iter 6/37 - loss 0.94367422 - samples/sec: 116.23 - lr: 0.001000\n",
      "2022-08-30 17:59:50,765 epoch 8 - iter 9/37 - loss 0.93503039 - samples/sec: 133.60 - lr: 0.001000\n",
      "2022-08-30 17:59:53,105 epoch 8 - iter 12/37 - loss 0.93755989 - samples/sec: 118.47 - lr: 0.001000\n",
      "2022-08-30 17:59:55,913 epoch 8 - iter 15/37 - loss 0.93518146 - samples/sec: 98.11 - lr: 0.001000\n",
      "2022-08-30 17:59:58,295 epoch 8 - iter 18/37 - loss 0.92866338 - samples/sec: 116.03 - lr: 0.001000\n",
      "2022-08-30 18:00:00,742 epoch 8 - iter 21/37 - loss 0.93047401 - samples/sec: 113.02 - lr: 0.001000\n",
      "2022-08-30 18:00:03,377 epoch 8 - iter 24/37 - loss 0.92854159 - samples/sec: 104.81 - lr: 0.001000\n",
      "2022-08-30 18:00:05,839 epoch 8 - iter 27/37 - loss 0.92726879 - samples/sec: 116.53 - lr: 0.001000\n",
      "2022-08-30 18:00:08,797 epoch 8 - iter 30/37 - loss 0.92882197 - samples/sec: 93.01 - lr: 0.001000\n",
      "2022-08-30 18:00:11,380 epoch 8 - iter 33/37 - loss 0.92921226 - samples/sec: 107.10 - lr: 0.001000\n",
      "2022-08-30 18:00:13,609 epoch 8 - iter 36/37 - loss 0.92800144 - samples/sec: 125.46 - lr: 0.001000\n",
      "2022-08-30 18:00:14,541 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:00:14,542 EPOCH 8 done: loss 0.9282 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:00:16,617 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:00:16,651 DEV : loss 0.7478482127189636 - f1-score (micro avg)  0.7368\n",
      "2022-08-30 18:00:16,668 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 18:00:16,669 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:00:18,893 epoch 9 - iter 3/37 - loss 0.94507986 - samples/sec: 121.46 - lr: 0.001000\n",
      "2022-08-30 18:00:21,613 epoch 9 - iter 6/37 - loss 0.93048083 - samples/sec: 101.89 - lr: 0.001000\n",
      "2022-08-30 18:00:24,183 epoch 9 - iter 9/37 - loss 0.92663322 - samples/sec: 107.70 - lr: 0.001000\n",
      "2022-08-30 18:00:26,658 epoch 9 - iter 12/37 - loss 0.92004704 - samples/sec: 111.71 - lr: 0.001000\n",
      "2022-08-30 18:00:28,870 epoch 9 - iter 15/37 - loss 0.92367012 - samples/sec: 125.35 - lr: 0.001000\n",
      "2022-08-30 18:00:31,444 epoch 9 - iter 18/37 - loss 0.92072773 - samples/sec: 107.19 - lr: 0.001000\n",
      "2022-08-30 18:00:33,461 epoch 9 - iter 21/37 - loss 0.91757847 - samples/sec: 140.33 - lr: 0.001000\n",
      "2022-08-30 18:00:36,035 epoch 9 - iter 24/37 - loss 0.91746397 - samples/sec: 108.48 - lr: 0.001000\n",
      "2022-08-30 18:00:38,498 epoch 9 - iter 27/37 - loss 0.91956422 - samples/sec: 112.31 - lr: 0.001000\n",
      "2022-08-30 18:00:41,049 epoch 9 - iter 30/37 - loss 0.91987334 - samples/sec: 109.05 - lr: 0.001000\n",
      "2022-08-30 18:00:43,602 epoch 9 - iter 33/37 - loss 0.92200489 - samples/sec: 108.09 - lr: 0.001000\n",
      "2022-08-30 18:00:46,485 epoch 9 - iter 36/37 - loss 0.92205199 - samples/sec: 95.71 - lr: 0.001000\n",
      "2022-08-30 18:00:47,240 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:00:47,241 EPOCH 9 done: loss 0.9219 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:00:48,054 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:00:48,088 DEV : loss 0.7448946833610535 - f1-score (micro avg)  0.7378\n",
      "2022-08-30 18:00:48,108 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 18:00:48,109 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:00:50,356 epoch 10 - iter 3/37 - loss 0.93163410 - samples/sec: 120.21 - lr: 0.001000\n",
      "2022-08-30 18:00:52,666 epoch 10 - iter 6/37 - loss 0.92511356 - samples/sec: 120.75 - lr: 0.001000\n",
      "2022-08-30 18:00:55,059 epoch 10 - iter 9/37 - loss 0.92714915 - samples/sec: 115.78 - lr: 0.001000\n",
      "2022-08-30 18:00:57,616 epoch 10 - iter 12/37 - loss 0.92772625 - samples/sec: 107.96 - lr: 0.001000\n",
      "2022-08-30 18:00:59,945 epoch 10 - iter 15/37 - loss 0.92986097 - samples/sec: 119.00 - lr: 0.001000\n",
      "2022-08-30 18:01:02,603 epoch 10 - iter 18/37 - loss 0.92765586 - samples/sec: 103.81 - lr: 0.001000\n",
      "2022-08-30 18:01:04,559 epoch 10 - iter 21/37 - loss 0.92765975 - samples/sec: 142.48 - lr: 0.001000\n",
      "2022-08-30 18:01:07,487 epoch 10 - iter 24/37 - loss 0.92643291 - samples/sec: 94.70 - lr: 0.001000\n",
      "2022-08-30 18:01:10,084 epoch 10 - iter 27/37 - loss 0.92462550 - samples/sec: 106.59 - lr: 0.001000\n",
      "2022-08-30 18:01:12,382 epoch 10 - iter 30/37 - loss 0.92326472 - samples/sec: 120.37 - lr: 0.001000\n",
      "2022-08-30 18:01:14,693 epoch 10 - iter 33/37 - loss 0.92429175 - samples/sec: 121.84 - lr: 0.001000\n",
      "2022-08-30 18:01:17,347 epoch 10 - iter 36/37 - loss 0.92295734 - samples/sec: 104.21 - lr: 0.001000\n",
      "2022-08-30 18:01:18,223 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:01:18,224 EPOCH 10 done: loss 0.9220 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:01:19,083 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:01:19,116 DEV : loss 0.7438938617706299 - f1-score (micro avg)  0.737\n",
      "2022-08-30 18:01:19,131 Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2022-08-30 18:01:19,132 BAD EPOCHS (no improvement): 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:01:19,967 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:01:19,968 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 18:01:20,148 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:01:21,507 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:01:21,531 0.7492\t0.7492\t0.7492\t0.7492\n",
      "2022-08-30 18:01:21,532 \n",
      "Results:\n",
      "- F-score (micro) 0.7492\n",
      "- F-score (macro) 0.6022\n",
      "- Accuracy 0.7492\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6629    0.7849    0.7188      1353\n",
      "         ADJ     0.5557    0.7202    0.6273       672\n",
      "       PUNCT     0.9836    0.9985    0.9910       660\n",
      "         ADP     0.8937    0.9163    0.9049       514\n",
      "        VERB     0.6430    0.6058    0.6239       449\n",
      "         AUX     0.9269    0.8328    0.8774       335\n",
      "       PROPN     0.8061    0.4125    0.5458       383\n",
      "       CCONJ     0.9895    0.9844    0.9869       192\n",
      "       SCONJ     0.9135    0.9185    0.9160       184\n",
      "         DET     0.6606    0.4472    0.5333       161\n",
      "         ADV     0.2727    0.1192    0.1659       151\n",
      "        PRON     0.9053    0.7478    0.8190       115\n",
      "         NUM     0.8500    0.2394    0.3736        71\n",
      "        PART     1.0000    0.3810    0.5517        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7492      5264\n",
      "   macro avg     0.6915    0.5693    0.6022      5264\n",
      "weighted avg     0.7557    0.7492    0.7404      5264\n",
      "\n",
      "2022-08-30 18:01:21,532 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:01:21,535 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:01:22,026 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 18:03:43,580 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:03:43,580 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 18:03:43,581 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:03:43,582 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 18:03:43,582 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:03:43,582 Parameters:\n",
      "2022-08-30 18:03:43,583  - learning_rate: \"0.001000\"\n",
      "2022-08-30 18:03:43,583  - mini_batch_size: \"90\"\n",
      "2022-08-30 18:03:43,584  - patience: \"3\"\n",
      "2022-08-30 18:03:43,585  - anneal_factor: \"0.5\"\n",
      "2022-08-30 18:03:43,586  - max_epochs: \"11\"\n",
      "2022-08-30 18:03:43,586  - shuffle: \"True\"\n",
      "2022-08-30 18:03:43,587  - train_with_dev: \"False\"\n",
      "2022-08-30 18:03:43,587  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 18:03:43,588 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:03:43,588 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 18:03:43,589 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:03:43,590 Device: cpu\n",
      "2022-08-30 18:03:43,590 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:03:43,591 Embeddings storage mode: cpu\n",
      "2022-08-30 18:03:43,592 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:03:45,873 epoch 1 - iter 3/37 - loss 0.92040798 - samples/sec: 118.37 - lr: 0.001000\n",
      "2022-08-30 18:03:48,573 epoch 1 - iter 6/37 - loss 0.89300713 - samples/sec: 102.27 - lr: 0.001000\n",
      "2022-08-30 18:03:50,821 epoch 1 - iter 9/37 - loss 0.89473326 - samples/sec: 123.85 - lr: 0.001000\n",
      "2022-08-30 18:03:53,046 epoch 1 - iter 12/37 - loss 0.89574028 - samples/sec: 125.12 - lr: 0.001000\n",
      "2022-08-30 18:03:55,363 epoch 1 - iter 15/37 - loss 0.90150482 - samples/sec: 120.05 - lr: 0.001000\n",
      "2022-08-30 18:03:57,733 epoch 1 - iter 18/37 - loss 0.89908511 - samples/sec: 117.85 - lr: 0.001000\n",
      "2022-08-30 18:04:00,360 epoch 1 - iter 21/37 - loss 0.89849525 - samples/sec: 105.35 - lr: 0.001000\n",
      "2022-08-30 18:04:02,745 epoch 1 - iter 24/37 - loss 0.89899502 - samples/sec: 116.53 - lr: 0.001000\n",
      "2022-08-30 18:04:05,124 epoch 1 - iter 27/37 - loss 0.89820960 - samples/sec: 116.08 - lr: 0.001000\n",
      "2022-08-30 18:04:07,153 epoch 1 - iter 30/37 - loss 0.89938022 - samples/sec: 136.85 - lr: 0.001000\n",
      "2022-08-30 18:04:09,775 epoch 1 - iter 33/37 - loss 0.90343908 - samples/sec: 105.39 - lr: 0.001000\n",
      "2022-08-30 18:04:12,575 epoch 1 - iter 36/37 - loss 0.92020260 - samples/sec: 99.37 - lr: 0.001000\n",
      "2022-08-30 18:04:13,738 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:04:13,738 EPOCH 1 done: loss 0.9252 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:04:14,552 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:04:14,583 DEV : loss 0.7503014206886292 - f1-score (micro avg)  0.7357\n",
      "2022-08-30 18:04:14,605 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:04:14,606 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:04:15,302 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:04:17,933 epoch 2 - iter 3/37 - loss 0.90280523 - samples/sec: 102.66 - lr: 0.001000\n",
      "2022-08-30 18:04:20,484 epoch 2 - iter 6/37 - loss 0.92350487 - samples/sec: 108.13 - lr: 0.001000\n",
      "2022-08-30 18:04:23,273 epoch 2 - iter 9/37 - loss 0.92234158 - samples/sec: 99.59 - lr: 0.001000\n",
      "2022-08-30 18:04:25,656 epoch 2 - iter 12/37 - loss 0.91604426 - samples/sec: 115.98 - lr: 0.001000\n",
      "2022-08-30 18:04:27,949 epoch 2 - iter 15/37 - loss 0.92014292 - samples/sec: 120.86 - lr: 0.001000\n",
      "2022-08-30 18:04:30,309 epoch 2 - iter 18/37 - loss 0.91702722 - samples/sec: 117.19 - lr: 0.001000\n",
      "2022-08-30 18:04:32,749 epoch 2 - iter 21/37 - loss 0.92002498 - samples/sec: 114.07 - lr: 0.001000\n",
      "2022-08-30 18:04:34,875 epoch 2 - iter 24/37 - loss 0.92103209 - samples/sec: 130.50 - lr: 0.001000\n",
      "2022-08-30 18:04:37,176 epoch 2 - iter 27/37 - loss 0.92360498 - samples/sec: 120.27 - lr: 0.001000\n",
      "2022-08-30 18:04:39,880 epoch 2 - iter 30/37 - loss 0.92274258 - samples/sec: 102.00 - lr: 0.001000\n",
      "2022-08-30 18:04:42,329 epoch 2 - iter 33/37 - loss 0.92252262 - samples/sec: 112.83 - lr: 0.001000\n",
      "2022-08-30 18:04:45,049 epoch 2 - iter 36/37 - loss 0.92401139 - samples/sec: 102.12 - lr: 0.001000\n",
      "2022-08-30 18:04:45,788 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:04:45,789 EPOCH 2 done: loss 0.9239 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:04:46,603 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:04:46,630 DEV : loss 0.7464645504951477 - f1-score (micro avg)  0.7383\n",
      "2022-08-30 18:04:46,649 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:04:46,650 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:04:47,368 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:04:49,614 epoch 3 - iter 3/37 - loss 0.94163064 - samples/sec: 120.27 - lr: 0.001000\n",
      "2022-08-30 18:04:52,430 epoch 3 - iter 6/37 - loss 0.92538040 - samples/sec: 98.15 - lr: 0.001000\n",
      "2022-08-30 18:04:55,211 epoch 3 - iter 9/37 - loss 0.93286889 - samples/sec: 101.35 - lr: 0.001000\n",
      "2022-08-30 18:04:57,357 epoch 3 - iter 12/37 - loss 0.92975603 - samples/sec: 129.06 - lr: 0.001000\n",
      "2022-08-30 18:04:59,757 epoch 3 - iter 15/37 - loss 0.92680031 - samples/sec: 115.78 - lr: 0.001000\n",
      "2022-08-30 18:05:02,341 epoch 3 - iter 18/37 - loss 0.92560384 - samples/sec: 106.85 - lr: 0.001000\n",
      "2022-08-30 18:05:04,987 epoch 3 - iter 21/37 - loss 0.92541607 - samples/sec: 105.84 - lr: 0.001000\n",
      "2022-08-30 18:05:07,648 epoch 3 - iter 24/37 - loss 0.92509835 - samples/sec: 103.97 - lr: 0.001000\n",
      "2022-08-30 18:05:10,077 epoch 3 - iter 27/37 - loss 0.92402130 - samples/sec: 113.73 - lr: 0.001000\n",
      "2022-08-30 18:05:12,809 epoch 3 - iter 30/37 - loss 0.92272020 - samples/sec: 100.97 - lr: 0.001000\n",
      "2022-08-30 18:05:15,082 epoch 3 - iter 33/37 - loss 0.92148132 - samples/sec: 121.73 - lr: 0.001000\n",
      "2022-08-30 18:05:17,461 epoch 3 - iter 36/37 - loss 0.92248278 - samples/sec: 116.48 - lr: 0.001000\n",
      "2022-08-30 18:05:18,310 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:05:18,311 EPOCH 3 done: loss 0.9223 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:05:19,117 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:05:19,146 DEV : loss 0.7447068095207214 - f1-score (micro avg)  0.7385\n",
      "2022-08-30 18:05:19,161 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:05:19,162 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:05:20,216 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:05:22,461 epoch 4 - iter 3/37 - loss 0.90362725 - samples/sec: 120.32 - lr: 0.001000\n",
      "2022-08-30 18:05:24,870 epoch 4 - iter 6/37 - loss 0.91482896 - samples/sec: 115.14 - lr: 0.001000\n",
      "2022-08-30 18:05:27,300 epoch 4 - iter 9/37 - loss 0.90153502 - samples/sec: 113.92 - lr: 0.001000\n",
      "2022-08-30 18:05:29,731 epoch 4 - iter 12/37 - loss 0.91351528 - samples/sec: 114.07 - lr: 0.001000\n",
      "2022-08-30 18:05:32,078 epoch 4 - iter 15/37 - loss 0.91967127 - samples/sec: 118.32 - lr: 0.001000\n",
      "2022-08-30 18:05:35,057 epoch 4 - iter 18/37 - loss 0.92445602 - samples/sec: 92.31 - lr: 0.001000\n",
      "2022-08-30 18:05:37,216 epoch 4 - iter 21/37 - loss 0.92469030 - samples/sec: 128.82 - lr: 0.001000\n",
      "2022-08-30 18:05:39,719 epoch 4 - iter 24/37 - loss 0.92595799 - samples/sec: 110.38 - lr: 0.001000\n",
      "2022-08-30 18:05:42,158 epoch 4 - iter 27/37 - loss 0.92471401 - samples/sec: 113.35 - lr: 0.001000\n",
      "2022-08-30 18:05:44,670 epoch 4 - iter 30/37 - loss 0.92213231 - samples/sec: 109.93 - lr: 0.001000\n",
      "2022-08-30 18:05:47,453 epoch 4 - iter 33/37 - loss 0.92172658 - samples/sec: 98.97 - lr: 0.001000\n",
      "2022-08-30 18:05:49,948 epoch 4 - iter 36/37 - loss 0.92378217 - samples/sec: 111.25 - lr: 0.001000\n",
      "2022-08-30 18:05:50,858 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:05:50,859 EPOCH 4 done: loss 0.9245 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:05:51,635 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:05:51,670 DEV : loss 0.7447991967201233 - f1-score (micro avg)  0.7365\n",
      "2022-08-30 18:05:51,686 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:05:51,687 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:05:54,078 epoch 5 - iter 3/37 - loss 0.89542094 - samples/sec: 113.02 - lr: 0.001000\n",
      "2022-08-30 18:05:56,307 epoch 5 - iter 6/37 - loss 0.92248189 - samples/sec: 124.37 - lr: 0.001000\n",
      "2022-08-30 18:05:59,702 epoch 5 - iter 9/37 - loss 0.92941967 - samples/sec: 81.08 - lr: 0.001000\n",
      "2022-08-30 18:06:02,326 epoch 5 - iter 12/37 - loss 0.92666178 - samples/sec: 105.02 - lr: 0.001000\n",
      "2022-08-30 18:06:04,910 epoch 5 - iter 15/37 - loss 0.92017821 - samples/sec: 109.85 - lr: 0.001000\n",
      "2022-08-30 18:06:07,257 epoch 5 - iter 18/37 - loss 0.91983648 - samples/sec: 117.80 - lr: 0.001000\n",
      "2022-08-30 18:06:09,554 epoch 5 - iter 21/37 - loss 0.92512703 - samples/sec: 120.86 - lr: 0.001000\n",
      "2022-08-30 18:06:11,837 epoch 5 - iter 24/37 - loss 0.92535915 - samples/sec: 121.73 - lr: 0.001000\n",
      "2022-08-30 18:06:14,684 epoch 5 - iter 27/37 - loss 0.92458774 - samples/sec: 96.88 - lr: 0.001000\n",
      "2022-08-30 18:06:16,921 epoch 5 - iter 30/37 - loss 0.92253331 - samples/sec: 123.85 - lr: 0.001000\n",
      "2022-08-30 18:06:19,494 epoch 5 - iter 33/37 - loss 0.92121545 - samples/sec: 107.31 - lr: 0.001000\n",
      "2022-08-30 18:06:21,768 epoch 5 - iter 36/37 - loss 0.92267387 - samples/sec: 122.39 - lr: 0.001000\n",
      "2022-08-30 18:06:22,625 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:06:22,626 EPOCH 5 done: loss 0.9225 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:06:23,419 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:06:23,446 DEV : loss 0.7422319054603577 - f1-score (micro avg)  0.7386\n",
      "2022-08-30 18:06:23,462 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:06:23,463 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:06:24,241 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:06:26,715 epoch 6 - iter 3/37 - loss 0.94395605 - samples/sec: 109.18 - lr: 0.001000\n",
      "2022-08-30 18:06:29,052 epoch 6 - iter 6/37 - loss 0.93498753 - samples/sec: 119.36 - lr: 0.001000\n",
      "2022-08-30 18:06:32,006 epoch 6 - iter 9/37 - loss 0.93420755 - samples/sec: 93.26 - lr: 0.001000\n",
      "2022-08-30 18:06:34,376 epoch 6 - iter 12/37 - loss 0.92464735 - samples/sec: 117.19 - lr: 0.001000\n",
      "2022-08-30 18:06:37,251 epoch 6 - iter 15/37 - loss 0.92083327 - samples/sec: 97.05 - lr: 0.001000\n",
      "2022-08-30 18:06:39,385 epoch 6 - iter 18/37 - loss 0.91808787 - samples/sec: 130.06 - lr: 0.001000\n",
      "2022-08-30 18:06:41,648 epoch 6 - iter 21/37 - loss 0.91712367 - samples/sec: 123.12 - lr: 0.001000\n",
      "2022-08-30 18:06:44,271 epoch 6 - iter 24/37 - loss 0.92080869 - samples/sec: 105.35 - lr: 0.001000\n",
      "2022-08-30 18:06:46,858 epoch 6 - iter 27/37 - loss 0.92279515 - samples/sec: 106.59 - lr: 0.001000\n",
      "2022-08-30 18:06:49,300 epoch 6 - iter 30/37 - loss 0.91769495 - samples/sec: 113.16 - lr: 0.001000\n",
      "2022-08-30 18:06:51,724 epoch 6 - iter 33/37 - loss 0.91632853 - samples/sec: 114.36 - lr: 0.001000\n",
      "2022-08-30 18:06:54,145 epoch 6 - iter 36/37 - loss 0.91926126 - samples/sec: 114.12 - lr: 0.001000\n",
      "2022-08-30 18:06:54,971 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:06:54,972 EPOCH 6 done: loss 0.9185 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:06:55,796 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:06:55,824 DEV : loss 0.7428961396217346 - f1-score (micro avg)  0.7414\n",
      "2022-08-30 18:06:55,839 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:06:55,840 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:06:56,546 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:06:59,334 epoch 7 - iter 3/37 - loss 0.92500037 - samples/sec: 96.91 - lr: 0.001000\n",
      "2022-08-30 18:07:02,028 epoch 7 - iter 6/37 - loss 0.94072703 - samples/sec: 104.61 - lr: 0.001000\n",
      "2022-08-30 18:07:04,775 epoch 7 - iter 9/37 - loss 0.93568098 - samples/sec: 100.41 - lr: 0.001000\n",
      "2022-08-30 18:07:07,301 epoch 7 - iter 12/37 - loss 0.93683042 - samples/sec: 109.40 - lr: 0.001000\n",
      "2022-08-30 18:07:09,698 epoch 7 - iter 15/37 - loss 0.93434953 - samples/sec: 115.78 - lr: 0.001000\n",
      "2022-08-30 18:07:12,056 epoch 7 - iter 18/37 - loss 0.93284530 - samples/sec: 118.32 - lr: 0.001000\n",
      "2022-08-30 18:07:14,339 epoch 7 - iter 21/37 - loss 0.93127297 - samples/sec: 122.28 - lr: 0.001000\n",
      "2022-08-30 18:07:16,562 epoch 7 - iter 24/37 - loss 0.93443303 - samples/sec: 125.29 - lr: 0.001000\n",
      "2022-08-30 18:07:18,877 epoch 7 - iter 27/37 - loss 0.93335523 - samples/sec: 121.13 - lr: 0.001000\n",
      "2022-08-30 18:07:21,184 epoch 7 - iter 30/37 - loss 0.93077411 - samples/sec: 120.32 - lr: 0.001000\n",
      "2022-08-30 18:07:23,836 epoch 7 - iter 33/37 - loss 0.92819459 - samples/sec: 104.09 - lr: 0.001000\n",
      "2022-08-30 18:07:26,515 epoch 7 - iter 36/37 - loss 0.92634890 - samples/sec: 103.17 - lr: 0.001000\n",
      "2022-08-30 18:07:27,329 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:07:27,330 EPOCH 7 done: loss 0.9255 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:07:28,110 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:07:28,141 DEV : loss 0.7414447665214539 - f1-score (micro avg)  0.7388\n",
      "2022-08-30 18:07:28,156 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:07:28,157 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:07:30,138 epoch 8 - iter 3/37 - loss 0.89746506 - samples/sec: 136.43 - lr: 0.001000\n",
      "2022-08-30 18:07:32,224 epoch 8 - iter 6/37 - loss 0.89692215 - samples/sec: 133.14 - lr: 0.001000\n",
      "2022-08-30 18:07:34,706 epoch 8 - iter 9/37 - loss 0.90534929 - samples/sec: 111.25 - lr: 0.001000\n",
      "2022-08-30 18:07:37,305 epoch 8 - iter 12/37 - loss 0.90739289 - samples/sec: 106.26 - lr: 0.001000\n",
      "2022-08-30 18:07:39,791 epoch 8 - iter 15/37 - loss 0.91576745 - samples/sec: 111.43 - lr: 0.001000\n",
      "2022-08-30 18:07:42,315 epoch 8 - iter 18/37 - loss 0.91853875 - samples/sec: 109.98 - lr: 0.001000\n",
      "2022-08-30 18:07:44,541 epoch 8 - iter 21/37 - loss 0.91621575 - samples/sec: 126.46 - lr: 0.001000\n",
      "2022-08-30 18:07:47,509 epoch 8 - iter 24/37 - loss 0.91760286 - samples/sec: 92.85 - lr: 0.001000\n",
      "2022-08-30 18:07:49,790 epoch 8 - iter 27/37 - loss 0.91514796 - samples/sec: 123.57 - lr: 0.001000\n",
      "2022-08-30 18:07:52,531 epoch 8 - iter 30/37 - loss 0.91651106 - samples/sec: 100.90 - lr: 0.001000\n",
      "2022-08-30 18:07:54,997 epoch 8 - iter 33/37 - loss 0.91599091 - samples/sec: 112.27 - lr: 0.001000\n",
      "2022-08-30 18:07:57,324 epoch 8 - iter 36/37 - loss 0.91671877 - samples/sec: 119.36 - lr: 0.001000\n",
      "2022-08-30 18:07:58,115 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:07:58,116 EPOCH 8 done: loss 0.9186 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:07:58,926 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:07:58,953 DEV : loss 0.7402653694152832 - f1-score (micro avg)  0.7383\n",
      "2022-08-30 18:07:58,969 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 18:07:58,970 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:08:01,288 epoch 9 - iter 3/37 - loss 0.92331611 - samples/sec: 116.53 - lr: 0.001000\n",
      "2022-08-30 18:08:03,750 epoch 9 - iter 6/37 - loss 0.91973109 - samples/sec: 112.36 - lr: 0.001000\n",
      "2022-08-30 18:08:06,257 epoch 9 - iter 9/37 - loss 0.92876438 - samples/sec: 110.07 - lr: 0.001000\n",
      "2022-08-30 18:08:08,635 epoch 9 - iter 12/37 - loss 0.92001811 - samples/sec: 116.18 - lr: 0.001000\n",
      "2022-08-30 18:08:10,868 epoch 9 - iter 15/37 - loss 0.92150001 - samples/sec: 124.31 - lr: 0.001000\n",
      "2022-08-30 18:08:13,499 epoch 9 - iter 18/37 - loss 0.91887832 - samples/sec: 104.90 - lr: 0.001000\n",
      "2022-08-30 18:08:16,310 epoch 9 - iter 21/37 - loss 0.92015978 - samples/sec: 98.47 - lr: 0.001000\n",
      "2022-08-30 18:08:18,919 epoch 9 - iter 24/37 - loss 0.91741516 - samples/sec: 107.40 - lr: 0.001000\n",
      "2022-08-30 18:08:21,533 epoch 9 - iter 27/37 - loss 0.92176460 - samples/sec: 105.63 - lr: 0.001000\n",
      "2022-08-30 18:08:23,987 epoch 9 - iter 30/37 - loss 0.92485789 - samples/sec: 112.88 - lr: 0.001000\n",
      "2022-08-30 18:08:26,542 epoch 9 - iter 33/37 - loss 0.92363989 - samples/sec: 108.17 - lr: 0.001000\n",
      "2022-08-30 18:08:29,141 epoch 9 - iter 36/37 - loss 0.92111548 - samples/sec: 107.06 - lr: 0.001000\n",
      "2022-08-30 18:08:29,862 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:08:29,863 EPOCH 9 done: loss 0.9210 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:08:30,609 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:08:30,640 DEV : loss 0.7393702268600464 - f1-score (micro avg)  0.7394\n",
      "2022-08-30 18:08:30,658 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 18:08:30,659 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:08:32,767 epoch 10 - iter 3/37 - loss 0.92592970 - samples/sec: 128.14 - lr: 0.001000\n",
      "2022-08-30 18:08:35,178 epoch 10 - iter 6/37 - loss 0.92362041 - samples/sec: 114.70 - lr: 0.001000\n",
      "2022-08-30 18:08:37,789 epoch 10 - iter 9/37 - loss 0.91527162 - samples/sec: 105.80 - lr: 0.001000\n",
      "2022-08-30 18:08:40,149 epoch 10 - iter 12/37 - loss 0.90853635 - samples/sec: 117.75 - lr: 0.001000\n",
      "2022-08-30 18:08:43,037 epoch 10 - iter 15/37 - loss 0.90895119 - samples/sec: 95.31 - lr: 0.001000\n",
      "2022-08-30 18:08:45,869 epoch 10 - iter 18/37 - loss 0.90643821 - samples/sec: 97.40 - lr: 0.001000\n",
      "2022-08-30 18:08:48,669 epoch 10 - iter 21/37 - loss 0.90789725 - samples/sec: 98.50 - lr: 0.001000\n",
      "2022-08-30 18:08:50,993 epoch 10 - iter 24/37 - loss 0.91031376 - samples/sec: 119.10 - lr: 0.001000\n",
      "2022-08-30 18:08:52,989 epoch 10 - iter 27/37 - loss 0.91498167 - samples/sec: 139.61 - lr: 0.001000\n",
      "2022-08-30 18:08:55,678 epoch 10 - iter 30/37 - loss 0.91537391 - samples/sec: 102.97 - lr: 0.001000\n",
      "2022-08-30 18:08:58,016 epoch 10 - iter 33/37 - loss 0.91481600 - samples/sec: 118.52 - lr: 0.001000\n",
      "2022-08-30 18:09:00,533 epoch 10 - iter 36/37 - loss 0.91596837 - samples/sec: 109.93 - lr: 0.001000\n",
      "2022-08-30 18:09:01,292 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:09:01,293 EPOCH 10 done: loss 0.9153 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:09:02,065 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:09:02,093 DEV : loss 0.7394107580184937 - f1-score (micro avg)  0.739\n",
      "2022-08-30 18:09:02,108 Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2022-08-30 18:09:02,109 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 18:09:02,110 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:09:04,367 epoch 11 - iter 3/37 - loss 0.92398369 - samples/sec: 119.68 - lr: 0.000500\n",
      "2022-08-30 18:09:06,726 epoch 11 - iter 6/37 - loss 0.89678170 - samples/sec: 118.27 - lr: 0.000500\n",
      "2022-08-30 18:09:09,116 epoch 11 - iter 9/37 - loss 0.90507271 - samples/sec: 116.53 - lr: 0.000500\n",
      "2022-08-30 18:09:12,052 epoch 11 - iter 12/37 - loss 0.91479853 - samples/sec: 94.21 - lr: 0.000500\n",
      "2022-08-30 18:09:14,916 epoch 11 - iter 15/37 - loss 0.92069198 - samples/sec: 96.29 - lr: 0.000500\n",
      "2022-08-30 18:09:17,243 epoch 11 - iter 18/37 - loss 0.92395454 - samples/sec: 119.36 - lr: 0.000500\n",
      "2022-08-30 18:09:19,613 epoch 11 - iter 21/37 - loss 0.91913439 - samples/sec: 116.88 - lr: 0.000500\n",
      "2022-08-30 18:09:21,922 epoch 11 - iter 24/37 - loss 0.92133976 - samples/sec: 119.84 - lr: 0.000500\n",
      "2022-08-30 18:09:24,991 epoch 11 - iter 27/37 - loss 0.92124973 - samples/sec: 89.76 - lr: 0.000500\n",
      "2022-08-30 18:09:27,627 epoch 11 - iter 30/37 - loss 0.91704533 - samples/sec: 104.85 - lr: 0.000500\n",
      "2022-08-30 18:09:29,896 epoch 11 - iter 33/37 - loss 0.91684634 - samples/sec: 122.01 - lr: 0.000500\n",
      "2022-08-30 18:09:32,205 epoch 11 - iter 36/37 - loss 0.91686128 - samples/sec: 121.18 - lr: 0.000500\n",
      "2022-08-30 18:09:33,041 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:09:33,042 EPOCH 11 done: loss 0.9172 - lr 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:09:33,855 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:09:33,885 DEV : loss 0.7387718558311462 - f1-score (micro avg)  0.7388\n",
      "2022-08-30 18:09:33,903 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:09:34,584 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:09:34,585 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 18:09:34,754 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:09:37,401 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:09:37,426 0.7509\t0.7509\t0.7509\t0.7509\n",
      "2022-08-30 18:09:37,427 \n",
      "Results:\n",
      "- F-score (micro) 0.7509\n",
      "- F-score (macro) 0.6068\n",
      "- Accuracy 0.7509\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6619    0.7901    0.7204      1353\n",
      "         ADJ     0.5632    0.7098    0.6280       672\n",
      "       PUNCT     0.9850    0.9970    0.9910       660\n",
      "         ADP     0.8937    0.9163    0.9049       514\n",
      "        VERB     0.6406    0.6192    0.6297       449\n",
      "         AUX     0.9333    0.8358    0.8819       335\n",
      "       PROPN     0.8030    0.4151    0.5473       383\n",
      "       CCONJ     0.9895    0.9844    0.9869       192\n",
      "       SCONJ     0.9135    0.9185    0.9160       184\n",
      "         DET     0.6429    0.4472    0.5275       161\n",
      "         ADV     0.2951    0.1192    0.1698       151\n",
      "        PRON     0.9053    0.7478    0.8190       115\n",
      "         NUM     0.8182    0.2535    0.3871        71\n",
      "        PART     1.0000    0.4286    0.6000        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7509      5264\n",
      "   macro avg     0.6903    0.5739    0.6068      5264\n",
      "weighted avg     0.7562    0.7509    0.7421      5264\n",
      "\n",
      "2022-08-30 18:09:37,427 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:09:37,430 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:09:37,906 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 7 #######################\n",
      "#######################################################\n",
      "2022-08-30 18:11:55,428 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:11:55,429 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 18:11:55,430 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:11:55,430 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 18:11:55,431 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:11:55,431 Parameters:\n",
      "2022-08-30 18:11:55,432  - learning_rate: \"0.001000\"\n",
      "2022-08-30 18:11:55,433  - mini_batch_size: \"90\"\n",
      "2022-08-30 18:11:55,433  - patience: \"3\"\n",
      "2022-08-30 18:11:55,434  - anneal_factor: \"0.5\"\n",
      "2022-08-30 18:11:55,434  - max_epochs: \"12\"\n",
      "2022-08-30 18:11:55,435  - shuffle: \"True\"\n",
      "2022-08-30 18:11:55,436  - train_with_dev: \"False\"\n",
      "2022-08-30 18:11:55,436  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 18:11:55,436 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:11:55,437 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 18:11:55,437 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:11:55,438 Device: cpu\n",
      "2022-08-30 18:11:55,439 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:11:55,439 Embeddings storage mode: cpu\n",
      "2022-08-30 18:11:55,440 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:11:57,710 epoch 1 - iter 3/37 - loss 0.93750366 - samples/sec: 119.00 - lr: 0.001000\n",
      "2022-08-30 18:12:00,320 epoch 1 - iter 6/37 - loss 0.90248161 - samples/sec: 105.88 - lr: 0.001000\n",
      "2022-08-30 18:12:02,530 epoch 1 - iter 9/37 - loss 0.89866700 - samples/sec: 127.54 - lr: 0.001000\n",
      "2022-08-30 18:12:04,765 epoch 1 - iter 12/37 - loss 0.89722231 - samples/sec: 124.25 - lr: 0.001000\n",
      "2022-08-30 18:12:07,038 epoch 1 - iter 15/37 - loss 0.89982939 - samples/sec: 121.95 - lr: 0.001000\n",
      "2022-08-30 18:12:09,330 epoch 1 - iter 18/37 - loss 0.89471687 - samples/sec: 121.02 - lr: 0.001000\n",
      "2022-08-30 18:12:11,943 epoch 1 - iter 21/37 - loss 0.89468265 - samples/sec: 106.05 - lr: 0.001000\n",
      "2022-08-30 18:12:14,236 epoch 1 - iter 24/37 - loss 0.89589014 - samples/sec: 120.70 - lr: 0.001000\n",
      "2022-08-30 18:12:16,618 epoch 1 - iter 27/37 - loss 0.89427897 - samples/sec: 116.08 - lr: 0.001000\n",
      "2022-08-30 18:12:18,627 epoch 1 - iter 30/37 - loss 0.89466464 - samples/sec: 138.53 - lr: 0.001000\n",
      "2022-08-30 18:12:21,262 epoch 1 - iter 33/37 - loss 0.89717661 - samples/sec: 105.63 - lr: 0.001000\n",
      "2022-08-30 18:12:24,060 epoch 1 - iter 36/37 - loss 0.91386517 - samples/sec: 98.43 - lr: 0.001000\n",
      "2022-08-30 18:12:25,161 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:12:25,162 EPOCH 1 done: loss 0.9195 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:12:25,958 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:12:25,987 DEV : loss 0.7450255751609802 - f1-score (micro avg)  0.7368\n",
      "2022-08-30 18:12:26,006 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:12:26,008 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:12:26,685 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:12:29,871 epoch 2 - iter 3/37 - loss 0.93004168 - samples/sec: 84.77 - lr: 0.001000\n",
      "2022-08-30 18:12:32,092 epoch 2 - iter 6/37 - loss 0.91330699 - samples/sec: 125.35 - lr: 0.001000\n",
      "2022-08-30 18:12:34,313 epoch 2 - iter 9/37 - loss 0.91659297 - samples/sec: 124.65 - lr: 0.001000\n",
      "2022-08-30 18:12:36,918 epoch 2 - iter 12/37 - loss 0.92602513 - samples/sec: 106.05 - lr: 0.001000\n",
      "2022-08-30 18:12:39,190 epoch 2 - iter 15/37 - loss 0.92491657 - samples/sec: 122.01 - lr: 0.001000\n",
      "2022-08-30 18:12:41,612 epoch 2 - iter 18/37 - loss 0.91849221 - samples/sec: 114.46 - lr: 0.001000\n",
      "2022-08-30 18:12:43,953 epoch 2 - iter 21/37 - loss 0.91397427 - samples/sec: 118.16 - lr: 0.001000\n",
      "2022-08-30 18:12:46,454 epoch 2 - iter 24/37 - loss 0.91900525 - samples/sec: 111.71 - lr: 0.001000\n",
      "2022-08-30 18:12:48,781 epoch 2 - iter 27/37 - loss 0.92160552 - samples/sec: 120.27 - lr: 0.001000\n",
      "2022-08-30 18:12:51,336 epoch 2 - iter 30/37 - loss 0.92140285 - samples/sec: 108.04 - lr: 0.001000\n",
      "2022-08-30 18:12:53,742 epoch 2 - iter 33/37 - loss 0.91835537 - samples/sec: 116.48 - lr: 0.001000\n",
      "2022-08-30 18:12:56,459 epoch 2 - iter 36/37 - loss 0.91714730 - samples/sec: 101.89 - lr: 0.001000\n",
      "2022-08-30 18:12:57,668 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:12:57,669 EPOCH 2 done: loss 0.9174 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:12:58,457 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:12:58,491 DEV : loss 0.7410719990730286 - f1-score (micro avg)  0.7398\n",
      "2022-08-30 18:12:58,511 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:12:58,512 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:12:59,213 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:13:01,408 epoch 3 - iter 3/37 - loss 0.89524555 - samples/sec: 123.18 - lr: 0.001000\n",
      "2022-08-30 18:13:04,000 epoch 3 - iter 6/37 - loss 0.91857086 - samples/sec: 107.61 - lr: 0.001000\n",
      "2022-08-30 18:13:06,139 epoch 3 - iter 9/37 - loss 0.91194710 - samples/sec: 130.43 - lr: 0.001000\n",
      "2022-08-30 18:13:08,791 epoch 3 - iter 12/37 - loss 0.90957238 - samples/sec: 104.21 - lr: 0.001000\n",
      "2022-08-30 18:13:11,086 epoch 3 - iter 15/37 - loss 0.91386365 - samples/sec: 120.54 - lr: 0.001000\n",
      "2022-08-30 18:13:13,929 epoch 3 - iter 18/37 - loss 0.91288680 - samples/sec: 96.81 - lr: 0.001000\n",
      "2022-08-30 18:13:16,182 epoch 3 - iter 21/37 - loss 0.91202335 - samples/sec: 123.46 - lr: 0.001000\n",
      "2022-08-30 18:13:18,837 epoch 3 - iter 24/37 - loss 0.91621745 - samples/sec: 103.93 - lr: 0.001000\n",
      "2022-08-30 18:13:21,817 epoch 3 - iter 27/37 - loss 0.91943550 - samples/sec: 92.37 - lr: 0.001000\n",
      "2022-08-30 18:13:24,248 epoch 3 - iter 30/37 - loss 0.91911334 - samples/sec: 113.78 - lr: 0.001000\n",
      "2022-08-30 18:13:26,638 epoch 3 - iter 33/37 - loss 0.91940895 - samples/sec: 115.68 - lr: 0.001000\n",
      "2022-08-30 18:13:29,078 epoch 3 - iter 36/37 - loss 0.92111241 - samples/sec: 113.54 - lr: 0.001000\n",
      "2022-08-30 18:13:29,986 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:13:29,987 EPOCH 3 done: loss 0.9202 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:13:30,813 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:13:30,841 DEV : loss 0.7398142218589783 - f1-score (micro avg)  0.7381\n",
      "2022-08-30 18:13:30,858 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:13:30,858 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:13:33,082 epoch 4 - iter 3/37 - loss 0.91701874 - samples/sec: 121.51 - lr: 0.001000\n",
      "2022-08-30 18:13:35,900 epoch 4 - iter 6/37 - loss 0.92935808 - samples/sec: 97.76 - lr: 0.001000\n",
      "2022-08-30 18:13:38,070 epoch 4 - iter 9/37 - loss 0.92041168 - samples/sec: 127.60 - lr: 0.001000\n",
      "2022-08-30 18:13:40,404 epoch 4 - iter 12/37 - loss 0.93004759 - samples/sec: 118.84 - lr: 0.001000\n",
      "2022-08-30 18:13:43,024 epoch 4 - iter 15/37 - loss 0.92396163 - samples/sec: 105.55 - lr: 0.001000\n",
      "2022-08-30 18:13:45,818 epoch 4 - iter 18/37 - loss 0.92530659 - samples/sec: 99.19 - lr: 0.001000\n",
      "2022-08-30 18:13:48,832 epoch 4 - iter 21/37 - loss 0.92397597 - samples/sec: 91.31 - lr: 0.001000\n",
      "2022-08-30 18:13:51,102 epoch 4 - iter 24/37 - loss 0.92161726 - samples/sec: 121.90 - lr: 0.001000\n",
      "2022-08-30 18:13:53,397 epoch 4 - iter 27/37 - loss 0.91904149 - samples/sec: 120.48 - lr: 0.001000\n",
      "2022-08-30 18:13:55,792 epoch 4 - iter 30/37 - loss 0.92148803 - samples/sec: 116.33 - lr: 0.001000\n",
      "2022-08-30 18:13:58,208 epoch 4 - iter 33/37 - loss 0.92007334 - samples/sec: 115.14 - lr: 0.001000\n",
      "2022-08-30 18:14:01,137 epoch 4 - iter 36/37 - loss 0.91918471 - samples/sec: 93.98 - lr: 0.001000\n",
      "2022-08-30 18:14:01,895 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:14:01,895 EPOCH 4 done: loss 0.9188 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:14:02,719 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:14:02,750 DEV : loss 0.7388976812362671 - f1-score (micro avg)  0.7391\n",
      "2022-08-30 18:14:02,768 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 18:14:02,769 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:14:05,508 epoch 5 - iter 3/37 - loss 0.90485622 - samples/sec: 98.65 - lr: 0.001000\n",
      "2022-08-30 18:14:08,532 epoch 5 - iter 6/37 - loss 0.90584214 - samples/sec: 92.28 - lr: 0.001000\n",
      "2022-08-30 18:14:11,077 epoch 5 - iter 9/37 - loss 0.90830347 - samples/sec: 108.65 - lr: 0.001000\n",
      "2022-08-30 18:14:14,185 epoch 5 - iter 12/37 - loss 0.91515911 - samples/sec: 88.70 - lr: 0.001000\n",
      "2022-08-30 18:14:16,483 epoch 5 - iter 15/37 - loss 0.92159114 - samples/sec: 120.64 - lr: 0.001000\n",
      "2022-08-30 18:14:18,993 epoch 5 - iter 18/37 - loss 0.91677965 - samples/sec: 110.16 - lr: 0.001000\n",
      "2022-08-30 18:14:21,045 epoch 5 - iter 21/37 - loss 0.91450788 - samples/sec: 135.47 - lr: 0.001000\n",
      "2022-08-30 18:14:23,320 epoch 5 - iter 24/37 - loss 0.91396880 - samples/sec: 121.95 - lr: 0.001000\n",
      "2022-08-30 18:14:25,839 epoch 5 - iter 27/37 - loss 0.91049128 - samples/sec: 110.07 - lr: 0.001000\n",
      "2022-08-30 18:14:28,172 epoch 5 - iter 30/37 - loss 0.91328984 - samples/sec: 118.79 - lr: 0.001000\n",
      "2022-08-30 18:14:30,473 epoch 5 - iter 33/37 - loss 0.91312355 - samples/sec: 120.59 - lr: 0.001000\n",
      "2022-08-30 18:14:32,949 epoch 5 - iter 36/37 - loss 0.91436858 - samples/sec: 112.88 - lr: 0.001000\n",
      "2022-08-30 18:14:33,800 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:14:33,801 EPOCH 5 done: loss 0.9139 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:14:34,576 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:14:34,607 DEV : loss 0.7383289933204651 - f1-score (micro avg)  0.7377\n",
      "2022-08-30 18:14:34,622 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 18:14:34,623 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:14:37,144 epoch 6 - iter 3/37 - loss 0.90124612 - samples/sec: 107.14 - lr: 0.001000\n",
      "2022-08-30 18:14:39,629 epoch 6 - iter 6/37 - loss 0.90680729 - samples/sec: 111.48 - lr: 0.001000\n",
      "2022-08-30 18:14:41,924 epoch 6 - iter 9/37 - loss 0.92048195 - samples/sec: 120.81 - lr: 0.001000\n",
      "2022-08-30 18:14:44,189 epoch 6 - iter 12/37 - loss 0.91956970 - samples/sec: 122.73 - lr: 0.001000\n",
      "2022-08-30 18:14:46,754 epoch 6 - iter 15/37 - loss 0.91670321 - samples/sec: 107.83 - lr: 0.001000\n",
      "2022-08-30 18:14:49,060 epoch 6 - iter 18/37 - loss 0.91731479 - samples/sec: 120.21 - lr: 0.001000\n",
      "2022-08-30 18:14:51,548 epoch 6 - iter 21/37 - loss 0.91496322 - samples/sec: 111.43 - lr: 0.001000\n",
      "2022-08-30 18:14:54,205 epoch 6 - iter 24/37 - loss 0.91595749 - samples/sec: 104.17 - lr: 0.001000\n",
      "2022-08-30 18:14:57,297 epoch 6 - iter 27/37 - loss 0.91432043 - samples/sec: 89.11 - lr: 0.001000\n",
      "2022-08-30 18:14:59,957 epoch 6 - iter 30/37 - loss 0.91450426 - samples/sec: 103.77 - lr: 0.001000\n",
      "2022-08-30 18:15:02,155 epoch 6 - iter 33/37 - loss 0.91281371 - samples/sec: 126.35 - lr: 0.001000\n",
      "2022-08-30 18:15:04,474 epoch 6 - iter 36/37 - loss 0.91266118 - samples/sec: 119.26 - lr: 0.001000\n",
      "2022-08-30 18:15:05,587 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:15:05,589 EPOCH 6 done: loss 0.9146 - lr 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:15:06,435 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:15:06,469 DEV : loss 0.7377650737762451 - f1-score (micro avg)  0.7388\n",
      "2022-08-30 18:15:06,484 Epoch     6: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2022-08-30 18:15:06,485 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 18:15:06,486 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:15:08,827 epoch 7 - iter 3/37 - loss 0.93057543 - samples/sec: 115.48 - lr: 0.000500\n",
      "2022-08-30 18:15:11,171 epoch 7 - iter 6/37 - loss 0.90817581 - samples/sec: 118.58 - lr: 0.000500\n",
      "2022-08-30 18:15:13,649 epoch 7 - iter 9/37 - loss 0.91189088 - samples/sec: 111.71 - lr: 0.000500\n",
      "2022-08-30 18:15:16,125 epoch 7 - iter 12/37 - loss 0.90869662 - samples/sec: 111.89 - lr: 0.000500\n",
      "2022-08-30 18:15:18,297 epoch 7 - iter 15/37 - loss 0.90859623 - samples/sec: 128.21 - lr: 0.000500\n",
      "2022-08-30 18:15:21,250 epoch 7 - iter 18/37 - loss 0.91232484 - samples/sec: 93.65 - lr: 0.000500\n",
      "2022-08-30 18:15:24,059 epoch 7 - iter 21/37 - loss 0.91413904 - samples/sec: 98.40 - lr: 0.000500\n",
      "2022-08-30 18:15:26,627 epoch 7 - iter 24/37 - loss 0.91319082 - samples/sec: 107.57 - lr: 0.000500\n",
      "2022-08-30 18:15:29,032 epoch 7 - iter 27/37 - loss 0.90859633 - samples/sec: 116.78 - lr: 0.000500\n",
      "2022-08-30 18:15:31,508 epoch 7 - iter 30/37 - loss 0.91041603 - samples/sec: 111.75 - lr: 0.000500\n",
      "2022-08-30 18:15:33,712 epoch 7 - iter 33/37 - loss 0.91105530 - samples/sec: 125.87 - lr: 0.000500\n",
      "2022-08-30 18:15:36,091 epoch 7 - iter 36/37 - loss 0.91335121 - samples/sec: 116.18 - lr: 0.000500\n",
      "2022-08-30 18:15:36,948 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:15:36,948 EPOCH 7 done: loss 0.9139 - lr 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:15:37,757 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:15:37,789 DEV : loss 0.7365325093269348 - f1-score (micro avg)  0.7393\n",
      "2022-08-30 18:15:37,805 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:15:37,806 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:15:40,244 epoch 8 - iter 3/37 - loss 0.91881624 - samples/sec: 110.79 - lr: 0.000500\n",
      "2022-08-30 18:15:42,733 epoch 8 - iter 6/37 - loss 0.92074585 - samples/sec: 111.11 - lr: 0.000500\n",
      "2022-08-30 18:15:45,191 epoch 8 - iter 9/37 - loss 0.91934251 - samples/sec: 112.73 - lr: 0.000500\n",
      "2022-08-30 18:15:47,390 epoch 8 - iter 12/37 - loss 0.92531505 - samples/sec: 126.23 - lr: 0.000500\n",
      "2022-08-30 18:15:50,657 epoch 8 - iter 15/37 - loss 0.91893305 - samples/sec: 84.51 - lr: 0.000500\n",
      "2022-08-30 18:15:52,837 epoch 8 - iter 18/37 - loss 0.91946754 - samples/sec: 128.76 - lr: 0.000500\n",
      "2022-08-30 18:15:55,450 epoch 8 - iter 21/37 - loss 0.91636154 - samples/sec: 105.59 - lr: 0.000500\n",
      "2022-08-30 18:15:57,654 epoch 8 - iter 24/37 - loss 0.91762340 - samples/sec: 127.42 - lr: 0.000500\n",
      "2022-08-30 18:16:00,090 epoch 8 - iter 27/37 - loss 0.91370253 - samples/sec: 113.64 - lr: 0.000500\n",
      "2022-08-30 18:16:02,507 epoch 8 - iter 30/37 - loss 0.91318283 - samples/sec: 114.70 - lr: 0.000500\n",
      "2022-08-30 18:16:05,141 epoch 8 - iter 33/37 - loss 0.91328845 - samples/sec: 105.47 - lr: 0.000500\n",
      "2022-08-30 18:16:07,705 epoch 8 - iter 36/37 - loss 0.91484727 - samples/sec: 107.74 - lr: 0.000500\n",
      "2022-08-30 18:16:08,581 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:16:08,582 EPOCH 8 done: loss 0.9154 - lr 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:16:09,367 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:16:09,397 DEV : loss 0.7366529107093811 - f1-score (micro avg)  0.7401\n",
      "2022-08-30 18:16:09,415 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:16:09,416 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:16:10,106 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:16:12,480 epoch 9 - iter 3/37 - loss 0.92338465 - samples/sec: 113.83 - lr: 0.000500\n",
      "2022-08-30 18:16:14,554 epoch 9 - iter 6/37 - loss 0.92852550 - samples/sec: 134.19 - lr: 0.000500\n",
      "2022-08-30 18:16:16,844 epoch 9 - iter 9/37 - loss 0.92084089 - samples/sec: 121.08 - lr: 0.000500\n",
      "2022-08-30 18:16:19,265 epoch 9 - iter 12/37 - loss 0.91491643 - samples/sec: 114.16 - lr: 0.000500\n",
      "2022-08-30 18:16:22,089 epoch 9 - iter 15/37 - loss 0.91912587 - samples/sec: 97.44 - lr: 0.000500\n",
      "2022-08-30 18:16:24,488 epoch 9 - iter 18/37 - loss 0.91985056 - samples/sec: 115.14 - lr: 0.000500\n",
      "2022-08-30 18:16:27,108 epoch 9 - iter 21/37 - loss 0.91527702 - samples/sec: 105.76 - lr: 0.000500\n",
      "2022-08-30 18:16:29,582 epoch 9 - iter 24/37 - loss 0.91598206 - samples/sec: 111.62 - lr: 0.000500\n",
      "2022-08-30 18:16:31,856 epoch 9 - iter 27/37 - loss 0.91685718 - samples/sec: 122.39 - lr: 0.000500\n",
      "2022-08-30 18:16:34,653 epoch 9 - iter 30/37 - loss 0.91904177 - samples/sec: 98.50 - lr: 0.000500\n",
      "2022-08-30 18:16:36,988 epoch 9 - iter 33/37 - loss 0.91787807 - samples/sec: 118.68 - lr: 0.000500\n",
      "2022-08-30 18:16:40,033 epoch 9 - iter 36/37 - loss 0.91526517 - samples/sec: 90.63 - lr: 0.000500\n",
      "2022-08-30 18:16:40,883 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:16:40,884 EPOCH 9 done: loss 0.9143 - lr 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:16:41,700 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:16:41,731 DEV : loss 0.7364141345024109 - f1-score (micro avg)  0.7399\n",
      "2022-08-30 18:16:41,748 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:16:41,749 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:16:43,899 epoch 10 - iter 3/37 - loss 0.92443425 - samples/sec: 125.64 - lr: 0.000500\n",
      "2022-08-30 18:16:46,548 epoch 10 - iter 6/37 - loss 0.91730536 - samples/sec: 104.25 - lr: 0.000500\n",
      "2022-08-30 18:16:48,954 epoch 10 - iter 9/37 - loss 0.91120590 - samples/sec: 116.18 - lr: 0.000500\n",
      "2022-08-30 18:16:52,012 epoch 10 - iter 12/37 - loss 0.91254107 - samples/sec: 90.39 - lr: 0.000500\n",
      "2022-08-30 18:16:54,236 epoch 10 - iter 15/37 - loss 0.91531317 - samples/sec: 125.00 - lr: 0.000500\n",
      "2022-08-30 18:16:56,878 epoch 10 - iter 18/37 - loss 0.91466455 - samples/sec: 104.49 - lr: 0.000500\n",
      "2022-08-30 18:16:59,569 epoch 10 - iter 21/37 - loss 0.91704766 - samples/sec: 102.74 - lr: 0.000500\n",
      "2022-08-30 18:17:02,184 epoch 10 - iter 24/37 - loss 0.91365543 - samples/sec: 106.13 - lr: 0.000500\n",
      "2022-08-30 18:17:04,564 epoch 10 - iter 27/37 - loss 0.91440013 - samples/sec: 116.43 - lr: 0.000500\n",
      "2022-08-30 18:17:06,913 epoch 10 - iter 30/37 - loss 0.91572248 - samples/sec: 118.32 - lr: 0.000500\n",
      "2022-08-30 18:17:09,442 epoch 10 - iter 33/37 - loss 0.91399251 - samples/sec: 109.27 - lr: 0.000500\n",
      "2022-08-30 18:17:12,019 epoch 10 - iter 36/37 - loss 0.91516548 - samples/sec: 108.43 - lr: 0.000500\n",
      "2022-08-30 18:17:12,854 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:17:12,855 EPOCH 10 done: loss 0.9142 - lr 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:17:13,620 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:17:13,649 DEV : loss 0.7361434698104858 - f1-score (micro avg)  0.7411\n",
      "2022-08-30 18:17:13,666 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:17:13,667 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:17:14,403 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:17:16,675 epoch 11 - iter 3/37 - loss 0.91544132 - samples/sec: 118.89 - lr: 0.000500\n",
      "2022-08-30 18:17:18,923 epoch 11 - iter 6/37 - loss 0.90718221 - samples/sec: 123.57 - lr: 0.000500\n",
      "2022-08-30 18:17:21,341 epoch 11 - iter 9/37 - loss 0.90904772 - samples/sec: 114.21 - lr: 0.000500\n",
      "2022-08-30 18:17:24,000 epoch 11 - iter 12/37 - loss 0.90581863 - samples/sec: 104.69 - lr: 0.000500\n",
      "2022-08-30 18:17:26,173 epoch 11 - iter 15/37 - loss 0.91203279 - samples/sec: 127.60 - lr: 0.000500\n",
      "2022-08-30 18:17:29,093 epoch 11 - iter 18/37 - loss 0.91696040 - samples/sec: 94.34 - lr: 0.000500\n",
      "2022-08-30 18:17:31,813 epoch 11 - iter 21/37 - loss 0.91359762 - samples/sec: 101.62 - lr: 0.000500\n",
      "2022-08-30 18:17:34,605 epoch 11 - iter 24/37 - loss 0.90938097 - samples/sec: 98.90 - lr: 0.000500\n",
      "2022-08-30 18:17:37,326 epoch 11 - iter 27/37 - loss 0.91223890 - samples/sec: 101.77 - lr: 0.000500\n",
      "2022-08-30 18:17:39,643 epoch 11 - iter 30/37 - loss 0.91140391 - samples/sec: 121.51 - lr: 0.000500\n",
      "2022-08-30 18:17:42,028 epoch 11 - iter 33/37 - loss 0.91124259 - samples/sec: 116.08 - lr: 0.000500\n",
      "2022-08-30 18:17:44,879 epoch 11 - iter 36/37 - loss 0.91304742 - samples/sec: 96.77 - lr: 0.000500\n",
      "2022-08-30 18:17:45,759 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:17:45,760 EPOCH 11 done: loss 0.9131 - lr 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:17:46,541 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:17:46,570 DEV : loss 0.7359204888343811 - f1-score (micro avg)  0.7404\n",
      "2022-08-30 18:17:46,585 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:17:46,586 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:17:48,854 epoch 12 - iter 3/37 - loss 0.88896927 - samples/sec: 119.15 - lr: 0.000500\n",
      "2022-08-30 18:17:51,137 epoch 12 - iter 6/37 - loss 0.89508052 - samples/sec: 121.68 - lr: 0.000500\n",
      "2022-08-30 18:17:53,698 epoch 12 - iter 9/37 - loss 0.90229467 - samples/sec: 107.78 - lr: 0.000500\n",
      "2022-08-30 18:17:56,321 epoch 12 - iter 12/37 - loss 0.90451603 - samples/sec: 105.35 - lr: 0.000500\n",
      "2022-08-30 18:17:58,902 epoch 12 - iter 15/37 - loss 0.90931605 - samples/sec: 107.74 - lr: 0.000500\n",
      "2022-08-30 18:18:01,625 epoch 12 - iter 18/37 - loss 0.91579864 - samples/sec: 101.81 - lr: 0.000500\n",
      "2022-08-30 18:18:04,138 epoch 12 - iter 21/37 - loss 0.91807695 - samples/sec: 109.98 - lr: 0.000500\n",
      "2022-08-30 18:18:06,949 epoch 12 - iter 24/37 - loss 0.91660611 - samples/sec: 98.11 - lr: 0.000500\n",
      "2022-08-30 18:18:09,223 epoch 12 - iter 27/37 - loss 0.91636012 - samples/sec: 121.68 - lr: 0.000500\n",
      "2022-08-30 18:18:11,563 epoch 12 - iter 30/37 - loss 0.91769308 - samples/sec: 118.27 - lr: 0.000500\n",
      "2022-08-30 18:18:14,512 epoch 12 - iter 33/37 - loss 0.91769474 - samples/sec: 93.75 - lr: 0.000500\n",
      "2022-08-30 18:18:16,700 epoch 12 - iter 36/37 - loss 0.91534546 - samples/sec: 127.00 - lr: 0.000500\n",
      "2022-08-30 18:18:17,583 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:18:17,584 EPOCH 12 done: loss 0.9144 - lr 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:18:18,389 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:18:18,417 DEV : loss 0.7353155016899109 - f1-score (micro avg)  0.7394\n",
      "2022-08-30 18:18:18,432 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:18:19,270 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:18:19,271 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 18:18:19,449 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:18:20,820 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:18:20,844 0.7536\t0.7536\t0.7536\t0.7536\n",
      "2022-08-30 18:18:20,844 \n",
      "Results:\n",
      "- F-score (micro) 0.7536\n",
      "- F-score (macro) 0.6179\n",
      "- Accuracy 0.7536\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.6671    0.7894    0.7231      1353\n",
      "         ADJ     0.5672    0.7158    0.6329       672\n",
      "       PUNCT     0.9850    0.9970    0.9910       660\n",
      "         ADP     0.8939    0.9183    0.9060       514\n",
      "        VERB     0.6417    0.6303    0.6360       449\n",
      "         AUX     0.9394    0.8328    0.8829       335\n",
      "       PROPN     0.8030    0.4151    0.5473       383\n",
      "       CCONJ     0.9895    0.9844    0.9869       192\n",
      "       SCONJ     0.9135    0.9185    0.9160       184\n",
      "         DET     0.6486    0.4472    0.5294       161\n",
      "         ADV     0.2879    0.1258    0.1751       151\n",
      "        PRON     0.9062    0.7565    0.8246       115\n",
      "         NUM     0.8636    0.2676    0.4086        71\n",
      "        PART     1.0000    0.5714    0.7273        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7536      5264\n",
      "   macro avg     0.6942    0.5856    0.6179      5264\n",
      "weighted avg     0.7592    0.7536    0.7453      5264\n",
      "\n",
      "2022-08-30 18:18:20,845 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:18:20,847 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:18:21,318 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 2 #######################\n",
      "#######################################################\n",
      "2022-08-30 18:20:37,016 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:20:37,017 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 18:20:37,017 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:20:37,018 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 18:20:37,019 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:20:37,019 Parameters:\n",
      "2022-08-30 18:20:37,020  - learning_rate: \"0.200667\"\n",
      "2022-08-30 18:20:37,020  - mini_batch_size: \"10\"\n",
      "2022-08-30 18:20:37,021  - patience: \"3\"\n",
      "2022-08-30 18:20:37,022  - anneal_factor: \"0.5\"\n",
      "2022-08-30 18:20:37,022  - max_epochs: \"10\"\n",
      "2022-08-30 18:20:37,023  - shuffle: \"True\"\n",
      "2022-08-30 18:20:37,024  - train_with_dev: \"False\"\n",
      "2022-08-30 18:20:37,025  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 18:20:37,025 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:20:37,025 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 18:20:37,026 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:20:37,027 Device: cpu\n",
      "2022-08-30 18:20:37,028 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:20:37,028 Embeddings storage mode: cpu\n",
      "2022-08-30 18:20:37,029 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:20:41,218 epoch 1 - iter 33/333 - loss 1.18019412 - samples/sec: 78.81 - lr: 0.200667\n",
      "2022-08-30 18:20:45,454 epoch 1 - iter 66/333 - loss 1.10348350 - samples/sec: 79.14 - lr: 0.200667\n",
      "2022-08-30 18:20:49,007 epoch 1 - iter 99/333 - loss 1.05805749 - samples/sec: 94.66 - lr: 0.200667\n",
      "2022-08-30 18:20:52,831 epoch 1 - iter 132/333 - loss 1.02916878 - samples/sec: 87.72 - lr: 0.200667\n",
      "2022-08-30 18:20:57,418 epoch 1 - iter 165/333 - loss 1.00522316 - samples/sec: 72.90 - lr: 0.200667\n",
      "2022-08-30 18:21:00,942 epoch 1 - iter 198/333 - loss 0.98154428 - samples/sec: 95.32 - lr: 0.200667\n",
      "2022-08-30 18:21:05,015 epoch 1 - iter 231/333 - loss 0.96579230 - samples/sec: 82.23 - lr: 0.200667\n",
      "2022-08-30 18:21:08,682 epoch 1 - iter 264/333 - loss 0.95028605 - samples/sec: 91.49 - lr: 0.200667\n",
      "2022-08-30 18:21:12,841 epoch 1 - iter 297/333 - loss 0.93800063 - samples/sec: 80.55 - lr: 0.200667\n",
      "2022-08-30 18:21:17,252 epoch 1 - iter 330/333 - loss 0.94496305 - samples/sec: 75.84 - lr: 0.200667\n",
      "2022-08-30 18:21:17,732 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:21:17,733 EPOCH 1 done: loss 0.9449 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:21:18,686 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:21:18,715 DEV : loss 0.7485576868057251 - f1-score (micro avg)  0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:21:18,733 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:21:18,734 saving best model\n",
      "2022-08-30 18:21:19,678 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:21:23,297 epoch 2 - iter 33/333 - loss 0.83601119 - samples/sec: 91.24 - lr: 0.200667\n",
      "2022-08-30 18:21:27,159 epoch 2 - iter 66/333 - loss 0.83422274 - samples/sec: 86.75 - lr: 0.200667\n",
      "2022-08-30 18:21:31,434 epoch 2 - iter 99/333 - loss 0.82935935 - samples/sec: 78.20 - lr: 0.200667\n",
      "2022-08-30 18:21:35,206 epoch 2 - iter 132/333 - loss 0.82350582 - samples/sec: 89.12 - lr: 0.200667\n",
      "2022-08-30 18:21:39,338 epoch 2 - iter 165/333 - loss 0.81581449 - samples/sec: 81.06 - lr: 0.200667\n",
      "2022-08-30 18:21:43,383 epoch 2 - iter 198/333 - loss 0.81048623 - samples/sec: 82.98 - lr: 0.200667\n",
      "2022-08-30 18:21:47,469 epoch 2 - iter 231/333 - loss 0.80549338 - samples/sec: 82.15 - lr: 0.200667\n",
      "2022-08-30 18:21:51,356 epoch 2 - iter 264/333 - loss 0.80113436 - samples/sec: 86.43 - lr: 0.200667\n",
      "2022-08-30 18:21:55,280 epoch 2 - iter 297/333 - loss 0.79477766 - samples/sec: 85.58 - lr: 0.200667\n",
      "2022-08-30 18:21:59,158 epoch 2 - iter 330/333 - loss 0.79143001 - samples/sec: 86.39 - lr: 0.200667\n",
      "2022-08-30 18:21:59,537 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:21:59,538 EPOCH 2 done: loss 0.7908 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:22:00,529 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:22:00,566 DEV : loss 0.5601281523704529 - f1-score (micro avg)  0.7927\n",
      "2022-08-30 18:22:00,583 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:22:00,584 saving best model\n",
      "2022-08-30 18:22:01,272 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:22:05,555 epoch 3 - iter 33/333 - loss 0.76328372 - samples/sec: 77.16 - lr: 0.200667\n",
      "2022-08-30 18:22:09,572 epoch 3 - iter 66/333 - loss 0.74287541 - samples/sec: 83.46 - lr: 0.200667\n",
      "2022-08-30 18:22:13,447 epoch 3 - iter 99/333 - loss 0.74046465 - samples/sec: 86.57 - lr: 0.200667\n",
      "2022-08-30 18:22:17,260 epoch 3 - iter 132/333 - loss 0.74040169 - samples/sec: 87.98 - lr: 0.200667\n",
      "2022-08-30 18:22:21,497 epoch 3 - iter 165/333 - loss 0.73903553 - samples/sec: 78.93 - lr: 0.200667\n",
      "2022-08-30 18:22:25,165 epoch 3 - iter 198/333 - loss 0.73647785 - samples/sec: 91.54 - lr: 0.200667\n",
      "2022-08-30 18:22:29,087 epoch 3 - iter 231/333 - loss 0.73427589 - samples/sec: 85.51 - lr: 0.200667\n",
      "2022-08-30 18:22:32,974 epoch 3 - iter 264/333 - loss 0.73049874 - samples/sec: 86.12 - lr: 0.200667\n",
      "2022-08-30 18:22:37,361 epoch 3 - iter 297/333 - loss 0.73011405 - samples/sec: 76.37 - lr: 0.200667\n",
      "2022-08-30 18:22:41,284 epoch 3 - iter 330/333 - loss 0.72754242 - samples/sec: 85.65 - lr: 0.200667\n",
      "2022-08-30 18:22:41,776 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:22:41,776 EPOCH 3 done: loss 0.7271 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:22:42,751 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:22:42,781 DEV : loss 0.5015012621879578 - f1-score (micro avg)  0.8117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:22:42,795 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:22:42,796 saving best model\n",
      "2022-08-30 18:22:43,505 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:22:47,740 epoch 4 - iter 33/333 - loss 0.70389581 - samples/sec: 77.96 - lr: 0.200667\n",
      "2022-08-30 18:22:51,705 epoch 4 - iter 66/333 - loss 0.70751711 - samples/sec: 84.44 - lr: 0.200667\n",
      "2022-08-30 18:22:55,349 epoch 4 - iter 99/333 - loss 0.69673888 - samples/sec: 92.05 - lr: 0.200667\n",
      "2022-08-30 18:22:59,304 epoch 4 - iter 132/333 - loss 0.69418913 - samples/sec: 84.90 - lr: 0.200667\n",
      "2022-08-30 18:23:03,224 epoch 4 - iter 165/333 - loss 0.69213286 - samples/sec: 85.49 - lr: 0.200667\n",
      "2022-08-30 18:23:06,923 epoch 4 - iter 198/333 - loss 0.68908992 - samples/sec: 90.73 - lr: 0.200667\n",
      "2022-08-30 18:23:10,806 epoch 4 - iter 231/333 - loss 0.68427700 - samples/sec: 86.27 - lr: 0.200667\n",
      "2022-08-30 18:23:14,827 epoch 4 - iter 264/333 - loss 0.68543508 - samples/sec: 83.25 - lr: 0.200667\n",
      "2022-08-30 18:23:18,821 epoch 4 - iter 297/333 - loss 0.68204067 - samples/sec: 83.82 - lr: 0.200667\n",
      "2022-08-30 18:23:23,273 epoch 4 - iter 330/333 - loss 0.68019615 - samples/sec: 75.12 - lr: 0.200667\n",
      "2022-08-30 18:23:23,591 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:23:23,592 EPOCH 4 done: loss 0.6804 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:23:25,845 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:23:25,882 DEV : loss 0.4741306006908417 - f1-score (micro avg)  0.8281\n",
      "2022-08-30 18:23:25,902 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:23:25,903 saving best model\n",
      "2022-08-30 18:23:26,615 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:23:30,895 epoch 5 - iter 33/333 - loss 0.63952714 - samples/sec: 77.16 - lr: 0.200667\n",
      "2022-08-30 18:23:34,738 epoch 5 - iter 66/333 - loss 0.64436939 - samples/sec: 87.28 - lr: 0.200667\n",
      "2022-08-30 18:23:38,702 epoch 5 - iter 99/333 - loss 0.64742871 - samples/sec: 84.57 - lr: 0.200667\n",
      "2022-08-30 18:23:42,677 epoch 5 - iter 132/333 - loss 0.65182444 - samples/sec: 84.40 - lr: 0.200667\n",
      "2022-08-30 18:23:46,650 epoch 5 - iter 165/333 - loss 0.64797036 - samples/sec: 84.31 - lr: 0.200667\n",
      "2022-08-30 18:23:50,535 epoch 5 - iter 198/333 - loss 0.64633651 - samples/sec: 86.36 - lr: 0.200667\n",
      "2022-08-30 18:23:54,750 epoch 5 - iter 231/333 - loss 0.64566642 - samples/sec: 79.37 - lr: 0.200667\n",
      "2022-08-30 18:23:58,548 epoch 5 - iter 264/333 - loss 0.64862545 - samples/sec: 88.26 - lr: 0.200667\n",
      "2022-08-30 18:24:02,542 epoch 5 - iter 297/333 - loss 0.64728164 - samples/sec: 83.95 - lr: 0.200667\n",
      "2022-08-30 18:24:06,517 epoch 5 - iter 330/333 - loss 0.64560087 - samples/sec: 84.25 - lr: 0.200667\n",
      "2022-08-30 18:24:06,958 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:24:06,959 EPOCH 5 done: loss 0.6458 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:24:07,911 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:24:07,941 DEV : loss 0.44900065660476685 - f1-score (micro avg)  0.833\n",
      "2022-08-30 18:24:07,960 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:24:07,961 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:24:08,774 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:24:12,540 epoch 6 - iter 33/333 - loss 0.64946299 - samples/sec: 87.72 - lr: 0.200667\n",
      "2022-08-30 18:24:16,545 epoch 6 - iter 66/333 - loss 0.63870639 - samples/sec: 83.67 - lr: 0.200667\n",
      "2022-08-30 18:24:20,643 epoch 6 - iter 99/333 - loss 0.63068969 - samples/sec: 81.74 - lr: 0.200667\n",
      "2022-08-30 18:24:24,379 epoch 6 - iter 132/333 - loss 0.63002296 - samples/sec: 89.77 - lr: 0.200667\n",
      "2022-08-30 18:24:28,990 epoch 6 - iter 165/333 - loss 0.63208364 - samples/sec: 72.72 - lr: 0.200667\n",
      "2022-08-30 18:24:33,351 epoch 6 - iter 198/333 - loss 0.63272088 - samples/sec: 76.83 - lr: 0.200667\n",
      "2022-08-30 18:24:37,176 epoch 6 - iter 231/333 - loss 0.62944128 - samples/sec: 87.98 - lr: 0.200667\n",
      "2022-08-30 18:24:40,857 epoch 6 - iter 264/333 - loss 0.62756848 - samples/sec: 91.16 - lr: 0.200667\n",
      "2022-08-30 18:24:45,045 epoch 6 - iter 297/333 - loss 0.62863291 - samples/sec: 80.06 - lr: 0.200667\n",
      "2022-08-30 18:24:48,635 epoch 6 - iter 330/333 - loss 0.62743851 - samples/sec: 93.54 - lr: 0.200667\n",
      "2022-08-30 18:24:49,063 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:24:49,064 EPOCH 6 done: loss 0.6276 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:24:50,043 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:24:50,071 DEV : loss 0.414346307516098 - f1-score (micro avg)  0.8465\n",
      "2022-08-30 18:24:50,091 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:24:50,092 saving best model\n",
      "2022-08-30 18:24:50,946 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:24:54,773 epoch 7 - iter 33/333 - loss 0.59861435 - samples/sec: 86.32 - lr: 0.200667\n",
      "2022-08-30 18:24:58,386 epoch 7 - iter 66/333 - loss 0.60132472 - samples/sec: 92.91 - lr: 0.200667\n",
      "2022-08-30 18:25:02,199 epoch 7 - iter 99/333 - loss 0.60514557 - samples/sec: 88.21 - lr: 0.200667\n",
      "2022-08-30 18:25:06,142 epoch 7 - iter 132/333 - loss 0.60219082 - samples/sec: 84.99 - lr: 0.200667\n",
      "2022-08-30 18:25:10,207 epoch 7 - iter 165/333 - loss 0.60234912 - samples/sec: 82.44 - lr: 0.200667\n",
      "2022-08-30 18:25:14,580 epoch 7 - iter 198/333 - loss 0.60105446 - samples/sec: 76.48 - lr: 0.200667\n",
      "2022-08-30 18:25:18,716 epoch 7 - iter 231/333 - loss 0.60246955 - samples/sec: 80.90 - lr: 0.200667\n",
      "2022-08-30 18:25:22,303 epoch 7 - iter 264/333 - loss 0.60013119 - samples/sec: 93.51 - lr: 0.200667\n",
      "2022-08-30 18:25:26,104 epoch 7 - iter 297/333 - loss 0.60070461 - samples/sec: 88.21 - lr: 0.200667\n",
      "2022-08-30 18:25:30,643 epoch 7 - iter 330/333 - loss 0.60182042 - samples/sec: 73.61 - lr: 0.200667\n",
      "2022-08-30 18:25:31,023 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:25:31,024 EPOCH 7 done: loss 0.6021 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:25:31,981 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:25:32,016 DEV : loss 0.403656542301178 - f1-score (micro avg)  0.8548\n",
      "2022-08-30 18:25:32,035 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:25:32,036 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:25:32,943 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:25:36,524 epoch 8 - iter 33/333 - loss 0.60375663 - samples/sec: 92.23 - lr: 0.200667\n",
      "2022-08-30 18:25:40,558 epoch 8 - iter 66/333 - loss 0.58503384 - samples/sec: 83.17 - lr: 0.200667\n",
      "2022-08-30 18:25:45,313 epoch 8 - iter 99/333 - loss 0.58890124 - samples/sec: 70.27 - lr: 0.200667\n",
      "2022-08-30 18:25:49,319 epoch 8 - iter 132/333 - loss 0.58615522 - samples/sec: 83.78 - lr: 0.200667\n",
      "2022-08-30 18:25:53,756 epoch 8 - iter 165/333 - loss 0.58005095 - samples/sec: 75.58 - lr: 0.200667\n",
      "2022-08-30 18:25:57,321 epoch 8 - iter 198/333 - loss 0.58493132 - samples/sec: 94.10 - lr: 0.200667\n",
      "2022-08-30 18:26:01,669 epoch 8 - iter 231/333 - loss 0.58543812 - samples/sec: 77.03 - lr: 0.200667\n",
      "2022-08-30 18:26:05,544 epoch 8 - iter 264/333 - loss 0.58501291 - samples/sec: 86.46 - lr: 0.200667\n",
      "2022-08-30 18:26:09,307 epoch 8 - iter 297/333 - loss 0.58165318 - samples/sec: 89.29 - lr: 0.200667\n",
      "2022-08-30 18:26:12,961 epoch 8 - iter 330/333 - loss 0.58181044 - samples/sec: 91.92 - lr: 0.200667\n",
      "2022-08-30 18:26:13,300 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:26:13,301 EPOCH 8 done: loss 0.5812 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:26:14,302 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:26:14,330 DEV : loss 0.38195404410362244 - f1-score (micro avg)  0.8657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:26:14,351 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:26:14,352 saving best model\n",
      "2022-08-30 18:26:15,034 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:26:19,090 epoch 9 - iter 33/333 - loss 0.58366139 - samples/sec: 81.44 - lr: 0.200667\n",
      "2022-08-30 18:26:22,972 epoch 9 - iter 66/333 - loss 0.56855973 - samples/sec: 86.39 - lr: 0.200667\n",
      "2022-08-30 18:26:26,727 epoch 9 - iter 99/333 - loss 0.56843805 - samples/sec: 89.33 - lr: 0.200667\n",
      "2022-08-30 18:26:30,653 epoch 9 - iter 132/333 - loss 0.57245272 - samples/sec: 85.34 - lr: 0.200667\n",
      "2022-08-30 18:26:34,680 epoch 9 - iter 165/333 - loss 0.57545446 - samples/sec: 83.08 - lr: 0.200667\n",
      "2022-08-30 18:26:38,580 epoch 9 - iter 198/333 - loss 0.57205527 - samples/sec: 85.94 - lr: 0.200667\n",
      "2022-08-30 18:26:42,545 epoch 9 - iter 231/333 - loss 0.57077896 - samples/sec: 84.59 - lr: 0.200667\n",
      "2022-08-30 18:26:46,415 epoch 9 - iter 264/333 - loss 0.57127803 - samples/sec: 86.59 - lr: 0.200667\n",
      "2022-08-30 18:26:50,261 epoch 9 - iter 297/333 - loss 0.57095578 - samples/sec: 87.37 - lr: 0.200667\n",
      "2022-08-30 18:26:54,594 epoch 9 - iter 330/333 - loss 0.57021178 - samples/sec: 77.17 - lr: 0.200667\n",
      "2022-08-30 18:26:54,999 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:26:55,000 EPOCH 9 done: loss 0.5694 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:26:56,015 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:26:56,046 DEV : loss 0.3726706802845001 - f1-score (micro avg)  0.8696\n",
      "2022-08-30 18:26:56,064 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:26:56,065 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:26:56,769 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:27:00,790 epoch 10 - iter 33/333 - loss 0.57393463 - samples/sec: 82.13 - lr: 0.200667\n",
      "2022-08-30 18:27:04,643 epoch 10 - iter 66/333 - loss 0.56429785 - samples/sec: 86.98 - lr: 0.200667\n",
      "2022-08-30 18:27:08,405 epoch 10 - iter 99/333 - loss 0.56526493 - samples/sec: 89.17 - lr: 0.200667\n",
      "2022-08-30 18:27:12,577 epoch 10 - iter 132/333 - loss 0.56405853 - samples/sec: 80.41 - lr: 0.200667\n",
      "2022-08-30 18:27:16,415 epoch 10 - iter 165/333 - loss 0.56158507 - samples/sec: 87.26 - lr: 0.200667\n",
      "2022-08-30 18:27:20,507 epoch 10 - iter 198/333 - loss 0.55717503 - samples/sec: 82.13 - lr: 0.200667\n",
      "2022-08-30 18:27:24,238 epoch 10 - iter 231/333 - loss 0.55896633 - samples/sec: 89.92 - lr: 0.200667\n",
      "2022-08-30 18:27:28,152 epoch 10 - iter 264/333 - loss 0.55916256 - samples/sec: 85.58 - lr: 0.200667\n",
      "2022-08-30 18:27:32,400 epoch 10 - iter 297/333 - loss 0.55926267 - samples/sec: 78.72 - lr: 0.200667\n",
      "2022-08-30 18:27:36,597 epoch 10 - iter 330/333 - loss 0.55891501 - samples/sec: 80.00 - lr: 0.200667\n",
      "2022-08-30 18:27:37,225 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:27:37,226 EPOCH 10 done: loss 0.5585 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:27:38,213 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:27:38,247 DEV : loss 0.3704012334346771 - f1-score (micro avg)  0.871\n",
      "2022-08-30 18:27:38,264 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:27:38,265 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:27:39,895 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:27:39,896 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 18:27:40,078 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:27:41,603 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:27:41,626 0.8782\t0.8782\t0.8782\t0.8782\n",
      "2022-08-30 18:27:41,627 \n",
      "Results:\n",
      "- F-score (micro) 0.8782\n",
      "- F-score (macro) 0.765\n",
      "- Accuracy 0.8782\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8196    0.8795    0.8485      1353\n",
      "         ADJ     0.8163    0.8065    0.8114       672\n",
      "       PUNCT     0.9985    1.0000    0.9992       660\n",
      "         ADP     0.9765    0.9708    0.9737       514\n",
      "        VERB     0.7976    0.8775    0.8356       449\n",
      "       PROPN     0.8497    0.6345    0.7265       383\n",
      "         AUX     0.9878    0.9672    0.9774       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         ADV     0.6402    0.6954    0.6667       151\n",
      "         DET     0.8299    0.7578    0.7922       161\n",
      "        PRON     0.9722    0.9130    0.9417       115\n",
      "         NUM     0.9592    0.6620    0.7833        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8782      5264\n",
      "   macro avg     0.7895    0.7480    0.7650      5264\n",
      "weighted avg     0.8809    0.8782    0.8775      5264\n",
      "\n",
      "2022-08-30 18:27:41,627 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:27:41,629 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:27:42,123 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 3 #######################\n",
      "#######################################################\n",
      "2022-08-30 18:29:58,511 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:29:58,512 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 18:29:58,512 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:29:58,513 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 18:29:58,513 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:29:58,514 Parameters:\n",
      "2022-08-30 18:29:58,515  - learning_rate: \"0.200667\"\n",
      "2022-08-30 18:29:58,515  - mini_batch_size: \"10\"\n",
      "2022-08-30 18:29:58,516  - patience: \"3\"\n",
      "2022-08-30 18:29:58,517  - anneal_factor: \"0.5\"\n",
      "2022-08-30 18:29:58,517  - max_epochs: \"11\"\n",
      "2022-08-30 18:29:58,518  - shuffle: \"True\"\n",
      "2022-08-30 18:29:58,519  - train_with_dev: \"False\"\n",
      "2022-08-30 18:29:58,519  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 18:29:58,520 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:29:58,520 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 18:29:58,521 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:29:58,522 Device: cpu\n",
      "2022-08-30 18:29:58,522 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:29:58,523 Embeddings storage mode: cpu\n",
      "2022-08-30 18:29:58,523 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:30:02,615 epoch 1 - iter 33/333 - loss 0.51117854 - samples/sec: 80.68 - lr: 0.200667\n",
      "2022-08-30 18:30:06,886 epoch 1 - iter 66/333 - loss 0.52197527 - samples/sec: 78.38 - lr: 0.200667\n",
      "2022-08-30 18:30:10,505 epoch 1 - iter 99/333 - loss 0.51806769 - samples/sec: 92.98 - lr: 0.200667\n",
      "2022-08-30 18:30:14,307 epoch 1 - iter 132/333 - loss 0.51259229 - samples/sec: 88.19 - lr: 0.200667\n",
      "2022-08-30 18:30:19,050 epoch 1 - iter 165/333 - loss 0.52148109 - samples/sec: 70.62 - lr: 0.200667\n",
      "2022-08-30 18:30:22,593 epoch 1 - iter 198/333 - loss 0.52049089 - samples/sec: 94.80 - lr: 0.200667\n",
      "2022-08-30 18:30:26,640 epoch 1 - iter 231/333 - loss 0.52285638 - samples/sec: 82.83 - lr: 0.200667\n",
      "2022-08-30 18:30:30,273 epoch 1 - iter 264/333 - loss 0.52263280 - samples/sec: 92.39 - lr: 0.200667\n",
      "2022-08-30 18:30:34,444 epoch 1 - iter 297/333 - loss 0.52559978 - samples/sec: 80.29 - lr: 0.200667\n",
      "2022-08-30 18:30:38,756 epoch 1 - iter 330/333 - loss 0.54234915 - samples/sec: 77.68 - lr: 0.200667\n",
      "2022-08-30 18:30:39,189 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:30:39,190 EPOCH 1 done: loss 0.5433 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:30:40,169 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:30:40,204 DEV : loss 0.4031663239002228 - f1-score (micro avg)  0.8621\n",
      "2022-08-30 18:30:40,220 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:30:40,221 saving best model\n",
      "2022-08-30 18:30:40,899 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:30:45,076 epoch 2 - iter 33/333 - loss 0.53751072 - samples/sec: 79.10 - lr: 0.200667\n",
      "2022-08-30 18:30:49,041 epoch 2 - iter 66/333 - loss 0.54456242 - samples/sec: 84.49 - lr: 0.200667\n",
      "2022-08-30 18:30:52,961 epoch 2 - iter 99/333 - loss 0.53700280 - samples/sec: 85.40 - lr: 0.200667\n",
      "2022-08-30 18:30:57,137 epoch 2 - iter 132/333 - loss 0.53042424 - samples/sec: 80.27 - lr: 0.200667\n",
      "2022-08-30 18:31:00,622 epoch 2 - iter 165/333 - loss 0.53416214 - samples/sec: 96.41 - lr: 0.200667\n",
      "2022-08-30 18:31:04,553 epoch 2 - iter 198/333 - loss 0.53680283 - samples/sec: 85.16 - lr: 0.200667\n",
      "2022-08-30 18:31:08,262 epoch 2 - iter 231/333 - loss 0.53859201 - samples/sec: 90.51 - lr: 0.200667\n",
      "2022-08-30 18:31:12,313 epoch 2 - iter 264/333 - loss 0.53931429 - samples/sec: 82.60 - lr: 0.200667\n",
      "2022-08-30 18:31:16,459 epoch 2 - iter 297/333 - loss 0.53743930 - samples/sec: 80.88 - lr: 0.200667\n",
      "2022-08-30 18:31:20,858 epoch 2 - iter 330/333 - loss 0.53659965 - samples/sec: 76.14 - lr: 0.200667\n",
      "2022-08-30 18:31:21,197 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:31:21,198 EPOCH 2 done: loss 0.5363 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:31:22,182 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:31:22,209 DEV : loss 0.36608007550239563 - f1-score (micro avg)  0.8717\n",
      "2022-08-30 18:31:22,226 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:31:22,227 saving best model\n",
      "2022-08-30 18:31:22,932 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:31:26,772 epoch 3 - iter 33/333 - loss 0.53491600 - samples/sec: 85.96 - lr: 0.200667\n",
      "2022-08-30 18:31:30,725 epoch 3 - iter 66/333 - loss 0.53367096 - samples/sec: 84.88 - lr: 0.200667\n",
      "2022-08-30 18:31:34,829 epoch 3 - iter 99/333 - loss 0.53280287 - samples/sec: 81.56 - lr: 0.200667\n",
      "2022-08-30 18:31:38,321 epoch 3 - iter 132/333 - loss 0.52797500 - samples/sec: 96.21 - lr: 0.200667\n",
      "2022-08-30 18:31:42,269 epoch 3 - iter 165/333 - loss 0.52490366 - samples/sec: 85.03 - lr: 0.200667\n",
      "2022-08-30 18:31:46,355 epoch 3 - iter 198/333 - loss 0.52665326 - samples/sec: 81.95 - lr: 0.200667\n",
      "2022-08-30 18:31:50,326 epoch 3 - iter 231/333 - loss 0.52748755 - samples/sec: 84.68 - lr: 0.200667\n",
      "2022-08-30 18:31:54,679 epoch 3 - iter 264/333 - loss 0.52831944 - samples/sec: 76.91 - lr: 0.200667\n",
      "2022-08-30 18:31:58,348 epoch 3 - iter 297/333 - loss 0.52727822 - samples/sec: 91.39 - lr: 0.200667\n",
      "2022-08-30 18:32:02,321 epoch 3 - iter 330/333 - loss 0.52897860 - samples/sec: 84.57 - lr: 0.200667\n",
      "2022-08-30 18:32:02,701 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:32:02,702 EPOCH 3 done: loss 0.5288 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:32:03,674 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:32:03,701 DEV : loss 0.33894824981689453 - f1-score (micro avg)  0.8803\n",
      "2022-08-30 18:32:03,721 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:32:03,722 saving best model\n",
      "2022-08-30 18:32:04,411 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:32:08,937 epoch 4 - iter 33/333 - loss 0.48957763 - samples/sec: 72.94 - lr: 0.200667\n",
      "2022-08-30 18:32:12,790 epoch 4 - iter 66/333 - loss 0.50423884 - samples/sec: 87.19 - lr: 0.200667\n",
      "2022-08-30 18:32:17,101 epoch 4 - iter 99/333 - loss 0.51474087 - samples/sec: 77.70 - lr: 0.200667\n",
      "2022-08-30 18:32:20,853 epoch 4 - iter 132/333 - loss 0.51052335 - samples/sec: 89.21 - lr: 0.200667\n",
      "2022-08-30 18:32:24,633 epoch 4 - iter 165/333 - loss 0.51421083 - samples/sec: 88.71 - lr: 0.200667\n",
      "2022-08-30 18:32:28,896 epoch 4 - iter 198/333 - loss 0.51393824 - samples/sec: 78.61 - lr: 0.200667\n",
      "2022-08-30 18:32:32,588 epoch 4 - iter 231/333 - loss 0.51682341 - samples/sec: 90.81 - lr: 0.200667\n",
      "2022-08-30 18:32:36,605 epoch 4 - iter 264/333 - loss 0.51710224 - samples/sec: 83.29 - lr: 0.200667\n",
      "2022-08-30 18:32:40,433 epoch 4 - iter 297/333 - loss 0.51637168 - samples/sec: 87.49 - lr: 0.200667\n",
      "2022-08-30 18:32:44,534 epoch 4 - iter 330/333 - loss 0.51707052 - samples/sec: 81.95 - lr: 0.200667\n",
      "2022-08-30 18:32:44,994 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:32:44,995 EPOCH 4 done: loss 0.5170 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:32:45,977 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:32:46,010 DEV : loss 0.3388396203517914 - f1-score (micro avg)  0.8816\n",
      "2022-08-30 18:32:46,031 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:32:46,032 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:32:46,800 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:32:51,101 epoch 5 - iter 33/333 - loss 0.53733154 - samples/sec: 76.78 - lr: 0.200667\n",
      "2022-08-30 18:32:55,259 epoch 5 - iter 66/333 - loss 0.51944202 - samples/sec: 80.66 - lr: 0.200667\n",
      "2022-08-30 18:32:59,344 epoch 5 - iter 99/333 - loss 0.51703119 - samples/sec: 82.09 - lr: 0.200667\n",
      "2022-08-30 18:33:03,085 epoch 5 - iter 132/333 - loss 0.51306939 - samples/sec: 89.92 - lr: 0.200667\n",
      "2022-08-30 18:33:07,439 epoch 5 - iter 165/333 - loss 0.51071423 - samples/sec: 76.85 - lr: 0.200667\n",
      "2022-08-30 18:33:11,304 epoch 5 - iter 198/333 - loss 0.51257753 - samples/sec: 87.00 - lr: 0.200667\n",
      "2022-08-30 18:33:15,162 epoch 5 - iter 231/333 - loss 0.51215758 - samples/sec: 86.86 - lr: 0.200667\n",
      "2022-08-30 18:33:18,681 epoch 5 - iter 264/333 - loss 0.51260064 - samples/sec: 95.38 - lr: 0.200667\n",
      "2022-08-30 18:33:22,703 epoch 5 - iter 297/333 - loss 0.51328751 - samples/sec: 83.21 - lr: 0.200667\n",
      "2022-08-30 18:33:26,703 epoch 5 - iter 330/333 - loss 0.51541696 - samples/sec: 83.67 - lr: 0.200667\n",
      "2022-08-30 18:33:27,098 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:33:27,099 EPOCH 5 done: loss 0.5148 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:33:28,062 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:33:28,093 DEV : loss 0.3311390280723572 - f1-score (micro avg)  0.8905\n",
      "2022-08-30 18:33:28,108 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:33:28,109 saving best model\n",
      "2022-08-30 18:33:28,830 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:33:32,431 epoch 6 - iter 33/333 - loss 0.51537692 - samples/sec: 91.69 - lr: 0.200667\n",
      "2022-08-30 18:33:36,550 epoch 6 - iter 66/333 - loss 0.50161389 - samples/sec: 81.56 - lr: 0.200667\n",
      "2022-08-30 18:33:40,535 epoch 6 - iter 99/333 - loss 0.50743307 - samples/sec: 84.31 - lr: 0.200667\n",
      "2022-08-30 18:33:44,574 epoch 6 - iter 132/333 - loss 0.50481342 - samples/sec: 82.89 - lr: 0.200667\n",
      "2022-08-30 18:33:48,418 epoch 6 - iter 165/333 - loss 0.50661995 - samples/sec: 87.26 - lr: 0.200667\n",
      "2022-08-30 18:33:52,382 epoch 6 - iter 198/333 - loss 0.50777085 - samples/sec: 84.88 - lr: 0.200667\n",
      "2022-08-30 18:33:56,173 epoch 6 - iter 231/333 - loss 0.50661747 - samples/sec: 88.60 - lr: 0.200667\n",
      "2022-08-30 18:34:00,697 epoch 6 - iter 264/333 - loss 0.50903477 - samples/sec: 73.86 - lr: 0.200667\n",
      "2022-08-30 18:34:04,751 epoch 6 - iter 297/333 - loss 0.50995884 - samples/sec: 82.73 - lr: 0.200667\n",
      "2022-08-30 18:34:09,057 epoch 6 - iter 330/333 - loss 0.50873416 - samples/sec: 77.76 - lr: 0.200667\n",
      "2022-08-30 18:34:09,477 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:34:09,478 EPOCH 6 done: loss 0.5082 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:34:10,479 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:34:10,508 DEV : loss 0.3298477232456207 - f1-score (micro avg)  0.8887\n",
      "2022-08-30 18:34:10,523 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:34:10,524 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:34:14,303 epoch 7 - iter 33/333 - loss 0.49514359 - samples/sec: 87.39 - lr: 0.200667\n",
      "2022-08-30 18:34:17,910 epoch 7 - iter 66/333 - loss 0.49092824 - samples/sec: 93.06 - lr: 0.200667\n",
      "2022-08-30 18:34:21,425 epoch 7 - iter 99/333 - loss 0.49385588 - samples/sec: 95.60 - lr: 0.200667\n",
      "2022-08-30 18:34:25,385 epoch 7 - iter 132/333 - loss 0.49479803 - samples/sec: 84.75 - lr: 0.200667\n",
      "2022-08-30 18:34:29,641 epoch 7 - iter 165/333 - loss 0.49679346 - samples/sec: 78.89 - lr: 0.200667\n",
      "2022-08-30 18:34:33,636 epoch 7 - iter 198/333 - loss 0.49754537 - samples/sec: 83.97 - lr: 0.200667\n",
      "2022-08-30 18:34:37,351 epoch 7 - iter 231/333 - loss 0.49601189 - samples/sec: 90.44 - lr: 0.200667\n",
      "2022-08-30 18:34:41,767 epoch 7 - iter 264/333 - loss 0.49406979 - samples/sec: 76.02 - lr: 0.200667\n",
      "2022-08-30 18:34:45,731 epoch 7 - iter 297/333 - loss 0.49568254 - samples/sec: 84.51 - lr: 0.200667\n",
      "2022-08-30 18:34:50,338 epoch 7 - iter 330/333 - loss 0.49885757 - samples/sec: 72.59 - lr: 0.200667\n",
      "2022-08-30 18:34:50,712 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:34:50,713 EPOCH 7 done: loss 0.4988 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:34:51,701 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:34:51,733 DEV : loss 0.3272915184497833 - f1-score (micro avg)  0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:34:51,755 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:34:51,756 saving best model\n",
      "2022-08-30 18:34:52,433 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:34:56,271 epoch 8 - iter 33/333 - loss 0.48277122 - samples/sec: 86.03 - lr: 0.200667\n",
      "2022-08-30 18:34:59,982 epoch 8 - iter 66/333 - loss 0.48068686 - samples/sec: 90.31 - lr: 0.200667\n",
      "2022-08-30 18:35:04,549 epoch 8 - iter 99/333 - loss 0.49159392 - samples/sec: 73.32 - lr: 0.200667\n",
      "2022-08-30 18:35:08,185 epoch 8 - iter 132/333 - loss 0.49090452 - samples/sec: 92.33 - lr: 0.200667\n",
      "2022-08-30 18:35:12,342 epoch 8 - iter 165/333 - loss 0.49265247 - samples/sec: 80.55 - lr: 0.200667\n",
      "2022-08-30 18:35:16,319 epoch 8 - iter 198/333 - loss 0.49088240 - samples/sec: 84.46 - lr: 0.200667\n",
      "2022-08-30 18:35:20,255 epoch 8 - iter 231/333 - loss 0.49312459 - samples/sec: 85.29 - lr: 0.200667\n",
      "2022-08-30 18:35:24,487 epoch 8 - iter 264/333 - loss 0.49208881 - samples/sec: 79.14 - lr: 0.200667\n",
      "2022-08-30 18:35:28,488 epoch 8 - iter 297/333 - loss 0.48980186 - samples/sec: 83.86 - lr: 0.200667\n",
      "2022-08-30 18:35:32,683 epoch 8 - iter 330/333 - loss 0.49117801 - samples/sec: 79.85 - lr: 0.200667\n",
      "2022-08-30 18:35:33,107 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:35:33,108 EPOCH 8 done: loss 0.4912 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:35:34,160 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:35:34,195 DEV : loss 0.31745290756225586 - f1-score (micro avg)  0.8921\n",
      "2022-08-30 18:35:34,213 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:35:34,214 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:35:34,913 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:35:38,781 epoch 9 - iter 33/333 - loss 0.48242726 - samples/sec: 85.38 - lr: 0.200667\n",
      "2022-08-30 18:35:42,483 epoch 9 - iter 66/333 - loss 0.48452833 - samples/sec: 90.68 - lr: 0.200667\n",
      "2022-08-30 18:35:46,169 epoch 9 - iter 99/333 - loss 0.48691665 - samples/sec: 91.29 - lr: 0.200667\n",
      "2022-08-30 18:35:50,124 epoch 9 - iter 132/333 - loss 0.48171723 - samples/sec: 84.81 - lr: 0.200667\n",
      "2022-08-30 18:35:54,422 epoch 9 - iter 165/333 - loss 0.48067687 - samples/sec: 77.94 - lr: 0.200667\n",
      "2022-08-30 18:35:58,816 epoch 9 - iter 198/333 - loss 0.48490027 - samples/sec: 76.37 - lr: 0.200667\n",
      "2022-08-30 18:36:03,355 epoch 9 - iter 231/333 - loss 0.48388197 - samples/sec: 73.73 - lr: 0.200667\n",
      "2022-08-30 18:36:07,533 epoch 9 - iter 264/333 - loss 0.48523573 - samples/sec: 80.33 - lr: 0.200667\n",
      "2022-08-30 18:36:11,317 epoch 9 - iter 297/333 - loss 0.48688139 - samples/sec: 88.71 - lr: 0.200667\n",
      "2022-08-30 18:36:15,154 epoch 9 - iter 330/333 - loss 0.48743283 - samples/sec: 87.42 - lr: 0.200667\n",
      "2022-08-30 18:36:15,672 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:36:15,673 EPOCH 9 done: loss 0.4882 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:36:16,645 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:36:16,676 DEV : loss 0.32275304198265076 - f1-score (micro avg)  0.8881\n",
      "2022-08-30 18:36:16,693 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:36:16,694 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:36:20,591 epoch 10 - iter 33/333 - loss 0.48514926 - samples/sec: 84.75 - lr: 0.200667\n",
      "2022-08-30 18:36:24,441 epoch 10 - iter 66/333 - loss 0.47735490 - samples/sec: 87.07 - lr: 0.200667\n",
      "2022-08-30 18:36:28,753 epoch 10 - iter 99/333 - loss 0.47806523 - samples/sec: 77.87 - lr: 0.200667\n",
      "2022-08-30 18:36:32,621 epoch 10 - iter 132/333 - loss 0.47902395 - samples/sec: 86.64 - lr: 0.200667\n",
      "2022-08-30 18:36:36,614 epoch 10 - iter 165/333 - loss 0.47631129 - samples/sec: 83.86 - lr: 0.200667\n",
      "2022-08-30 18:36:40,514 epoch 10 - iter 198/333 - loss 0.47828327 - samples/sec: 85.96 - lr: 0.200667\n",
      "2022-08-30 18:36:44,499 epoch 10 - iter 231/333 - loss 0.47990149 - samples/sec: 84.18 - lr: 0.200667\n",
      "2022-08-30 18:36:48,324 epoch 10 - iter 264/333 - loss 0.48208378 - samples/sec: 87.65 - lr: 0.200667\n",
      "2022-08-30 18:36:52,643 epoch 10 - iter 297/333 - loss 0.48491506 - samples/sec: 77.61 - lr: 0.200667\n",
      "2022-08-30 18:36:56,618 epoch 10 - iter 330/333 - loss 0.48415046 - samples/sec: 84.38 - lr: 0.200667\n",
      "2022-08-30 18:36:57,164 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:36:57,165 EPOCH 10 done: loss 0.4844 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:36:58,163 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:36:58,197 DEV : loss 0.30877092480659485 - f1-score (micro avg)  0.8942\n",
      "2022-08-30 18:36:58,213 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:36:58,214 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:36:58,914 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:37:03,082 epoch 11 - iter 33/333 - loss 0.48566095 - samples/sec: 79.25 - lr: 0.200667\n",
      "2022-08-30 18:37:06,838 epoch 11 - iter 66/333 - loss 0.48319313 - samples/sec: 89.33 - lr: 0.200667\n",
      "2022-08-30 18:37:11,155 epoch 11 - iter 99/333 - loss 0.48592727 - samples/sec: 77.52 - lr: 0.200667\n",
      "2022-08-30 18:37:15,407 epoch 11 - iter 132/333 - loss 0.48205597 - samples/sec: 78.72 - lr: 0.200667\n",
      "2022-08-30 18:37:19,386 epoch 11 - iter 165/333 - loss 0.48653456 - samples/sec: 84.33 - lr: 0.200667\n",
      "2022-08-30 18:37:23,119 epoch 11 - iter 198/333 - loss 0.48439650 - samples/sec: 90.14 - lr: 0.200667\n",
      "2022-08-30 18:37:27,638 epoch 11 - iter 231/333 - loss 0.48452503 - samples/sec: 74.09 - lr: 0.200667\n",
      "2022-08-30 18:37:31,228 epoch 11 - iter 264/333 - loss 0.48062714 - samples/sec: 93.48 - lr: 0.200667\n",
      "2022-08-30 18:37:35,075 epoch 11 - iter 297/333 - loss 0.48011543 - samples/sec: 87.09 - lr: 0.200667\n",
      "2022-08-30 18:37:39,150 epoch 11 - iter 330/333 - loss 0.48036940 - samples/sec: 82.23 - lr: 0.200667\n",
      "2022-08-30 18:37:39,553 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:37:39,553 EPOCH 11 done: loss 0.4808 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:37:40,548 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:37:40,582 DEV : loss 0.31218963861465454 - f1-score (micro avg)  0.8949\n",
      "2022-08-30 18:37:40,597 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:37:40,598 saving best model\n",
      "2022-08-30 18:37:42,057 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:37:42,058 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 18:37:42,250 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:37:43,802 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:37:43,825 0.8976\t0.8976\t0.8976\t0.8976\n",
      "2022-08-30 18:37:43,825 \n",
      "Results:\n",
      "- F-score (micro) 0.8976\n",
      "- F-score (macro) 0.7806\n",
      "- Accuracy 0.8976\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8411    0.9157    0.8769      1353\n",
      "         ADJ     0.8266    0.8869    0.8557       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9881    0.9689    0.9784       514\n",
      "        VERB     0.8337    0.8820    0.8571       449\n",
      "         AUX     0.9908    0.9672    0.9789       335\n",
      "       PROPN     0.8618    0.6188    0.7204       383\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         ADV     0.7603    0.7351    0.7475       151\n",
      "         DET     0.9344    0.7081    0.8057       161\n",
      "        PRON     1.0000    0.9217    0.9593       115\n",
      "         NUM     0.9455    0.7324    0.8254        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8976      5264\n",
      "   macro avg     0.8104    0.7588    0.7806      5264\n",
      "weighted avg     0.9003    0.8976    0.8961      5264\n",
      "\n",
      "2022-08-30 18:37:43,825 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:37:43,827 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:37:44,303 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 18:40:02,628 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:40:02,629 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 18:40:02,629 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:40:02,630 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 18:40:02,630 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:40:02,631 Parameters:\n",
      "2022-08-30 18:40:02,631  - learning_rate: \"0.200667\"\n",
      "2022-08-30 18:40:02,632  - mini_batch_size: \"10\"\n",
      "2022-08-30 18:40:02,632  - patience: \"3\"\n",
      "2022-08-30 18:40:02,633  - anneal_factor: \"0.5\"\n",
      "2022-08-30 18:40:02,633  - max_epochs: \"12\"\n",
      "2022-08-30 18:40:02,633  - shuffle: \"True\"\n",
      "2022-08-30 18:40:02,634  - train_with_dev: \"False\"\n",
      "2022-08-30 18:40:02,635  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 18:40:02,636 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:40:02,636 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 18:40:02,637 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:40:02,637 Device: cpu\n",
      "2022-08-30 18:40:02,637 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:40:02,638 Embeddings storage mode: cpu\n",
      "2022-08-30 18:40:02,638 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:40:06,712 epoch 1 - iter 33/333 - loss 0.43585689 - samples/sec: 81.08 - lr: 0.200667\n",
      "2022-08-30 18:40:10,960 epoch 1 - iter 66/333 - loss 0.45381379 - samples/sec: 78.82 - lr: 0.200667\n",
      "2022-08-30 18:40:14,552 epoch 1 - iter 99/333 - loss 0.45066571 - samples/sec: 93.48 - lr: 0.200667\n",
      "2022-08-30 18:40:18,390 epoch 1 - iter 132/333 - loss 0.44649974 - samples/sec: 87.23 - lr: 0.200667\n",
      "2022-08-30 18:40:22,981 epoch 1 - iter 165/333 - loss 0.45360157 - samples/sec: 73.07 - lr: 0.200667\n",
      "2022-08-30 18:40:26,545 epoch 1 - iter 198/333 - loss 0.45174256 - samples/sec: 94.31 - lr: 0.200667\n",
      "2022-08-30 18:40:30,627 epoch 1 - iter 231/333 - loss 0.45288099 - samples/sec: 82.07 - lr: 0.200667\n",
      "2022-08-30 18:40:34,292 epoch 1 - iter 264/333 - loss 0.45219474 - samples/sec: 91.51 - lr: 0.200667\n",
      "2022-08-30 18:40:38,420 epoch 1 - iter 297/333 - loss 0.45583505 - samples/sec: 81.00 - lr: 0.200667\n",
      "2022-08-30 18:40:42,745 epoch 1 - iter 330/333 - loss 0.46958768 - samples/sec: 77.41 - lr: 0.200667\n",
      "2022-08-30 18:40:43,180 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:40:43,181 EPOCH 1 done: loss 0.4701 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:40:44,167 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:40:44,196 DEV : loss 0.33774441480636597 - f1-score (micro avg)  0.8806\n",
      "2022-08-30 18:40:44,214 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:40:44,215 saving best model\n",
      "2022-08-30 18:40:44,892 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:40:48,820 epoch 2 - iter 33/333 - loss 0.46557659 - samples/sec: 84.05 - lr: 0.200667\n",
      "2022-08-30 18:40:53,246 epoch 2 - iter 66/333 - loss 0.46945001 - samples/sec: 75.67 - lr: 0.200667\n",
      "2022-08-30 18:40:57,056 epoch 2 - iter 99/333 - loss 0.47072257 - samples/sec: 87.91 - lr: 0.200667\n",
      "2022-08-30 18:41:00,991 epoch 2 - iter 132/333 - loss 0.47524702 - samples/sec: 85.05 - lr: 0.200667\n",
      "2022-08-30 18:41:05,040 epoch 2 - iter 165/333 - loss 0.47703976 - samples/sec: 82.85 - lr: 0.200667\n",
      "2022-08-30 18:41:09,395 epoch 2 - iter 198/333 - loss 0.47675150 - samples/sec: 76.85 - lr: 0.200667\n",
      "2022-08-30 18:41:12,945 epoch 2 - iter 231/333 - loss 0.47618285 - samples/sec: 94.77 - lr: 0.200667\n",
      "2022-08-30 18:41:17,340 epoch 2 - iter 264/333 - loss 0.47640780 - samples/sec: 76.11 - lr: 0.200667\n",
      "2022-08-30 18:41:21,015 epoch 2 - iter 297/333 - loss 0.47994200 - samples/sec: 91.59 - lr: 0.200667\n",
      "2022-08-30 18:41:24,968 epoch 2 - iter 330/333 - loss 0.47759589 - samples/sec: 84.88 - lr: 0.200667\n",
      "2022-08-30 18:41:25,409 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:41:25,410 EPOCH 2 done: loss 0.4772 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:41:26,406 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:41:26,437 DEV : loss 0.312365859746933 - f1-score (micro avg)  0.897\n",
      "2022-08-30 18:41:26,453 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:41:26,454 saving best model\n",
      "2022-08-30 18:41:27,457 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:41:31,196 epoch 3 - iter 33/333 - loss 0.45002507 - samples/sec: 88.31 - lr: 0.200667\n",
      "2022-08-30 18:41:35,534 epoch 3 - iter 66/333 - loss 0.46042225 - samples/sec: 77.07 - lr: 0.200667\n",
      "2022-08-30 18:41:39,763 epoch 3 - iter 99/333 - loss 0.45946175 - samples/sec: 79.14 - lr: 0.200667\n",
      "2022-08-30 18:41:43,674 epoch 3 - iter 132/333 - loss 0.45915094 - samples/sec: 85.69 - lr: 0.200667\n",
      "2022-08-30 18:41:47,774 epoch 3 - iter 165/333 - loss 0.46328095 - samples/sec: 81.78 - lr: 0.200667\n",
      "2022-08-30 18:41:51,745 epoch 3 - iter 198/333 - loss 0.46748435 - samples/sec: 84.33 - lr: 0.200667\n",
      "2022-08-30 18:41:55,867 epoch 3 - iter 231/333 - loss 0.46720711 - samples/sec: 81.14 - lr: 0.200667\n",
      "2022-08-30 18:41:59,999 epoch 3 - iter 264/333 - loss 0.46743506 - samples/sec: 81.02 - lr: 0.200667\n",
      "2022-08-30 18:42:03,686 epoch 3 - iter 297/333 - loss 0.46709859 - samples/sec: 91.14 - lr: 0.200667\n",
      "2022-08-30 18:42:07,465 epoch 3 - iter 330/333 - loss 0.46753384 - samples/sec: 88.73 - lr: 0.200667\n",
      "2022-08-30 18:42:07,842 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:42:07,843 EPOCH 3 done: loss 0.4670 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:42:10,115 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:42:10,146 DEV : loss 0.30976441502571106 - f1-score (micro avg)  0.896\n",
      "2022-08-30 18:42:10,162 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:42:10,162 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:42:14,284 epoch 4 - iter 33/333 - loss 0.44499210 - samples/sec: 80.10 - lr: 0.200667\n",
      "2022-08-30 18:42:18,399 epoch 4 - iter 66/333 - loss 0.44994667 - samples/sec: 81.52 - lr: 0.200667\n",
      "2022-08-30 18:42:22,400 epoch 4 - iter 99/333 - loss 0.45409161 - samples/sec: 83.95 - lr: 0.200667\n",
      "2022-08-30 18:42:26,385 epoch 4 - iter 132/333 - loss 0.45825146 - samples/sec: 84.31 - lr: 0.200667\n",
      "2022-08-30 18:42:30,256 epoch 4 - iter 165/333 - loss 0.46411527 - samples/sec: 86.86 - lr: 0.200667\n",
      "2022-08-30 18:42:34,709 epoch 4 - iter 198/333 - loss 0.46686877 - samples/sec: 75.03 - lr: 0.200667\n",
      "2022-08-30 18:42:38,623 epoch 4 - iter 231/333 - loss 0.46654206 - samples/sec: 85.69 - lr: 0.200667\n",
      "2022-08-30 18:42:42,670 epoch 4 - iter 264/333 - loss 0.46796224 - samples/sec: 82.73 - lr: 0.200667\n",
      "2022-08-30 18:42:46,522 epoch 4 - iter 297/333 - loss 0.46744098 - samples/sec: 86.93 - lr: 0.200667\n",
      "2022-08-30 18:42:50,471 epoch 4 - iter 330/333 - loss 0.46901623 - samples/sec: 84.90 - lr: 0.200667\n",
      "2022-08-30 18:42:50,813 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:42:50,814 EPOCH 4 done: loss 0.4695 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:42:51,782 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:42:51,809 DEV : loss 0.29168134927749634 - f1-score (micro avg)  0.8998\n",
      "2022-08-30 18:42:51,828 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:42:51,829 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:42:52,524 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:42:56,535 epoch 5 - iter 33/333 - loss 0.44266888 - samples/sec: 82.34 - lr: 0.200667\n",
      "2022-08-30 18:43:00,336 epoch 5 - iter 66/333 - loss 0.45910112 - samples/sec: 88.14 - lr: 0.200667\n",
      "2022-08-30 18:43:04,214 epoch 5 - iter 99/333 - loss 0.46264301 - samples/sec: 86.55 - lr: 0.200667\n",
      "2022-08-30 18:43:08,254 epoch 5 - iter 132/333 - loss 0.46245088 - samples/sec: 82.96 - lr: 0.200667\n",
      "2022-08-30 18:43:12,031 epoch 5 - iter 165/333 - loss 0.46180969 - samples/sec: 88.66 - lr: 0.200667\n",
      "2022-08-30 18:43:16,061 epoch 5 - iter 198/333 - loss 0.46529777 - samples/sec: 83.10 - lr: 0.200667\n",
      "2022-08-30 18:43:19,910 epoch 5 - iter 231/333 - loss 0.46205584 - samples/sec: 87.05 - lr: 0.200667\n",
      "2022-08-30 18:43:23,931 epoch 5 - iter 264/333 - loss 0.46436995 - samples/sec: 83.40 - lr: 0.200667\n",
      "2022-08-30 18:43:28,102 epoch 5 - iter 297/333 - loss 0.46395562 - samples/sec: 80.19 - lr: 0.200667\n",
      "2022-08-30 18:43:32,238 epoch 5 - iter 330/333 - loss 0.46549225 - samples/sec: 80.90 - lr: 0.200667\n",
      "2022-08-30 18:43:32,706 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:43:32,706 EPOCH 5 done: loss 0.4649 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:43:33,688 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:43:33,719 DEV : loss 0.30513185262680054 - f1-score (micro avg)  0.8985\n",
      "2022-08-30 18:43:33,736 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:43:33,737 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:43:37,230 epoch 6 - iter 33/333 - loss 0.45366379 - samples/sec: 94.58 - lr: 0.200667\n",
      "2022-08-30 18:43:41,387 epoch 6 - iter 66/333 - loss 0.45423342 - samples/sec: 80.43 - lr: 0.200667\n",
      "2022-08-30 18:43:45,310 epoch 6 - iter 99/333 - loss 0.46213818 - samples/sec: 85.60 - lr: 0.200667\n",
      "2022-08-30 18:43:49,482 epoch 6 - iter 132/333 - loss 0.45788533 - samples/sec: 80.35 - lr: 0.200667\n",
      "2022-08-30 18:43:53,882 epoch 6 - iter 165/333 - loss 0.45738245 - samples/sec: 76.14 - lr: 0.200667\n",
      "2022-08-30 18:43:57,686 epoch 6 - iter 198/333 - loss 0.45489807 - samples/sec: 88.12 - lr: 0.200667\n",
      "2022-08-30 18:44:01,623 epoch 6 - iter 231/333 - loss 0.45648992 - samples/sec: 85.03 - lr: 0.200667\n",
      "2022-08-30 18:44:05,932 epoch 6 - iter 264/333 - loss 0.45555793 - samples/sec: 77.68 - lr: 0.200667\n",
      "2022-08-30 18:44:09,861 epoch 6 - iter 297/333 - loss 0.45598108 - samples/sec: 85.38 - lr: 0.200667\n",
      "2022-08-30 18:44:13,495 epoch 6 - iter 330/333 - loss 0.45671622 - samples/sec: 92.51 - lr: 0.200667\n",
      "2022-08-30 18:44:14,032 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:44:14,033 EPOCH 6 done: loss 0.4570 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:44:15,032 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:44:15,062 DEV : loss 0.29539912939071655 - f1-score (micro avg)  0.8994\n",
      "2022-08-30 18:44:15,081 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 18:44:15,083 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:44:19,191 epoch 7 - iter 33/333 - loss 0.44860181 - samples/sec: 80.41 - lr: 0.200667\n",
      "2022-08-30 18:44:23,011 epoch 7 - iter 66/333 - loss 0.45368378 - samples/sec: 87.72 - lr: 0.200667\n",
      "2022-08-30 18:44:26,917 epoch 7 - iter 99/333 - loss 0.45243234 - samples/sec: 85.85 - lr: 0.200667\n",
      "2022-08-30 18:44:30,723 epoch 7 - iter 132/333 - loss 0.45184271 - samples/sec: 88.05 - lr: 0.200667\n",
      "2022-08-30 18:44:34,802 epoch 7 - iter 165/333 - loss 0.45256780 - samples/sec: 82.11 - lr: 0.200667\n",
      "2022-08-30 18:44:39,123 epoch 7 - iter 198/333 - loss 0.45510922 - samples/sec: 77.61 - lr: 0.200667\n",
      "2022-08-30 18:44:42,891 epoch 7 - iter 231/333 - loss 0.45603241 - samples/sec: 88.92 - lr: 0.200667\n",
      "2022-08-30 18:44:47,127 epoch 7 - iter 264/333 - loss 0.45486567 - samples/sec: 78.99 - lr: 0.200667\n",
      "2022-08-30 18:44:50,961 epoch 7 - iter 297/333 - loss 0.45731983 - samples/sec: 87.39 - lr: 0.200667\n",
      "2022-08-30 18:44:54,884 epoch 7 - iter 330/333 - loss 0.45763900 - samples/sec: 85.54 - lr: 0.200667\n",
      "2022-08-30 18:44:55,216 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:44:55,216 EPOCH 7 done: loss 0.4577 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:44:56,211 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:44:56,238 DEV : loss 0.29880499839782715 - f1-score (micro avg)  0.8977\n",
      "2022-08-30 18:44:56,255 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:44:56,256 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:45:00,046 epoch 8 - iter 33/333 - loss 0.45297437 - samples/sec: 87.12 - lr: 0.200667\n",
      "2022-08-30 18:45:04,091 epoch 8 - iter 66/333 - loss 0.45756830 - samples/sec: 82.81 - lr: 0.200667\n",
      "2022-08-30 18:45:08,045 epoch 8 - iter 99/333 - loss 0.45792695 - samples/sec: 84.66 - lr: 0.200667\n",
      "2022-08-30 18:45:12,252 epoch 8 - iter 132/333 - loss 0.45611148 - samples/sec: 79.59 - lr: 0.200667\n",
      "2022-08-30 18:45:16,228 epoch 8 - iter 165/333 - loss 0.45529356 - samples/sec: 84.25 - lr: 0.200667\n",
      "2022-08-30 18:45:19,927 epoch 8 - iter 198/333 - loss 0.45240071 - samples/sec: 90.71 - lr: 0.200667\n",
      "2022-08-30 18:45:23,670 epoch 8 - iter 231/333 - loss 0.45420859 - samples/sec: 89.65 - lr: 0.200667\n",
      "2022-08-30 18:45:27,775 epoch 8 - iter 264/333 - loss 0.45598753 - samples/sec: 81.78 - lr: 0.200667\n",
      "2022-08-30 18:45:32,030 epoch 8 - iter 297/333 - loss 0.45609502 - samples/sec: 78.59 - lr: 0.200667\n",
      "2022-08-30 18:45:36,098 epoch 8 - iter 330/333 - loss 0.45357117 - samples/sec: 82.48 - lr: 0.200667\n",
      "2022-08-30 18:45:36,455 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:45:36,456 EPOCH 8 done: loss 0.4529 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:45:37,445 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:45:37,475 DEV : loss 0.29311710596084595 - f1-score (micro avg)  0.9027\n",
      "2022-08-30 18:45:37,492 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:45:37,493 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:45:38,194 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:45:41,756 epoch 9 - iter 33/333 - loss 0.43070654 - samples/sec: 92.72 - lr: 0.200667\n",
      "2022-08-30 18:45:45,748 epoch 9 - iter 66/333 - loss 0.44256135 - samples/sec: 83.88 - lr: 0.200667\n",
      "2022-08-30 18:45:50,072 epoch 9 - iter 99/333 - loss 0.45345182 - samples/sec: 77.39 - lr: 0.200667\n",
      "2022-08-30 18:45:54,628 epoch 9 - iter 132/333 - loss 0.45611459 - samples/sec: 73.38 - lr: 0.200667\n",
      "2022-08-30 18:45:58,498 epoch 9 - iter 165/333 - loss 0.45960316 - samples/sec: 86.68 - lr: 0.200667\n",
      "2022-08-30 18:46:02,334 epoch 9 - iter 198/333 - loss 0.45715404 - samples/sec: 87.63 - lr: 0.200667\n",
      "2022-08-30 18:46:06,326 epoch 9 - iter 231/333 - loss 0.45757799 - samples/sec: 84.18 - lr: 0.200667\n",
      "2022-08-30 18:46:10,027 epoch 9 - iter 264/333 - loss 0.45453548 - samples/sec: 90.78 - lr: 0.200667\n",
      "2022-08-30 18:46:14,162 epoch 9 - iter 297/333 - loss 0.45478160 - samples/sec: 81.04 - lr: 0.200667\n",
      "2022-08-30 18:46:18,225 epoch 9 - iter 330/333 - loss 0.45499819 - samples/sec: 82.50 - lr: 0.200667\n",
      "2022-08-30 18:46:18,624 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:46:18,624 EPOCH 9 done: loss 0.4552 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:46:19,635 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:46:19,664 DEV : loss 0.2948198616504669 - f1-score (micro avg)  0.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:46:19,681 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:46:19,682 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:46:23,523 epoch 10 - iter 33/333 - loss 0.44693478 - samples/sec: 85.96 - lr: 0.200667\n",
      "2022-08-30 18:46:27,339 epoch 10 - iter 66/333 - loss 0.45093784 - samples/sec: 87.88 - lr: 0.200667\n",
      "2022-08-30 18:46:31,360 epoch 10 - iter 99/333 - loss 0.45474786 - samples/sec: 83.54 - lr: 0.200667\n",
      "2022-08-30 18:46:35,692 epoch 10 - iter 132/333 - loss 0.45337533 - samples/sec: 77.48 - lr: 0.200667\n",
      "2022-08-30 18:46:40,191 epoch 10 - iter 165/333 - loss 0.45569395 - samples/sec: 74.26 - lr: 0.200667\n",
      "2022-08-30 18:46:44,207 epoch 10 - iter 198/333 - loss 0.45310833 - samples/sec: 83.61 - lr: 0.200667\n",
      "2022-08-30 18:46:47,963 epoch 10 - iter 231/333 - loss 0.45402480 - samples/sec: 89.43 - lr: 0.200667\n",
      "2022-08-30 18:46:52,070 epoch 10 - iter 264/333 - loss 0.45376882 - samples/sec: 81.62 - lr: 0.200667\n",
      "2022-08-30 18:46:55,718 epoch 10 - iter 297/333 - loss 0.45395894 - samples/sec: 92.20 - lr: 0.200667\n",
      "2022-08-30 18:46:59,770 epoch 10 - iter 330/333 - loss 0.45361833 - samples/sec: 82.60 - lr: 0.200667\n",
      "2022-08-30 18:47:00,160 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:47:00,161 EPOCH 10 done: loss 0.4538 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:47:01,143 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:47:01,175 DEV : loss 0.28007134795188904 - f1-score (micro avg)  0.9025\n",
      "2022-08-30 18:47:01,193 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:47:01,194 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:47:05,115 epoch 11 - iter 33/333 - loss 0.44609253 - samples/sec: 84.25 - lr: 0.200667\n",
      "2022-08-30 18:47:08,937 epoch 11 - iter 66/333 - loss 0.45852729 - samples/sec: 87.70 - lr: 0.200667\n",
      "2022-08-30 18:47:12,659 epoch 11 - iter 99/333 - loss 0.45381307 - samples/sec: 90.39 - lr: 0.200667\n",
      "2022-08-30 18:47:16,711 epoch 11 - iter 132/333 - loss 0.44981096 - samples/sec: 82.56 - lr: 0.200667\n",
      "2022-08-30 18:47:20,719 epoch 11 - iter 165/333 - loss 0.45107987 - samples/sec: 83.63 - lr: 0.200667\n",
      "2022-08-30 18:47:24,737 epoch 11 - iter 198/333 - loss 0.44860229 - samples/sec: 83.48 - lr: 0.200667\n",
      "2022-08-30 18:47:28,824 epoch 11 - iter 231/333 - loss 0.45060869 - samples/sec: 81.93 - lr: 0.200667\n",
      "2022-08-30 18:47:33,447 epoch 11 - iter 264/333 - loss 0.44901791 - samples/sec: 72.34 - lr: 0.200667\n",
      "2022-08-30 18:47:37,182 epoch 11 - iter 297/333 - loss 0.44940766 - samples/sec: 89.80 - lr: 0.200667\n",
      "2022-08-30 18:47:40,846 epoch 11 - iter 330/333 - loss 0.44802237 - samples/sec: 91.56 - lr: 0.200667\n",
      "2022-08-30 18:47:41,216 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:47:41,217 EPOCH 11 done: loss 0.4478 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:47:42,234 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:47:42,269 DEV : loss 0.3070683181285858 - f1-score (micro avg)  0.8985\n",
      "2022-08-30 18:47:42,290 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 18:47:42,291 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:47:46,312 epoch 12 - iter 33/333 - loss 0.44048647 - samples/sec: 82.15 - lr: 0.200667\n",
      "2022-08-30 18:47:50,152 epoch 12 - iter 66/333 - loss 0.43592466 - samples/sec: 87.53 - lr: 0.200667\n",
      "2022-08-30 18:47:54,296 epoch 12 - iter 99/333 - loss 0.44312178 - samples/sec: 80.80 - lr: 0.200667\n",
      "2022-08-30 18:47:58,264 epoch 12 - iter 132/333 - loss 0.44293016 - samples/sec: 84.49 - lr: 0.200667\n",
      "2022-08-30 18:48:02,613 epoch 12 - iter 165/333 - loss 0.44358416 - samples/sec: 76.96 - lr: 0.200667\n",
      "2022-08-30 18:48:06,188 epoch 12 - iter 198/333 - loss 0.44598261 - samples/sec: 93.83 - lr: 0.200667\n",
      "2022-08-30 18:48:10,126 epoch 12 - iter 231/333 - loss 0.44543293 - samples/sec: 85.01 - lr: 0.200667\n",
      "2022-08-30 18:48:14,494 epoch 12 - iter 264/333 - loss 0.44773167 - samples/sec: 76.62 - lr: 0.200667\n",
      "2022-08-30 18:48:18,194 epoch 12 - iter 297/333 - loss 0.44744480 - samples/sec: 90.76 - lr: 0.200667\n",
      "2022-08-30 18:48:22,222 epoch 12 - iter 330/333 - loss 0.44725884 - samples/sec: 83.17 - lr: 0.200667\n",
      "2022-08-30 18:48:22,595 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:48:22,596 EPOCH 12 done: loss 0.4467 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:48:23,558 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:48:23,586 DEV : loss 0.28313884139060974 - f1-score (micro avg)  0.9017\n",
      "2022-08-30 18:48:23,604 Epoch    12: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 18:48:23,605 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 18:48:24,625 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:48:24,626 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 18:48:24,811 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 16.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:48:26,358 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:48:26,387 0.9071\t0.9071\t0.9071\t0.9071\n",
      "2022-08-30 18:48:26,388 \n",
      "Results:\n",
      "- F-score (micro) 0.9071\n",
      "- F-score (macro) 0.7882\n",
      "- Accuracy 0.9071\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8669    0.9143    0.8899      1353\n",
      "         ADJ     0.8389    0.8988    0.8678       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9748    0.9786    0.9767       514\n",
      "        VERB     0.8581    0.9020    0.8795       449\n",
      "       PROPN     0.8472    0.6658    0.7456       383\n",
      "         AUX     0.9879    0.9731    0.9805       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8929    0.7764    0.8306       161\n",
      "         ADV     0.7956    0.7219    0.7569       151\n",
      "        PRON     1.0000    0.9304    0.9640       115\n",
      "         NUM     0.9811    0.7324    0.8387        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9071      5264\n",
      "   macro avg     0.8139    0.7686    0.7882      5264\n",
      "weighted avg     0.9080    0.9071    0.9059      5264\n",
      "\n",
      "2022-08-30 18:48:26,389 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:48:26,390 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:48:26,869 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 3 #######################\n",
      "#######################################################\n",
      "2022-08-30 18:50:43,543 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:50:43,543 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 18:50:43,544 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:50:43,545 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 18:50:43,545 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:50:43,546 Parameters:\n",
      "2022-08-30 18:50:43,546  - learning_rate: \"0.200667\"\n",
      "2022-08-30 18:50:43,547  - mini_batch_size: \"30\"\n",
      "2022-08-30 18:50:43,547  - patience: \"3\"\n",
      "2022-08-30 18:50:43,548  - anneal_factor: \"0.5\"\n",
      "2022-08-30 18:50:43,549  - max_epochs: \"10\"\n",
      "2022-08-30 18:50:43,549  - shuffle: \"True\"\n",
      "2022-08-30 18:50:43,549  - train_with_dev: \"False\"\n",
      "2022-08-30 18:50:43,550  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 18:50:43,550 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:50:43,551 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 18:50:43,552 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:50:43,552 Device: cpu\n",
      "2022-08-30 18:50:43,553 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:50:43,553 Embeddings storage mode: cpu\n",
      "2022-08-30 18:50:43,554 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:50:47,468 epoch 1 - iter 11/111 - loss 0.40997675 - samples/sec: 84.31 - lr: 0.200667\n",
      "2022-08-30 18:50:51,606 epoch 1 - iter 22/111 - loss 0.42201687 - samples/sec: 80.90 - lr: 0.200667\n",
      "2022-08-30 18:50:55,193 epoch 1 - iter 33/111 - loss 0.41534758 - samples/sec: 93.48 - lr: 0.200667\n",
      "2022-08-30 18:50:58,955 epoch 1 - iter 44/111 - loss 0.41290223 - samples/sec: 89.17 - lr: 0.200667\n",
      "2022-08-30 18:51:03,268 epoch 1 - iter 55/111 - loss 0.41958204 - samples/sec: 77.59 - lr: 0.200667\n",
      "2022-08-30 18:51:07,021 epoch 1 - iter 66/111 - loss 0.41858565 - samples/sec: 89.41 - lr: 0.200667\n",
      "2022-08-30 18:51:11,113 epoch 1 - iter 77/111 - loss 0.42093606 - samples/sec: 81.89 - lr: 0.200667\n",
      "2022-08-30 18:51:14,837 epoch 1 - iter 88/111 - loss 0.42013768 - samples/sec: 90.09 - lr: 0.200667\n",
      "2022-08-30 18:51:18,843 epoch 1 - iter 99/111 - loss 0.42253397 - samples/sec: 83.67 - lr: 0.200667\n",
      "2022-08-30 18:51:23,220 epoch 1 - iter 110/111 - loss 0.43603031 - samples/sec: 76.40 - lr: 0.200667\n",
      "2022-08-30 18:51:23,723 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:51:23,723 EPOCH 1 done: loss 0.4365 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:51:24,624 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:51:24,659 DEV : loss 0.31190866231918335 - f1-score (micro avg)  0.8918\n",
      "2022-08-30 18:51:24,675 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:51:24,676 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:51:25,377 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:51:29,235 epoch 2 - iter 11/111 - loss 0.44076105 - samples/sec: 85.56 - lr: 0.200667\n",
      "2022-08-30 18:51:33,100 epoch 2 - iter 22/111 - loss 0.42712481 - samples/sec: 86.73 - lr: 0.200667\n",
      "2022-08-30 18:51:37,025 epoch 2 - iter 33/111 - loss 0.42458645 - samples/sec: 85.63 - lr: 0.200667\n",
      "2022-08-30 18:51:40,998 epoch 2 - iter 44/111 - loss 0.42768434 - samples/sec: 84.38 - lr: 0.200667\n",
      "2022-08-30 18:51:44,904 epoch 2 - iter 55/111 - loss 0.42735444 - samples/sec: 85.85 - lr: 0.200667\n",
      "2022-08-30 18:51:49,110 epoch 2 - iter 66/111 - loss 0.42539957 - samples/sec: 79.56 - lr: 0.200667\n",
      "2022-08-30 18:51:53,297 epoch 2 - iter 77/111 - loss 0.42875667 - samples/sec: 79.88 - lr: 0.200667\n",
      "2022-08-30 18:51:57,483 epoch 2 - iter 88/111 - loss 0.42891520 - samples/sec: 80.14 - lr: 0.200667\n",
      "2022-08-30 18:52:01,851 epoch 2 - iter 99/111 - loss 0.42940940 - samples/sec: 76.55 - lr: 0.200667\n",
      "2022-08-30 18:52:06,065 epoch 2 - iter 110/111 - loss 0.42781550 - samples/sec: 79.44 - lr: 0.200667\n",
      "2022-08-30 18:52:06,507 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:52:06,507 EPOCH 2 done: loss 0.4275 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:52:07,379 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:52:07,416 DEV : loss 0.2746453583240509 - f1-score (micro avg)  0.9107\n",
      "2022-08-30 18:52:07,432 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:52:07,433 saving best model\n",
      "2022-08-30 18:52:08,404 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:52:12,292 epoch 3 - iter 11/111 - loss 0.39904932 - samples/sec: 84.92 - lr: 0.200667\n",
      "2022-08-30 18:52:16,441 epoch 3 - iter 22/111 - loss 0.40301396 - samples/sec: 80.66 - lr: 0.200667\n",
      "2022-08-30 18:52:20,809 epoch 3 - iter 33/111 - loss 0.40848788 - samples/sec: 77.17 - lr: 0.200667\n",
      "2022-08-30 18:52:25,210 epoch 3 - iter 44/111 - loss 0.40430145 - samples/sec: 76.16 - lr: 0.200667\n",
      "2022-08-30 18:52:29,680 epoch 3 - iter 55/111 - loss 0.40832918 - samples/sec: 74.88 - lr: 0.200667\n",
      "2022-08-30 18:52:33,832 epoch 3 - iter 66/111 - loss 0.40849839 - samples/sec: 80.76 - lr: 0.200667\n",
      "2022-08-30 18:52:38,362 epoch 3 - iter 77/111 - loss 0.41028048 - samples/sec: 73.83 - lr: 0.200667\n",
      "2022-08-30 18:52:42,709 epoch 3 - iter 88/111 - loss 0.41260500 - samples/sec: 77.21 - lr: 0.200667\n",
      "2022-08-30 18:52:46,717 epoch 3 - iter 99/111 - loss 0.41142631 - samples/sec: 83.65 - lr: 0.200667\n",
      "2022-08-30 18:52:50,907 epoch 3 - iter 110/111 - loss 0.41436823 - samples/sec: 80.00 - lr: 0.200667\n",
      "2022-08-30 18:52:51,291 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:52:51,291 EPOCH 3 done: loss 0.4144 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:52:52,229 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:52:52,262 DEV : loss 0.27141013741493225 - f1-score (micro avg)  0.9084\n",
      "2022-08-30 18:52:52,279 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 18:52:52,280 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:52:56,202 epoch 4 - iter 11/111 - loss 0.42827184 - samples/sec: 84.18 - lr: 0.200667\n",
      "2022-08-30 18:53:00,250 epoch 4 - iter 22/111 - loss 0.41432443 - samples/sec: 82.85 - lr: 0.200667\n",
      "2022-08-30 18:53:04,219 epoch 4 - iter 33/111 - loss 0.40987275 - samples/sec: 84.40 - lr: 0.200667\n",
      "2022-08-30 18:53:08,398 epoch 4 - iter 44/111 - loss 0.41320230 - samples/sec: 80.06 - lr: 0.200667\n",
      "2022-08-30 18:53:12,922 epoch 4 - iter 55/111 - loss 0.41444024 - samples/sec: 74.29 - lr: 0.200667\n",
      "2022-08-30 18:53:17,304 epoch 4 - iter 66/111 - loss 0.41672136 - samples/sec: 76.27 - lr: 0.200667\n",
      "2022-08-30 18:53:21,639 epoch 4 - iter 77/111 - loss 0.41807033 - samples/sec: 77.27 - lr: 0.200667\n",
      "2022-08-30 18:53:25,695 epoch 4 - iter 88/111 - loss 0.41826996 - samples/sec: 82.73 - lr: 0.200667\n",
      "2022-08-30 18:53:29,650 epoch 4 - iter 99/111 - loss 0.41835929 - samples/sec: 84.62 - lr: 0.200667\n",
      "2022-08-30 18:53:33,570 epoch 4 - iter 110/111 - loss 0.41783349 - samples/sec: 85.43 - lr: 0.200667\n",
      "2022-08-30 18:53:33,954 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:53:33,955 EPOCH 4 done: loss 0.4180 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:53:34,857 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:53:34,889 DEV : loss 0.2738994359970093 - f1-score (micro avg)  0.9058\n",
      "2022-08-30 18:53:34,908 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 18:53:34,909 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:53:38,822 epoch 5 - iter 11/111 - loss 0.42098559 - samples/sec: 84.40 - lr: 0.200667\n",
      "2022-08-30 18:53:43,016 epoch 5 - iter 22/111 - loss 0.40696883 - samples/sec: 79.77 - lr: 0.200667\n",
      "2022-08-30 18:53:47,025 epoch 5 - iter 33/111 - loss 0.40961375 - samples/sec: 83.52 - lr: 0.200667\n",
      "2022-08-30 18:53:51,300 epoch 5 - iter 44/111 - loss 0.40887361 - samples/sec: 78.29 - lr: 0.200667\n",
      "2022-08-30 18:53:55,327 epoch 5 - iter 55/111 - loss 0.41029189 - samples/sec: 83.33 - lr: 0.200667\n",
      "2022-08-30 18:53:59,215 epoch 5 - iter 66/111 - loss 0.41247046 - samples/sec: 86.59 - lr: 0.200667\n",
      "2022-08-30 18:54:03,276 epoch 5 - iter 77/111 - loss 0.41358316 - samples/sec: 82.48 - lr: 0.200667\n",
      "2022-08-30 18:54:07,303 epoch 5 - iter 88/111 - loss 0.41237708 - samples/sec: 83.08 - lr: 0.200667\n",
      "2022-08-30 18:54:11,313 epoch 5 - iter 99/111 - loss 0.41183383 - samples/sec: 83.69 - lr: 0.200667\n",
      "2022-08-30 18:54:15,447 epoch 5 - iter 110/111 - loss 0.41146806 - samples/sec: 81.04 - lr: 0.200667\n",
      "2022-08-30 18:54:15,843 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:54:15,844 EPOCH 5 done: loss 0.4116 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:54:16,718 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:54:16,749 DEV : loss 0.2751830816268921 - f1-score (micro avg)  0.9071\n",
      "2022-08-30 18:54:16,766 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 18:54:16,767 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:54:20,950 epoch 6 - iter 11/111 - loss 0.39274645 - samples/sec: 78.91 - lr: 0.200667\n",
      "2022-08-30 18:54:25,046 epoch 6 - iter 22/111 - loss 0.40008452 - samples/sec: 81.66 - lr: 0.200667\n",
      "2022-08-30 18:54:29,125 epoch 6 - iter 33/111 - loss 0.40156369 - samples/sec: 82.01 - lr: 0.200667\n",
      "2022-08-30 18:54:33,267 epoch 6 - iter 44/111 - loss 0.40501504 - samples/sec: 80.90 - lr: 0.200667\n",
      "2022-08-30 18:54:37,088 epoch 6 - iter 55/111 - loss 0.40489913 - samples/sec: 87.72 - lr: 0.200667\n",
      "2022-08-30 18:54:40,928 epoch 6 - iter 66/111 - loss 0.40519130 - samples/sec: 87.37 - lr: 0.200667\n",
      "2022-08-30 18:54:44,945 epoch 6 - iter 77/111 - loss 0.40338457 - samples/sec: 83.44 - lr: 0.200667\n",
      "2022-08-30 18:54:48,740 epoch 6 - iter 88/111 - loss 0.40442072 - samples/sec: 88.28 - lr: 0.200667\n",
      "2022-08-30 18:54:53,176 epoch 6 - iter 99/111 - loss 0.40492597 - samples/sec: 75.50 - lr: 0.200667\n",
      "2022-08-30 18:54:57,771 epoch 6 - iter 110/111 - loss 0.40739951 - samples/sec: 72.78 - lr: 0.200667\n",
      "2022-08-30 18:54:58,084 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:54:58,084 EPOCH 6 done: loss 0.4081 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:54:58,957 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:54:58,989 DEV : loss 0.2697398364543915 - f1-score (micro avg)  0.9081\n",
      "2022-08-30 18:54:59,010 Epoch     6: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 18:54:59,011 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 18:54:59,012 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:55:03,090 epoch 7 - iter 11/111 - loss 0.38541994 - samples/sec: 80.96 - lr: 0.100333\n",
      "2022-08-30 18:55:07,032 epoch 7 - iter 22/111 - loss 0.38332236 - samples/sec: 84.96 - lr: 0.100333\n",
      "2022-08-30 18:55:11,253 epoch 7 - iter 33/111 - loss 0.38040003 - samples/sec: 79.33 - lr: 0.100333\n",
      "2022-08-30 18:55:15,788 epoch 7 - iter 44/111 - loss 0.38271377 - samples/sec: 73.86 - lr: 0.100333\n",
      "2022-08-30 18:55:19,926 epoch 7 - iter 55/111 - loss 0.38425429 - samples/sec: 81.66 - lr: 0.100333\n",
      "2022-08-30 18:55:24,076 epoch 7 - iter 66/111 - loss 0.38599147 - samples/sec: 80.80 - lr: 0.100333\n",
      "2022-08-30 18:55:28,304 epoch 7 - iter 77/111 - loss 0.38677453 - samples/sec: 79.29 - lr: 0.100333\n",
      "2022-08-30 18:55:32,211 epoch 7 - iter 88/111 - loss 0.38820243 - samples/sec: 86.18 - lr: 0.100333\n",
      "2022-08-30 18:55:36,575 epoch 7 - iter 99/111 - loss 0.38806739 - samples/sec: 76.67 - lr: 0.100333\n",
      "2022-08-30 18:55:40,979 epoch 7 - iter 110/111 - loss 0.38735508 - samples/sec: 76.00 - lr: 0.100333\n",
      "2022-08-30 18:55:41,479 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:55:41,480 EPOCH 7 done: loss 0.3878 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:55:42,372 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:55:42,409 DEV : loss 0.2667105495929718 - f1-score (micro avg)  0.9092\n",
      "2022-08-30 18:55:42,432 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:55:42,433 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:55:46,333 epoch 8 - iter 11/111 - loss 0.39086705 - samples/sec: 84.68 - lr: 0.100333\n",
      "2022-08-30 18:55:51,116 epoch 8 - iter 22/111 - loss 0.37420846 - samples/sec: 70.08 - lr: 0.100333\n",
      "2022-08-30 18:55:55,721 epoch 8 - iter 33/111 - loss 0.38502651 - samples/sec: 72.71 - lr: 0.100333\n",
      "2022-08-30 18:56:00,165 epoch 8 - iter 44/111 - loss 0.39118575 - samples/sec: 75.45 - lr: 0.100333\n",
      "2022-08-30 18:56:04,596 epoch 8 - iter 55/111 - loss 0.39197126 - samples/sec: 75.64 - lr: 0.100333\n",
      "2022-08-30 18:56:09,022 epoch 8 - iter 66/111 - loss 0.39260591 - samples/sec: 75.84 - lr: 0.100333\n",
      "2022-08-30 18:56:13,400 epoch 8 - iter 77/111 - loss 0.39169122 - samples/sec: 76.60 - lr: 0.100333\n",
      "2022-08-30 18:56:17,756 epoch 8 - iter 88/111 - loss 0.38925907 - samples/sec: 76.99 - lr: 0.100333\n",
      "2022-08-30 18:56:22,607 epoch 8 - iter 99/111 - loss 0.39040382 - samples/sec: 68.91 - lr: 0.100333\n",
      "2022-08-30 18:56:26,975 epoch 8 - iter 110/111 - loss 0.38849629 - samples/sec: 76.73 - lr: 0.100333\n",
      "2022-08-30 18:56:27,330 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:56:27,331 EPOCH 8 done: loss 0.3886 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:56:28,286 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:56:28,319 DEV : loss 0.2643972635269165 - f1-score (micro avg)  0.9111\n",
      "2022-08-30 18:56:28,335 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:56:28,336 saving best model\n",
      "2022-08-30 18:56:29,304 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:56:33,699 epoch 9 - iter 11/111 - loss 0.37316609 - samples/sec: 75.10 - lr: 0.100333\n",
      "2022-08-30 18:56:38,061 epoch 9 - iter 22/111 - loss 0.37342339 - samples/sec: 77.10 - lr: 0.100333\n",
      "2022-08-30 18:56:42,441 epoch 9 - iter 33/111 - loss 0.38378724 - samples/sec: 76.55 - lr: 0.100333\n",
      "2022-08-30 18:56:46,755 epoch 9 - iter 44/111 - loss 0.38594495 - samples/sec: 78.09 - lr: 0.100333\n",
      "2022-08-30 18:56:51,095 epoch 9 - iter 55/111 - loss 0.38638925 - samples/sec: 77.16 - lr: 0.100333\n",
      "2022-08-30 18:56:55,632 epoch 9 - iter 66/111 - loss 0.38762286 - samples/sec: 73.86 - lr: 0.100333\n",
      "2022-08-30 18:57:00,315 epoch 9 - iter 77/111 - loss 0.38847894 - samples/sec: 71.50 - lr: 0.100333\n",
      "2022-08-30 18:57:04,469 epoch 9 - iter 88/111 - loss 0.38562675 - samples/sec: 80.98 - lr: 0.100333\n",
      "2022-08-30 18:57:09,073 epoch 9 - iter 99/111 - loss 0.38448937 - samples/sec: 72.80 - lr: 0.100333\n",
      "2022-08-30 18:57:14,015 epoch 9 - iter 110/111 - loss 0.38499627 - samples/sec: 67.85 - lr: 0.100333\n",
      "2022-08-30 18:57:14,505 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:57:14,505 EPOCH 9 done: loss 0.3850 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:57:15,440 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:57:15,470 DEV : loss 0.26437392830848694 - f1-score (micro avg)  0.9113\n",
      "2022-08-30 18:57:15,485 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 18:57:15,486 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:57:16,603 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:57:20,965 epoch 10 - iter 11/111 - loss 0.39125570 - samples/sec: 75.71 - lr: 0.100333\n",
      "2022-08-30 18:57:25,591 epoch 10 - iter 22/111 - loss 0.37259623 - samples/sec: 72.29 - lr: 0.100333\n",
      "2022-08-30 18:57:29,975 epoch 10 - iter 33/111 - loss 0.37488893 - samples/sec: 76.48 - lr: 0.100333\n",
      "2022-08-30 18:57:34,523 epoch 10 - iter 44/111 - loss 0.37107398 - samples/sec: 73.68 - lr: 0.100333\n",
      "2022-08-30 18:57:38,830 epoch 10 - iter 55/111 - loss 0.37235138 - samples/sec: 78.20 - lr: 0.100333\n",
      "2022-08-30 18:57:43,318 epoch 10 - iter 66/111 - loss 0.37241051 - samples/sec: 74.69 - lr: 0.100333\n",
      "2022-08-30 18:57:48,144 epoch 10 - iter 77/111 - loss 0.37742670 - samples/sec: 69.47 - lr: 0.100333\n",
      "2022-08-30 18:57:52,716 epoch 10 - iter 88/111 - loss 0.37819711 - samples/sec: 73.41 - lr: 0.100333\n",
      "2022-08-30 18:57:57,339 epoch 10 - iter 99/111 - loss 0.37932218 - samples/sec: 72.46 - lr: 0.100333\n",
      "2022-08-30 18:58:01,609 epoch 10 - iter 110/111 - loss 0.37759003 - samples/sec: 78.83 - lr: 0.100333\n",
      "2022-08-30 18:58:02,012 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:58:02,013 EPOCH 10 done: loss 0.3780 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:58:04,201 Evaluating as a multi-label problem: False\n",
      "2022-08-30 18:58:04,233 DEV : loss 0.26530709862709045 - f1-score (micro avg)  0.9103\n",
      "2022-08-30 18:58:04,253 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:58:04,972 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:58:04,973 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 18:58:05,148 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:58:06,565 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:58:06,589 0.9145\t0.9145\t0.9145\t0.9145\n",
      "2022-08-30 18:58:06,590 \n",
      "Results:\n",
      "- F-score (micro) 0.9145\n",
      "- F-score (macro) 0.7959\n",
      "- Accuracy 0.9145\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8793    0.9150    0.8968      1353\n",
      "         ADJ     0.8602    0.8884    0.8741       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9902    0.9825    0.9863       514\n",
      "        VERB     0.8848    0.9065    0.8955       449\n",
      "       PROPN     0.8253    0.7154    0.7664       383\n",
      "         AUX     0.9909    0.9761    0.9835       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.8636    0.8261    0.8444       161\n",
      "         ADV     0.7806    0.8013    0.7908       151\n",
      "        PRON     1.0000    0.9304    0.9640       115\n",
      "         NUM     0.9815    0.7465    0.8480        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9145      5264\n",
      "   macro avg     0.8150    0.7808    0.7959      5264\n",
      "weighted avg     0.9152    0.9145    0.9141      5264\n",
      "\n",
      "2022-08-30 18:58:06,590 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 18:58:06,592 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 18:58:07,092 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 19:00:47,686 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:00:47,687 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 19:00:47,688 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:00:47,689 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 19:00:47,690 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:00:47,690 Parameters:\n",
      "2022-08-30 19:00:47,691  - learning_rate: \"0.200667\"\n",
      "2022-08-30 19:00:47,692  - mini_batch_size: \"30\"\n",
      "2022-08-30 19:00:47,692  - patience: \"3\"\n",
      "2022-08-30 19:00:47,693  - anneal_factor: \"0.5\"\n",
      "2022-08-30 19:00:47,694  - max_epochs: \"11\"\n",
      "2022-08-30 19:00:47,695  - shuffle: \"True\"\n",
      "2022-08-30 19:00:47,695  - train_with_dev: \"False\"\n",
      "2022-08-30 19:00:47,696  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 19:00:47,697 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:00:47,698 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 19:00:47,698 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:00:47,699 Device: cpu\n",
      "2022-08-30 19:00:47,699 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:00:47,700 Embeddings storage mode: cpu\n",
      "2022-08-30 19:00:47,700 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:00:52,089 epoch 1 - iter 11/111 - loss 0.35496654 - samples/sec: 75.22 - lr: 0.200667\n",
      "2022-08-30 19:00:56,703 epoch 1 - iter 22/111 - loss 0.36951663 - samples/sec: 72.56 - lr: 0.200667\n",
      "2022-08-30 19:01:00,598 epoch 1 - iter 33/111 - loss 0.36953380 - samples/sec: 86.34 - lr: 0.200667\n",
      "2022-08-30 19:01:04,613 epoch 1 - iter 44/111 - loss 0.36790186 - samples/sec: 83.40 - lr: 0.200667\n",
      "2022-08-30 19:01:09,275 epoch 1 - iter 55/111 - loss 0.37323889 - samples/sec: 71.79 - lr: 0.200667\n",
      "2022-08-30 19:01:13,157 epoch 1 - iter 66/111 - loss 0.37306407 - samples/sec: 86.50 - lr: 0.200667\n",
      "2022-08-30 19:01:17,410 epoch 1 - iter 77/111 - loss 0.37419896 - samples/sec: 78.74 - lr: 0.200667\n",
      "2022-08-30 19:01:21,215 epoch 1 - iter 88/111 - loss 0.37704846 - samples/sec: 88.38 - lr: 0.200667\n",
      "2022-08-30 19:01:25,438 epoch 1 - iter 99/111 - loss 0.37962217 - samples/sec: 79.21 - lr: 0.200667\n",
      "2022-08-30 19:01:30,030 epoch 1 - iter 110/111 - loss 0.39271502 - samples/sec: 72.94 - lr: 0.200667\n",
      "2022-08-30 19:01:30,517 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:01:30,518 EPOCH 1 done: loss 0.3931 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:01:31,391 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:01:31,422 DEV : loss 0.29525017738342285 - f1-score (micro avg)  0.8975\n",
      "2022-08-30 19:01:31,443 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:01:31,445 saving best model\n",
      "2022-08-30 19:01:32,413 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:01:36,487 epoch 2 - iter 11/111 - loss 0.41155881 - samples/sec: 81.04 - lr: 0.200667\n",
      "2022-08-30 19:01:40,248 epoch 2 - iter 22/111 - loss 0.39978415 - samples/sec: 89.77 - lr: 0.200667\n",
      "2022-08-30 19:01:44,169 epoch 2 - iter 33/111 - loss 0.39213422 - samples/sec: 85.54 - lr: 0.200667\n",
      "2022-08-30 19:01:48,134 epoch 2 - iter 44/111 - loss 0.39281050 - samples/sec: 84.51 - lr: 0.200667\n",
      "2022-08-30 19:01:52,648 epoch 2 - iter 55/111 - loss 0.39062253 - samples/sec: 74.09 - lr: 0.200667\n",
      "2022-08-30 19:01:56,408 epoch 2 - iter 66/111 - loss 0.39507375 - samples/sec: 89.41 - lr: 0.200667\n",
      "2022-08-30 19:02:01,038 epoch 2 - iter 77/111 - loss 0.39263938 - samples/sec: 72.30 - lr: 0.200667\n",
      "2022-08-30 19:02:05,159 epoch 2 - iter 88/111 - loss 0.39469924 - samples/sec: 81.24 - lr: 0.200667\n",
      "2022-08-30 19:02:09,462 epoch 2 - iter 99/111 - loss 0.39848689 - samples/sec: 77.81 - lr: 0.200667\n",
      "2022-08-30 19:02:13,638 epoch 2 - iter 110/111 - loss 0.39787641 - samples/sec: 80.19 - lr: 0.200667\n",
      "2022-08-30 19:02:14,084 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:02:14,084 EPOCH 2 done: loss 0.3975 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:02:15,076 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:02:15,109 DEV : loss 0.2685544490814209 - f1-score (micro avg)  0.9081\n",
      "2022-08-30 19:02:15,125 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:02:15,126 saving best model\n",
      "2022-08-30 19:02:16,008 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:02:19,862 epoch 3 - iter 11/111 - loss 0.37966485 - samples/sec: 85.67 - lr: 0.200667\n",
      "2022-08-30 19:02:23,929 epoch 3 - iter 22/111 - loss 0.37699517 - samples/sec: 82.36 - lr: 0.200667\n",
      "2022-08-30 19:02:27,976 epoch 3 - iter 33/111 - loss 0.38357498 - samples/sec: 82.77 - lr: 0.200667\n",
      "2022-08-30 19:02:32,026 epoch 3 - iter 44/111 - loss 0.38670818 - samples/sec: 82.81 - lr: 0.200667\n",
      "2022-08-30 19:02:36,317 epoch 3 - iter 55/111 - loss 0.38691060 - samples/sec: 77.98 - lr: 0.200667\n",
      "2022-08-30 19:02:40,324 epoch 3 - iter 66/111 - loss 0.38851622 - samples/sec: 83.80 - lr: 0.200667\n",
      "2022-08-30 19:02:44,336 epoch 3 - iter 77/111 - loss 0.38795282 - samples/sec: 83.78 - lr: 0.200667\n",
      "2022-08-30 19:02:48,817 epoch 3 - iter 88/111 - loss 0.38966021 - samples/sec: 74.86 - lr: 0.200667\n",
      "2022-08-30 19:02:52,793 epoch 3 - iter 99/111 - loss 0.39272316 - samples/sec: 84.23 - lr: 0.200667\n",
      "2022-08-30 19:02:57,272 epoch 3 - iter 110/111 - loss 0.39453372 - samples/sec: 74.73 - lr: 0.200667\n",
      "2022-08-30 19:02:57,763 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:02:57,764 EPOCH 3 done: loss 0.3941 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:02:58,674 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:02:58,710 DEV : loss 0.2630036175251007 - f1-score (micro avg)  0.9102\n",
      "2022-08-30 19:02:58,731 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:02:58,732 saving best model\n",
      "2022-08-30 19:02:59,523 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:03:03,893 epoch 4 - iter 11/111 - loss 0.39375157 - samples/sec: 75.60 - lr: 0.200667\n",
      "2022-08-30 19:03:07,613 epoch 4 - iter 22/111 - loss 0.39272713 - samples/sec: 90.16 - lr: 0.200667\n",
      "2022-08-30 19:03:11,866 epoch 4 - iter 33/111 - loss 0.39394463 - samples/sec: 78.93 - lr: 0.200667\n",
      "2022-08-30 19:03:16,116 epoch 4 - iter 44/111 - loss 0.39050548 - samples/sec: 78.74 - lr: 0.200667\n",
      "2022-08-30 19:03:20,367 epoch 4 - iter 55/111 - loss 0.39005766 - samples/sec: 78.72 - lr: 0.200667\n",
      "2022-08-30 19:03:24,585 epoch 4 - iter 66/111 - loss 0.39237293 - samples/sec: 79.46 - lr: 0.200667\n",
      "2022-08-30 19:03:28,519 epoch 4 - iter 77/111 - loss 0.39353472 - samples/sec: 85.12 - lr: 0.200667\n",
      "2022-08-30 19:03:32,665 epoch 4 - iter 88/111 - loss 0.39301717 - samples/sec: 81.02 - lr: 0.200667\n",
      "2022-08-30 19:03:36,633 epoch 4 - iter 99/111 - loss 0.39343890 - samples/sec: 84.44 - lr: 0.200667\n",
      "2022-08-30 19:03:40,739 epoch 4 - iter 110/111 - loss 0.39409027 - samples/sec: 81.62 - lr: 0.200667\n",
      "2022-08-30 19:03:41,151 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:03:41,151 EPOCH 4 done: loss 0.3946 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:03:42,061 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:03:42,092 DEV : loss 0.26720330119132996 - f1-score (micro avg)  0.9043\n",
      "2022-08-30 19:03:42,108 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:03:42,109 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:03:46,272 epoch 5 - iter 11/111 - loss 0.41168922 - samples/sec: 79.31 - lr: 0.200667\n",
      "2022-08-30 19:03:50,512 epoch 5 - iter 22/111 - loss 0.41108197 - samples/sec: 78.95 - lr: 0.200667\n",
      "2022-08-30 19:03:54,410 epoch 5 - iter 33/111 - loss 0.40302536 - samples/sec: 85.98 - lr: 0.200667\n",
      "2022-08-30 19:03:58,565 epoch 5 - iter 44/111 - loss 0.39475466 - samples/sec: 80.86 - lr: 0.200667\n",
      "2022-08-30 19:04:02,364 epoch 5 - iter 55/111 - loss 0.39615368 - samples/sec: 88.31 - lr: 0.200667\n",
      "2022-08-30 19:04:06,469 epoch 5 - iter 66/111 - loss 0.39488496 - samples/sec: 81.72 - lr: 0.200667\n",
      "2022-08-30 19:04:10,241 epoch 5 - iter 77/111 - loss 0.39780305 - samples/sec: 89.65 - lr: 0.200667\n",
      "2022-08-30 19:04:14,629 epoch 5 - iter 88/111 - loss 0.39853865 - samples/sec: 76.25 - lr: 0.200667\n",
      "2022-08-30 19:04:19,190 epoch 5 - iter 99/111 - loss 0.39944081 - samples/sec: 73.53 - lr: 0.200667\n",
      "2022-08-30 19:04:23,638 epoch 5 - iter 110/111 - loss 0.39873675 - samples/sec: 75.29 - lr: 0.200667\n",
      "2022-08-30 19:04:24,044 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:04:24,045 EPOCH 5 done: loss 0.3985 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:04:24,926 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:04:24,961 DEV : loss 0.2749645709991455 - f1-score (micro avg)  0.9064\n",
      "2022-08-30 19:04:24,978 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:04:24,979 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:04:28,891 epoch 6 - iter 11/111 - loss 0.39082554 - samples/sec: 84.40 - lr: 0.200667\n",
      "2022-08-30 19:04:33,130 epoch 6 - iter 22/111 - loss 0.39001515 - samples/sec: 79.04 - lr: 0.200667\n",
      "2022-08-30 19:04:37,573 epoch 6 - iter 33/111 - loss 0.38754627 - samples/sec: 75.26 - lr: 0.200667\n",
      "2022-08-30 19:04:41,777 epoch 6 - iter 44/111 - loss 0.38581050 - samples/sec: 79.75 - lr: 0.200667\n",
      "2022-08-30 19:04:45,756 epoch 6 - iter 55/111 - loss 0.39046677 - samples/sec: 84.38 - lr: 0.200667\n",
      "2022-08-30 19:04:49,573 epoch 6 - iter 66/111 - loss 0.38942610 - samples/sec: 87.88 - lr: 0.200667\n",
      "2022-08-30 19:04:53,980 epoch 6 - iter 77/111 - loss 0.39064561 - samples/sec: 75.88 - lr: 0.200667\n",
      "2022-08-30 19:04:57,787 epoch 6 - iter 88/111 - loss 0.39092786 - samples/sec: 88.05 - lr: 0.200667\n",
      "2022-08-30 19:05:02,063 epoch 6 - iter 99/111 - loss 0.39319949 - samples/sec: 78.18 - lr: 0.200667\n",
      "2022-08-30 19:05:06,161 epoch 6 - iter 110/111 - loss 0.39485984 - samples/sec: 81.66 - lr: 0.200667\n",
      "2022-08-30 19:05:06,592 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:05:06,593 EPOCH 6 done: loss 0.3954 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:05:07,455 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:05:07,485 DEV : loss 0.2692013382911682 - f1-score (micro avg)  0.9071\n",
      "2022-08-30 19:05:07,503 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 19:05:07,504 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:05:11,542 epoch 7 - iter 11/111 - loss 0.39452954 - samples/sec: 81.74 - lr: 0.200667\n",
      "2022-08-30 19:05:15,480 epoch 7 - iter 22/111 - loss 0.38490623 - samples/sec: 85.23 - lr: 0.200667\n",
      "2022-08-30 19:05:19,787 epoch 7 - iter 33/111 - loss 0.39194732 - samples/sec: 77.78 - lr: 0.200667\n",
      "2022-08-30 19:05:23,752 epoch 7 - iter 44/111 - loss 0.39227920 - samples/sec: 84.79 - lr: 0.200667\n",
      "2022-08-30 19:05:27,944 epoch 7 - iter 55/111 - loss 0.39155276 - samples/sec: 79.77 - lr: 0.200667\n",
      "2022-08-30 19:05:31,623 epoch 7 - iter 66/111 - loss 0.39150681 - samples/sec: 91.36 - lr: 0.200667\n",
      "2022-08-30 19:05:36,052 epoch 7 - iter 77/111 - loss 0.39284067 - samples/sec: 75.48 - lr: 0.200667\n",
      "2022-08-30 19:05:39,985 epoch 7 - iter 88/111 - loss 0.39229854 - samples/sec: 85.25 - lr: 0.200667\n",
      "2022-08-30 19:05:44,468 epoch 7 - iter 99/111 - loss 0.39124362 - samples/sec: 74.56 - lr: 0.200667\n",
      "2022-08-30 19:05:48,529 epoch 7 - iter 110/111 - loss 0.38921616 - samples/sec: 82.56 - lr: 0.200667\n",
      "2022-08-30 19:05:48,943 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:05:48,943 EPOCH 7 done: loss 0.3896 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:05:49,802 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:05:49,833 DEV : loss 0.2580714225769043 - f1-score (micro avg)  0.9107\n",
      "2022-08-30 19:05:49,849 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:05:49,850 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:05:50,574 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:05:54,506 epoch 8 - iter 11/111 - loss 0.38216365 - samples/sec: 83.99 - lr: 0.200667\n",
      "2022-08-30 19:05:58,966 epoch 8 - iter 22/111 - loss 0.38687249 - samples/sec: 75.21 - lr: 0.200667\n",
      "2022-08-30 19:06:03,164 epoch 8 - iter 33/111 - loss 0.37947046 - samples/sec: 79.79 - lr: 0.200667\n",
      "2022-08-30 19:06:07,682 epoch 8 - iter 44/111 - loss 0.37816396 - samples/sec: 73.97 - lr: 0.200667\n",
      "2022-08-30 19:06:11,651 epoch 8 - iter 55/111 - loss 0.38189583 - samples/sec: 84.51 - lr: 0.200667\n",
      "2022-08-30 19:06:15,435 epoch 8 - iter 66/111 - loss 0.38313953 - samples/sec: 88.69 - lr: 0.200667\n",
      "2022-08-30 19:06:19,719 epoch 8 - iter 77/111 - loss 0.38194169 - samples/sec: 78.55 - lr: 0.200667\n",
      "2022-08-30 19:06:23,790 epoch 8 - iter 88/111 - loss 0.38396238 - samples/sec: 82.27 - lr: 0.200667\n",
      "2022-08-30 19:06:27,946 epoch 8 - iter 99/111 - loss 0.38632136 - samples/sec: 80.70 - lr: 0.200667\n",
      "2022-08-30 19:06:32,272 epoch 8 - iter 110/111 - loss 0.38741915 - samples/sec: 77.48 - lr: 0.200667\n",
      "2022-08-30 19:06:32,753 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:06:32,753 EPOCH 8 done: loss 0.3878 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:06:33,661 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:06:33,695 DEV : loss 0.2624897062778473 - f1-score (micro avg)  0.911\n",
      "2022-08-30 19:06:33,710 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:06:33,711 saving best model\n",
      "2022-08-30 19:06:34,411 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:06:38,903 epoch 9 - iter 11/111 - loss 0.40158391 - samples/sec: 73.48 - lr: 0.200667\n",
      "2022-08-30 19:06:43,399 epoch 9 - iter 22/111 - loss 0.40169090 - samples/sec: 74.32 - lr: 0.200667\n",
      "2022-08-30 19:06:47,900 epoch 9 - iter 33/111 - loss 0.40455948 - samples/sec: 74.75 - lr: 0.200667\n",
      "2022-08-30 19:06:52,062 epoch 9 - iter 44/111 - loss 0.39872937 - samples/sec: 80.41 - lr: 0.200667\n",
      "2022-08-30 19:06:55,976 epoch 9 - iter 55/111 - loss 0.39542067 - samples/sec: 85.83 - lr: 0.200667\n",
      "2022-08-30 19:07:00,046 epoch 9 - iter 66/111 - loss 0.39436996 - samples/sec: 82.46 - lr: 0.200667\n",
      "2022-08-30 19:07:04,209 epoch 9 - iter 77/111 - loss 0.39635575 - samples/sec: 80.35 - lr: 0.200667\n",
      "2022-08-30 19:07:08,136 epoch 9 - iter 88/111 - loss 0.39412301 - samples/sec: 85.25 - lr: 0.200667\n",
      "2022-08-30 19:07:12,444 epoch 9 - iter 99/111 - loss 0.39431138 - samples/sec: 77.78 - lr: 0.200667\n",
      "2022-08-30 19:07:16,601 epoch 9 - iter 110/111 - loss 0.39384081 - samples/sec: 80.47 - lr: 0.200667\n",
      "2022-08-30 19:07:16,964 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:07:16,965 EPOCH 9 done: loss 0.3942 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:07:17,876 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:07:17,910 DEV : loss 0.2632925510406494 - f1-score (micro avg)  0.9081\n",
      "2022-08-30 19:07:17,926 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:07:17,927 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:07:22,399 epoch 10 - iter 11/111 - loss 0.37897324 - samples/sec: 73.81 - lr: 0.200667\n",
      "2022-08-30 19:07:26,383 epoch 10 - iter 22/111 - loss 0.38486381 - samples/sec: 84.44 - lr: 0.200667\n",
      "2022-08-30 19:07:30,164 epoch 10 - iter 33/111 - loss 0.38072148 - samples/sec: 88.73 - lr: 0.200667\n",
      "2022-08-30 19:07:34,284 epoch 10 - iter 44/111 - loss 0.37608817 - samples/sec: 81.30 - lr: 0.200667\n",
      "2022-08-30 19:07:38,497 epoch 10 - iter 55/111 - loss 0.38101138 - samples/sec: 79.61 - lr: 0.200667\n",
      "2022-08-30 19:07:42,314 epoch 10 - iter 66/111 - loss 0.38069595 - samples/sec: 88.28 - lr: 0.200667\n",
      "2022-08-30 19:07:46,945 epoch 10 - iter 77/111 - loss 0.38052214 - samples/sec: 72.48 - lr: 0.200667\n",
      "2022-08-30 19:07:50,879 epoch 10 - iter 88/111 - loss 0.38153967 - samples/sec: 85.16 - lr: 0.200667\n",
      "2022-08-30 19:07:55,149 epoch 10 - iter 99/111 - loss 0.38335115 - samples/sec: 78.38 - lr: 0.200667\n",
      "2022-08-30 19:07:59,345 epoch 10 - iter 110/111 - loss 0.38474626 - samples/sec: 79.75 - lr: 0.200667\n",
      "2022-08-30 19:07:59,772 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:07:59,773 EPOCH 10 done: loss 0.3842 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:08:00,624 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:08:00,652 DEV : loss 0.2630670368671417 - f1-score (micro avg)  0.9111\n",
      "2022-08-30 19:08:00,668 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:08:00,669 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:08:01,371 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:08:05,203 epoch 11 - iter 11/111 - loss 0.38127234 - samples/sec: 86.21 - lr: 0.200667\n",
      "2022-08-30 19:08:09,281 epoch 11 - iter 22/111 - loss 0.37633523 - samples/sec: 82.17 - lr: 0.200667\n",
      "2022-08-30 19:08:13,401 epoch 11 - iter 33/111 - loss 0.37312135 - samples/sec: 81.18 - lr: 0.200667\n",
      "2022-08-30 19:08:17,672 epoch 11 - iter 44/111 - loss 0.37414077 - samples/sec: 78.61 - lr: 0.200667\n",
      "2022-08-30 19:08:21,559 epoch 11 - iter 55/111 - loss 0.37599997 - samples/sec: 86.39 - lr: 0.200667\n",
      "2022-08-30 19:08:26,049 epoch 11 - iter 66/111 - loss 0.37343900 - samples/sec: 74.66 - lr: 0.200667\n",
      "2022-08-30 19:08:30,133 epoch 11 - iter 77/111 - loss 0.37554618 - samples/sec: 82.09 - lr: 0.200667\n",
      "2022-08-30 19:08:34,210 epoch 11 - iter 88/111 - loss 0.37699860 - samples/sec: 82.07 - lr: 0.200667\n",
      "2022-08-30 19:08:38,748 epoch 11 - iter 99/111 - loss 0.37668765 - samples/sec: 73.64 - lr: 0.200667\n",
      "2022-08-30 19:08:42,665 epoch 11 - iter 110/111 - loss 0.37842922 - samples/sec: 85.49 - lr: 0.200667\n",
      "2022-08-30 19:08:43,002 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:08:43,003 EPOCH 11 done: loss 0.3780 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:08:43,897 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:08:43,924 DEV : loss 0.2511693835258484 - f1-score (micro avg)  0.9116\n",
      "2022-08-30 19:08:43,940 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:08:43,941 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:08:45,316 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:08:45,317 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 19:08:45,497 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:08:46,980 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:08:47,010 0.9117\t0.9117\t0.9117\t0.9117\n",
      "2022-08-30 19:08:47,011 \n",
      "Results:\n",
      "- F-score (micro) 0.9117\n",
      "- F-score (macro) 0.7916\n",
      "- Accuracy 0.9117\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8844    0.8995    0.8919      1353\n",
      "         ADJ     0.8769    0.8690    0.8729       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9883    0.9825    0.9854       514\n",
      "        VERB     0.8634    0.9154    0.8886       449\n",
      "       PROPN     0.7918    0.7546    0.7727       383\n",
      "         AUX     0.9909    0.9791    0.9850       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8024    0.8323    0.8171       161\n",
      "         ADV     0.8027    0.7815    0.7919       151\n",
      "        PRON     1.0000    0.9304    0.9640       115\n",
      "         NUM     0.9310    0.7606    0.8372        71\n",
      "        PART     0.9444    0.8095    0.8718        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9117      5264\n",
      "   macro avg     0.8035    0.7818    0.7916      5264\n",
      "weighted avg     0.9119    0.9117    0.9115      5264\n",
      "\n",
      "2022-08-30 19:08:47,012 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:08:47,014 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 19:08:47,520 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 19:11:07,201 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:11:07,202 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 19:11:07,203 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:11:07,203 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 19:11:07,204 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:11:07,205 Parameters:\n",
      "2022-08-30 19:11:07,206  - learning_rate: \"0.200667\"\n",
      "2022-08-30 19:11:07,206  - mini_batch_size: \"30\"\n",
      "2022-08-30 19:11:07,207  - patience: \"3\"\n",
      "2022-08-30 19:11:07,207  - anneal_factor: \"0.5\"\n",
      "2022-08-30 19:11:07,208  - max_epochs: \"12\"\n",
      "2022-08-30 19:11:07,209  - shuffle: \"True\"\n",
      "2022-08-30 19:11:07,209  - train_with_dev: \"False\"\n",
      "2022-08-30 19:11:07,210  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 19:11:07,210 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:11:07,211 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 19:11:07,211 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:11:07,212 Device: cpu\n",
      "2022-08-30 19:11:07,212 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:11:07,213 Embeddings storage mode: cpu\n",
      "2022-08-30 19:11:07,214 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:11:11,474 epoch 1 - iter 11/111 - loss 0.35306303 - samples/sec: 77.52 - lr: 0.200667\n",
      "2022-08-30 19:11:15,790 epoch 1 - iter 22/111 - loss 0.36657085 - samples/sec: 77.68 - lr: 0.200667\n",
      "2022-08-30 19:11:19,365 epoch 1 - iter 33/111 - loss 0.35853248 - samples/sec: 93.80 - lr: 0.200667\n",
      "2022-08-30 19:11:23,196 epoch 1 - iter 44/111 - loss 0.36162149 - samples/sec: 87.91 - lr: 0.200667\n",
      "2022-08-30 19:11:27,589 epoch 1 - iter 55/111 - loss 0.36520873 - samples/sec: 76.09 - lr: 0.200667\n",
      "2022-08-30 19:11:31,370 epoch 1 - iter 66/111 - loss 0.36373213 - samples/sec: 88.71 - lr: 0.200667\n",
      "2022-08-30 19:11:35,572 epoch 1 - iter 77/111 - loss 0.36620216 - samples/sec: 79.81 - lr: 0.200667\n",
      "2022-08-30 19:11:39,332 epoch 1 - iter 88/111 - loss 0.36633082 - samples/sec: 89.72 - lr: 0.200667\n",
      "2022-08-30 19:11:43,329 epoch 1 - iter 99/111 - loss 0.36709885 - samples/sec: 84.12 - lr: 0.200667\n",
      "2022-08-30 19:11:47,861 epoch 1 - iter 110/111 - loss 0.38145899 - samples/sec: 74.11 - lr: 0.200667\n",
      "2022-08-30 19:11:48,314 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:11:48,314 EPOCH 1 done: loss 0.3823 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:11:49,258 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:11:49,285 DEV : loss 0.2742147743701935 - f1-score (micro avg)  0.9074\n",
      "2022-08-30 19:11:49,300 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:11:49,302 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:11:50,026 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:11:54,537 epoch 2 - iter 11/111 - loss 0.39968219 - samples/sec: 73.20 - lr: 0.200667\n",
      "2022-08-30 19:11:58,888 epoch 2 - iter 22/111 - loss 0.38391363 - samples/sec: 77.19 - lr: 0.200667\n",
      "2022-08-30 19:12:02,959 epoch 2 - iter 33/111 - loss 0.37775403 - samples/sec: 82.25 - lr: 0.200667\n",
      "2022-08-30 19:12:06,823 epoch 2 - iter 44/111 - loss 0.37831535 - samples/sec: 86.77 - lr: 0.200667\n",
      "2022-08-30 19:12:11,371 epoch 2 - iter 55/111 - loss 0.37983222 - samples/sec: 73.45 - lr: 0.200667\n",
      "2022-08-30 19:12:15,506 epoch 2 - iter 66/111 - loss 0.38056501 - samples/sec: 81.24 - lr: 0.200667\n",
      "2022-08-30 19:12:19,690 epoch 2 - iter 77/111 - loss 0.38039831 - samples/sec: 80.21 - lr: 0.200667\n",
      "2022-08-30 19:12:23,869 epoch 2 - iter 88/111 - loss 0.37811760 - samples/sec: 80.12 - lr: 0.200667\n",
      "2022-08-30 19:12:28,056 epoch 2 - iter 99/111 - loss 0.38044044 - samples/sec: 80.02 - lr: 0.200667\n",
      "2022-08-30 19:12:31,785 epoch 2 - iter 110/111 - loss 0.37987324 - samples/sec: 89.82 - lr: 0.200667\n",
      "2022-08-30 19:12:32,145 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:12:32,146 EPOCH 2 done: loss 0.3803 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:12:33,059 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:12:33,092 DEV : loss 0.2560090720653534 - f1-score (micro avg)  0.9124\n",
      "2022-08-30 19:12:33,108 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:12:33,109 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:12:33,883 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:12:38,014 epoch 3 - iter 11/111 - loss 0.37219997 - samples/sec: 79.90 - lr: 0.200667\n",
      "2022-08-30 19:12:42,286 epoch 3 - iter 22/111 - loss 0.36539071 - samples/sec: 78.52 - lr: 0.200667\n",
      "2022-08-30 19:12:46,844 epoch 3 - iter 33/111 - loss 0.36941442 - samples/sec: 73.33 - lr: 0.200667\n",
      "2022-08-30 19:12:51,157 epoch 3 - iter 44/111 - loss 0.36947419 - samples/sec: 77.81 - lr: 0.200667\n",
      "2022-08-30 19:12:55,269 epoch 3 - iter 55/111 - loss 0.37106090 - samples/sec: 81.62 - lr: 0.200667\n",
      "2022-08-30 19:12:59,476 epoch 3 - iter 66/111 - loss 0.37062020 - samples/sec: 79.63 - lr: 0.200667\n",
      "2022-08-30 19:13:03,964 epoch 3 - iter 77/111 - loss 0.37104360 - samples/sec: 74.75 - lr: 0.200667\n",
      "2022-08-30 19:13:08,641 epoch 3 - iter 88/111 - loss 0.37453095 - samples/sec: 71.79 - lr: 0.200667\n",
      "2022-08-30 19:13:13,222 epoch 3 - iter 99/111 - loss 0.37425952 - samples/sec: 73.02 - lr: 0.200667\n",
      "2022-08-30 19:13:17,633 epoch 3 - iter 110/111 - loss 0.37738379 - samples/sec: 75.83 - lr: 0.200667\n",
      "2022-08-30 19:13:18,055 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:13:18,056 EPOCH 3 done: loss 0.3772 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:13:18,947 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:13:18,983 DEV : loss 0.2570388913154602 - f1-score (micro avg)  0.9121\n",
      "2022-08-30 19:13:19,000 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:13:19,001 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:13:23,036 epoch 4 - iter 11/111 - loss 0.36725486 - samples/sec: 81.80 - lr: 0.200667\n",
      "2022-08-30 19:13:27,230 epoch 4 - iter 22/111 - loss 0.36929402 - samples/sec: 79.85 - lr: 0.200667\n",
      "2022-08-30 19:13:31,542 epoch 4 - iter 33/111 - loss 0.37805946 - samples/sec: 77.70 - lr: 0.200667\n",
      "2022-08-30 19:13:35,988 epoch 4 - iter 44/111 - loss 0.37507000 - samples/sec: 75.34 - lr: 0.200667\n",
      "2022-08-30 19:13:40,208 epoch 4 - iter 55/111 - loss 0.37270441 - samples/sec: 79.44 - lr: 0.200667\n",
      "2022-08-30 19:13:44,462 epoch 4 - iter 66/111 - loss 0.37596124 - samples/sec: 78.80 - lr: 0.200667\n",
      "2022-08-30 19:13:48,728 epoch 4 - iter 77/111 - loss 0.37655615 - samples/sec: 78.55 - lr: 0.200667\n",
      "2022-08-30 19:13:53,006 epoch 4 - iter 88/111 - loss 0.37968209 - samples/sec: 78.31 - lr: 0.200667\n",
      "2022-08-30 19:13:57,051 epoch 4 - iter 99/111 - loss 0.38004033 - samples/sec: 82.83 - lr: 0.200667\n",
      "2022-08-30 19:14:01,824 epoch 4 - iter 110/111 - loss 0.38131288 - samples/sec: 70.00 - lr: 0.200667\n",
      "2022-08-30 19:14:02,336 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:14:02,336 EPOCH 4 done: loss 0.3806 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:14:03,374 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:14:03,414 DEV : loss 0.2549718916416168 - f1-score (micro avg)  0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:14:03,435 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 19:14:03,437 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:14:07,864 epoch 5 - iter 11/111 - loss 0.36070746 - samples/sec: 74.60 - lr: 0.200667\n",
      "2022-08-30 19:14:12,599 epoch 5 - iter 22/111 - loss 0.37502400 - samples/sec: 70.65 - lr: 0.200667\n",
      "2022-08-30 19:14:17,134 epoch 5 - iter 33/111 - loss 0.37248689 - samples/sec: 73.88 - lr: 0.200667\n",
      "2022-08-30 19:14:21,567 epoch 5 - iter 44/111 - loss 0.37091939 - samples/sec: 75.57 - lr: 0.200667\n",
      "2022-08-30 19:14:26,059 epoch 5 - iter 55/111 - loss 0.37277717 - samples/sec: 74.68 - lr: 0.200667\n",
      "2022-08-30 19:14:31,144 epoch 5 - iter 66/111 - loss 0.37185464 - samples/sec: 65.76 - lr: 0.200667\n",
      "2022-08-30 19:14:35,858 epoch 5 - iter 77/111 - loss 0.37247617 - samples/sec: 71.00 - lr: 0.200667\n",
      "2022-08-30 19:14:40,078 epoch 5 - iter 88/111 - loss 0.37606335 - samples/sec: 79.54 - lr: 0.200667\n",
      "2022-08-30 19:14:44,729 epoch 5 - iter 99/111 - loss 0.37505751 - samples/sec: 71.97 - lr: 0.200667\n",
      "2022-08-30 19:14:49,312 epoch 5 - iter 110/111 - loss 0.37517547 - samples/sec: 73.05 - lr: 0.200667\n",
      "2022-08-30 19:14:49,720 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:14:49,721 EPOCH 5 done: loss 0.3752 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:14:52,015 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:14:52,051 DEV : loss 0.25516608357429504 - f1-score (micro avg)  0.9139\n",
      "2022-08-30 19:14:52,068 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:14:52,070 saving best model\n",
      "2022-08-30 19:14:52,805 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:14:57,129 epoch 6 - iter 11/111 - loss 0.37127085 - samples/sec: 76.39 - lr: 0.200667\n",
      "2022-08-30 19:15:01,660 epoch 6 - iter 22/111 - loss 0.37578176 - samples/sec: 73.99 - lr: 0.200667\n",
      "2022-08-30 19:15:06,005 epoch 6 - iter 33/111 - loss 0.37457107 - samples/sec: 77.10 - lr: 0.200667\n",
      "2022-08-30 19:15:10,643 epoch 6 - iter 44/111 - loss 0.37254741 - samples/sec: 72.23 - lr: 0.200667\n",
      "2022-08-30 19:15:15,489 epoch 6 - iter 55/111 - loss 0.37129477 - samples/sec: 69.02 - lr: 0.200667\n",
      "2022-08-30 19:15:21,148 epoch 6 - iter 66/111 - loss 0.37230596 - samples/sec: 59.59 - lr: 0.200667\n",
      "2022-08-30 19:15:25,531 epoch 6 - iter 77/111 - loss 0.37207118 - samples/sec: 76.55 - lr: 0.200667\n",
      "2022-08-30 19:15:29,679 epoch 6 - iter 88/111 - loss 0.37289764 - samples/sec: 81.22 - lr: 0.200667\n",
      "2022-08-30 19:15:34,031 epoch 6 - iter 99/111 - loss 0.37463367 - samples/sec: 77.01 - lr: 0.200667\n",
      "2022-08-30 19:15:38,449 epoch 6 - iter 110/111 - loss 0.37542024 - samples/sec: 75.74 - lr: 0.200667\n",
      "2022-08-30 19:15:38,862 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:15:38,863 EPOCH 6 done: loss 0.3752 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:15:39,719 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:15:39,750 DEV : loss 0.26115477085113525 - f1-score (micro avg)  0.9108\n",
      "2022-08-30 19:15:39,767 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:15:39,768 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:15:43,919 epoch 7 - iter 11/111 - loss 0.35713538 - samples/sec: 79.52 - lr: 0.200667\n",
      "2022-08-30 19:15:47,911 epoch 7 - iter 22/111 - loss 0.35862443 - samples/sec: 83.91 - lr: 0.200667\n",
      "2022-08-30 19:15:52,417 epoch 7 - iter 33/111 - loss 0.36370154 - samples/sec: 74.24 - lr: 0.200667\n",
      "2022-08-30 19:15:56,417 epoch 7 - iter 44/111 - loss 0.36750031 - samples/sec: 83.86 - lr: 0.200667\n",
      "2022-08-30 19:16:00,741 epoch 7 - iter 55/111 - loss 0.36785036 - samples/sec: 77.70 - lr: 0.200667\n",
      "2022-08-30 19:16:04,798 epoch 7 - iter 66/111 - loss 0.36985303 - samples/sec: 82.55 - lr: 0.200667\n",
      "2022-08-30 19:16:09,055 epoch 7 - iter 77/111 - loss 0.36858465 - samples/sec: 78.79 - lr: 0.200667\n",
      "2022-08-30 19:16:12,934 epoch 7 - iter 88/111 - loss 0.36802719 - samples/sec: 86.57 - lr: 0.200667\n",
      "2022-08-30 19:16:17,627 epoch 7 - iter 99/111 - loss 0.36920096 - samples/sec: 71.38 - lr: 0.200667\n",
      "2022-08-30 19:16:21,820 epoch 7 - iter 110/111 - loss 0.37069534 - samples/sec: 79.94 - lr: 0.200667\n",
      "2022-08-30 19:16:22,187 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:16:22,188 EPOCH 7 done: loss 0.3708 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:16:23,112 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:16:23,145 DEV : loss 0.26902076601982117 - f1-score (micro avg)  0.9081\n",
      "2022-08-30 19:16:23,168 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:16:23,170 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:16:27,268 epoch 8 - iter 11/111 - loss 0.37597551 - samples/sec: 80.55 - lr: 0.200667\n",
      "2022-08-30 19:16:31,614 epoch 8 - iter 22/111 - loss 0.36767362 - samples/sec: 76.96 - lr: 0.200667\n",
      "2022-08-30 19:16:35,728 epoch 8 - iter 33/111 - loss 0.36978134 - samples/sec: 81.64 - lr: 0.200667\n",
      "2022-08-30 19:16:40,160 epoch 8 - iter 44/111 - loss 0.36990695 - samples/sec: 75.48 - lr: 0.200667\n",
      "2022-08-30 19:16:44,796 epoch 8 - iter 55/111 - loss 0.36639256 - samples/sec: 72.35 - lr: 0.200667\n",
      "2022-08-30 19:16:49,246 epoch 8 - iter 66/111 - loss 0.36948461 - samples/sec: 75.45 - lr: 0.200667\n",
      "2022-08-30 19:16:53,504 epoch 8 - iter 77/111 - loss 0.37129687 - samples/sec: 78.68 - lr: 0.200667\n",
      "2022-08-30 19:16:58,073 epoch 8 - iter 88/111 - loss 0.37129048 - samples/sec: 73.78 - lr: 0.200667\n",
      "2022-08-30 19:17:02,486 epoch 8 - iter 99/111 - loss 0.37307606 - samples/sec: 76.02 - lr: 0.200667\n",
      "2022-08-30 19:17:07,006 epoch 8 - iter 110/111 - loss 0.37429682 - samples/sec: 74.24 - lr: 0.200667\n",
      "2022-08-30 19:17:07,480 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:17:07,481 EPOCH 8 done: loss 0.3752 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:17:08,451 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:17:08,484 DEV : loss 0.25288712978363037 - f1-score (micro avg)  0.9131\n",
      "2022-08-30 19:17:08,505 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:17:08,506 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:17:12,759 epoch 9 - iter 11/111 - loss 0.36747490 - samples/sec: 77.63 - lr: 0.200667\n",
      "2022-08-30 19:17:17,081 epoch 9 - iter 22/111 - loss 0.37505229 - samples/sec: 77.54 - lr: 0.200667\n",
      "2022-08-30 19:17:21,506 epoch 9 - iter 33/111 - loss 0.36937241 - samples/sec: 75.72 - lr: 0.200667\n",
      "2022-08-30 19:17:25,866 epoch 9 - iter 44/111 - loss 0.37002238 - samples/sec: 76.98 - lr: 0.200667\n",
      "2022-08-30 19:17:30,385 epoch 9 - iter 55/111 - loss 0.36665681 - samples/sec: 74.07 - lr: 0.200667\n",
      "2022-08-30 19:17:34,713 epoch 9 - iter 66/111 - loss 0.36819918 - samples/sec: 77.77 - lr: 0.200667\n",
      "2022-08-30 19:17:39,177 epoch 9 - iter 77/111 - loss 0.36538503 - samples/sec: 75.16 - lr: 0.200667\n",
      "2022-08-30 19:17:44,118 epoch 9 - iter 88/111 - loss 0.36422744 - samples/sec: 67.62 - lr: 0.200667\n",
      "2022-08-30 19:17:48,999 epoch 9 - iter 99/111 - loss 0.36644369 - samples/sec: 68.51 - lr: 0.200667\n",
      "2022-08-30 19:17:53,307 epoch 9 - iter 110/111 - loss 0.36848133 - samples/sec: 77.77 - lr: 0.200667\n",
      "2022-08-30 19:17:53,755 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:17:53,755 EPOCH 9 done: loss 0.3682 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:17:54,739 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:17:54,777 DEV : loss 0.25516146421432495 - f1-score (micro avg)  0.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:17:54,799 Epoch     9: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 19:17:54,800 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 19:17:54,801 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:17:59,005 epoch 10 - iter 11/111 - loss 0.36889125 - samples/sec: 78.53 - lr: 0.100333\n",
      "2022-08-30 19:18:03,349 epoch 10 - iter 22/111 - loss 0.36344046 - samples/sec: 77.16 - lr: 0.100333\n",
      "2022-08-30 19:18:07,655 epoch 10 - iter 33/111 - loss 0.35552100 - samples/sec: 78.01 - lr: 0.100333\n",
      "2022-08-30 19:18:12,211 epoch 10 - iter 44/111 - loss 0.35594398 - samples/sec: 73.45 - lr: 0.100333\n",
      "2022-08-30 19:18:16,301 epoch 10 - iter 55/111 - loss 0.35835095 - samples/sec: 81.97 - lr: 0.100333\n",
      "2022-08-30 19:18:20,324 epoch 10 - iter 66/111 - loss 0.35661831 - samples/sec: 83.46 - lr: 0.100333\n",
      "2022-08-30 19:18:24,465 epoch 10 - iter 77/111 - loss 0.35214889 - samples/sec: 81.10 - lr: 0.100333\n",
      "2022-08-30 19:18:28,469 epoch 10 - iter 88/111 - loss 0.35328869 - samples/sec: 83.95 - lr: 0.100333\n",
      "2022-08-30 19:18:32,942 epoch 10 - iter 99/111 - loss 0.35361831 - samples/sec: 74.86 - lr: 0.100333\n",
      "2022-08-30 19:18:36,879 epoch 10 - iter 110/111 - loss 0.35407562 - samples/sec: 85.07 - lr: 0.100333\n",
      "2022-08-30 19:18:37,335 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:18:37,336 EPOCH 10 done: loss 0.3541 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:18:38,319 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:18:38,358 DEV : loss 0.25073039531707764 - f1-score (micro avg)  0.9154\n",
      "2022-08-30 19:18:38,381 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:18:38,382 saving best model\n",
      "2022-08-30 19:18:39,378 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:18:43,313 epoch 11 - iter 11/111 - loss 0.33888062 - samples/sec: 83.90 - lr: 0.100333\n",
      "2022-08-30 19:18:47,242 epoch 11 - iter 22/111 - loss 0.34840628 - samples/sec: 85.58 - lr: 0.100333\n",
      "2022-08-30 19:18:51,679 epoch 11 - iter 33/111 - loss 0.34416650 - samples/sec: 75.48 - lr: 0.100333\n",
      "2022-08-30 19:18:55,567 epoch 11 - iter 44/111 - loss 0.34831554 - samples/sec: 86.39 - lr: 0.100333\n",
      "2022-08-30 19:18:59,745 epoch 11 - iter 55/111 - loss 0.34723960 - samples/sec: 80.10 - lr: 0.100333\n",
      "2022-08-30 19:19:04,321 epoch 11 - iter 66/111 - loss 0.34716927 - samples/sec: 73.14 - lr: 0.100333\n",
      "2022-08-30 19:19:08,577 epoch 11 - iter 77/111 - loss 0.34904363 - samples/sec: 78.81 - lr: 0.100333\n",
      "2022-08-30 19:19:12,712 epoch 11 - iter 88/111 - loss 0.34788139 - samples/sec: 81.18 - lr: 0.100333\n",
      "2022-08-30 19:19:17,156 epoch 11 - iter 99/111 - loss 0.34934437 - samples/sec: 75.24 - lr: 0.100333\n",
      "2022-08-30 19:19:20,815 epoch 11 - iter 110/111 - loss 0.34982826 - samples/sec: 91.67 - lr: 0.100333\n",
      "2022-08-30 19:19:21,288 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:19:21,289 EPOCH 11 done: loss 0.3502 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:19:22,191 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:19:22,219 DEV : loss 0.2507064640522003 - f1-score (micro avg)  0.9152\n",
      "2022-08-30 19:19:22,239 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:19:22,240 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:19:26,600 epoch 12 - iter 11/111 - loss 0.34589060 - samples/sec: 75.72 - lr: 0.100333\n",
      "2022-08-30 19:19:30,402 epoch 12 - iter 22/111 - loss 0.34832840 - samples/sec: 88.12 - lr: 0.100333\n",
      "2022-08-30 19:19:34,296 epoch 12 - iter 33/111 - loss 0.34813412 - samples/sec: 86.64 - lr: 0.100333\n",
      "2022-08-30 19:19:38,506 epoch 12 - iter 44/111 - loss 0.35005976 - samples/sec: 79.65 - lr: 0.100333\n",
      "2022-08-30 19:19:42,708 epoch 12 - iter 55/111 - loss 0.34759935 - samples/sec: 79.96 - lr: 0.100333\n",
      "2022-08-30 19:19:46,758 epoch 12 - iter 66/111 - loss 0.34816858 - samples/sec: 82.62 - lr: 0.100333\n",
      "2022-08-30 19:19:50,769 epoch 12 - iter 77/111 - loss 0.34725049 - samples/sec: 83.52 - lr: 0.100333\n",
      "2022-08-30 19:19:54,755 epoch 12 - iter 88/111 - loss 0.34751498 - samples/sec: 84.06 - lr: 0.100333\n",
      "2022-08-30 19:19:59,367 epoch 12 - iter 99/111 - loss 0.34804809 - samples/sec: 72.50 - lr: 0.100333\n",
      "2022-08-30 19:20:03,382 epoch 12 - iter 110/111 - loss 0.34886246 - samples/sec: 83.86 - lr: 0.100333\n",
      "2022-08-30 19:20:03,759 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:20:03,760 EPOCH 12 done: loss 0.3487 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:20:04,632 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:20:04,665 DEV : loss 0.2515270411968231 - f1-score (micro avg)  0.9152\n",
      "2022-08-30 19:20:04,684 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:20:05,368 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:20:05,369 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 19:20:05,548 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:20:06,943 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:20:06,966 0.9212\t0.9212\t0.9212\t0.9212\n",
      "2022-08-30 19:20:06,966 \n",
      "Results:\n",
      "- F-score (micro) 0.9212\n",
      "- F-score (macro) 0.8013\n",
      "- Accuracy 0.9212\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8887    0.9202    0.9041      1353\n",
      "         ADJ     0.8718    0.9003    0.8858       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9922    0.9844    0.9883       514\n",
      "        VERB     0.8921    0.9020    0.8970       449\n",
      "       PROPN     0.8378    0.7415    0.7867       383\n",
      "         AUX     0.9851    0.9881    0.9866       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.8662    0.8447    0.8553       161\n",
      "         ADV     0.8212    0.8212    0.8212       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9811    0.7324    0.8387        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9212      5264\n",
      "   macro avg     0.8200    0.7867    0.8013      5264\n",
      "weighted avg     0.9217    0.9212    0.9208      5264\n",
      "\n",
      "2022-08-30 19:20:06,967 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:20:06,968 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 19:20:07,486 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 19:22:27,761 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:22:27,762 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 19:22:27,763 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:22:27,763 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 19:22:27,764 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:22:27,764 Parameters:\n",
      "2022-08-30 19:22:27,764  - learning_rate: \"0.200667\"\n",
      "2022-08-30 19:22:27,765  - mini_batch_size: \"50\"\n",
      "2022-08-30 19:22:27,766  - patience: \"3\"\n",
      "2022-08-30 19:22:27,767  - anneal_factor: \"0.5\"\n",
      "2022-08-30 19:22:27,768  - max_epochs: \"10\"\n",
      "2022-08-30 19:22:27,768  - shuffle: \"True\"\n",
      "2022-08-30 19:22:27,769  - train_with_dev: \"False\"\n",
      "2022-08-30 19:22:27,769  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 19:22:27,769 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:22:27,770 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 19:22:27,771 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:22:27,771 Device: cpu\n",
      "2022-08-30 19:22:27,771 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:22:27,772 Embeddings storage mode: cpu\n",
      "2022-08-30 19:22:27,772 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:22:30,605 epoch 1 - iter 6/67 - loss 0.32016364 - samples/sec: 105.97 - lr: 0.200667\n",
      "2022-08-30 19:22:33,860 epoch 1 - iter 12/67 - loss 0.33054835 - samples/sec: 94.07 - lr: 0.200667\n",
      "2022-08-30 19:22:36,684 epoch 1 - iter 18/67 - loss 0.33645134 - samples/sec: 108.26 - lr: 0.200667\n",
      "2022-08-30 19:22:39,447 epoch 1 - iter 24/67 - loss 0.34135192 - samples/sec: 110.78 - lr: 0.200667\n",
      "2022-08-30 19:22:42,489 epoch 1 - iter 30/67 - loss 0.33991370 - samples/sec: 100.81 - lr: 0.200667\n",
      "2022-08-30 19:22:45,596 epoch 1 - iter 36/67 - loss 0.34083598 - samples/sec: 99.14 - lr: 0.200667\n",
      "2022-08-30 19:22:48,573 epoch 1 - iter 42/67 - loss 0.33992924 - samples/sec: 103.34 - lr: 0.200667\n",
      "2022-08-30 19:22:51,430 epoch 1 - iter 48/67 - loss 0.34177691 - samples/sec: 107.26 - lr: 0.200667\n",
      "2022-08-30 19:22:54,155 epoch 1 - iter 54/67 - loss 0.34029877 - samples/sec: 112.87 - lr: 0.200667\n",
      "2022-08-30 19:22:57,344 epoch 1 - iter 60/67 - loss 0.34364275 - samples/sec: 96.06 - lr: 0.200667\n",
      "2022-08-30 19:23:00,834 epoch 1 - iter 66/67 - loss 0.35532641 - samples/sec: 87.69 - lr: 0.200667\n",
      "2022-08-30 19:23:01,279 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:23:01,279 EPOCH 1 done: loss 0.3558 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:23:02,108 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:23:02,138 DEV : loss 0.26747533679008484 - f1-score (micro avg)  0.9068\n",
      "2022-08-30 19:23:02,154 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:23:02,155 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:23:02,877 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:23:05,645 epoch 2 - iter 6/67 - loss 0.35681357 - samples/sec: 108.46 - lr: 0.200667\n",
      "2022-08-30 19:23:08,901 epoch 2 - iter 12/67 - loss 0.35259229 - samples/sec: 93.72 - lr: 0.200667\n",
      "2022-08-30 19:23:11,955 epoch 2 - iter 18/67 - loss 0.35620432 - samples/sec: 100.37 - lr: 0.200667\n",
      "2022-08-30 19:23:14,937 epoch 2 - iter 24/67 - loss 0.35962318 - samples/sec: 102.70 - lr: 0.200667\n",
      "2022-08-30 19:23:17,783 epoch 2 - iter 30/67 - loss 0.35887803 - samples/sec: 107.72 - lr: 0.200667\n",
      "2022-08-30 19:23:20,687 epoch 2 - iter 36/67 - loss 0.36200601 - samples/sec: 105.45 - lr: 0.200667\n",
      "2022-08-30 19:23:23,980 epoch 2 - iter 42/67 - loss 0.36435515 - samples/sec: 92.85 - lr: 0.200667\n",
      "2022-08-30 19:23:27,581 epoch 2 - iter 48/67 - loss 0.36335126 - samples/sec: 84.67 - lr: 0.200667\n",
      "2022-08-30 19:23:30,707 epoch 2 - iter 54/67 - loss 0.36065797 - samples/sec: 99.08 - lr: 0.200667\n",
      "2022-08-30 19:23:33,740 epoch 2 - iter 60/67 - loss 0.36001766 - samples/sec: 100.94 - lr: 0.200667\n",
      "2022-08-30 19:23:36,889 epoch 2 - iter 66/67 - loss 0.35847345 - samples/sec: 97.18 - lr: 0.200667\n",
      "2022-08-30 19:23:37,438 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:23:37,439 EPOCH 2 done: loss 0.3590 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:23:38,277 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:23:38,309 DEV : loss 0.25395479798316956 - f1-score (micro avg)  0.9134\n",
      "2022-08-30 19:23:38,330 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:23:38,331 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:23:39,395 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:23:42,464 epoch 3 - iter 6/67 - loss 0.36694798 - samples/sec: 97.85 - lr: 0.200667\n",
      "2022-08-30 19:23:45,216 epoch 3 - iter 12/67 - loss 0.35402383 - samples/sec: 113.16 - lr: 0.200667\n",
      "2022-08-30 19:23:48,669 epoch 3 - iter 18/67 - loss 0.35324089 - samples/sec: 88.31 - lr: 0.200667\n",
      "2022-08-30 19:23:51,770 epoch 3 - iter 24/67 - loss 0.35334215 - samples/sec: 98.65 - lr: 0.200667\n",
      "2022-08-30 19:23:54,777 epoch 3 - iter 30/67 - loss 0.35339318 - samples/sec: 101.94 - lr: 0.200667\n",
      "2022-08-30 19:23:58,013 epoch 3 - iter 36/67 - loss 0.35177926 - samples/sec: 94.34 - lr: 0.200667\n",
      "2022-08-30 19:24:01,394 epoch 3 - iter 42/67 - loss 0.35649625 - samples/sec: 90.42 - lr: 0.200667\n",
      "2022-08-30 19:24:04,528 epoch 3 - iter 48/67 - loss 0.35766269 - samples/sec: 98.14 - lr: 0.200667\n",
      "2022-08-30 19:24:07,353 epoch 3 - iter 54/67 - loss 0.35801044 - samples/sec: 108.85 - lr: 0.200667\n",
      "2022-08-30 19:24:10,841 epoch 3 - iter 60/67 - loss 0.35910418 - samples/sec: 87.72 - lr: 0.200667\n",
      "2022-08-30 19:24:13,814 epoch 3 - iter 66/67 - loss 0.35936893 - samples/sec: 103.06 - lr: 0.200667\n",
      "2022-08-30 19:24:14,192 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:24:14,193 EPOCH 3 done: loss 0.3590 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:24:15,064 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:24:15,094 DEV : loss 0.2561115324497223 - f1-score (micro avg)  0.9147\n",
      "2022-08-30 19:24:15,109 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:24:15,110 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:24:15,906 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:24:19,071 epoch 4 - iter 6/67 - loss 0.35013711 - samples/sec: 94.82 - lr: 0.200667\n",
      "2022-08-30 19:24:22,206 epoch 4 - iter 12/67 - loss 0.35215320 - samples/sec: 97.43 - lr: 0.200667\n",
      "2022-08-30 19:24:25,156 epoch 4 - iter 18/67 - loss 0.35287897 - samples/sec: 103.73 - lr: 0.200667\n",
      "2022-08-30 19:24:28,028 epoch 4 - iter 24/67 - loss 0.35468004 - samples/sec: 106.53 - lr: 0.200667\n",
      "2022-08-30 19:24:31,252 epoch 4 - iter 30/67 - loss 0.35098630 - samples/sec: 94.73 - lr: 0.200667\n",
      "2022-08-30 19:24:34,900 epoch 4 - iter 36/67 - loss 0.35269644 - samples/sec: 83.66 - lr: 0.200667\n",
      "2022-08-30 19:24:37,974 epoch 4 - iter 42/67 - loss 0.35250573 - samples/sec: 99.63 - lr: 0.200667\n",
      "2022-08-30 19:24:41,048 epoch 4 - iter 48/67 - loss 0.35500305 - samples/sec: 99.97 - lr: 0.200667\n",
      "2022-08-30 19:24:43,965 epoch 4 - iter 54/67 - loss 0.35395786 - samples/sec: 105.15 - lr: 0.200667\n",
      "2022-08-30 19:24:46,914 epoch 4 - iter 60/67 - loss 0.35424169 - samples/sec: 103.84 - lr: 0.200667\n",
      "2022-08-30 19:24:49,833 epoch 4 - iter 66/67 - loss 0.35390118 - samples/sec: 105.26 - lr: 0.200667\n",
      "2022-08-30 19:24:50,271 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:24:50,272 EPOCH 4 done: loss 0.3546 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:24:51,143 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:24:51,176 DEV : loss 0.2590382695198059 - f1-score (micro avg)  0.9118\n",
      "2022-08-30 19:24:51,191 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:24:51,192 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:24:54,025 epoch 5 - iter 6/67 - loss 0.34366866 - samples/sec: 105.93 - lr: 0.200667\n",
      "2022-08-30 19:24:57,103 epoch 5 - iter 12/67 - loss 0.34494670 - samples/sec: 99.34 - lr: 0.200667\n",
      "2022-08-30 19:25:00,288 epoch 5 - iter 18/67 - loss 0.34549781 - samples/sec: 95.97 - lr: 0.200667\n",
      "2022-08-30 19:25:03,604 epoch 5 - iter 24/67 - loss 0.34874614 - samples/sec: 92.08 - lr: 0.200667\n",
      "2022-08-30 19:25:06,608 epoch 5 - iter 30/67 - loss 0.35140083 - samples/sec: 101.97 - lr: 0.200667\n",
      "2022-08-30 19:25:09,295 epoch 5 - iter 36/67 - loss 0.34902982 - samples/sec: 114.55 - lr: 0.200667\n",
      "2022-08-30 19:25:12,550 epoch 5 - iter 42/67 - loss 0.35082650 - samples/sec: 94.16 - lr: 0.200667\n",
      "2022-08-30 19:25:15,450 epoch 5 - iter 48/67 - loss 0.35123160 - samples/sec: 106.50 - lr: 0.200667\n",
      "2022-08-30 19:25:18,834 epoch 5 - iter 54/67 - loss 0.35439703 - samples/sec: 90.31 - lr: 0.200667\n",
      "2022-08-30 19:25:22,183 epoch 5 - iter 60/67 - loss 0.35545026 - samples/sec: 91.46 - lr: 0.200667\n",
      "2022-08-30 19:25:25,323 epoch 5 - iter 66/67 - loss 0.35618174 - samples/sec: 97.24 - lr: 0.200667\n",
      "2022-08-30 19:25:25,755 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:25:25,755 EPOCH 5 done: loss 0.3565 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:25:26,609 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:25:26,636 DEV : loss 0.24786245822906494 - f1-score (micro avg)  0.9142\n",
      "2022-08-30 19:25:26,652 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 19:25:26,654 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:25:29,725 epoch 6 - iter 6/67 - loss 0.34712894 - samples/sec: 97.72 - lr: 0.200667\n",
      "2022-08-30 19:25:33,084 epoch 6 - iter 12/67 - loss 0.35447994 - samples/sec: 90.85 - lr: 0.200667\n",
      "2022-08-30 19:25:36,287 epoch 6 - iter 18/67 - loss 0.34780803 - samples/sec: 95.51 - lr: 0.200667\n",
      "2022-08-30 19:25:39,062 epoch 6 - iter 24/67 - loss 0.34944423 - samples/sec: 110.70 - lr: 0.200667\n",
      "2022-08-30 19:25:42,104 epoch 6 - iter 30/67 - loss 0.35248707 - samples/sec: 100.87 - lr: 0.200667\n",
      "2022-08-30 19:25:45,373 epoch 6 - iter 36/67 - loss 0.35332257 - samples/sec: 93.43 - lr: 0.200667\n",
      "2022-08-30 19:25:48,600 epoch 6 - iter 42/67 - loss 0.35242713 - samples/sec: 95.27 - lr: 0.200667\n",
      "2022-08-30 19:25:51,423 epoch 6 - iter 48/67 - loss 0.35567718 - samples/sec: 108.38 - lr: 0.200667\n",
      "2022-08-30 19:25:54,323 epoch 6 - iter 54/67 - loss 0.35420900 - samples/sec: 106.04 - lr: 0.200667\n",
      "2022-08-30 19:25:57,145 epoch 6 - iter 60/67 - loss 0.35467817 - samples/sec: 109.17 - lr: 0.200667\n",
      "2022-08-30 19:26:00,605 epoch 6 - iter 66/67 - loss 0.35680099 - samples/sec: 88.21 - lr: 0.200667\n",
      "2022-08-30 19:26:00,934 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:26:00,935 EPOCH 6 done: loss 0.3565 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:26:01,784 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:26:01,822 DEV : loss 0.24557040631771088 - f1-score (micro avg)  0.9198\n",
      "2022-08-30 19:26:01,839 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:26:01,840 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:26:02,577 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:26:05,183 epoch 7 - iter 6/67 - loss 0.33960674 - samples/sec: 115.16 - lr: 0.200667\n",
      "2022-08-30 19:26:08,624 epoch 7 - iter 12/67 - loss 0.34326489 - samples/sec: 88.76 - lr: 0.200667\n",
      "2022-08-30 19:26:11,612 epoch 7 - iter 18/67 - loss 0.34383086 - samples/sec: 102.99 - lr: 0.200667\n",
      "2022-08-30 19:26:15,104 epoch 7 - iter 24/67 - loss 0.34770589 - samples/sec: 87.64 - lr: 0.200667\n",
      "2022-08-30 19:26:18,174 epoch 7 - iter 30/67 - loss 0.34820224 - samples/sec: 99.57 - lr: 0.200667\n",
      "2022-08-30 19:26:21,079 epoch 7 - iter 36/67 - loss 0.34932585 - samples/sec: 105.41 - lr: 0.200667\n",
      "2022-08-30 19:26:24,265 epoch 7 - iter 42/67 - loss 0.34983942 - samples/sec: 95.88 - lr: 0.200667\n",
      "2022-08-30 19:26:27,559 epoch 7 - iter 48/67 - loss 0.35265359 - samples/sec: 92.74 - lr: 0.200667\n",
      "2022-08-30 19:26:30,594 epoch 7 - iter 54/67 - loss 0.35455014 - samples/sec: 100.87 - lr: 0.200667\n",
      "2022-08-30 19:26:33,519 epoch 7 - iter 60/67 - loss 0.35437813 - samples/sec: 104.71 - lr: 0.200667\n",
      "2022-08-30 19:26:36,636 epoch 7 - iter 66/67 - loss 0.35375336 - samples/sec: 99.04 - lr: 0.200667\n",
      "2022-08-30 19:26:37,001 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:26:37,002 EPOCH 7 done: loss 0.3537 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:26:37,826 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:26:37,858 DEV : loss 0.24599039554595947 - f1-score (micro avg)  0.9139\n",
      "2022-08-30 19:26:37,872 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:26:37,874 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:26:41,016 epoch 8 - iter 6/67 - loss 0.33770594 - samples/sec: 95.57 - lr: 0.200667\n",
      "2022-08-30 19:26:44,235 epoch 8 - iter 12/67 - loss 0.34005069 - samples/sec: 95.06 - lr: 0.200667\n",
      "2022-08-30 19:26:47,592 epoch 8 - iter 18/67 - loss 0.34470766 - samples/sec: 91.13 - lr: 0.200667\n",
      "2022-08-30 19:26:50,863 epoch 8 - iter 24/67 - loss 0.34741589 - samples/sec: 93.46 - lr: 0.200667\n",
      "2022-08-30 19:26:53,592 epoch 8 - iter 30/67 - loss 0.35087445 - samples/sec: 112.49 - lr: 0.200667\n",
      "2022-08-30 19:26:56,416 epoch 8 - iter 36/67 - loss 0.34642204 - samples/sec: 108.42 - lr: 0.200667\n",
      "2022-08-30 19:26:59,580 epoch 8 - iter 42/67 - loss 0.34801152 - samples/sec: 97.59 - lr: 0.200667\n",
      "2022-08-30 19:27:02,583 epoch 8 - iter 48/67 - loss 0.34904395 - samples/sec: 101.97 - lr: 0.200667\n",
      "2022-08-30 19:27:05,553 epoch 8 - iter 54/67 - loss 0.34847771 - samples/sec: 103.23 - lr: 0.200667\n",
      "2022-08-30 19:27:08,824 epoch 8 - iter 60/67 - loss 0.34821237 - samples/sec: 93.31 - lr: 0.200667\n",
      "2022-08-30 19:27:11,919 epoch 8 - iter 66/67 - loss 0.34989318 - samples/sec: 98.94 - lr: 0.200667\n",
      "2022-08-30 19:27:12,295 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:27:12,295 EPOCH 8 done: loss 0.3501 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:27:13,175 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:27:13,206 DEV : loss 0.25150585174560547 - f1-score (micro avg)  0.9163\n",
      "2022-08-30 19:27:13,224 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 19:27:13,225 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:27:16,287 epoch 9 - iter 6/67 - loss 0.36311145 - samples/sec: 98.01 - lr: 0.200667\n",
      "2022-08-30 19:27:19,340 epoch 9 - iter 12/67 - loss 0.34934139 - samples/sec: 100.50 - lr: 0.200667\n",
      "2022-08-30 19:27:22,225 epoch 9 - iter 18/67 - loss 0.35448064 - samples/sec: 107.91 - lr: 0.200667\n",
      "2022-08-30 19:27:25,669 epoch 9 - iter 24/67 - loss 0.35926612 - samples/sec: 88.58 - lr: 0.200667\n",
      "2022-08-30 19:27:29,564 epoch 9 - iter 30/67 - loss 0.35434500 - samples/sec: 78.35 - lr: 0.200667\n",
      "2022-08-30 19:27:32,623 epoch 9 - iter 36/67 - loss 0.35210590 - samples/sec: 100.77 - lr: 0.200667\n",
      "2022-08-30 19:27:35,852 epoch 9 - iter 42/67 - loss 0.35292443 - samples/sec: 94.85 - lr: 0.200667\n",
      "2022-08-30 19:27:38,637 epoch 9 - iter 48/67 - loss 0.35348169 - samples/sec: 110.17 - lr: 0.200667\n",
      "2022-08-30 19:27:42,272 epoch 9 - iter 54/67 - loss 0.35364193 - samples/sec: 84.03 - lr: 0.200667\n",
      "2022-08-30 19:27:45,675 epoch 9 - iter 60/67 - loss 0.35144199 - samples/sec: 89.71 - lr: 0.200667\n",
      "2022-08-30 19:27:48,897 epoch 9 - iter 66/67 - loss 0.34992154 - samples/sec: 95.39 - lr: 0.200667\n",
      "2022-08-30 19:27:49,411 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:27:49,412 EPOCH 9 done: loss 0.3500 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:27:50,462 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:27:50,501 DEV : loss 0.2566758692264557 - f1-score (micro avg)  0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:27:50,523 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 19:27:50,525 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:27:54,098 epoch 10 - iter 6/67 - loss 0.33353431 - samples/sec: 83.99 - lr: 0.200667\n",
      "2022-08-30 19:27:57,753 epoch 10 - iter 12/67 - loss 0.33952787 - samples/sec: 83.87 - lr: 0.200667\n",
      "2022-08-30 19:28:00,864 epoch 10 - iter 18/67 - loss 0.34461809 - samples/sec: 98.26 - lr: 0.200667\n",
      "2022-08-30 19:28:03,722 epoch 10 - iter 24/67 - loss 0.33910415 - samples/sec: 107.18 - lr: 0.200667\n",
      "2022-08-30 19:28:06,854 epoch 10 - iter 30/67 - loss 0.34343571 - samples/sec: 97.70 - lr: 0.200667\n",
      "2022-08-30 19:28:09,912 epoch 10 - iter 36/67 - loss 0.34185954 - samples/sec: 100.08 - lr: 0.200667\n",
      "2022-08-30 19:28:13,305 epoch 10 - iter 42/67 - loss 0.34587215 - samples/sec: 90.13 - lr: 0.200667\n",
      "2022-08-30 19:28:16,656 epoch 10 - iter 48/67 - loss 0.34774541 - samples/sec: 92.51 - lr: 0.200667\n",
      "2022-08-30 19:28:19,528 epoch 10 - iter 54/67 - loss 0.34738645 - samples/sec: 106.63 - lr: 0.200667\n",
      "2022-08-30 19:28:22,631 epoch 10 - iter 60/67 - loss 0.34653284 - samples/sec: 98.81 - lr: 0.200667\n",
      "2022-08-30 19:28:26,081 epoch 10 - iter 66/67 - loss 0.34757826 - samples/sec: 88.86 - lr: 0.200667\n",
      "2022-08-30 19:28:26,410 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:28:26,410 EPOCH 10 done: loss 0.3474 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:28:28,680 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:28:28,718 DEV : loss 0.24956263601779938 - f1-score (micro avg)  0.9142\n",
      "2022-08-30 19:28:28,739 Epoch    10: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 19:28:28,739 BAD EPOCHS (no improvement): 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:28:29,507 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:28:29,508 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 19:28:29,695 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:28:31,142 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:28:31,173 0.9198\t0.9198\t0.9198\t0.9198\n",
      "2022-08-30 19:28:31,173 \n",
      "Results:\n",
      "- F-score (micro) 0.9198\n",
      "- F-score (macro) 0.8018\n",
      "- Accuracy 0.9198\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8796    0.9180    0.8984      1353\n",
      "         ADJ     0.8848    0.8914    0.8881       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9922    0.9844    0.9883       514\n",
      "        VERB     0.8841    0.9176    0.9005       449\n",
      "       PROPN     0.8132    0.7389    0.7743       383\n",
      "         AUX     0.9909    0.9791    0.9850       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.9048    0.8261    0.8636       161\n",
      "         ADV     0.8378    0.8212    0.8294       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9474    0.7606    0.8437        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9198      5264\n",
      "   macro avg     0.8199    0.7868    0.8018      5264\n",
      "weighted avg     0.9201    0.9198    0.9195      5264\n",
      "\n",
      "2022-08-30 19:28:31,174 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:28:31,176 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:28:31,697 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 19:30:59,706 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:30:59,706 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 19:30:59,707 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:30:59,707 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 19:30:59,708 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:30:59,708 Parameters:\n",
      "2022-08-30 19:30:59,709  - learning_rate: \"0.200667\"\n",
      "2022-08-30 19:30:59,710  - mini_batch_size: \"50\"\n",
      "2022-08-30 19:30:59,711  - patience: \"3\"\n",
      "2022-08-30 19:30:59,711  - anneal_factor: \"0.5\"\n",
      "2022-08-30 19:30:59,712  - max_epochs: \"11\"\n",
      "2022-08-30 19:30:59,712  - shuffle: \"True\"\n",
      "2022-08-30 19:30:59,713  - train_with_dev: \"False\"\n",
      "2022-08-30 19:30:59,713  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 19:30:59,714 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:30:59,714 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 19:30:59,715 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:30:59,715 Device: cpu\n",
      "2022-08-30 19:30:59,716 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:30:59,716 Embeddings storage mode: cpu\n",
      "2022-08-30 19:30:59,717 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:31:02,617 epoch 1 - iter 6/67 - loss 0.33619990 - samples/sec: 103.56 - lr: 0.200667\n",
      "2022-08-30 19:31:05,934 epoch 1 - iter 12/67 - loss 0.33744119 - samples/sec: 92.17 - lr: 0.200667\n",
      "2022-08-30 19:31:08,812 epoch 1 - iter 18/67 - loss 0.34030545 - samples/sec: 106.38 - lr: 0.200667\n",
      "2022-08-30 19:31:11,666 epoch 1 - iter 24/67 - loss 0.34074635 - samples/sec: 107.33 - lr: 0.200667\n",
      "2022-08-30 19:31:14,740 epoch 1 - iter 30/67 - loss 0.34282466 - samples/sec: 99.60 - lr: 0.200667\n",
      "2022-08-30 19:31:17,859 epoch 1 - iter 36/67 - loss 0.34277214 - samples/sec: 97.94 - lr: 0.200667\n",
      "2022-08-30 19:31:20,900 epoch 1 - iter 42/67 - loss 0.34259188 - samples/sec: 100.57 - lr: 0.200667\n",
      "2022-08-30 19:31:23,758 epoch 1 - iter 48/67 - loss 0.34285379 - samples/sec: 107.03 - lr: 0.200667\n",
      "2022-08-30 19:31:26,586 epoch 1 - iter 54/67 - loss 0.34195183 - samples/sec: 108.54 - lr: 0.200667\n",
      "2022-08-30 19:31:29,863 epoch 1 - iter 60/67 - loss 0.34525614 - samples/sec: 93.55 - lr: 0.200667\n",
      "2022-08-30 19:31:33,259 epoch 1 - iter 66/67 - loss 0.35626329 - samples/sec: 89.87 - lr: 0.200667\n",
      "2022-08-30 19:31:33,770 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:31:33,771 EPOCH 1 done: loss 0.3567 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:31:34,576 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:31:34,606 DEV : loss 0.2712271511554718 - f1-score (micro avg)  0.9082\n",
      "2022-08-30 19:31:34,627 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:31:34,628 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:31:35,342 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:31:38,679 epoch 2 - iter 6/67 - loss 0.36158645 - samples/sec: 89.96 - lr: 0.200667\n",
      "2022-08-30 19:31:41,785 epoch 2 - iter 12/67 - loss 0.36206239 - samples/sec: 98.46 - lr: 0.200667\n",
      "2022-08-30 19:31:45,162 epoch 2 - iter 18/67 - loss 0.35653890 - samples/sec: 90.39 - lr: 0.200667\n",
      "2022-08-30 19:31:48,814 epoch 2 - iter 24/67 - loss 0.35120429 - samples/sec: 83.47 - lr: 0.200667\n",
      "2022-08-30 19:31:51,957 epoch 2 - iter 30/67 - loss 0.35264848 - samples/sec: 97.62 - lr: 0.200667\n",
      "2022-08-30 19:31:54,956 epoch 2 - iter 36/67 - loss 0.35126981 - samples/sec: 102.56 - lr: 0.200667\n",
      "2022-08-30 19:31:58,201 epoch 2 - iter 42/67 - loss 0.34934788 - samples/sec: 94.25 - lr: 0.200667\n",
      "2022-08-30 19:32:01,295 epoch 2 - iter 48/67 - loss 0.35097780 - samples/sec: 98.72 - lr: 0.200667\n",
      "2022-08-30 19:32:04,296 epoch 2 - iter 54/67 - loss 0.35217610 - samples/sec: 102.15 - lr: 0.200667\n",
      "2022-08-30 19:32:07,423 epoch 2 - iter 60/67 - loss 0.35118180 - samples/sec: 98.23 - lr: 0.200667\n",
      "2022-08-30 19:32:10,265 epoch 2 - iter 66/67 - loss 0.35185755 - samples/sec: 108.26 - lr: 0.200667\n",
      "2022-08-30 19:32:10,705 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:32:10,706 EPOCH 2 done: loss 0.3513 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:32:11,543 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:32:11,571 DEV : loss 0.24555431306362152 - f1-score (micro avg)  0.9165\n",
      "2022-08-30 19:32:11,589 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:32:11,591 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:32:12,453 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:32:16,021 epoch 3 - iter 6/67 - loss 0.36261284 - samples/sec: 84.13 - lr: 0.200667\n",
      "2022-08-30 19:32:19,186 epoch 3 - iter 12/67 - loss 0.35663940 - samples/sec: 96.84 - lr: 0.200667\n",
      "2022-08-30 19:32:22,306 epoch 3 - iter 18/67 - loss 0.34577363 - samples/sec: 98.14 - lr: 0.200667\n",
      "2022-08-30 19:32:25,525 epoch 3 - iter 24/67 - loss 0.34683482 - samples/sec: 95.85 - lr: 0.200667\n",
      "2022-08-30 19:32:28,769 epoch 3 - iter 30/67 - loss 0.34443980 - samples/sec: 94.85 - lr: 0.200667\n",
      "2022-08-30 19:32:31,906 epoch 3 - iter 36/67 - loss 0.34366202 - samples/sec: 98.30 - lr: 0.200667\n",
      "2022-08-30 19:32:35,134 epoch 3 - iter 42/67 - loss 0.34450078 - samples/sec: 94.58 - lr: 0.200667\n",
      "2022-08-30 19:32:38,257 epoch 3 - iter 48/67 - loss 0.34401541 - samples/sec: 97.82 - lr: 0.200667\n",
      "2022-08-30 19:32:41,289 epoch 3 - iter 54/67 - loss 0.34634496 - samples/sec: 101.01 - lr: 0.200667\n",
      "2022-08-30 19:32:44,310 epoch 3 - iter 60/67 - loss 0.34698857 - samples/sec: 101.35 - lr: 0.200667\n",
      "2022-08-30 19:32:47,202 epoch 3 - iter 66/67 - loss 0.34844336 - samples/sec: 106.08 - lr: 0.200667\n",
      "2022-08-30 19:32:47,602 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:32:47,603 EPOCH 3 done: loss 0.3484 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:32:48,520 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:32:48,558 DEV : loss 0.25206005573272705 - f1-score (micro avg)  0.9128\n",
      "2022-08-30 19:32:48,579 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:32:48,580 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:32:51,737 epoch 4 - iter 6/67 - loss 0.32204159 - samples/sec: 95.09 - lr: 0.200667\n",
      "2022-08-30 19:32:54,655 epoch 4 - iter 12/67 - loss 0.32685189 - samples/sec: 105.26 - lr: 0.200667\n",
      "2022-08-30 19:32:58,034 epoch 4 - iter 18/67 - loss 0.33013706 - samples/sec: 90.39 - lr: 0.200667\n",
      "2022-08-30 19:33:01,363 epoch 4 - iter 24/67 - loss 0.33276828 - samples/sec: 91.86 - lr: 0.200667\n",
      "2022-08-30 19:33:04,247 epoch 4 - iter 30/67 - loss 0.34019183 - samples/sec: 106.95 - lr: 0.200667\n",
      "2022-08-30 19:33:07,105 epoch 4 - iter 36/67 - loss 0.34373638 - samples/sec: 107.18 - lr: 0.200667\n",
      "2022-08-30 19:33:10,084 epoch 4 - iter 42/67 - loss 0.34396377 - samples/sec: 102.63 - lr: 0.200667\n",
      "2022-08-30 19:33:13,165 epoch 4 - iter 48/67 - loss 0.34537469 - samples/sec: 99.14 - lr: 0.200667\n",
      "2022-08-30 19:33:16,599 epoch 4 - iter 54/67 - loss 0.34457543 - samples/sec: 89.07 - lr: 0.200667\n",
      "2022-08-30 19:33:19,568 epoch 4 - iter 60/67 - loss 0.34263584 - samples/sec: 103.38 - lr: 0.200667\n",
      "2022-08-30 19:33:23,212 epoch 4 - iter 66/67 - loss 0.34469818 - samples/sec: 83.87 - lr: 0.200667\n",
      "2022-08-30 19:33:23,689 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:33:23,690 EPOCH 4 done: loss 0.3447 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:33:24,548 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:33:24,580 DEV : loss 0.24820424616336823 - f1-score (micro avg)  0.9155\n",
      "2022-08-30 19:33:24,595 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 19:33:24,596 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:33:27,476 epoch 5 - iter 6/67 - loss 0.33241483 - samples/sec: 104.24 - lr: 0.200667\n",
      "2022-08-30 19:33:30,875 epoch 5 - iter 12/67 - loss 0.33177609 - samples/sec: 90.47 - lr: 0.200667\n",
      "2022-08-30 19:33:34,311 epoch 5 - iter 18/67 - loss 0.33542710 - samples/sec: 89.05 - lr: 0.200667\n",
      "2022-08-30 19:33:37,341 epoch 5 - iter 24/67 - loss 0.33730664 - samples/sec: 101.32 - lr: 0.200667\n",
      "2022-08-30 19:33:40,339 epoch 5 - iter 30/67 - loss 0.33968004 - samples/sec: 102.35 - lr: 0.200667\n",
      "2022-08-30 19:33:43,275 epoch 5 - iter 36/67 - loss 0.33966228 - samples/sec: 105.41 - lr: 0.200667\n",
      "2022-08-30 19:33:46,839 epoch 5 - iter 42/67 - loss 0.33964913 - samples/sec: 85.62 - lr: 0.200667\n",
      "2022-08-30 19:33:49,890 epoch 5 - iter 48/67 - loss 0.34134236 - samples/sec: 100.44 - lr: 0.200667\n",
      "2022-08-30 19:33:53,197 epoch 5 - iter 54/67 - loss 0.34392538 - samples/sec: 92.34 - lr: 0.200667\n",
      "2022-08-30 19:33:56,274 epoch 5 - iter 60/67 - loss 0.34336909 - samples/sec: 99.62 - lr: 0.200667\n",
      "2022-08-30 19:33:59,269 epoch 5 - iter 66/67 - loss 0.34349544 - samples/sec: 102.11 - lr: 0.200667\n",
      "2022-08-30 19:33:59,699 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:33:59,700 EPOCH 5 done: loss 0.3438 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:34:00,544 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:34:00,582 DEV : loss 0.2473987638950348 - f1-score (micro avg)  0.9159\n",
      "2022-08-30 19:34:00,602 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 19:34:00,604 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:34:03,458 epoch 6 - iter 6/67 - loss 0.36031593 - samples/sec: 105.15 - lr: 0.200667\n",
      "2022-08-30 19:34:06,342 epoch 6 - iter 12/67 - loss 0.35846239 - samples/sec: 106.19 - lr: 0.200667\n",
      "2022-08-30 19:34:09,216 epoch 6 - iter 18/67 - loss 0.34955039 - samples/sec: 107.60 - lr: 0.200667\n",
      "2022-08-30 19:34:12,367 epoch 6 - iter 24/67 - loss 0.34689157 - samples/sec: 97.09 - lr: 0.200667\n",
      "2022-08-30 19:34:15,291 epoch 6 - iter 30/67 - loss 0.34619654 - samples/sec: 105.67 - lr: 0.200667\n",
      "2022-08-30 19:34:18,378 epoch 6 - iter 36/67 - loss 0.34646662 - samples/sec: 99.24 - lr: 0.200667\n",
      "2022-08-30 19:34:21,723 epoch 6 - iter 42/67 - loss 0.34508362 - samples/sec: 92.05 - lr: 0.200667\n",
      "2022-08-30 19:34:25,300 epoch 6 - iter 48/67 - loss 0.34478302 - samples/sec: 85.40 - lr: 0.200667\n",
      "2022-08-30 19:34:28,697 epoch 6 - iter 54/67 - loss 0.34474742 - samples/sec: 89.87 - lr: 0.200667\n",
      "2022-08-30 19:34:31,894 epoch 6 - iter 60/67 - loss 0.34396042 - samples/sec: 95.79 - lr: 0.200667\n",
      "2022-08-30 19:34:35,316 epoch 6 - iter 66/67 - loss 0.34421432 - samples/sec: 89.18 - lr: 0.200667\n",
      "2022-08-30 19:34:35,779 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:34:35,779 EPOCH 6 done: loss 0.3441 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:34:36,631 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:34:36,660 DEV : loss 0.24972611665725708 - f1-score (micro avg)  0.9159\n",
      "2022-08-30 19:34:36,675 Epoch     6: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 19:34:36,675 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 19:34:36,676 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:34:39,653 epoch 7 - iter 6/67 - loss 0.32734814 - samples/sec: 100.81 - lr: 0.100333\n",
      "2022-08-30 19:34:42,841 epoch 7 - iter 12/67 - loss 0.33156823 - samples/sec: 96.03 - lr: 0.100333\n",
      "2022-08-30 19:34:45,903 epoch 7 - iter 18/67 - loss 0.33386488 - samples/sec: 99.93 - lr: 0.100333\n",
      "2022-08-30 19:34:49,046 epoch 7 - iter 24/67 - loss 0.33418078 - samples/sec: 97.43 - lr: 0.100333\n",
      "2022-08-30 19:34:52,347 epoch 7 - iter 30/67 - loss 0.33724841 - samples/sec: 92.45 - lr: 0.100333\n",
      "2022-08-30 19:34:55,702 epoch 7 - iter 36/67 - loss 0.33569715 - samples/sec: 91.38 - lr: 0.100333\n",
      "2022-08-30 19:34:58,791 epoch 7 - iter 42/67 - loss 0.33398842 - samples/sec: 99.67 - lr: 0.100333\n",
      "2022-08-30 19:35:01,821 epoch 7 - iter 48/67 - loss 0.33513723 - samples/sec: 101.08 - lr: 0.100333\n",
      "2022-08-30 19:35:05,488 epoch 7 - iter 54/67 - loss 0.33518804 - samples/sec: 83.22 - lr: 0.100333\n",
      "2022-08-30 19:35:08,303 epoch 7 - iter 60/67 - loss 0.33505644 - samples/sec: 109.05 - lr: 0.100333\n",
      "2022-08-30 19:35:11,549 epoch 7 - iter 66/67 - loss 0.33380028 - samples/sec: 94.58 - lr: 0.100333\n",
      "2022-08-30 19:35:12,160 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:35:12,161 EPOCH 7 done: loss 0.3337 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:35:13,062 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:35:13,094 DEV : loss 0.2453930526971817 - f1-score (micro avg)  0.9159\n",
      "2022-08-30 19:35:13,114 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:35:13,115 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:35:16,349 epoch 8 - iter 6/67 - loss 0.33396672 - samples/sec: 92.82 - lr: 0.100333\n",
      "2022-08-30 19:35:19,630 epoch 8 - iter 12/67 - loss 0.32098088 - samples/sec: 94.10 - lr: 0.100333\n",
      "2022-08-30 19:35:22,767 epoch 8 - iter 18/67 - loss 0.32535825 - samples/sec: 97.69 - lr: 0.100333\n",
      "2022-08-30 19:35:25,950 epoch 8 - iter 24/67 - loss 0.32425443 - samples/sec: 96.31 - lr: 0.100333\n",
      "2022-08-30 19:35:29,062 epoch 8 - iter 30/67 - loss 0.32581329 - samples/sec: 98.20 - lr: 0.100333\n",
      "2022-08-30 19:35:32,350 epoch 8 - iter 36/67 - loss 0.32854220 - samples/sec: 92.99 - lr: 0.100333\n",
      "2022-08-30 19:35:35,659 epoch 8 - iter 42/67 - loss 0.32819354 - samples/sec: 92.62 - lr: 0.100333\n",
      "2022-08-30 19:35:38,606 epoch 8 - iter 48/67 - loss 0.32819410 - samples/sec: 103.88 - lr: 0.100333\n",
      "2022-08-30 19:35:41,730 epoch 8 - iter 54/67 - loss 0.32794966 - samples/sec: 98.36 - lr: 0.100333\n",
      "2022-08-30 19:35:45,236 epoch 8 - iter 60/67 - loss 0.32897526 - samples/sec: 87.08 - lr: 0.100333\n",
      "2022-08-30 19:35:48,307 epoch 8 - iter 66/67 - loss 0.33005714 - samples/sec: 99.54 - lr: 0.100333\n",
      "2022-08-30 19:35:48,777 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:35:48,778 EPOCH 8 done: loss 0.3299 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:35:49,635 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:35:49,669 DEV : loss 0.24315184354782104 - f1-score (micro avg)  0.9173\n",
      "2022-08-30 19:35:49,685 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:35:49,687 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:35:50,516 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:35:53,410 epoch 9 - iter 6/67 - loss 0.31476567 - samples/sec: 103.73 - lr: 0.100333\n",
      "2022-08-30 19:35:56,520 epoch 9 - iter 12/67 - loss 0.31759147 - samples/sec: 99.04 - lr: 0.100333\n",
      "2022-08-30 19:35:59,598 epoch 9 - iter 18/67 - loss 0.31923337 - samples/sec: 100.13 - lr: 0.100333\n",
      "2022-08-30 19:36:02,578 epoch 9 - iter 24/67 - loss 0.32414322 - samples/sec: 103.02 - lr: 0.100333\n",
      "2022-08-30 19:36:05,643 epoch 9 - iter 30/67 - loss 0.32434649 - samples/sec: 99.77 - lr: 0.100333\n",
      "2022-08-30 19:36:09,363 epoch 9 - iter 36/67 - loss 0.32144047 - samples/sec: 82.12 - lr: 0.100333\n",
      "2022-08-30 19:36:12,941 epoch 9 - iter 42/67 - loss 0.32205894 - samples/sec: 85.96 - lr: 0.100333\n",
      "2022-08-30 19:36:16,489 epoch 9 - iter 48/67 - loss 0.32370984 - samples/sec: 86.21 - lr: 0.100333\n",
      "2022-08-30 19:36:19,868 epoch 9 - iter 54/67 - loss 0.32496704 - samples/sec: 90.80 - lr: 0.100333\n",
      "2022-08-30 19:36:22,789 epoch 9 - iter 60/67 - loss 0.32442465 - samples/sec: 105.37 - lr: 0.100333\n",
      "2022-08-30 19:36:25,864 epoch 9 - iter 66/67 - loss 0.32396697 - samples/sec: 99.50 - lr: 0.100333\n",
      "2022-08-30 19:36:26,311 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:36:26,312 EPOCH 9 done: loss 0.3243 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:36:27,214 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:36:27,243 DEV : loss 0.24403735995292664 - f1-score (micro avg)  0.9188\n",
      "2022-08-30 19:36:27,258 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:36:27,259 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:36:28,383 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:36:32,045 epoch 10 - iter 6/67 - loss 0.31609802 - samples/sec: 81.94 - lr: 0.100333\n",
      "2022-08-30 19:36:35,128 epoch 10 - iter 12/67 - loss 0.32681278 - samples/sec: 99.17 - lr: 0.100333\n",
      "2022-08-30 19:36:38,247 epoch 10 - iter 18/67 - loss 0.32711570 - samples/sec: 98.07 - lr: 0.100333\n",
      "2022-08-30 19:36:41,476 epoch 10 - iter 24/67 - loss 0.32726510 - samples/sec: 94.70 - lr: 0.100333\n",
      "2022-08-30 19:36:44,639 epoch 10 - iter 30/67 - loss 0.32514182 - samples/sec: 96.77 - lr: 0.100333\n",
      "2022-08-30 19:36:47,663 epoch 10 - iter 36/67 - loss 0.32622875 - samples/sec: 101.28 - lr: 0.100333\n",
      "2022-08-30 19:36:50,843 epoch 10 - iter 42/67 - loss 0.32611117 - samples/sec: 96.06 - lr: 0.100333\n",
      "2022-08-30 19:36:54,243 epoch 10 - iter 48/67 - loss 0.32557470 - samples/sec: 89.71 - lr: 0.100333\n",
      "2022-08-30 19:36:57,074 epoch 10 - iter 54/67 - loss 0.32570838 - samples/sec: 108.19 - lr: 0.100333\n",
      "2022-08-30 19:37:00,115 epoch 10 - iter 60/67 - loss 0.32776432 - samples/sec: 100.74 - lr: 0.100333\n",
      "2022-08-30 19:37:03,214 epoch 10 - iter 66/67 - loss 0.32751504 - samples/sec: 98.88 - lr: 0.100333\n",
      "2022-08-30 19:37:03,669 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:37:03,670 EPOCH 10 done: loss 0.3280 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:37:04,524 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:37:04,556 DEV : loss 0.24342818558216095 - f1-score (micro avg)  0.9178\n",
      "2022-08-30 19:37:04,571 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:37:04,572 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:37:07,839 epoch 11 - iter 6/67 - loss 0.31040790 - samples/sec: 91.88 - lr: 0.100333\n",
      "2022-08-30 19:37:10,869 epoch 11 - iter 12/67 - loss 0.32238708 - samples/sec: 101.08 - lr: 0.100333\n",
      "2022-08-30 19:37:14,008 epoch 11 - iter 18/67 - loss 0.31539749 - samples/sec: 97.50 - lr: 0.100333\n",
      "2022-08-30 19:37:16,986 epoch 11 - iter 24/67 - loss 0.31754120 - samples/sec: 102.88 - lr: 0.100333\n",
      "2022-08-30 19:37:20,335 epoch 11 - iter 30/67 - loss 0.31519438 - samples/sec: 91.32 - lr: 0.100333\n",
      "2022-08-30 19:37:23,412 epoch 11 - iter 36/67 - loss 0.31763570 - samples/sec: 99.77 - lr: 0.100333\n",
      "2022-08-30 19:37:26,544 epoch 11 - iter 42/67 - loss 0.32055801 - samples/sec: 98.43 - lr: 0.100333\n",
      "2022-08-30 19:37:30,228 epoch 11 - iter 48/67 - loss 0.32080763 - samples/sec: 82.90 - lr: 0.100333\n",
      "2022-08-30 19:37:33,596 epoch 11 - iter 54/67 - loss 0.32071421 - samples/sec: 90.61 - lr: 0.100333\n",
      "2022-08-30 19:37:36,389 epoch 11 - iter 60/67 - loss 0.32208077 - samples/sec: 109.73 - lr: 0.100333\n",
      "2022-08-30 19:37:39,573 epoch 11 - iter 66/67 - loss 0.32132007 - samples/sec: 96.15 - lr: 0.100333\n",
      "2022-08-30 19:37:39,977 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:37:39,978 EPOCH 11 done: loss 0.3213 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:37:40,838 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:37:40,868 DEV : loss 0.24444147944450378 - f1-score (micro avg)  0.9173\n",
      "2022-08-30 19:37:40,888 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:37:41,593 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:37:41,594 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 19:37:41,788 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:37:43,171 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:37:43,195 0.9212\t0.9212\t0.9212\t0.9212\n",
      "2022-08-30 19:37:43,196 \n",
      "Results:\n",
      "- F-score (micro) 0.9212\n",
      "- F-score (macro) 0.8649\n",
      "- Accuracy 0.9212\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8831    0.9268    0.9044      1353\n",
      "         ADJ     0.8699    0.8958    0.8827       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9921    0.9825    0.9873       514\n",
      "        VERB     0.8922    0.9220    0.9069       449\n",
      "       PROPN     0.8338    0.7076    0.7655       383\n",
      "         AUX     0.9880    0.9821    0.9850       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8903    0.8571    0.8734       161\n",
      "         ADV     0.8462    0.8013    0.8231       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     1.0000    0.7465    0.8548        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9212      5264\n",
      "   macro avg     0.8859    0.8484    0.8649      5264\n",
      "weighted avg     0.9216    0.9212    0.9205      5264\n",
      "\n",
      "2022-08-30 19:37:43,197 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:37:43,199 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:37:43,703 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 19:40:06,524 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:40:06,524 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 19:40:06,525 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:40:06,526 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 19:40:06,526 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:40:06,527 Parameters:\n",
      "2022-08-30 19:40:06,527  - learning_rate: \"0.200667\"\n",
      "2022-08-30 19:40:06,528  - mini_batch_size: \"50\"\n",
      "2022-08-30 19:40:06,528  - patience: \"3\"\n",
      "2022-08-30 19:40:06,529  - anneal_factor: \"0.5\"\n",
      "2022-08-30 19:40:06,529  - max_epochs: \"12\"\n",
      "2022-08-30 19:40:06,530  - shuffle: \"True\"\n",
      "2022-08-30 19:40:06,530  - train_with_dev: \"False\"\n",
      "2022-08-30 19:40:06,531  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 19:40:06,532 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:40:06,532 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 19:40:06,533 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:40:06,534 Device: cpu\n",
      "2022-08-30 19:40:06,534 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:40:06,535 Embeddings storage mode: cpu\n",
      "2022-08-30 19:40:06,535 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:40:09,317 epoch 1 - iter 6/67 - loss 0.32338194 - samples/sec: 107.91 - lr: 0.200667\n",
      "2022-08-30 19:40:12,519 epoch 1 - iter 12/67 - loss 0.32626756 - samples/sec: 95.97 - lr: 0.200667\n",
      "2022-08-30 19:40:15,297 epoch 1 - iter 18/67 - loss 0.32426511 - samples/sec: 110.33 - lr: 0.200667\n",
      "2022-08-30 19:40:18,038 epoch 1 - iter 24/67 - loss 0.32087526 - samples/sec: 111.86 - lr: 0.200667\n",
      "2022-08-30 19:40:21,030 epoch 1 - iter 30/67 - loss 0.32504424 - samples/sec: 102.25 - lr: 0.200667\n",
      "2022-08-30 19:40:24,022 epoch 1 - iter 36/67 - loss 0.32385411 - samples/sec: 102.18 - lr: 0.200667\n",
      "2022-08-30 19:40:26,973 epoch 1 - iter 42/67 - loss 0.32327309 - samples/sec: 103.81 - lr: 0.200667\n",
      "2022-08-30 19:40:29,816 epoch 1 - iter 48/67 - loss 0.32338427 - samples/sec: 107.87 - lr: 0.200667\n",
      "2022-08-30 19:40:32,644 epoch 1 - iter 54/67 - loss 0.32253938 - samples/sec: 108.66 - lr: 0.200667\n",
      "2022-08-30 19:40:35,817 epoch 1 - iter 60/67 - loss 0.32577566 - samples/sec: 96.40 - lr: 0.200667\n",
      "2022-08-30 19:40:39,110 epoch 1 - iter 66/67 - loss 0.33688807 - samples/sec: 92.71 - lr: 0.200667\n",
      "2022-08-30 19:40:39,602 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:40:39,603 EPOCH 1 done: loss 0.3374 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:40:40,453 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:40:40,484 DEV : loss 0.2633821368217468 - f1-score (micro avg)  0.9087\n",
      "2022-08-30 19:40:40,501 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:40:40,502 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:40:41,184 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:40:44,116 epoch 2 - iter 6/67 - loss 0.33939842 - samples/sec: 102.35 - lr: 0.200667\n",
      "2022-08-30 19:40:46,940 epoch 2 - iter 12/67 - loss 0.33204650 - samples/sec: 108.70 - lr: 0.200667\n",
      "2022-08-30 19:40:50,240 epoch 2 - iter 18/67 - loss 0.33415828 - samples/sec: 92.76 - lr: 0.200667\n",
      "2022-08-30 19:40:53,573 epoch 2 - iter 24/67 - loss 0.33778248 - samples/sec: 91.77 - lr: 0.200667\n",
      "2022-08-30 19:40:56,343 epoch 2 - iter 30/67 - loss 0.33889296 - samples/sec: 110.50 - lr: 0.200667\n",
      "2022-08-30 19:40:59,382 epoch 2 - iter 36/67 - loss 0.33867248 - samples/sec: 101.70 - lr: 0.200667\n",
      "2022-08-30 19:41:02,768 epoch 2 - iter 42/67 - loss 0.34073781 - samples/sec: 90.44 - lr: 0.200667\n",
      "2022-08-30 19:41:05,803 epoch 2 - iter 48/67 - loss 0.34109853 - samples/sec: 100.67 - lr: 0.200667\n",
      "2022-08-30 19:41:08,855 epoch 2 - iter 54/67 - loss 0.34196811 - samples/sec: 100.23 - lr: 0.200667\n",
      "2022-08-30 19:41:11,757 epoch 2 - iter 60/67 - loss 0.34139774 - samples/sec: 105.60 - lr: 0.200667\n",
      "2022-08-30 19:41:14,927 epoch 2 - iter 66/67 - loss 0.34068035 - samples/sec: 96.53 - lr: 0.200667\n",
      "2022-08-30 19:41:15,322 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:41:15,323 EPOCH 2 done: loss 0.3409 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:41:16,172 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:41:16,202 DEV : loss 0.24801474809646606 - f1-score (micro avg)  0.9146\n",
      "2022-08-30 19:41:16,217 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:41:16,218 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:41:16,916 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:41:19,835 epoch 3 - iter 6/67 - loss 0.34068505 - samples/sec: 102.88 - lr: 0.200667\n",
      "2022-08-30 19:41:23,180 epoch 3 - iter 12/67 - loss 0.33484198 - samples/sec: 91.27 - lr: 0.200667\n",
      "2022-08-30 19:41:26,534 epoch 3 - iter 18/67 - loss 0.33923150 - samples/sec: 91.07 - lr: 0.200667\n",
      "2022-08-30 19:41:29,267 epoch 3 - iter 24/67 - loss 0.34013991 - samples/sec: 112.07 - lr: 0.200667\n",
      "2022-08-30 19:41:32,269 epoch 3 - iter 30/67 - loss 0.33739043 - samples/sec: 101.90 - lr: 0.200667\n",
      "2022-08-30 19:41:35,390 epoch 3 - iter 36/67 - loss 0.33670717 - samples/sec: 98.07 - lr: 0.200667\n",
      "2022-08-30 19:41:38,485 epoch 3 - iter 42/67 - loss 0.33698242 - samples/sec: 98.98 - lr: 0.200667\n",
      "2022-08-30 19:41:41,716 epoch 3 - iter 48/67 - loss 0.33619123 - samples/sec: 94.91 - lr: 0.200667\n",
      "2022-08-30 19:41:44,829 epoch 3 - iter 54/67 - loss 0.33581546 - samples/sec: 98.23 - lr: 0.200667\n",
      "2022-08-30 19:41:47,767 epoch 3 - iter 60/67 - loss 0.33772253 - samples/sec: 104.42 - lr: 0.200667\n",
      "2022-08-30 19:41:50,692 epoch 3 - iter 66/67 - loss 0.33652269 - samples/sec: 104.53 - lr: 0.200667\n",
      "2022-08-30 19:41:51,211 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:41:51,212 EPOCH 3 done: loss 0.3369 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:41:52,045 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:41:52,075 DEV : loss 0.24271409213542938 - f1-score (micro avg)  0.9178\n",
      "2022-08-30 19:41:52,091 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:41:52,092 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:41:53,244 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:41:56,111 epoch 4 - iter 6/67 - loss 0.34296016 - samples/sec: 104.71 - lr: 0.200667\n",
      "2022-08-30 19:41:58,798 epoch 4 - iter 12/67 - loss 0.33696998 - samples/sec: 114.07 - lr: 0.200667\n",
      "2022-08-30 19:42:01,714 epoch 4 - iter 18/67 - loss 0.33169979 - samples/sec: 104.93 - lr: 0.200667\n",
      "2022-08-30 19:42:05,009 epoch 4 - iter 24/67 - loss 0.33447584 - samples/sec: 92.65 - lr: 0.200667\n",
      "2022-08-30 19:42:07,822 epoch 4 - iter 30/67 - loss 0.33507182 - samples/sec: 109.09 - lr: 0.200667\n",
      "2022-08-30 19:42:11,032 epoch 4 - iter 36/67 - loss 0.33385337 - samples/sec: 95.45 - lr: 0.200667\n",
      "2022-08-30 19:42:13,993 epoch 4 - iter 42/67 - loss 0.33505424 - samples/sec: 103.20 - lr: 0.200667\n",
      "2022-08-30 19:42:17,139 epoch 4 - iter 48/67 - loss 0.33550814 - samples/sec: 97.15 - lr: 0.200667\n",
      "2022-08-30 19:42:19,996 epoch 4 - iter 54/67 - loss 0.33658247 - samples/sec: 107.18 - lr: 0.200667\n",
      "2022-08-30 19:42:23,245 epoch 4 - iter 60/67 - loss 0.33701292 - samples/sec: 94.25 - lr: 0.200667\n",
      "2022-08-30 19:42:26,255 epoch 4 - iter 66/67 - loss 0.33852886 - samples/sec: 101.63 - lr: 0.200667\n",
      "2022-08-30 19:42:26,775 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:42:26,776 EPOCH 4 done: loss 0.3386 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:42:28,919 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:42:28,948 DEV : loss 0.24604949355125427 - f1-score (micro avg)  0.9155\n",
      "2022-08-30 19:42:28,965 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:42:28,966 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:42:31,760 epoch 5 - iter 6/67 - loss 0.33680985 - samples/sec: 107.41 - lr: 0.200667\n",
      "2022-08-30 19:42:34,650 epoch 5 - iter 12/67 - loss 0.34033452 - samples/sec: 105.97 - lr: 0.200667\n",
      "2022-08-30 19:42:37,630 epoch 5 - iter 18/67 - loss 0.34041985 - samples/sec: 103.34 - lr: 0.200667\n",
      "2022-08-30 19:42:40,949 epoch 5 - iter 24/67 - loss 0.33996261 - samples/sec: 92.71 - lr: 0.200667\n",
      "2022-08-30 19:42:43,771 epoch 5 - iter 30/67 - loss 0.34171953 - samples/sec: 108.50 - lr: 0.200667\n",
      "2022-08-30 19:42:46,759 epoch 5 - iter 36/67 - loss 0.34018151 - samples/sec: 102.39 - lr: 0.200667\n",
      "2022-08-30 19:42:49,785 epoch 5 - iter 42/67 - loss 0.34015074 - samples/sec: 101.08 - lr: 0.200667\n",
      "2022-08-30 19:42:53,011 epoch 5 - iter 48/67 - loss 0.34135750 - samples/sec: 94.88 - lr: 0.200667\n",
      "2022-08-30 19:42:56,009 epoch 5 - iter 54/67 - loss 0.34205174 - samples/sec: 102.25 - lr: 0.200667\n",
      "2022-08-30 19:42:59,204 epoch 5 - iter 60/67 - loss 0.34320465 - samples/sec: 95.79 - lr: 0.200667\n",
      "2022-08-30 19:43:02,761 epoch 5 - iter 66/67 - loss 0.34277045 - samples/sec: 85.76 - lr: 0.200667\n",
      "2022-08-30 19:43:03,170 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:43:03,171 EPOCH 5 done: loss 0.3428 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:43:03,991 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:43:04,020 DEV : loss 0.2506684958934784 - f1-score (micro avg)  0.9126\n",
      "2022-08-30 19:43:04,037 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 19:43:04,038 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:43:06,865 epoch 6 - iter 6/67 - loss 0.34685527 - samples/sec: 106.19 - lr: 0.200667\n",
      "2022-08-30 19:43:09,817 epoch 6 - iter 12/67 - loss 0.34445481 - samples/sec: 103.70 - lr: 0.200667\n",
      "2022-08-30 19:43:12,868 epoch 6 - iter 18/67 - loss 0.34208880 - samples/sec: 100.23 - lr: 0.200667\n",
      "2022-08-30 19:43:15,758 epoch 6 - iter 24/67 - loss 0.33902647 - samples/sec: 106.01 - lr: 0.200667\n",
      "2022-08-30 19:43:18,672 epoch 6 - iter 30/67 - loss 0.33909923 - samples/sec: 105.86 - lr: 0.200667\n",
      "2022-08-30 19:43:22,143 epoch 6 - iter 36/67 - loss 0.33990913 - samples/sec: 87.92 - lr: 0.200667\n",
      "2022-08-30 19:43:25,315 epoch 6 - iter 42/67 - loss 0.34315529 - samples/sec: 96.62 - lr: 0.200667\n",
      "2022-08-30 19:43:28,548 epoch 6 - iter 48/67 - loss 0.34255829 - samples/sec: 94.70 - lr: 0.200667\n",
      "2022-08-30 19:43:31,318 epoch 6 - iter 54/67 - loss 0.34058796 - samples/sec: 110.91 - lr: 0.200667\n",
      "2022-08-30 19:43:34,263 epoch 6 - iter 60/67 - loss 0.33896207 - samples/sec: 104.13 - lr: 0.200667\n",
      "2022-08-30 19:43:37,180 epoch 6 - iter 66/67 - loss 0.34090660 - samples/sec: 104.86 - lr: 0.200667\n",
      "2022-08-30 19:43:37,596 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:43:37,597 EPOCH 6 done: loss 0.3413 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:43:38,392 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:43:38,423 DEV : loss 0.2457042932510376 - f1-score (micro avg)  0.9154\n",
      "2022-08-30 19:43:38,442 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 19:43:38,443 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:43:41,309 epoch 7 - iter 6/67 - loss 0.35060664 - samples/sec: 104.71 - lr: 0.200667\n",
      "2022-08-30 19:43:44,370 epoch 7 - iter 12/67 - loss 0.34184394 - samples/sec: 100.91 - lr: 0.200667\n",
      "2022-08-30 19:43:47,519 epoch 7 - iter 18/67 - loss 0.33946676 - samples/sec: 97.82 - lr: 0.200667\n",
      "2022-08-30 19:43:50,497 epoch 7 - iter 24/67 - loss 0.33990981 - samples/sec: 102.99 - lr: 0.200667\n",
      "2022-08-30 19:43:54,206 epoch 7 - iter 30/67 - loss 0.33437952 - samples/sec: 82.37 - lr: 0.200667\n",
      "2022-08-30 19:43:57,210 epoch 7 - iter 36/67 - loss 0.33266896 - samples/sec: 101.73 - lr: 0.200667\n",
      "2022-08-30 19:44:00,306 epoch 7 - iter 42/67 - loss 0.33214040 - samples/sec: 98.91 - lr: 0.200667\n",
      "2022-08-30 19:44:03,165 epoch 7 - iter 48/67 - loss 0.33150917 - samples/sec: 107.10 - lr: 0.200667\n",
      "2022-08-30 19:44:06,338 epoch 7 - iter 54/67 - loss 0.33264546 - samples/sec: 96.34 - lr: 0.200667\n",
      "2022-08-30 19:44:09,345 epoch 7 - iter 60/67 - loss 0.33388214 - samples/sec: 102.04 - lr: 0.200667\n",
      "2022-08-30 19:44:12,173 epoch 7 - iter 66/67 - loss 0.33465897 - samples/sec: 108.74 - lr: 0.200667\n",
      "2022-08-30 19:44:12,587 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:44:12,587 EPOCH 7 done: loss 0.3342 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:44:13,417 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:44:13,443 DEV : loss 0.24959738552570343 - f1-score (micro avg)  0.9139\n",
      "2022-08-30 19:44:13,459 Epoch     7: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 19:44:13,459 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 19:44:13,460 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:44:16,213 epoch 8 - iter 6/67 - loss 0.32344699 - samples/sec: 109.05 - lr: 0.100333\n",
      "2022-08-30 19:44:19,890 epoch 8 - iter 12/67 - loss 0.32744084 - samples/sec: 82.85 - lr: 0.100333\n",
      "2022-08-30 19:44:22,853 epoch 8 - iter 18/67 - loss 0.32608339 - samples/sec: 103.20 - lr: 0.100333\n",
      "2022-08-30 19:44:25,707 epoch 8 - iter 24/67 - loss 0.32383184 - samples/sec: 107.60 - lr: 0.100333\n",
      "2022-08-30 19:44:28,784 epoch 8 - iter 30/67 - loss 0.32734166 - samples/sec: 99.37 - lr: 0.100333\n",
      "2022-08-30 19:44:31,931 epoch 8 - iter 36/67 - loss 0.32819551 - samples/sec: 97.47 - lr: 0.100333\n",
      "2022-08-30 19:44:35,325 epoch 8 - iter 42/67 - loss 0.32620923 - samples/sec: 90.14 - lr: 0.100333\n",
      "2022-08-30 19:44:38,181 epoch 8 - iter 48/67 - loss 0.32712645 - samples/sec: 107.53 - lr: 0.100333\n",
      "2022-08-30 19:44:41,581 epoch 8 - iter 54/67 - loss 0.32573787 - samples/sec: 90.09 - lr: 0.100333\n",
      "2022-08-30 19:44:44,912 epoch 8 - iter 60/67 - loss 0.32587372 - samples/sec: 91.66 - lr: 0.100333\n",
      "2022-08-30 19:44:48,093 epoch 8 - iter 66/67 - loss 0.32570582 - samples/sec: 96.18 - lr: 0.100333\n",
      "2022-08-30 19:44:48,565 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:44:48,566 EPOCH 8 done: loss 0.3250 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:44:49,398 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:44:49,428 DEV : loss 0.24004100263118744 - f1-score (micro avg)  0.9172\n",
      "2022-08-30 19:44:49,443 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:44:49,444 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:44:52,618 epoch 9 - iter 6/67 - loss 0.29771663 - samples/sec: 94.58 - lr: 0.100333\n",
      "2022-08-30 19:44:55,646 epoch 9 - iter 12/67 - loss 0.31154169 - samples/sec: 101.52 - lr: 0.100333\n",
      "2022-08-30 19:44:59,259 epoch 9 - iter 18/67 - loss 0.31830761 - samples/sec: 84.70 - lr: 0.100333\n",
      "2022-08-30 19:45:02,399 epoch 9 - iter 24/67 - loss 0.31575860 - samples/sec: 97.40 - lr: 0.100333\n",
      "2022-08-30 19:45:05,671 epoch 9 - iter 30/67 - loss 0.31390590 - samples/sec: 93.66 - lr: 0.100333\n",
      "2022-08-30 19:45:08,540 epoch 9 - iter 36/67 - loss 0.31396407 - samples/sec: 106.84 - lr: 0.100333\n",
      "2022-08-30 19:45:11,815 epoch 9 - iter 42/67 - loss 0.31708659 - samples/sec: 93.23 - lr: 0.100333\n",
      "2022-08-30 19:45:14,647 epoch 9 - iter 48/67 - loss 0.31792497 - samples/sec: 108.42 - lr: 0.100333\n",
      "2022-08-30 19:45:17,913 epoch 9 - iter 54/67 - loss 0.32010746 - samples/sec: 93.66 - lr: 0.100333\n",
      "2022-08-30 19:45:21,354 epoch 9 - iter 60/67 - loss 0.32093266 - samples/sec: 88.82 - lr: 0.100333\n",
      "2022-08-30 19:45:24,839 epoch 9 - iter 66/67 - loss 0.32264321 - samples/sec: 88.05 - lr: 0.100333\n",
      "2022-08-30 19:45:25,217 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:45:25,217 EPOCH 9 done: loss 0.3225 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:45:26,065 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:45:26,101 DEV : loss 0.240717813372612 - f1-score (micro avg)  0.9185\n",
      "2022-08-30 19:45:26,117 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:45:26,117 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:45:26,874 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:45:30,040 epoch 10 - iter 6/67 - loss 0.30913372 - samples/sec: 94.82 - lr: 0.100333\n",
      "2022-08-30 19:45:33,308 epoch 10 - iter 12/67 - loss 0.32257855 - samples/sec: 93.55 - lr: 0.100333\n",
      "2022-08-30 19:45:36,630 epoch 10 - iter 18/67 - loss 0.31676593 - samples/sec: 92.34 - lr: 0.100333\n",
      "2022-08-30 19:45:39,585 epoch 10 - iter 24/67 - loss 0.31308363 - samples/sec: 103.66 - lr: 0.100333\n",
      "2022-08-30 19:45:43,111 epoch 10 - iter 30/67 - loss 0.31221484 - samples/sec: 86.61 - lr: 0.100333\n",
      "2022-08-30 19:45:46,374 epoch 10 - iter 36/67 - loss 0.31027253 - samples/sec: 93.64 - lr: 0.100333\n",
      "2022-08-30 19:45:49,349 epoch 10 - iter 42/67 - loss 0.31347817 - samples/sec: 103.27 - lr: 0.100333\n",
      "2022-08-30 19:45:52,460 epoch 10 - iter 48/67 - loss 0.31580434 - samples/sec: 99.67 - lr: 0.100333\n",
      "2022-08-30 19:45:55,098 epoch 10 - iter 54/67 - loss 0.31836833 - samples/sec: 117.19 - lr: 0.100333\n",
      "2022-08-30 19:45:58,565 epoch 10 - iter 60/67 - loss 0.31831924 - samples/sec: 88.11 - lr: 0.100333\n",
      "2022-08-30 19:46:02,157 epoch 10 - iter 66/67 - loss 0.31882208 - samples/sec: 85.30 - lr: 0.100333\n",
      "2022-08-30 19:46:02,678 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:46:02,679 EPOCH 10 done: loss 0.3193 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:46:03,560 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:46:03,592 DEV : loss 0.24060526490211487 - f1-score (micro avg)  0.9167\n",
      "2022-08-30 19:46:03,608 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:46:03,609 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:46:06,776 epoch 11 - iter 6/67 - loss 0.31909622 - samples/sec: 94.77 - lr: 0.100333\n",
      "2022-08-30 19:46:09,812 epoch 11 - iter 12/67 - loss 0.31718457 - samples/sec: 100.84 - lr: 0.100333\n",
      "2022-08-30 19:46:13,003 epoch 11 - iter 18/67 - loss 0.32467816 - samples/sec: 95.97 - lr: 0.100333\n",
      "2022-08-30 19:46:16,110 epoch 11 - iter 24/67 - loss 0.32214210 - samples/sec: 98.63 - lr: 0.100333\n",
      "2022-08-30 19:46:19,194 epoch 11 - iter 30/67 - loss 0.32132339 - samples/sec: 99.24 - lr: 0.100333\n",
      "2022-08-30 19:46:22,950 epoch 11 - iter 36/67 - loss 0.31653548 - samples/sec: 81.20 - lr: 0.100333\n",
      "2022-08-30 19:46:25,817 epoch 11 - iter 42/67 - loss 0.31653178 - samples/sec: 106.91 - lr: 0.100333\n",
      "2022-08-30 19:46:28,900 epoch 11 - iter 48/67 - loss 0.31758687 - samples/sec: 99.22 - lr: 0.100333\n",
      "2022-08-30 19:46:32,305 epoch 11 - iter 54/67 - loss 0.31921799 - samples/sec: 89.69 - lr: 0.100333\n",
      "2022-08-30 19:46:35,290 epoch 11 - iter 60/67 - loss 0.32065609 - samples/sec: 104.18 - lr: 0.100333\n",
      "2022-08-30 19:46:38,093 epoch 11 - iter 66/67 - loss 0.31802804 - samples/sec: 109.25 - lr: 0.100333\n",
      "2022-08-30 19:46:38,464 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:46:38,464 EPOCH 11 done: loss 0.3177 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:46:39,305 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:46:39,336 DEV : loss 0.23910678923130035 - f1-score (micro avg)  0.9175\n",
      "2022-08-30 19:46:39,356 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 19:46:39,358 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:46:42,153 epoch 12 - iter 6/67 - loss 0.28714084 - samples/sec: 107.41 - lr: 0.100333\n",
      "2022-08-30 19:46:45,403 epoch 12 - iter 12/67 - loss 0.29088596 - samples/sec: 94.03 - lr: 0.100333\n",
      "2022-08-30 19:46:48,817 epoch 12 - iter 18/67 - loss 0.30077827 - samples/sec: 89.82 - lr: 0.100333\n",
      "2022-08-30 19:46:51,977 epoch 12 - iter 24/67 - loss 0.31075640 - samples/sec: 96.71 - lr: 0.100333\n",
      "2022-08-30 19:46:54,752 epoch 12 - iter 30/67 - loss 0.30703352 - samples/sec: 110.54 - lr: 0.100333\n",
      "2022-08-30 19:46:58,291 epoch 12 - iter 36/67 - loss 0.30862754 - samples/sec: 86.31 - lr: 0.100333\n",
      "2022-08-30 19:47:01,300 epoch 12 - iter 42/67 - loss 0.30914689 - samples/sec: 102.32 - lr: 0.100333\n",
      "2022-08-30 19:47:04,312 epoch 12 - iter 48/67 - loss 0.30887963 - samples/sec: 101.71 - lr: 0.100333\n",
      "2022-08-30 19:47:07,722 epoch 12 - iter 54/67 - loss 0.31147009 - samples/sec: 89.82 - lr: 0.100333\n",
      "2022-08-30 19:47:11,028 epoch 12 - iter 60/67 - loss 0.31190806 - samples/sec: 92.59 - lr: 0.100333\n",
      "2022-08-30 19:47:14,330 epoch 12 - iter 66/67 - loss 0.31169101 - samples/sec: 92.49 - lr: 0.100333\n",
      "2022-08-30 19:47:14,850 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:47:14,850 EPOCH 12 done: loss 0.3117 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:47:15,805 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:47:15,848 DEV : loss 0.2402932345867157 - f1-score (micro avg)  0.9168\n",
      "2022-08-30 19:47:15,870 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:47:16,910 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:47:16,911 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 19:47:17,109 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:47:18,539 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:47:18,567 0.9217\t0.9217\t0.9217\t0.9217\n",
      "2022-08-30 19:47:18,567 \n",
      "Results:\n",
      "- F-score (micro) 0.9217\n",
      "- F-score (macro) 0.8042\n",
      "- Accuracy 0.9217\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8894    0.9217    0.9053      1353\n",
      "         ADJ     0.8546    0.9182    0.8852       672\n",
      "       PUNCT     0.9985    1.0000    0.9992       660\n",
      "         ADP     0.9941    0.9825    0.9883       514\n",
      "        VERB     0.8938    0.8998    0.8968       449\n",
      "       PROPN     0.8603    0.7076    0.7765       383\n",
      "         AUX     0.9880    0.9851    0.9865       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.9073    0.8509    0.8782       161\n",
      "         ADV     0.8182    0.8344    0.8262       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9636    0.7465    0.8413        71\n",
      "        PART     1.0000    0.8571    0.9231        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9217      5264\n",
      "   macro avg     0.8217    0.7904    0.8042      5264\n",
      "weighted avg     0.9224    0.9217    0.9210      5264\n",
      "\n",
      "2022-08-30 19:47:18,568 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:47:18,570 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:47:19,082 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 19:49:47,710 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:49:47,711 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 19:49:47,711 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:49:47,712 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 19:49:47,712 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:49:47,712 Parameters:\n",
      "2022-08-30 19:49:47,713  - learning_rate: \"0.200667\"\n",
      "2022-08-30 19:49:47,713  - mini_batch_size: \"70\"\n",
      "2022-08-30 19:49:47,714  - patience: \"3\"\n",
      "2022-08-30 19:49:47,714  - anneal_factor: \"0.5\"\n",
      "2022-08-30 19:49:47,715  - max_epochs: \"10\"\n",
      "2022-08-30 19:49:47,716  - shuffle: \"True\"\n",
      "2022-08-30 19:49:47,717  - train_with_dev: \"False\"\n",
      "2022-08-30 19:49:47,717  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 19:49:47,717 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:49:47,718 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 19:49:47,718 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:49:47,719 Device: cpu\n",
      "2022-08-30 19:49:47,720 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:49:47,720 Embeddings storage mode: cpu\n",
      "2022-08-30 19:49:47,721 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:49:50,177 epoch 1 - iter 4/48 - loss 0.30871523 - samples/sec: 114.05 - lr: 0.200667\n",
      "2022-08-30 19:49:53,285 epoch 1 - iter 8/48 - loss 0.31869688 - samples/sec: 92.11 - lr: 0.200667\n",
      "2022-08-30 19:49:55,751 epoch 1 - iter 12/48 - loss 0.32230469 - samples/sec: 117.06 - lr: 0.200667\n",
      "2022-08-30 19:49:58,307 epoch 1 - iter 16/48 - loss 0.31574904 - samples/sec: 112.22 - lr: 0.200667\n",
      "2022-08-30 19:50:00,966 epoch 1 - iter 20/48 - loss 0.30894071 - samples/sec: 108.19 - lr: 0.200667\n",
      "2022-08-30 19:50:03,848 epoch 1 - iter 24/48 - loss 0.31366776 - samples/sec: 99.26 - lr: 0.200667\n",
      "2022-08-30 19:50:06,334 epoch 1 - iter 28/48 - loss 0.31253742 - samples/sec: 115.23 - lr: 0.200667\n",
      "2022-08-30 19:50:09,064 epoch 1 - iter 32/48 - loss 0.31186783 - samples/sec: 105.38 - lr: 0.200667\n",
      "2022-08-30 19:50:11,633 epoch 1 - iter 36/48 - loss 0.31348540 - samples/sec: 111.69 - lr: 0.200667\n",
      "2022-08-30 19:50:14,333 epoch 1 - iter 40/48 - loss 0.31077387 - samples/sec: 106.22 - lr: 0.200667\n",
      "2022-08-30 19:50:17,162 epoch 1 - iter 44/48 - loss 0.31553590 - samples/sec: 101.52 - lr: 0.200667\n",
      "2022-08-30 19:50:20,293 epoch 1 - iter 48/48 - loss 0.32484461 - samples/sec: 91.62 - lr: 0.200667\n",
      "2022-08-30 19:50:20,354 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:50:20,355 EPOCH 1 done: loss 0.3248 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:50:21,256 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:50:21,286 DEV : loss 0.2570335865020752 - f1-score (micro avg)  0.9098\n",
      "2022-08-30 19:50:21,306 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:50:21,307 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:50:22,023 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:50:24,840 epoch 2 - iter 4/48 - loss 0.33949392 - samples/sec: 99.47 - lr: 0.200667\n",
      "2022-08-30 19:50:27,556 epoch 2 - iter 8/48 - loss 0.33156677 - samples/sec: 105.42 - lr: 0.200667\n",
      "2022-08-30 19:50:30,548 epoch 2 - iter 12/48 - loss 0.33097199 - samples/sec: 95.82 - lr: 0.200667\n",
      "2022-08-30 19:50:33,418 epoch 2 - iter 16/48 - loss 0.33071586 - samples/sec: 99.82 - lr: 0.200667\n",
      "2022-08-30 19:50:36,405 epoch 2 - iter 20/48 - loss 0.32779315 - samples/sec: 96.32 - lr: 0.200667\n",
      "2022-08-30 19:50:39,310 epoch 2 - iter 24/48 - loss 0.32961750 - samples/sec: 99.43 - lr: 0.200667\n",
      "2022-08-30 19:50:42,075 epoch 2 - iter 28/48 - loss 0.33110470 - samples/sec: 103.78 - lr: 0.200667\n",
      "2022-08-30 19:50:44,693 epoch 2 - iter 32/48 - loss 0.33109495 - samples/sec: 109.42 - lr: 0.200667\n",
      "2022-08-30 19:50:47,194 epoch 2 - iter 36/48 - loss 0.33045775 - samples/sec: 114.80 - lr: 0.200667\n",
      "2022-08-30 19:50:49,762 epoch 2 - iter 40/48 - loss 0.32984588 - samples/sec: 111.51 - lr: 0.200667\n",
      "2022-08-30 19:50:52,228 epoch 2 - iter 44/48 - loss 0.32854144 - samples/sec: 116.52 - lr: 0.200667\n",
      "2022-08-30 19:50:55,071 epoch 2 - iter 48/48 - loss 0.32691083 - samples/sec: 100.39 - lr: 0.200667\n",
      "2022-08-30 19:50:55,126 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:50:55,126 EPOCH 2 done: loss 0.3269 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:50:55,947 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:50:55,979 DEV : loss 0.24922680854797363 - f1-score (micro avg)  0.9139\n",
      "2022-08-30 19:50:55,996 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:50:55,997 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:50:56,699 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:50:59,552 epoch 3 - iter 4/48 - loss 0.31966277 - samples/sec: 98.21 - lr: 0.200667\n",
      "2022-08-30 19:51:02,629 epoch 3 - iter 8/48 - loss 0.32413274 - samples/sec: 92.87 - lr: 0.200667\n",
      "2022-08-30 19:51:05,304 epoch 3 - iter 12/48 - loss 0.32280544 - samples/sec: 106.87 - lr: 0.200667\n",
      "2022-08-30 19:51:08,028 epoch 3 - iter 16/48 - loss 0.31846458 - samples/sec: 105.34 - lr: 0.200667\n",
      "2022-08-30 19:51:10,948 epoch 3 - iter 20/48 - loss 0.31793220 - samples/sec: 97.90 - lr: 0.200667\n",
      "2022-08-30 19:51:13,421 epoch 3 - iter 24/48 - loss 0.32165555 - samples/sec: 115.94 - lr: 0.200667\n",
      "2022-08-30 19:51:16,068 epoch 3 - iter 28/48 - loss 0.32229702 - samples/sec: 108.19 - lr: 0.200667\n",
      "2022-08-30 19:51:19,021 epoch 3 - iter 32/48 - loss 0.32258353 - samples/sec: 96.92 - lr: 0.200667\n",
      "2022-08-30 19:51:21,677 epoch 3 - iter 36/48 - loss 0.32184284 - samples/sec: 107.94 - lr: 0.200667\n",
      "2022-08-30 19:51:24,379 epoch 3 - iter 40/48 - loss 0.32321635 - samples/sec: 105.86 - lr: 0.200667\n",
      "2022-08-30 19:51:26,990 epoch 3 - iter 44/48 - loss 0.32372040 - samples/sec: 111.33 - lr: 0.200667\n",
      "2022-08-30 19:51:29,545 epoch 3 - iter 48/48 - loss 0.32442150 - samples/sec: 112.40 - lr: 0.200667\n",
      "2022-08-30 19:51:29,610 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:51:29,610 EPOCH 3 done: loss 0.3244 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:51:30,493 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:51:30,534 DEV : loss 0.2435920685529709 - f1-score (micro avg)  0.9155\n",
      "2022-08-30 19:51:30,558 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:51:30,559 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:51:31,271 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:51:33,832 epoch 4 - iter 4/48 - loss 0.31261952 - samples/sec: 109.37 - lr: 0.200667\n",
      "2022-08-30 19:51:36,136 epoch 4 - iter 8/48 - loss 0.31025537 - samples/sec: 124.67 - lr: 0.200667\n",
      "2022-08-30 19:51:38,621 epoch 4 - iter 12/48 - loss 0.31512141 - samples/sec: 115.65 - lr: 0.200667\n",
      "2022-08-30 19:51:41,545 epoch 4 - iter 16/48 - loss 0.32707087 - samples/sec: 98.11 - lr: 0.200667\n",
      "2022-08-30 19:51:44,445 epoch 4 - iter 20/48 - loss 0.32678028 - samples/sec: 98.66 - lr: 0.200667\n",
      "2022-08-30 19:51:47,394 epoch 4 - iter 24/48 - loss 0.32695003 - samples/sec: 97.05 - lr: 0.200667\n",
      "2022-08-30 19:51:50,342 epoch 4 - iter 28/48 - loss 0.32380250 - samples/sec: 98.25 - lr: 0.200667\n",
      "2022-08-30 19:51:53,013 epoch 4 - iter 32/48 - loss 0.32691903 - samples/sec: 108.19 - lr: 0.200667\n",
      "2022-08-30 19:51:55,666 epoch 4 - iter 36/48 - loss 0.32593764 - samples/sec: 107.98 - lr: 0.200667\n",
      "2022-08-30 19:51:58,328 epoch 4 - iter 40/48 - loss 0.32689339 - samples/sec: 107.61 - lr: 0.200667\n",
      "2022-08-30 19:52:00,957 epoch 4 - iter 44/48 - loss 0.32761684 - samples/sec: 111.42 - lr: 0.200667\n",
      "2022-08-30 19:52:03,421 epoch 4 - iter 48/48 - loss 0.32744320 - samples/sec: 116.62 - lr: 0.200667\n",
      "2022-08-30 19:52:03,503 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:52:03,504 EPOCH 4 done: loss 0.3274 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:52:04,347 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:52:04,380 DEV : loss 0.24670639634132385 - f1-score (micro avg)  0.9142\n",
      "2022-08-30 19:52:04,399 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:52:04,400 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:52:06,751 epoch 5 - iter 4/48 - loss 0.31920162 - samples/sec: 119.15 - lr: 0.200667\n",
      "2022-08-30 19:52:09,178 epoch 5 - iter 8/48 - loss 0.32371933 - samples/sec: 118.29 - lr: 0.200667\n",
      "2022-08-30 19:52:12,338 epoch 5 - iter 12/48 - loss 0.32050675 - samples/sec: 90.26 - lr: 0.200667\n",
      "2022-08-30 19:52:15,002 epoch 5 - iter 16/48 - loss 0.32420579 - samples/sec: 108.57 - lr: 0.200667\n",
      "2022-08-30 19:52:17,505 epoch 5 - iter 20/48 - loss 0.32554040 - samples/sec: 114.66 - lr: 0.200667\n",
      "2022-08-30 19:52:20,286 epoch 5 - iter 24/48 - loss 0.32528722 - samples/sec: 103.32 - lr: 0.200667\n",
      "2022-08-30 19:52:22,900 epoch 5 - iter 28/48 - loss 0.32219934 - samples/sec: 109.59 - lr: 0.200667\n",
      "2022-08-30 19:52:25,193 epoch 5 - iter 32/48 - loss 0.32540624 - samples/sec: 125.45 - lr: 0.200667\n",
      "2022-08-30 19:52:28,212 epoch 5 - iter 36/48 - loss 0.32508425 - samples/sec: 94.85 - lr: 0.200667\n",
      "2022-08-30 19:52:31,097 epoch 5 - iter 40/48 - loss 0.32426670 - samples/sec: 99.19 - lr: 0.200667\n",
      "2022-08-30 19:52:34,177 epoch 5 - iter 44/48 - loss 0.32414622 - samples/sec: 93.61 - lr: 0.200667\n",
      "2022-08-30 19:52:36,927 epoch 5 - iter 48/48 - loss 0.32329724 - samples/sec: 103.97 - lr: 0.200667\n",
      "2022-08-30 19:52:36,986 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:52:36,986 EPOCH 5 done: loss 0.3233 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:52:37,843 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:52:37,875 DEV : loss 0.2516809105873108 - f1-score (micro avg)  0.9131\n",
      "2022-08-30 19:52:37,896 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 19:52:37,897 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:52:40,881 epoch 6 - iter 4/48 - loss 0.30955612 - samples/sec: 93.87 - lr: 0.200667\n",
      "2022-08-30 19:52:43,963 epoch 6 - iter 8/48 - loss 0.30783923 - samples/sec: 92.56 - lr: 0.200667\n",
      "2022-08-30 19:52:46,892 epoch 6 - iter 12/48 - loss 0.31306862 - samples/sec: 97.63 - lr: 0.200667\n",
      "2022-08-30 19:52:49,539 epoch 6 - iter 16/48 - loss 0.31402837 - samples/sec: 108.57 - lr: 0.200667\n",
      "2022-08-30 19:52:52,079 epoch 6 - iter 20/48 - loss 0.31553519 - samples/sec: 112.81 - lr: 0.200667\n",
      "2022-08-30 19:52:54,834 epoch 6 - iter 24/48 - loss 0.32190559 - samples/sec: 103.93 - lr: 0.200667\n",
      "2022-08-30 19:52:57,191 epoch 6 - iter 28/48 - loss 0.32363568 - samples/sec: 121.63 - lr: 0.200667\n",
      "2022-08-30 19:52:59,709 epoch 6 - iter 32/48 - loss 0.32451983 - samples/sec: 114.52 - lr: 0.200667\n",
      "2022-08-30 19:53:02,506 epoch 6 - iter 36/48 - loss 0.32353999 - samples/sec: 102.26 - lr: 0.200667\n",
      "2022-08-30 19:53:05,032 epoch 6 - iter 40/48 - loss 0.32266486 - samples/sec: 113.41 - lr: 0.200667\n",
      "2022-08-30 19:53:07,740 epoch 6 - iter 44/48 - loss 0.32162940 - samples/sec: 105.70 - lr: 0.200667\n",
      "2022-08-30 19:53:10,508 epoch 6 - iter 48/48 - loss 0.32220232 - samples/sec: 103.47 - lr: 0.200667\n",
      "2022-08-30 19:53:10,579 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:53:10,579 EPOCH 6 done: loss 0.3222 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:53:11,379 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:53:11,411 DEV : loss 0.2466978281736374 - f1-score (micro avg)  0.9185\n",
      "2022-08-30 19:53:11,426 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:53:11,427 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:53:12,223 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:53:14,698 epoch 7 - iter 4/48 - loss 0.33084121 - samples/sec: 113.27 - lr: 0.200667\n",
      "2022-08-30 19:53:17,184 epoch 7 - iter 8/48 - loss 0.32648919 - samples/sec: 115.27 - lr: 0.200667\n",
      "2022-08-30 19:53:19,545 epoch 7 - iter 12/48 - loss 0.32782630 - samples/sec: 121.69 - lr: 0.200667\n",
      "2022-08-30 19:53:22,217 epoch 7 - iter 16/48 - loss 0.32399216 - samples/sec: 107.24 - lr: 0.200667\n",
      "2022-08-30 19:53:25,197 epoch 7 - iter 20/48 - loss 0.32780917 - samples/sec: 95.79 - lr: 0.200667\n",
      "2022-08-30 19:53:27,894 epoch 7 - iter 24/48 - loss 0.32337613 - samples/sec: 106.18 - lr: 0.200667\n",
      "2022-08-30 19:53:31,119 epoch 7 - iter 28/48 - loss 0.32406373 - samples/sec: 88.38 - lr: 0.200667\n",
      "2022-08-30 19:53:33,993 epoch 7 - iter 32/48 - loss 0.32574859 - samples/sec: 99.64 - lr: 0.200667\n",
      "2022-08-30 19:53:36,746 epoch 7 - iter 36/48 - loss 0.32416832 - samples/sec: 103.97 - lr: 0.200667\n",
      "2022-08-30 19:53:39,351 epoch 7 - iter 40/48 - loss 0.32491808 - samples/sec: 110.19 - lr: 0.200667\n",
      "2022-08-30 19:53:41,948 epoch 7 - iter 44/48 - loss 0.32442761 - samples/sec: 112.22 - lr: 0.200667\n",
      "2022-08-30 19:53:44,432 epoch 7 - iter 48/48 - loss 0.32122202 - samples/sec: 115.80 - lr: 0.200667\n",
      "2022-08-30 19:53:44,488 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:53:44,489 EPOCH 7 done: loss 0.3212 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:53:45,262 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:53:45,293 DEV : loss 0.24902057647705078 - f1-score (micro avg)  0.9178\n",
      "2022-08-30 19:53:45,308 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:53:45,309 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:53:47,789 epoch 8 - iter 4/48 - loss 0.33114459 - samples/sec: 112.95 - lr: 0.200667\n",
      "2022-08-30 19:53:50,565 epoch 8 - iter 8/48 - loss 0.32450902 - samples/sec: 102.90 - lr: 0.200667\n",
      "2022-08-30 19:53:53,124 epoch 8 - iter 12/48 - loss 0.32027495 - samples/sec: 112.09 - lr: 0.200667\n",
      "2022-08-30 19:53:55,683 epoch 8 - iter 16/48 - loss 0.32337757 - samples/sec: 111.91 - lr: 0.200667\n",
      "2022-08-30 19:53:58,233 epoch 8 - iter 20/48 - loss 0.32914754 - samples/sec: 112.31 - lr: 0.200667\n",
      "2022-08-30 19:54:00,963 epoch 8 - iter 24/48 - loss 0.32899381 - samples/sec: 104.79 - lr: 0.200667\n",
      "2022-08-30 19:54:03,860 epoch 8 - iter 28/48 - loss 0.33068876 - samples/sec: 98.73 - lr: 0.200667\n",
      "2022-08-30 19:54:06,715 epoch 8 - iter 32/48 - loss 0.33016975 - samples/sec: 100.04 - lr: 0.200667\n",
      "2022-08-30 19:54:10,878 epoch 8 - iter 36/48 - loss 0.33003806 - samples/sec: 68.28 - lr: 0.200667\n",
      "2022-08-30 19:54:13,835 epoch 8 - iter 40/48 - loss 0.32918155 - samples/sec: 96.55 - lr: 0.200667\n",
      "2022-08-30 19:54:16,552 epoch 8 - iter 44/48 - loss 0.32617811 - samples/sec: 105.34 - lr: 0.200667\n",
      "2022-08-30 19:54:18,975 epoch 8 - iter 48/48 - loss 0.32567038 - samples/sec: 118.59 - lr: 0.200667\n",
      "2022-08-30 19:54:19,033 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:54:19,033 EPOCH 8 done: loss 0.3257 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:54:19,842 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:54:19,868 DEV : loss 0.24826039373874664 - f1-score (micro avg)  0.9146\n",
      "2022-08-30 19:54:19,883 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 19:54:19,884 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:54:22,612 epoch 9 - iter 4/48 - loss 0.30263596 - samples/sec: 102.71 - lr: 0.200667\n",
      "2022-08-30 19:54:25,066 epoch 9 - iter 8/48 - loss 0.31008790 - samples/sec: 117.06 - lr: 0.200667\n",
      "2022-08-30 19:54:27,660 epoch 9 - iter 12/48 - loss 0.31354084 - samples/sec: 110.58 - lr: 0.200667\n",
      "2022-08-30 19:54:30,350 epoch 9 - iter 16/48 - loss 0.31466832 - samples/sec: 107.36 - lr: 0.200667\n",
      "2022-08-30 19:54:32,946 epoch 9 - iter 20/48 - loss 0.31497382 - samples/sec: 110.80 - lr: 0.200667\n",
      "2022-08-30 19:54:35,468 epoch 9 - iter 24/48 - loss 0.31819499 - samples/sec: 113.68 - lr: 0.200667\n",
      "2022-08-30 19:54:38,373 epoch 9 - iter 28/48 - loss 0.31881819 - samples/sec: 99.08 - lr: 0.200667\n",
      "2022-08-30 19:54:41,085 epoch 9 - iter 32/48 - loss 0.31831090 - samples/sec: 105.74 - lr: 0.200667\n",
      "2022-08-30 19:54:44,033 epoch 9 - iter 36/48 - loss 0.31696767 - samples/sec: 97.02 - lr: 0.200667\n",
      "2022-08-30 19:54:47,188 epoch 9 - iter 40/48 - loss 0.31766445 - samples/sec: 90.53 - lr: 0.200667\n",
      "2022-08-30 19:54:50,188 epoch 9 - iter 44/48 - loss 0.31966610 - samples/sec: 95.34 - lr: 0.200667\n",
      "2022-08-30 19:54:52,721 epoch 9 - iter 48/48 - loss 0.32035406 - samples/sec: 113.41 - lr: 0.200667\n",
      "2022-08-30 19:54:52,781 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:54:52,782 EPOCH 9 done: loss 0.3204 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:54:53,594 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:54:53,623 DEV : loss 0.2465985268354416 - f1-score (micro avg)  0.9172\n",
      "2022-08-30 19:54:53,638 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 19:54:53,639 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:54:56,396 epoch 10 - iter 4/48 - loss 0.31598458 - samples/sec: 101.60 - lr: 0.200667\n",
      "2022-08-30 19:54:58,937 epoch 10 - iter 8/48 - loss 0.31492601 - samples/sec: 113.27 - lr: 0.200667\n",
      "2022-08-30 19:55:01,561 epoch 10 - iter 12/48 - loss 0.32283649 - samples/sec: 109.29 - lr: 0.200667\n",
      "2022-08-30 19:55:04,014 epoch 10 - iter 16/48 - loss 0.32231157 - samples/sec: 116.86 - lr: 0.200667\n",
      "2022-08-30 19:55:06,905 epoch 10 - iter 20/48 - loss 0.32417582 - samples/sec: 98.97 - lr: 0.200667\n",
      "2022-08-30 19:55:09,780 epoch 10 - iter 24/48 - loss 0.31894528 - samples/sec: 99.47 - lr: 0.200667\n",
      "2022-08-30 19:55:12,143 epoch 10 - iter 28/48 - loss 0.31707654 - samples/sec: 121.53 - lr: 0.200667\n",
      "2022-08-30 19:55:14,672 epoch 10 - iter 32/48 - loss 0.31713687 - samples/sec: 113.50 - lr: 0.200667\n",
      "2022-08-30 19:55:17,100 epoch 10 - iter 36/48 - loss 0.31761126 - samples/sec: 118.09 - lr: 0.200667\n",
      "2022-08-30 19:55:19,956 epoch 10 - iter 40/48 - loss 0.31748627 - samples/sec: 100.00 - lr: 0.200667\n",
      "2022-08-30 19:55:23,319 epoch 10 - iter 44/48 - loss 0.31800848 - samples/sec: 84.69 - lr: 0.200667\n",
      "2022-08-30 19:55:25,961 epoch 10 - iter 48/48 - loss 0.31712464 - samples/sec: 108.70 - lr: 0.200667\n",
      "2022-08-30 19:55:26,021 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:55:26,022 EPOCH 10 done: loss 0.3171 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:55:26,815 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:55:26,842 DEV : loss 0.23851951956748962 - f1-score (micro avg)  0.9168\n",
      "2022-08-30 19:55:26,857 Epoch    10: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 19:55:26,858 BAD EPOCHS (no improvement): 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:55:27,828 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:55:27,829 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 19:55:28,008 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:55:29,323 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:55:29,352 0.9212\t0.9212\t0.9212\t0.9212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:55:29,354 \n",
      "Results:\n",
      "- F-score (micro) 0.9212\n",
      "- F-score (macro) 0.8022\n",
      "- Accuracy 0.9212\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8787    0.9261    0.9018      1353\n",
      "         ADJ     0.8608    0.9107    0.8850       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9902    0.9844    0.9873       514\n",
      "        VERB     0.9159    0.8976    0.9066       449\n",
      "       PROPN     0.8466    0.7206    0.7786       383\n",
      "         AUX     0.9880    0.9791    0.9835       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.9167    0.8199    0.8656       161\n",
      "         ADV     0.8389    0.8278    0.8333       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9474    0.7606    0.8437        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9212      5264\n",
      "   macro avg     0.8226    0.7856    0.8022      5264\n",
      "weighted avg     0.9218    0.9212    0.9206      5264\n",
      "\n",
      "2022-08-30 19:55:29,356 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:55:29,359 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 19:55:29,837 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 19:57:56,146 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:57:56,147 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 19:57:56,147 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:57:56,148 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 19:57:56,149 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:57:56,149 Parameters:\n",
      "2022-08-30 19:57:56,150  - learning_rate: \"0.200667\"\n",
      "2022-08-30 19:57:56,151  - mini_batch_size: \"70\"\n",
      "2022-08-30 19:57:56,151  - patience: \"3\"\n",
      "2022-08-30 19:57:56,152  - anneal_factor: \"0.5\"\n",
      "2022-08-30 19:57:56,152  - max_epochs: \"11\"\n",
      "2022-08-30 19:57:56,153  - shuffle: \"True\"\n",
      "2022-08-30 19:57:56,153  - train_with_dev: \"False\"\n",
      "2022-08-30 19:57:56,154  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 19:57:56,154 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:57:56,155 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 19:57:56,155 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:57:56,155 Device: cpu\n",
      "2022-08-30 19:57:56,156 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:57:56,156 Embeddings storage mode: cpu\n",
      "2022-08-30 19:57:56,156 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:57:58,632 epoch 1 - iter 4/48 - loss 0.30521650 - samples/sec: 113.18 - lr: 0.200667\n",
      "2022-08-30 19:58:01,600 epoch 1 - iter 8/48 - loss 0.30990255 - samples/sec: 96.15 - lr: 0.200667\n",
      "2022-08-30 19:58:03,922 epoch 1 - iter 12/48 - loss 0.31284096 - samples/sec: 123.78 - lr: 0.200667\n",
      "2022-08-30 19:58:06,630 epoch 1 - iter 16/48 - loss 0.30565752 - samples/sec: 106.02 - lr: 0.200667\n",
      "2022-08-30 19:58:09,198 epoch 1 - iter 20/48 - loss 0.29841253 - samples/sec: 112.13 - lr: 0.200667\n",
      "2022-08-30 19:58:12,014 epoch 1 - iter 24/48 - loss 0.30310195 - samples/sec: 101.38 - lr: 0.200667\n",
      "2022-08-30 19:58:14,661 epoch 1 - iter 28/48 - loss 0.30338351 - samples/sec: 108.02 - lr: 0.200667\n",
      "2022-08-30 19:58:17,420 epoch 1 - iter 32/48 - loss 0.30314745 - samples/sec: 103.93 - lr: 0.200667\n",
      "2022-08-30 19:58:19,880 epoch 1 - iter 36/48 - loss 0.30519740 - samples/sec: 118.09 - lr: 0.200667\n",
      "2022-08-30 19:58:22,585 epoch 1 - iter 40/48 - loss 0.30418257 - samples/sec: 105.66 - lr: 0.200667\n",
      "2022-08-30 19:58:25,288 epoch 1 - iter 44/48 - loss 0.30921410 - samples/sec: 105.90 - lr: 0.200667\n",
      "2022-08-30 19:58:28,343 epoch 1 - iter 48/48 - loss 0.31978861 - samples/sec: 93.83 - lr: 0.200667\n",
      "2022-08-30 19:58:28,415 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:58:28,416 EPOCH 1 done: loss 0.3198 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:58:29,251 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:58:29,278 DEV : loss 0.2558616101741791 - f1-score (micro avg)  0.9108\n",
      "2022-08-30 19:58:29,294 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:58:29,295 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:58:30,411 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:58:32,973 epoch 2 - iter 4/48 - loss 0.32892563 - samples/sec: 109.42 - lr: 0.200667\n",
      "2022-08-30 19:58:35,419 epoch 2 - iter 8/48 - loss 0.33439065 - samples/sec: 117.40 - lr: 0.200667\n",
      "2022-08-30 19:58:37,901 epoch 2 - iter 12/48 - loss 0.32728066 - samples/sec: 116.04 - lr: 0.200667\n",
      "2022-08-30 19:58:40,455 epoch 2 - iter 16/48 - loss 0.32879101 - samples/sec: 112.27 - lr: 0.200667\n",
      "2022-08-30 19:58:43,397 epoch 2 - iter 20/48 - loss 0.32423074 - samples/sec: 97.32 - lr: 0.200667\n",
      "2022-08-30 19:58:46,420 epoch 2 - iter 24/48 - loss 0.32454261 - samples/sec: 95.14 - lr: 0.200667\n",
      "2022-08-30 19:58:49,036 epoch 2 - iter 28/48 - loss 0.32398251 - samples/sec: 109.55 - lr: 0.200667\n",
      "2022-08-30 19:58:51,719 epoch 2 - iter 32/48 - loss 0.32339196 - samples/sec: 106.63 - lr: 0.200667\n",
      "2022-08-30 19:58:54,562 epoch 2 - iter 36/48 - loss 0.32150696 - samples/sec: 100.61 - lr: 0.200667\n",
      "2022-08-30 19:58:57,192 epoch 2 - iter 40/48 - loss 0.32192197 - samples/sec: 108.70 - lr: 0.200667\n",
      "2022-08-30 19:59:00,009 epoch 2 - iter 44/48 - loss 0.32180009 - samples/sec: 101.63 - lr: 0.200667\n",
      "2022-08-30 19:59:02,395 epoch 2 - iter 48/48 - loss 0.32324416 - samples/sec: 121.11 - lr: 0.200667\n",
      "2022-08-30 19:59:02,462 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:59:02,463 EPOCH 2 done: loss 0.3232 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:59:03,284 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:59:03,310 DEV : loss 0.24124456942081451 - f1-score (micro avg)  0.9168\n",
      "2022-08-30 19:59:03,324 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 19:59:03,325 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:59:04,074 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:59:07,018 epoch 3 - iter 4/48 - loss 0.33296474 - samples/sec: 95.14 - lr: 0.200667\n",
      "2022-08-30 19:59:10,204 epoch 3 - iter 8/48 - loss 0.34005450 - samples/sec: 89.66 - lr: 0.200667\n",
      "2022-08-30 19:59:13,099 epoch 3 - iter 12/48 - loss 0.33456877 - samples/sec: 98.77 - lr: 0.200667\n",
      "2022-08-30 19:59:15,902 epoch 3 - iter 16/48 - loss 0.33186703 - samples/sec: 102.15 - lr: 0.200667\n",
      "2022-08-30 19:59:18,596 epoch 3 - iter 20/48 - loss 0.33277662 - samples/sec: 106.10 - lr: 0.200667\n",
      "2022-08-30 19:59:21,090 epoch 3 - iter 24/48 - loss 0.32953740 - samples/sec: 115.18 - lr: 0.200667\n",
      "2022-08-30 19:59:23,406 epoch 3 - iter 28/48 - loss 0.32760710 - samples/sec: 124.44 - lr: 0.200667\n",
      "2022-08-30 19:59:26,206 epoch 3 - iter 32/48 - loss 0.32717860 - samples/sec: 102.38 - lr: 0.200667\n",
      "2022-08-30 19:59:28,507 epoch 3 - iter 36/48 - loss 0.32466227 - samples/sec: 124.83 - lr: 0.200667\n",
      "2022-08-30 19:59:31,270 epoch 3 - iter 40/48 - loss 0.32539816 - samples/sec: 103.97 - lr: 0.200667\n",
      "2022-08-30 19:59:34,163 epoch 3 - iter 44/48 - loss 0.32413195 - samples/sec: 98.63 - lr: 0.200667\n",
      "2022-08-30 19:59:36,640 epoch 3 - iter 48/48 - loss 0.32406076 - samples/sec: 116.09 - lr: 0.200667\n",
      "2022-08-30 19:59:36,736 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 19:59:36,737 EPOCH 3 done: loss 0.3241 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:59:37,600 Evaluating as a multi-label problem: False\n",
      "2022-08-30 19:59:37,635 DEV : loss 0.24674035608768463 - f1-score (micro avg)  0.9155\n",
      "2022-08-30 19:59:37,653 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 19:59:37,655 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 19:59:40,728 epoch 4 - iter 4/48 - loss 0.31671338 - samples/sec: 91.15 - lr: 0.200667\n",
      "2022-08-30 19:59:43,201 epoch 4 - iter 8/48 - loss 0.31387252 - samples/sec: 116.13 - lr: 0.200667\n",
      "2022-08-30 19:59:46,527 epoch 4 - iter 12/48 - loss 0.32053440 - samples/sec: 85.84 - lr: 0.200667\n",
      "2022-08-30 19:59:49,143 epoch 4 - iter 16/48 - loss 0.32488373 - samples/sec: 109.37 - lr: 0.200667\n",
      "2022-08-30 19:59:51,948 epoch 4 - iter 20/48 - loss 0.32372639 - samples/sec: 102.08 - lr: 0.200667\n",
      "2022-08-30 19:59:54,370 epoch 4 - iter 24/48 - loss 0.32044766 - samples/sec: 118.39 - lr: 0.200667\n",
      "2022-08-30 19:59:56,868 epoch 4 - iter 28/48 - loss 0.32012111 - samples/sec: 115.61 - lr: 0.200667\n",
      "2022-08-30 19:59:59,558 epoch 4 - iter 32/48 - loss 0.32428930 - samples/sec: 106.38 - lr: 0.200667\n",
      "2022-08-30 20:00:02,031 epoch 4 - iter 36/48 - loss 0.32446438 - samples/sec: 116.23 - lr: 0.200667\n",
      "2022-08-30 20:00:05,030 epoch 4 - iter 40/48 - loss 0.32469736 - samples/sec: 95.43 - lr: 0.200667\n",
      "2022-08-30 20:00:08,134 epoch 4 - iter 44/48 - loss 0.32347491 - samples/sec: 92.01 - lr: 0.200667\n",
      "2022-08-30 20:00:10,581 epoch 4 - iter 48/48 - loss 0.32383756 - samples/sec: 117.55 - lr: 0.200667\n",
      "2022-08-30 20:00:10,639 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:00:10,640 EPOCH 4 done: loss 0.3238 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:00:11,447 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:00:11,478 DEV : loss 0.24307586252689362 - f1-score (micro avg)  0.9162\n",
      "2022-08-30 20:00:11,497 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:00:11,498 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:00:14,005 epoch 5 - iter 4/48 - loss 0.29573030 - samples/sec: 111.78 - lr: 0.200667\n",
      "2022-08-30 20:00:17,054 epoch 5 - iter 8/48 - loss 0.30110721 - samples/sec: 94.02 - lr: 0.200667\n",
      "2022-08-30 20:00:19,708 epoch 5 - iter 12/48 - loss 0.30486301 - samples/sec: 108.28 - lr: 0.200667\n",
      "2022-08-30 20:00:22,479 epoch 5 - iter 16/48 - loss 0.30948518 - samples/sec: 103.36 - lr: 0.200667\n",
      "2022-08-30 20:00:25,622 epoch 5 - iter 20/48 - loss 0.31317541 - samples/sec: 90.85 - lr: 0.200667\n",
      "2022-08-30 20:00:28,055 epoch 5 - iter 24/48 - loss 0.31294530 - samples/sec: 118.04 - lr: 0.200667\n",
      "2022-08-30 20:00:31,139 epoch 5 - iter 28/48 - loss 0.31376687 - samples/sec: 92.53 - lr: 0.200667\n",
      "2022-08-30 20:00:33,861 epoch 5 - iter 32/48 - loss 0.31568818 - samples/sec: 105.30 - lr: 0.200667\n",
      "2022-08-30 20:00:36,937 epoch 5 - iter 36/48 - loss 0.31410130 - samples/sec: 92.81 - lr: 0.200667\n",
      "2022-08-30 20:00:39,664 epoch 5 - iter 40/48 - loss 0.31601796 - samples/sec: 105.03 - lr: 0.200667\n",
      "2022-08-30 20:00:42,594 epoch 5 - iter 44/48 - loss 0.31774402 - samples/sec: 97.66 - lr: 0.200667\n",
      "2022-08-30 20:00:45,139 epoch 5 - iter 48/48 - loss 0.31815729 - samples/sec: 112.99 - lr: 0.200667\n",
      "2022-08-30 20:00:45,202 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:00:45,203 EPOCH 5 done: loss 0.3182 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:00:46,102 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:00:46,141 DEV : loss 0.24002625048160553 - f1-score (micro avg)  0.9146\n",
      "2022-08-30 20:00:46,160 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 20:00:46,161 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:00:49,387 epoch 6 - iter 4/48 - loss 0.29589036 - samples/sec: 86.85 - lr: 0.200667\n",
      "2022-08-30 20:00:52,286 epoch 6 - iter 8/48 - loss 0.30120015 - samples/sec: 99.43 - lr: 0.200667\n",
      "2022-08-30 20:00:55,198 epoch 6 - iter 12/48 - loss 0.30700225 - samples/sec: 98.28 - lr: 0.200667\n",
      "2022-08-30 20:00:58,850 epoch 6 - iter 16/48 - loss 0.30647842 - samples/sec: 78.10 - lr: 0.200667\n",
      "2022-08-30 20:01:01,851 epoch 6 - iter 20/48 - loss 0.30767822 - samples/sec: 95.37 - lr: 0.200667\n",
      "2022-08-30 20:01:04,745 epoch 6 - iter 24/48 - loss 0.31239693 - samples/sec: 99.09 - lr: 0.200667\n",
      "2022-08-30 20:01:07,962 epoch 6 - iter 28/48 - loss 0.31565352 - samples/sec: 88.88 - lr: 0.200667\n",
      "2022-08-30 20:01:11,470 epoch 6 - iter 32/48 - loss 0.31583700 - samples/sec: 81.47 - lr: 0.200667\n",
      "2022-08-30 20:01:14,777 epoch 6 - iter 36/48 - loss 0.31676493 - samples/sec: 86.42 - lr: 0.200667\n",
      "2022-08-30 20:01:17,653 epoch 6 - iter 40/48 - loss 0.31608753 - samples/sec: 99.46 - lr: 0.200667\n",
      "2022-08-30 20:01:20,786 epoch 6 - iter 44/48 - loss 0.31796270 - samples/sec: 91.32 - lr: 0.200667\n",
      "2022-08-30 20:01:23,611 epoch 6 - iter 48/48 - loss 0.31699343 - samples/sec: 101.89 - lr: 0.200667\n",
      "2022-08-30 20:01:23,678 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:01:23,679 EPOCH 6 done: loss 0.3170 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:01:24,615 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:01:24,647 DEV : loss 0.24130135774612427 - f1-score (micro avg)  0.9159\n",
      "2022-08-30 20:01:24,670 Epoch     6: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 20:01:24,671 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 20:01:24,672 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:01:27,651 epoch 7 - iter 4/48 - loss 0.32503762 - samples/sec: 94.05 - lr: 0.100333\n",
      "2022-08-30 20:01:30,319 epoch 7 - iter 8/48 - loss 0.32305726 - samples/sec: 107.65 - lr: 0.100333\n",
      "2022-08-30 20:01:33,263 epoch 7 - iter 12/48 - loss 0.32016493 - samples/sec: 97.59 - lr: 0.100333\n",
      "2022-08-30 20:01:36,105 epoch 7 - iter 16/48 - loss 0.31808709 - samples/sec: 101.03 - lr: 0.100333\n",
      "2022-08-30 20:01:39,097 epoch 7 - iter 20/48 - loss 0.31521543 - samples/sec: 95.82 - lr: 0.100333\n",
      "2022-08-30 20:01:41,986 epoch 7 - iter 24/48 - loss 0.31305060 - samples/sec: 98.92 - lr: 0.100333\n",
      "2022-08-30 20:01:44,753 epoch 7 - iter 28/48 - loss 0.31249845 - samples/sec: 103.67 - lr: 0.100333\n",
      "2022-08-30 20:01:47,842 epoch 7 - iter 32/48 - loss 0.31076628 - samples/sec: 92.50 - lr: 0.100333\n",
      "2022-08-30 20:01:50,477 epoch 7 - iter 36/48 - loss 0.31081903 - samples/sec: 108.91 - lr: 0.100333\n",
      "2022-08-30 20:01:53,551 epoch 7 - iter 40/48 - loss 0.30982358 - samples/sec: 93.62 - lr: 0.100333\n",
      "2022-08-30 20:01:56,243 epoch 7 - iter 44/48 - loss 0.30809725 - samples/sec: 107.23 - lr: 0.100333\n",
      "2022-08-30 20:01:59,303 epoch 7 - iter 48/48 - loss 0.30913041 - samples/sec: 93.46 - lr: 0.100333\n",
      "2022-08-30 20:01:59,389 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:01:59,391 EPOCH 7 done: loss 0.3091 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:02:00,237 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:02:00,269 DEV : loss 0.23878633975982666 - f1-score (micro avg)  0.9175\n",
      "2022-08-30 20:02:00,287 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:02:00,288 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:02:01,004 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:02:03,677 epoch 8 - iter 4/48 - loss 0.28912452 - samples/sec: 104.87 - lr: 0.100333\n",
      "2022-08-30 20:02:06,822 epoch 8 - iter 8/48 - loss 0.30142426 - samples/sec: 91.03 - lr: 0.100333\n",
      "2022-08-30 20:02:09,815 epoch 8 - iter 12/48 - loss 0.29726560 - samples/sec: 95.46 - lr: 0.100333\n",
      "2022-08-30 20:02:12,768 epoch 8 - iter 16/48 - loss 0.30074730 - samples/sec: 96.62 - lr: 0.100333\n",
      "2022-08-30 20:02:15,704 epoch 8 - iter 20/48 - loss 0.30081189 - samples/sec: 97.29 - lr: 0.100333\n",
      "2022-08-30 20:02:18,301 epoch 8 - iter 24/48 - loss 0.30419652 - samples/sec: 110.65 - lr: 0.100333\n",
      "2022-08-30 20:02:21,237 epoch 8 - iter 28/48 - loss 0.30575013 - samples/sec: 98.14 - lr: 0.100333\n",
      "2022-08-30 20:02:24,088 epoch 8 - iter 32/48 - loss 0.30631265 - samples/sec: 100.43 - lr: 0.100333\n",
      "2022-08-30 20:02:27,025 epoch 8 - iter 36/48 - loss 0.30549263 - samples/sec: 97.44 - lr: 0.100333\n",
      "2022-08-30 20:02:30,228 epoch 8 - iter 40/48 - loss 0.30535750 - samples/sec: 89.43 - lr: 0.100333\n",
      "2022-08-30 20:02:33,348 epoch 8 - iter 44/48 - loss 0.30663575 - samples/sec: 91.82 - lr: 0.100333\n",
      "2022-08-30 20:02:36,441 epoch 8 - iter 48/48 - loss 0.30655035 - samples/sec: 93.61 - lr: 0.100333\n",
      "2022-08-30 20:02:36,512 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:02:36,513 EPOCH 8 done: loss 0.3066 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:02:37,391 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:02:37,432 DEV : loss 0.23989520967006683 - f1-score (micro avg)  0.9185\n",
      "2022-08-30 20:02:37,461 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:02:37,464 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:02:38,369 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:02:41,145 epoch 9 - iter 4/48 - loss 0.30445069 - samples/sec: 100.94 - lr: 0.100333\n",
      "2022-08-30 20:02:44,328 epoch 9 - iter 8/48 - loss 0.31045066 - samples/sec: 90.03 - lr: 0.100333\n",
      "2022-08-30 20:02:47,653 epoch 9 - iter 12/48 - loss 0.30298641 - samples/sec: 86.15 - lr: 0.100333\n",
      "2022-08-30 20:02:50,746 epoch 9 - iter 16/48 - loss 0.30718162 - samples/sec: 92.68 - lr: 0.100333\n",
      "2022-08-30 20:02:53,325 epoch 9 - iter 20/48 - loss 0.30634109 - samples/sec: 111.34 - lr: 0.100333\n",
      "2022-08-30 20:02:55,974 epoch 9 - iter 24/48 - loss 0.30783701 - samples/sec: 109.21 - lr: 0.100333\n",
      "2022-08-30 20:02:59,022 epoch 9 - iter 28/48 - loss 0.30535879 - samples/sec: 93.88 - lr: 0.100333\n",
      "2022-08-30 20:03:01,752 epoch 9 - iter 32/48 - loss 0.30403437 - samples/sec: 105.11 - lr: 0.100333\n",
      "2022-08-30 20:03:04,534 epoch 9 - iter 36/48 - loss 0.30376920 - samples/sec: 102.94 - lr: 0.100333\n",
      "2022-08-30 20:03:08,121 epoch 9 - iter 40/48 - loss 0.30358218 - samples/sec: 79.53 - lr: 0.100333\n",
      "2022-08-30 20:03:10,865 epoch 9 - iter 44/48 - loss 0.30247514 - samples/sec: 104.42 - lr: 0.100333\n",
      "2022-08-30 20:03:13,450 epoch 9 - iter 48/48 - loss 0.30272062 - samples/sec: 110.98 - lr: 0.100333\n",
      "2022-08-30 20:03:13,511 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:03:13,512 EPOCH 9 done: loss 0.3027 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:03:14,405 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:03:14,442 DEV : loss 0.23985713720321655 - f1-score (micro avg)  0.9191\n",
      "2022-08-30 20:03:14,466 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:03:14,467 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:03:15,629 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:03:18,341 epoch 10 - iter 4/48 - loss 0.28832000 - samples/sec: 103.28 - lr: 0.100333\n",
      "2022-08-30 20:03:21,224 epoch 10 - iter 8/48 - loss 0.29424783 - samples/sec: 100.04 - lr: 0.100333\n",
      "2022-08-30 20:03:23,995 epoch 10 - iter 12/48 - loss 0.29352793 - samples/sec: 103.40 - lr: 0.100333\n",
      "2022-08-30 20:03:27,005 epoch 10 - iter 16/48 - loss 0.29542660 - samples/sec: 95.01 - lr: 0.100333\n",
      "2022-08-30 20:03:30,000 epoch 10 - iter 20/48 - loss 0.30006893 - samples/sec: 95.47 - lr: 0.100333\n",
      "2022-08-30 20:03:33,375 epoch 10 - iter 24/48 - loss 0.30167419 - samples/sec: 84.64 - lr: 0.100333\n",
      "2022-08-30 20:03:35,996 epoch 10 - iter 28/48 - loss 0.30301728 - samples/sec: 110.19 - lr: 0.100333\n",
      "2022-08-30 20:03:38,883 epoch 10 - iter 32/48 - loss 0.30394943 - samples/sec: 99.26 - lr: 0.100333\n",
      "2022-08-30 20:03:42,019 epoch 10 - iter 36/48 - loss 0.30328462 - samples/sec: 91.38 - lr: 0.100333\n",
      "2022-08-30 20:03:45,455 epoch 10 - iter 40/48 - loss 0.30407776 - samples/sec: 82.91 - lr: 0.100333\n",
      "2022-08-30 20:03:48,242 epoch 10 - iter 44/48 - loss 0.30540909 - samples/sec: 102.75 - lr: 0.100333\n",
      "2022-08-30 20:03:51,049 epoch 10 - iter 48/48 - loss 0.30514081 - samples/sec: 102.08 - lr: 0.100333\n",
      "2022-08-30 20:03:51,115 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:03:51,115 EPOCH 10 done: loss 0.3051 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:03:52,111 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:03:52,148 DEV : loss 0.2375156730413437 - f1-score (micro avg)  0.9198\n",
      "2022-08-30 20:03:52,168 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:03:52,169 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:03:53,371 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:03:56,556 epoch 11 - iter 4/48 - loss 0.29918465 - samples/sec: 87.94 - lr: 0.100333\n",
      "2022-08-30 20:03:59,951 epoch 11 - iter 8/48 - loss 0.29091512 - samples/sec: 84.29 - lr: 0.100333\n",
      "2022-08-30 20:04:02,624 epoch 11 - iter 12/48 - loss 0.29486473 - samples/sec: 107.49 - lr: 0.100333\n",
      "2022-08-30 20:04:06,060 epoch 11 - iter 16/48 - loss 0.29695940 - samples/sec: 83.16 - lr: 0.100333\n",
      "2022-08-30 20:04:09,004 epoch 11 - iter 20/48 - loss 0.29944014 - samples/sec: 97.49 - lr: 0.100333\n",
      "2022-08-30 20:04:12,057 epoch 11 - iter 24/48 - loss 0.30114167 - samples/sec: 93.68 - lr: 0.100333\n",
      "2022-08-30 20:04:15,693 epoch 11 - iter 28/48 - loss 0.30165199 - samples/sec: 78.43 - lr: 0.100333\n",
      "2022-08-30 20:04:18,622 epoch 11 - iter 32/48 - loss 0.30134450 - samples/sec: 97.80 - lr: 0.100333\n",
      "2022-08-30 20:04:21,411 epoch 11 - iter 36/48 - loss 0.30225701 - samples/sec: 102.79 - lr: 0.100333\n",
      "2022-08-30 20:04:24,486 epoch 11 - iter 40/48 - loss 0.30355186 - samples/sec: 93.46 - lr: 0.100333\n",
      "2022-08-30 20:04:27,197 epoch 11 - iter 44/48 - loss 0.30296577 - samples/sec: 105.70 - lr: 0.100333\n",
      "2022-08-30 20:04:30,078 epoch 11 - iter 48/48 - loss 0.30348520 - samples/sec: 99.50 - lr: 0.100333\n",
      "2022-08-30 20:04:30,139 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:04:30,139 EPOCH 11 done: loss 0.3035 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:04:31,011 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:04:31,048 DEV : loss 0.23840561509132385 - f1-score (micro avg)  0.9183\n",
      "2022-08-30 20:04:31,070 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:04:31,767 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:04:31,768 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 20:04:31,941 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:04:33,326 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:04:33,356 0.924\t0.924\t0.924\t0.924\n",
      "2022-08-30 20:04:33,358 \n",
      "Results:\n",
      "- F-score (micro) 0.924\n",
      "- F-score (macro) 0.805\n",
      "- Accuracy 0.924\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8948    0.9180    0.9062      1353\n",
      "         ADJ     0.8737    0.9062    0.8897       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9941    0.9844    0.9892       514\n",
      "        VERB     0.9013    0.9154    0.9083       449\n",
      "       PROPN     0.8130    0.7493    0.7799       383\n",
      "         AUX     0.9910    0.9881    0.9895       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8896    0.8509    0.8698       161\n",
      "         ADV     0.8467    0.8411    0.8439       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9815    0.7465    0.8480        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9240      5264\n",
      "   macro avg     0.8228    0.7907    0.8050      5264\n",
      "weighted avg     0.9243    0.9240    0.9237      5264\n",
      "\n",
      "2022-08-30 20:04:33,359 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:04:33,365 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 20:04:33,859 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 7 #######################\n",
      "#######################################################\n",
      "2022-08-30 20:07:01,856 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:07:01,857 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 20:07:01,857 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:07:01,858 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 20:07:01,859 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:07:01,859 Parameters:\n",
      "2022-08-30 20:07:01,860  - learning_rate: \"0.200667\"\n",
      "2022-08-30 20:07:01,860  - mini_batch_size: \"70\"\n",
      "2022-08-30 20:07:01,861  - patience: \"3\"\n",
      "2022-08-30 20:07:01,861  - anneal_factor: \"0.5\"\n",
      "2022-08-30 20:07:01,861  - max_epochs: \"12\"\n",
      "2022-08-30 20:07:01,862  - shuffle: \"True\"\n",
      "2022-08-30 20:07:01,862  - train_with_dev: \"False\"\n",
      "2022-08-30 20:07:01,863  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 20:07:01,863 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:07:01,864 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 20:07:01,865 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:07:01,865 Device: cpu\n",
      "2022-08-30 20:07:01,865 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:07:01,866 Embeddings storage mode: cpu\n",
      "2022-08-30 20:07:01,867 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:07:04,301 epoch 1 - iter 4/48 - loss 0.29079285 - samples/sec: 115.04 - lr: 0.200667\n",
      "2022-08-30 20:07:07,295 epoch 1 - iter 8/48 - loss 0.30375948 - samples/sec: 95.89 - lr: 0.200667\n",
      "2022-08-30 20:07:09,648 epoch 1 - iter 12/48 - loss 0.30851711 - samples/sec: 122.00 - lr: 0.200667\n",
      "2022-08-30 20:07:12,151 epoch 1 - iter 16/48 - loss 0.30208148 - samples/sec: 114.38 - lr: 0.200667\n",
      "2022-08-30 20:07:14,794 epoch 1 - iter 20/48 - loss 0.29557458 - samples/sec: 108.40 - lr: 0.200667\n",
      "2022-08-30 20:07:17,496 epoch 1 - iter 24/48 - loss 0.29945157 - samples/sec: 106.02 - lr: 0.200667\n",
      "2022-08-30 20:07:19,991 epoch 1 - iter 28/48 - loss 0.29980473 - samples/sec: 115.70 - lr: 0.200667\n",
      "2022-08-30 20:07:22,668 epoch 1 - iter 32/48 - loss 0.30024019 - samples/sec: 107.24 - lr: 0.200667\n",
      "2022-08-30 20:07:25,054 epoch 1 - iter 36/48 - loss 0.30232810 - samples/sec: 120.33 - lr: 0.200667\n",
      "2022-08-30 20:07:27,647 epoch 1 - iter 40/48 - loss 0.30058315 - samples/sec: 110.28 - lr: 0.200667\n",
      "2022-08-30 20:07:30,260 epoch 1 - iter 44/48 - loss 0.30619734 - samples/sec: 109.63 - lr: 0.200667\n",
      "2022-08-30 20:07:33,257 epoch 1 - iter 48/48 - loss 0.31484473 - samples/sec: 95.21 - lr: 0.200667\n",
      "2022-08-30 20:07:33,312 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:07:33,313 EPOCH 1 done: loss 0.3148 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:07:35,444 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:07:35,472 DEV : loss 0.2550424039363861 - f1-score (micro avg)  0.9116\n",
      "2022-08-30 20:07:35,487 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:07:35,488 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:07:36,172 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:07:38,799 epoch 2 - iter 4/48 - loss 0.32293450 - samples/sec: 106.63 - lr: 0.200667\n",
      "2022-08-30 20:07:41,662 epoch 2 - iter 8/48 - loss 0.31552901 - samples/sec: 99.71 - lr: 0.200667\n",
      "2022-08-30 20:07:43,919 epoch 2 - iter 12/48 - loss 0.31630743 - samples/sec: 127.56 - lr: 0.200667\n",
      "2022-08-30 20:07:46,916 epoch 2 - iter 16/48 - loss 0.31493829 - samples/sec: 95.17 - lr: 0.200667\n",
      "2022-08-30 20:07:49,285 epoch 2 - iter 20/48 - loss 0.31341158 - samples/sec: 120.90 - lr: 0.200667\n",
      "2022-08-30 20:07:51,885 epoch 2 - iter 24/48 - loss 0.31269554 - samples/sec: 110.02 - lr: 0.200667\n",
      "2022-08-30 20:07:54,687 epoch 2 - iter 28/48 - loss 0.31107254 - samples/sec: 102.19 - lr: 0.200667\n",
      "2022-08-30 20:07:57,522 epoch 2 - iter 32/48 - loss 0.30982791 - samples/sec: 101.23 - lr: 0.200667\n",
      "2022-08-30 20:08:00,079 epoch 2 - iter 36/48 - loss 0.31118408 - samples/sec: 113.91 - lr: 0.200667\n",
      "2022-08-30 20:08:03,131 epoch 2 - iter 40/48 - loss 0.31143939 - samples/sec: 93.52 - lr: 0.200667\n",
      "2022-08-30 20:08:05,880 epoch 2 - iter 44/48 - loss 0.30968177 - samples/sec: 103.90 - lr: 0.200667\n",
      "2022-08-30 20:08:08,204 epoch 2 - iter 48/48 - loss 0.31036599 - samples/sec: 123.57 - lr: 0.200667\n",
      "2022-08-30 20:08:08,259 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:08:08,260 EPOCH 2 done: loss 0.3104 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:08:09,107 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:08:09,136 DEV : loss 0.24091270565986633 - f1-score (micro avg)  0.9183\n",
      "2022-08-30 20:08:09,156 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:08:09,158 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:08:09,947 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:08:12,673 epoch 3 - iter 4/48 - loss 0.30960996 - samples/sec: 102.79 - lr: 0.200667\n",
      "2022-08-30 20:08:14,914 epoch 3 - iter 8/48 - loss 0.30988369 - samples/sec: 128.03 - lr: 0.200667\n",
      "2022-08-30 20:08:17,446 epoch 3 - iter 12/48 - loss 0.30829545 - samples/sec: 113.27 - lr: 0.200667\n",
      "2022-08-30 20:08:20,084 epoch 3 - iter 16/48 - loss 0.31109557 - samples/sec: 110.28 - lr: 0.200667\n",
      "2022-08-30 20:08:22,879 epoch 3 - iter 20/48 - loss 0.31086969 - samples/sec: 102.26 - lr: 0.200667\n",
      "2022-08-30 20:08:25,513 epoch 3 - iter 24/48 - loss 0.31309397 - samples/sec: 108.57 - lr: 0.200667\n",
      "2022-08-30 20:08:28,109 epoch 3 - iter 28/48 - loss 0.31281021 - samples/sec: 111.82 - lr: 0.200667\n",
      "2022-08-30 20:08:30,735 epoch 3 - iter 32/48 - loss 0.31142306 - samples/sec: 108.91 - lr: 0.200667\n",
      "2022-08-30 20:08:33,832 epoch 3 - iter 36/48 - loss 0.31342489 - samples/sec: 92.20 - lr: 0.200667\n",
      "2022-08-30 20:08:36,497 epoch 3 - iter 40/48 - loss 0.31435868 - samples/sec: 108.40 - lr: 0.200667\n",
      "2022-08-30 20:08:39,673 epoch 3 - iter 44/48 - loss 0.31491312 - samples/sec: 90.35 - lr: 0.200667\n",
      "2022-08-30 20:08:42,749 epoch 3 - iter 48/48 - loss 0.31445017 - samples/sec: 92.81 - lr: 0.200667\n",
      "2022-08-30 20:08:42,811 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:08:42,811 EPOCH 3 done: loss 0.3145 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:08:43,689 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:08:43,725 DEV : loss 0.24451786279678345 - f1-score (micro avg)  0.917\n",
      "2022-08-30 20:08:43,742 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:08:43,743 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:08:46,283 epoch 4 - iter 4/48 - loss 0.29998850 - samples/sec: 110.32 - lr: 0.200667\n",
      "2022-08-30 20:08:48,847 epoch 4 - iter 8/48 - loss 0.30420959 - samples/sec: 112.04 - lr: 0.200667\n",
      "2022-08-30 20:08:51,446 epoch 4 - iter 12/48 - loss 0.31030148 - samples/sec: 110.19 - lr: 0.200667\n",
      "2022-08-30 20:08:54,712 epoch 4 - iter 16/48 - loss 0.30976209 - samples/sec: 87.39 - lr: 0.200667\n",
      "2022-08-30 20:08:57,636 epoch 4 - iter 20/48 - loss 0.30854068 - samples/sec: 97.63 - lr: 0.200667\n",
      "2022-08-30 20:09:00,635 epoch 4 - iter 24/48 - loss 0.30697326 - samples/sec: 95.11 - lr: 0.200667\n",
      "2022-08-30 20:09:03,604 epoch 4 - iter 28/48 - loss 0.30913404 - samples/sec: 96.79 - lr: 0.200667\n",
      "2022-08-30 20:09:06,669 epoch 4 - iter 32/48 - loss 0.30949354 - samples/sec: 93.24 - lr: 0.200667\n",
      "2022-08-30 20:09:09,188 epoch 4 - iter 36/48 - loss 0.31125293 - samples/sec: 114.38 - lr: 0.200667\n",
      "2022-08-30 20:09:12,050 epoch 4 - iter 40/48 - loss 0.31328052 - samples/sec: 100.29 - lr: 0.200667\n",
      "2022-08-30 20:09:14,916 epoch 4 - iter 44/48 - loss 0.31232733 - samples/sec: 99.86 - lr: 0.200667\n",
      "2022-08-30 20:09:17,818 epoch 4 - iter 48/48 - loss 0.31140834 - samples/sec: 98.35 - lr: 0.200667\n",
      "2022-08-30 20:09:17,875 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:09:17,876 EPOCH 4 done: loss 0.3114 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:09:18,720 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:09:18,756 DEV : loss 0.24622097611427307 - f1-score (micro avg)  0.9185\n",
      "2022-08-30 20:09:18,772 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:09:18,773 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:09:19,527 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:09:22,110 epoch 5 - iter 4/48 - loss 0.31533025 - samples/sec: 108.57 - lr: 0.200667\n",
      "2022-08-30 20:09:25,311 epoch 5 - iter 8/48 - loss 0.31232359 - samples/sec: 89.34 - lr: 0.200667\n",
      "2022-08-30 20:09:28,116 epoch 5 - iter 12/48 - loss 0.31387521 - samples/sec: 102.87 - lr: 0.200667\n",
      "2022-08-30 20:09:31,112 epoch 5 - iter 16/48 - loss 0.30774343 - samples/sec: 95.27 - lr: 0.200667\n",
      "2022-08-30 20:09:33,676 epoch 5 - iter 20/48 - loss 0.30857431 - samples/sec: 111.96 - lr: 0.200667\n",
      "2022-08-30 20:09:36,885 epoch 5 - iter 24/48 - loss 0.30992874 - samples/sec: 89.09 - lr: 0.200667\n",
      "2022-08-30 20:09:39,534 epoch 5 - iter 28/48 - loss 0.31276671 - samples/sec: 108.44 - lr: 0.200667\n",
      "2022-08-30 20:09:42,076 epoch 5 - iter 32/48 - loss 0.31309748 - samples/sec: 112.99 - lr: 0.200667\n",
      "2022-08-30 20:09:44,627 epoch 5 - iter 36/48 - loss 0.31465876 - samples/sec: 112.54 - lr: 0.200667\n",
      "2022-08-30 20:09:47,194 epoch 5 - iter 40/48 - loss 0.31272848 - samples/sec: 111.73 - lr: 0.200667\n",
      "2022-08-30 20:09:49,923 epoch 5 - iter 44/48 - loss 0.31291472 - samples/sec: 104.79 - lr: 0.200667\n",
      "2022-08-30 20:09:52,889 epoch 5 - iter 48/48 - loss 0.31348522 - samples/sec: 96.35 - lr: 0.200667\n",
      "2022-08-30 20:09:52,953 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:09:52,954 EPOCH 5 done: loss 0.3135 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:09:53,739 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:09:53,771 DEV : loss 0.24664676189422607 - f1-score (micro avg)  0.9175\n",
      "2022-08-30 20:09:53,786 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:09:53,787 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:09:56,376 epoch 6 - iter 4/48 - loss 0.29106866 - samples/sec: 108.19 - lr: 0.200667\n",
      "2022-08-30 20:09:59,617 epoch 6 - iter 8/48 - loss 0.30827906 - samples/sec: 89.77 - lr: 0.200667\n",
      "2022-08-30 20:10:02,423 epoch 6 - iter 12/48 - loss 0.30727863 - samples/sec: 102.56 - lr: 0.200667\n",
      "2022-08-30 20:10:04,972 epoch 6 - iter 16/48 - loss 0.30641730 - samples/sec: 114.15 - lr: 0.200667\n",
      "2022-08-30 20:10:07,651 epoch 6 - iter 20/48 - loss 0.30983223 - samples/sec: 107.20 - lr: 0.200667\n",
      "2022-08-30 20:10:11,018 epoch 6 - iter 24/48 - loss 0.31064638 - samples/sec: 84.77 - lr: 0.200667\n",
      "2022-08-30 20:10:14,051 epoch 6 - iter 28/48 - loss 0.30977934 - samples/sec: 94.63 - lr: 0.200667\n",
      "2022-08-30 20:10:16,629 epoch 6 - iter 32/48 - loss 0.31055367 - samples/sec: 111.11 - lr: 0.200667\n",
      "2022-08-30 20:10:19,271 epoch 6 - iter 36/48 - loss 0.31123269 - samples/sec: 109.16 - lr: 0.200667\n",
      "2022-08-30 20:10:22,258 epoch 6 - iter 40/48 - loss 0.31271610 - samples/sec: 95.69 - lr: 0.200667\n",
      "2022-08-30 20:10:24,930 epoch 6 - iter 44/48 - loss 0.31208788 - samples/sec: 107.16 - lr: 0.200667\n",
      "2022-08-30 20:10:27,709 epoch 6 - iter 48/48 - loss 0.31217085 - samples/sec: 102.79 - lr: 0.200667\n",
      "2022-08-30 20:10:27,777 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:10:27,778 EPOCH 6 done: loss 0.3122 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:10:28,631 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:10:28,658 DEV : loss 0.24384556710720062 - f1-score (micro avg)  0.9215\n",
      "2022-08-30 20:10:28,676 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:10:28,677 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:10:29,546 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:10:32,307 epoch 7 - iter 4/48 - loss 0.30606052 - samples/sec: 101.45 - lr: 0.200667\n",
      "2022-08-30 20:10:35,048 epoch 7 - iter 8/48 - loss 0.30980145 - samples/sec: 104.83 - lr: 0.200667\n",
      "2022-08-30 20:10:37,949 epoch 7 - iter 12/48 - loss 0.31037929 - samples/sec: 98.42 - lr: 0.200667\n",
      "2022-08-30 20:10:40,910 epoch 7 - iter 16/48 - loss 0.30889458 - samples/sec: 96.62 - lr: 0.200667\n",
      "2022-08-30 20:10:43,969 epoch 7 - iter 20/48 - loss 0.31150202 - samples/sec: 93.40 - lr: 0.200667\n",
      "2022-08-30 20:10:46,447 epoch 7 - iter 24/48 - loss 0.31503609 - samples/sec: 115.75 - lr: 0.200667\n",
      "2022-08-30 20:10:48,990 epoch 7 - iter 28/48 - loss 0.31053591 - samples/sec: 112.99 - lr: 0.200667\n",
      "2022-08-30 20:10:51,477 epoch 7 - iter 32/48 - loss 0.31148957 - samples/sec: 115.37 - lr: 0.200667\n",
      "2022-08-30 20:10:53,969 epoch 7 - iter 36/48 - loss 0.31145141 - samples/sec: 115.89 - lr: 0.200667\n",
      "2022-08-30 20:10:57,335 epoch 7 - iter 40/48 - loss 0.31248019 - samples/sec: 84.95 - lr: 0.200667\n",
      "2022-08-30 20:11:00,234 epoch 7 - iter 44/48 - loss 0.31321960 - samples/sec: 100.12 - lr: 0.200667\n",
      "2022-08-30 20:11:03,070 epoch 7 - iter 48/48 - loss 0.31430171 - samples/sec: 101.16 - lr: 0.200667\n",
      "2022-08-30 20:11:03,126 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:11:03,127 EPOCH 7 done: loss 0.3143 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:11:03,977 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:11:04,008 DEV : loss 0.24515843391418457 - f1-score (micro avg)  0.9172\n",
      "2022-08-30 20:11:04,027 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:11:04,029 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:11:06,696 epoch 8 - iter 4/48 - loss 0.28799632 - samples/sec: 105.02 - lr: 0.200667\n",
      "2022-08-30 20:11:09,870 epoch 8 - iter 8/48 - loss 0.30277509 - samples/sec: 89.87 - lr: 0.200667\n",
      "2022-08-30 20:11:12,399 epoch 8 - iter 12/48 - loss 0.30646479 - samples/sec: 113.46 - lr: 0.200667\n",
      "2022-08-30 20:11:15,627 epoch 8 - iter 16/48 - loss 0.30484349 - samples/sec: 88.89 - lr: 0.200667\n",
      "2022-08-30 20:11:18,525 epoch 8 - iter 20/48 - loss 0.31008651 - samples/sec: 98.63 - lr: 0.200667\n",
      "2022-08-30 20:11:21,617 epoch 8 - iter 24/48 - loss 0.30846282 - samples/sec: 92.87 - lr: 0.200667\n",
      "2022-08-30 20:11:24,340 epoch 8 - iter 28/48 - loss 0.30864197 - samples/sec: 105.74 - lr: 0.200667\n",
      "2022-08-30 20:11:27,760 epoch 8 - iter 32/48 - loss 0.30969796 - samples/sec: 83.76 - lr: 0.200667\n",
      "2022-08-30 20:11:30,487 epoch 8 - iter 36/48 - loss 0.30865683 - samples/sec: 104.91 - lr: 0.200667\n",
      "2022-08-30 20:11:33,177 epoch 8 - iter 40/48 - loss 0.30805286 - samples/sec: 107.36 - lr: 0.200667\n",
      "2022-08-30 20:11:35,988 epoch 8 - iter 44/48 - loss 0.30832310 - samples/sec: 102.08 - lr: 0.200667\n",
      "2022-08-30 20:11:38,630 epoch 8 - iter 48/48 - loss 0.30772373 - samples/sec: 108.53 - lr: 0.200667\n",
      "2022-08-30 20:11:38,705 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:11:38,706 EPOCH 8 done: loss 0.3077 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:11:39,499 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:11:39,528 DEV : loss 0.24538464844226837 - f1-score (micro avg)  0.9175\n",
      "2022-08-30 20:11:39,548 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:11:39,550 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:11:42,193 epoch 9 - iter 4/48 - loss 0.29257748 - samples/sec: 105.98 - lr: 0.200667\n",
      "2022-08-30 20:11:45,078 epoch 9 - iter 8/48 - loss 0.29975520 - samples/sec: 99.12 - lr: 0.200667\n",
      "2022-08-30 20:11:47,776 epoch 9 - iter 12/48 - loss 0.30435405 - samples/sec: 105.98 - lr: 0.200667\n",
      "2022-08-30 20:11:50,310 epoch 9 - iter 16/48 - loss 0.30355416 - samples/sec: 113.68 - lr: 0.200667\n",
      "2022-08-30 20:11:53,328 epoch 9 - iter 20/48 - loss 0.30099615 - samples/sec: 94.96 - lr: 0.200667\n",
      "2022-08-30 20:11:56,373 epoch 9 - iter 24/48 - loss 0.30432805 - samples/sec: 94.55 - lr: 0.200667\n",
      "2022-08-30 20:11:59,635 epoch 9 - iter 28/48 - loss 0.30397776 - samples/sec: 87.99 - lr: 0.200667\n",
      "2022-08-30 20:12:02,267 epoch 9 - iter 32/48 - loss 0.30584356 - samples/sec: 108.97 - lr: 0.200667\n",
      "2022-08-30 20:12:05,162 epoch 9 - iter 36/48 - loss 0.30676820 - samples/sec: 98.97 - lr: 0.200667\n",
      "2022-08-30 20:12:07,987 epoch 9 - iter 40/48 - loss 0.30648590 - samples/sec: 101.22 - lr: 0.200667\n",
      "2022-08-30 20:12:10,784 epoch 9 - iter 44/48 - loss 0.30714169 - samples/sec: 102.51 - lr: 0.200667\n",
      "2022-08-30 20:12:13,179 epoch 9 - iter 48/48 - loss 0.30704925 - samples/sec: 120.04 - lr: 0.200667\n",
      "2022-08-30 20:12:13,243 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:12:13,244 EPOCH 9 done: loss 0.3070 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:12:14,149 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:12:14,179 DEV : loss 0.24505023658275604 - f1-score (micro avg)  0.9165\n",
      "2022-08-30 20:12:14,196 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 20:12:14,197 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:12:17,071 epoch 10 - iter 4/48 - loss 0.31647113 - samples/sec: 97.46 - lr: 0.200667\n",
      "2022-08-30 20:12:20,022 epoch 10 - iter 8/48 - loss 0.31227750 - samples/sec: 96.95 - lr: 0.200667\n",
      "2022-08-30 20:12:23,750 epoch 10 - iter 12/48 - loss 0.30879784 - samples/sec: 76.42 - lr: 0.200667\n",
      "2022-08-30 20:12:27,014 epoch 10 - iter 16/48 - loss 0.30824386 - samples/sec: 87.51 - lr: 0.200667\n",
      "2022-08-30 20:12:29,583 epoch 10 - iter 20/48 - loss 0.30477751 - samples/sec: 111.75 - lr: 0.200667\n",
      "2022-08-30 20:12:32,236 epoch 10 - iter 24/48 - loss 0.30453817 - samples/sec: 108.44 - lr: 0.200667\n",
      "2022-08-30 20:12:35,015 epoch 10 - iter 28/48 - loss 0.30806667 - samples/sec: 102.94 - lr: 0.200667\n",
      "2022-08-30 20:12:37,810 epoch 10 - iter 32/48 - loss 0.30937827 - samples/sec: 102.60 - lr: 0.200667\n",
      "2022-08-30 20:12:40,245 epoch 10 - iter 36/48 - loss 0.31061441 - samples/sec: 117.79 - lr: 0.200667\n",
      "2022-08-30 20:12:42,954 epoch 10 - iter 40/48 - loss 0.31345258 - samples/sec: 105.58 - lr: 0.200667\n",
      "2022-08-30 20:12:45,604 epoch 10 - iter 44/48 - loss 0.31266337 - samples/sec: 108.15 - lr: 0.200667\n",
      "2022-08-30 20:12:48,270 epoch 10 - iter 48/48 - loss 0.31089864 - samples/sec: 107.40 - lr: 0.200667\n",
      "2022-08-30 20:12:48,326 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:12:48,327 EPOCH 10 done: loss 0.3109 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:12:49,157 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:12:49,189 DEV : loss 0.24279983341693878 - f1-score (micro avg)  0.9147\n",
      "2022-08-30 20:12:49,207 Epoch    10: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 20:12:49,208 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 20:12:49,209 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:12:51,929 epoch 11 - iter 4/48 - loss 0.31509473 - samples/sec: 102.98 - lr: 0.100333\n",
      "2022-08-30 20:12:54,853 epoch 11 - iter 8/48 - loss 0.30507822 - samples/sec: 97.80 - lr: 0.100333\n",
      "2022-08-30 20:12:57,513 epoch 11 - iter 12/48 - loss 0.30393293 - samples/sec: 108.15 - lr: 0.100333\n",
      "2022-08-30 20:13:00,398 epoch 11 - iter 16/48 - loss 0.30065469 - samples/sec: 99.40 - lr: 0.100333\n",
      "2022-08-30 20:13:03,007 epoch 11 - iter 20/48 - loss 0.30243046 - samples/sec: 111.07 - lr: 0.100333\n",
      "2022-08-30 20:13:06,140 epoch 11 - iter 24/48 - loss 0.30125395 - samples/sec: 91.15 - lr: 0.100333\n",
      "2022-08-30 20:13:09,046 epoch 11 - iter 28/48 - loss 0.30134323 - samples/sec: 98.21 - lr: 0.100333\n",
      "2022-08-30 20:13:11,780 epoch 11 - iter 32/48 - loss 0.29950842 - samples/sec: 104.69 - lr: 0.100333\n",
      "2022-08-30 20:13:14,711 epoch 11 - iter 36/48 - loss 0.29964709 - samples/sec: 97.53 - lr: 0.100333\n",
      "2022-08-30 20:13:17,125 epoch 11 - iter 40/48 - loss 0.30133106 - samples/sec: 118.80 - lr: 0.100333\n",
      "2022-08-30 20:13:19,617 epoch 11 - iter 44/48 - loss 0.30066343 - samples/sec: 115.04 - lr: 0.100333\n",
      "2022-08-30 20:13:22,682 epoch 11 - iter 48/48 - loss 0.30233764 - samples/sec: 93.09 - lr: 0.100333\n",
      "2022-08-30 20:13:22,747 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:13:22,748 EPOCH 11 done: loss 0.3023 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:13:23,598 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:13:23,629 DEV : loss 0.23752328753471375 - f1-score (micro avg)  0.9201\n",
      "2022-08-30 20:13:23,650 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:13:23,651 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:13:26,938 epoch 12 - iter 4/48 - loss 0.30493303 - samples/sec: 85.22 - lr: 0.100333\n",
      "2022-08-30 20:13:29,881 epoch 12 - iter 8/48 - loss 0.30533182 - samples/sec: 97.29 - lr: 0.100333\n",
      "2022-08-30 20:13:32,481 epoch 12 - iter 12/48 - loss 0.30324707 - samples/sec: 110.15 - lr: 0.100333\n",
      "2022-08-30 20:13:35,135 epoch 12 - iter 16/48 - loss 0.29990484 - samples/sec: 107.95 - lr: 0.100333\n",
      "2022-08-30 20:13:38,203 epoch 12 - iter 20/48 - loss 0.29716022 - samples/sec: 93.02 - lr: 0.100333\n",
      "2022-08-30 20:13:41,264 epoch 12 - iter 24/48 - loss 0.29900329 - samples/sec: 93.55 - lr: 0.100333\n",
      "2022-08-30 20:13:43,781 epoch 12 - iter 28/48 - loss 0.29976253 - samples/sec: 114.10 - lr: 0.100333\n",
      "2022-08-30 20:13:46,355 epoch 12 - iter 32/48 - loss 0.30063799 - samples/sec: 111.15 - lr: 0.100333\n",
      "2022-08-30 20:13:49,216 epoch 12 - iter 36/48 - loss 0.30206724 - samples/sec: 100.28 - lr: 0.100333\n",
      "2022-08-30 20:13:51,844 epoch 12 - iter 40/48 - loss 0.29972359 - samples/sec: 108.84 - lr: 0.100333\n",
      "2022-08-30 20:13:54,720 epoch 12 - iter 44/48 - loss 0.30060386 - samples/sec: 99.77 - lr: 0.100333\n",
      "2022-08-30 20:13:57,420 epoch 12 - iter 48/48 - loss 0.29900496 - samples/sec: 106.33 - lr: 0.100333\n",
      "2022-08-30 20:13:57,509 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:13:57,510 EPOCH 12 done: loss 0.2990 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:13:58,355 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:13:58,389 DEV : loss 0.23773935437202454 - f1-score (micro avg)  0.9189\n",
      "2022-08-30 20:13:58,409 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:13:59,151 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:13:59,152 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 20:13:59,345 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:14:00,768 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:14:00,794 0.9233\t0.9233\t0.9233\t0.9233\n",
      "2022-08-30 20:14:00,794 \n",
      "Results:\n",
      "- F-score (micro) 0.9233\n",
      "- F-score (macro) 0.8023\n",
      "- Accuracy 0.9233\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8898    0.9246    0.9069      1353\n",
      "         ADJ     0.8868    0.8973    0.8920       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9922    0.9864    0.9893       514\n",
      "        VERB     0.8903    0.9220    0.9059       449\n",
      "       PROPN     0.8399    0.7258    0.7787       383\n",
      "         AUX     0.9880    0.9791    0.9835       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8650    0.8758    0.8704       161\n",
      "         ADV     0.8224    0.8278    0.8251       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9464    0.7465    0.8346        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9233      5264\n",
      "   macro avg     0.8187    0.7893    0.8023      5264\n",
      "weighted avg     0.9234    0.9233    0.9227      5264\n",
      "\n",
      "2022-08-30 20:14:00,795 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:14:00,800 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 20:14:01,388 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 20:16:29,601 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:16:29,602 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 20:16:29,603 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:16:29,603 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 20:16:29,604 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:16:29,605 Parameters:\n",
      "2022-08-30 20:16:29,605  - learning_rate: \"0.200667\"\n",
      "2022-08-30 20:16:29,606  - mini_batch_size: \"90\"\n",
      "2022-08-30 20:16:29,607  - patience: \"3\"\n",
      "2022-08-30 20:16:29,607  - anneal_factor: \"0.5\"\n",
      "2022-08-30 20:16:29,608  - max_epochs: \"10\"\n",
      "2022-08-30 20:16:29,608  - shuffle: \"True\"\n",
      "2022-08-30 20:16:29,609  - train_with_dev: \"False\"\n",
      "2022-08-30 20:16:29,609  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 20:16:29,610 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:16:29,610 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 20:16:29,611 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:16:29,611 Device: cpu\n",
      "2022-08-30 20:16:29,612 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:16:29,613 Embeddings storage mode: cpu\n",
      "2022-08-30 20:16:29,613 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:16:31,972 epoch 1 - iter 3/37 - loss 0.28466422 - samples/sec: 114.55 - lr: 0.200667\n",
      "2022-08-30 20:16:34,811 epoch 1 - iter 6/37 - loss 0.29087490 - samples/sec: 97.10 - lr: 0.200667\n",
      "2022-08-30 20:16:37,094 epoch 1 - iter 9/37 - loss 0.29783362 - samples/sec: 121.18 - lr: 0.200667\n",
      "2022-08-30 20:16:39,502 epoch 1 - iter 12/37 - loss 0.29343466 - samples/sec: 114.70 - lr: 0.200667\n",
      "2022-08-30 20:16:41,939 epoch 1 - iter 15/37 - loss 0.28944593 - samples/sec: 113.97 - lr: 0.200667\n",
      "2022-08-30 20:16:44,292 epoch 1 - iter 18/37 - loss 0.29413742 - samples/sec: 118.39 - lr: 0.200667\n",
      "2022-08-30 20:16:46,973 epoch 1 - iter 21/37 - loss 0.29223094 - samples/sec: 103.09 - lr: 0.200667\n",
      "2022-08-30 20:16:49,532 epoch 1 - iter 24/37 - loss 0.29141048 - samples/sec: 108.28 - lr: 0.200667\n",
      "2022-08-30 20:16:51,850 epoch 1 - iter 27/37 - loss 0.29215856 - samples/sec: 119.58 - lr: 0.200667\n",
      "2022-08-30 20:16:54,028 epoch 1 - iter 30/37 - loss 0.29222208 - samples/sec: 127.12 - lr: 0.200667\n",
      "2022-08-30 20:16:56,868 epoch 1 - iter 33/37 - loss 0.29476204 - samples/sec: 96.98 - lr: 0.200667\n",
      "2022-08-30 20:16:59,779 epoch 1 - iter 36/37 - loss 0.30395175 - samples/sec: 94.94 - lr: 0.200667\n",
      "2022-08-30 20:17:00,915 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:17:00,916 EPOCH 1 done: loss 0.3067 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:17:01,752 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:17:01,783 DEV : loss 0.25964659452438354 - f1-score (micro avg)  0.9129\n",
      "2022-08-30 20:17:01,800 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:17:01,802 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:17:02,776 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:17:05,126 epoch 2 - iter 3/37 - loss 0.31530183 - samples/sec: 114.99 - lr: 0.200667\n",
      "2022-08-30 20:17:07,736 epoch 2 - iter 6/37 - loss 0.31316091 - samples/sec: 105.76 - lr: 0.200667\n",
      "2022-08-30 20:17:10,094 epoch 2 - iter 9/37 - loss 0.30955920 - samples/sec: 117.54 - lr: 0.200667\n",
      "2022-08-30 20:17:12,675 epoch 2 - iter 12/37 - loss 0.30738972 - samples/sec: 106.84 - lr: 0.200667\n",
      "2022-08-30 20:17:15,561 epoch 2 - iter 15/37 - loss 0.30299164 - samples/sec: 95.61 - lr: 0.200667\n",
      "2022-08-30 20:17:17,863 epoch 2 - iter 18/37 - loss 0.30402469 - samples/sec: 120.70 - lr: 0.200667\n",
      "2022-08-30 20:17:20,043 epoch 2 - iter 21/37 - loss 0.30406038 - samples/sec: 127.30 - lr: 0.200667\n",
      "2022-08-30 20:17:22,391 epoch 2 - iter 24/37 - loss 0.30731201 - samples/sec: 118.06 - lr: 0.200667\n",
      "2022-08-30 20:17:25,434 epoch 2 - iter 27/37 - loss 0.30889530 - samples/sec: 91.00 - lr: 0.200667\n",
      "2022-08-30 20:17:27,904 epoch 2 - iter 30/37 - loss 0.30897384 - samples/sec: 113.02 - lr: 0.200667\n",
      "2022-08-30 20:17:30,564 epoch 2 - iter 33/37 - loss 0.30901360 - samples/sec: 103.65 - lr: 0.200667\n",
      "2022-08-30 20:17:33,541 epoch 2 - iter 36/37 - loss 0.31034404 - samples/sec: 92.47 - lr: 0.200667\n",
      "2022-08-30 20:17:34,358 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:17:34,360 EPOCH 2 done: loss 0.3100 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:17:35,197 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:17:35,226 DEV : loss 0.24315568804740906 - f1-score (micro avg)  0.916\n",
      "2022-08-30 20:17:35,244 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:17:35,245 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:17:36,021 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:17:38,476 epoch 3 - iter 3/37 - loss 0.31815273 - samples/sec: 110.02 - lr: 0.200667\n",
      "2022-08-30 20:17:40,799 epoch 3 - iter 6/37 - loss 0.30768336 - samples/sec: 119.89 - lr: 0.200667\n",
      "2022-08-30 20:17:43,723 epoch 3 - iter 9/37 - loss 0.30020363 - samples/sec: 94.37 - lr: 0.200667\n",
      "2022-08-30 20:17:47,055 epoch 3 - iter 12/37 - loss 0.29843569 - samples/sec: 82.44 - lr: 0.200667\n",
      "2022-08-30 20:17:49,425 epoch 3 - iter 15/37 - loss 0.29816804 - samples/sec: 117.09 - lr: 0.200667\n",
      "2022-08-30 20:17:51,924 epoch 3 - iter 18/37 - loss 0.29956763 - samples/sec: 110.79 - lr: 0.200667\n",
      "2022-08-30 20:17:54,510 epoch 3 - iter 21/37 - loss 0.29999080 - samples/sec: 107.87 - lr: 0.200667\n",
      "2022-08-30 20:17:57,038 epoch 3 - iter 24/37 - loss 0.30097463 - samples/sec: 109.44 - lr: 0.200667\n",
      "2022-08-30 20:17:59,462 epoch 3 - iter 27/37 - loss 0.30050128 - samples/sec: 113.97 - lr: 0.200667\n",
      "2022-08-30 20:18:02,433 epoch 3 - iter 30/37 - loss 0.30216182 - samples/sec: 93.62 - lr: 0.200667\n",
      "2022-08-30 20:18:04,745 epoch 3 - iter 33/37 - loss 0.30190034 - samples/sec: 121.08 - lr: 0.200667\n",
      "2022-08-30 20:18:07,096 epoch 3 - iter 36/37 - loss 0.30512860 - samples/sec: 117.70 - lr: 0.200667\n",
      "2022-08-30 20:18:07,980 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:18:07,981 EPOCH 3 done: loss 0.3056 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:18:08,800 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:18:08,832 DEV : loss 0.24731683731079102 - f1-score (micro avg)  0.918\n",
      "2022-08-30 20:18:08,851 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:18:08,852 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:18:09,557 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:18:12,413 epoch 4 - iter 3/37 - loss 0.32481341 - samples/sec: 94.57 - lr: 0.200667\n",
      "2022-08-30 20:18:14,623 epoch 4 - iter 6/37 - loss 0.31301470 - samples/sec: 127.24 - lr: 0.200667\n",
      "2022-08-30 20:18:17,540 epoch 4 - iter 9/37 - loss 0.31092115 - samples/sec: 95.47 - lr: 0.200667\n",
      "2022-08-30 20:18:20,061 epoch 4 - iter 12/37 - loss 0.30432081 - samples/sec: 109.80 - lr: 0.200667\n",
      "2022-08-30 20:18:23,084 epoch 4 - iter 15/37 - loss 0.30426421 - samples/sec: 91.19 - lr: 0.200667\n",
      "2022-08-30 20:18:25,592 epoch 4 - iter 18/37 - loss 0.30560511 - samples/sec: 110.20 - lr: 0.200667\n",
      "2022-08-30 20:18:27,894 epoch 4 - iter 21/37 - loss 0.30737061 - samples/sec: 120.37 - lr: 0.200667\n",
      "2022-08-30 20:18:30,339 epoch 4 - iter 24/37 - loss 0.30651465 - samples/sec: 113.59 - lr: 0.200667\n",
      "2022-08-30 20:18:32,706 epoch 4 - iter 27/37 - loss 0.30796312 - samples/sec: 118.63 - lr: 0.200667\n",
      "2022-08-30 20:18:35,089 epoch 4 - iter 30/37 - loss 0.30938695 - samples/sec: 115.93 - lr: 0.200667\n",
      "2022-08-30 20:18:37,515 epoch 4 - iter 33/37 - loss 0.30904444 - samples/sec: 113.92 - lr: 0.200667\n",
      "2022-08-30 20:18:39,823 epoch 4 - iter 36/37 - loss 0.30762399 - samples/sec: 119.79 - lr: 0.200667\n",
      "2022-08-30 20:18:40,925 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:18:40,926 EPOCH 4 done: loss 0.3080 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:18:42,946 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:18:42,975 DEV : loss 0.24200692772865295 - f1-score (micro avg)  0.9181\n",
      "2022-08-30 20:18:42,991 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:18:42,992 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:18:43,841 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:18:46,648 epoch 5 - iter 3/37 - loss 0.31409924 - samples/sec: 96.26 - lr: 0.200667\n",
      "2022-08-30 20:18:49,237 epoch 5 - iter 6/37 - loss 0.30979994 - samples/sec: 106.64 - lr: 0.200667\n",
      "2022-08-30 20:18:51,611 epoch 5 - iter 9/37 - loss 0.30321513 - samples/sec: 116.53 - lr: 0.200667\n",
      "2022-08-30 20:18:54,196 epoch 5 - iter 12/37 - loss 0.29646454 - samples/sec: 106.80 - lr: 0.200667\n",
      "2022-08-30 20:18:56,641 epoch 5 - iter 15/37 - loss 0.30027371 - samples/sec: 113.16 - lr: 0.200667\n",
      "2022-08-30 20:18:59,530 epoch 5 - iter 18/37 - loss 0.30196261 - samples/sec: 95.41 - lr: 0.200667\n",
      "2022-08-30 20:19:02,332 epoch 5 - iter 21/37 - loss 0.30001783 - samples/sec: 98.72 - lr: 0.200667\n",
      "2022-08-30 20:19:04,768 epoch 5 - iter 24/37 - loss 0.30190585 - samples/sec: 116.03 - lr: 0.200667\n",
      "2022-08-30 20:19:07,002 epoch 5 - iter 27/37 - loss 0.30143576 - samples/sec: 124.65 - lr: 0.200667\n",
      "2022-08-30 20:19:09,668 epoch 5 - iter 30/37 - loss 0.30170894 - samples/sec: 103.85 - lr: 0.200667\n",
      "2022-08-30 20:19:11,949 epoch 5 - iter 33/37 - loss 0.30098040 - samples/sec: 121.35 - lr: 0.200667\n",
      "2022-08-30 20:19:14,701 epoch 5 - iter 36/37 - loss 0.30364480 - samples/sec: 100.37 - lr: 0.200667\n",
      "2022-08-30 20:19:15,569 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:19:15,570 EPOCH 5 done: loss 0.3034 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:19:16,343 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:19:16,383 DEV : loss 0.23674353957176208 - f1-score (micro avg)  0.9202\n",
      "2022-08-30 20:19:16,413 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:19:16,415 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:19:17,126 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:19:19,613 epoch 6 - iter 3/37 - loss 0.30888763 - samples/sec: 108.65 - lr: 0.200667\n",
      "2022-08-30 20:19:22,390 epoch 6 - iter 6/37 - loss 0.29961392 - samples/sec: 99.45 - lr: 0.200667\n",
      "2022-08-30 20:19:24,994 epoch 6 - iter 9/37 - loss 0.30417663 - samples/sec: 106.22 - lr: 0.200667\n",
      "2022-08-30 20:19:28,000 epoch 6 - iter 12/37 - loss 0.30115846 - samples/sec: 91.81 - lr: 0.200667\n",
      "2022-08-30 20:19:30,404 epoch 6 - iter 15/37 - loss 0.30297905 - samples/sec: 115.04 - lr: 0.200667\n",
      "2022-08-30 20:19:32,919 epoch 6 - iter 18/37 - loss 0.30260679 - samples/sec: 110.20 - lr: 0.200667\n",
      "2022-08-30 20:19:35,911 epoch 6 - iter 21/37 - loss 0.30214939 - samples/sec: 92.06 - lr: 0.200667\n",
      "2022-08-30 20:19:38,472 epoch 6 - iter 24/37 - loss 0.30151222 - samples/sec: 108.13 - lr: 0.200667\n",
      "2022-08-30 20:19:41,053 epoch 6 - iter 27/37 - loss 0.30303149 - samples/sec: 107.36 - lr: 0.200667\n",
      "2022-08-30 20:19:43,663 epoch 6 - iter 30/37 - loss 0.30295905 - samples/sec: 105.84 - lr: 0.200667\n",
      "2022-08-30 20:19:46,195 epoch 6 - iter 33/37 - loss 0.30408402 - samples/sec: 109.31 - lr: 0.200667\n",
      "2022-08-30 20:19:48,509 epoch 6 - iter 36/37 - loss 0.30393880 - samples/sec: 119.79 - lr: 0.200667\n",
      "2022-08-30 20:19:49,407 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:19:49,409 EPOCH 6 done: loss 0.3043 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:19:50,282 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:19:50,310 DEV : loss 0.24185161292552948 - f1-score (micro avg)  0.9214\n",
      "2022-08-30 20:19:50,326 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:19:50,327 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:19:51,024 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:19:53,634 epoch 7 - iter 3/37 - loss 0.30193802 - samples/sec: 103.53 - lr: 0.200667\n",
      "2022-08-30 20:19:56,321 epoch 7 - iter 6/37 - loss 0.30902103 - samples/sec: 102.74 - lr: 0.200667\n",
      "2022-08-30 20:19:58,903 epoch 7 - iter 9/37 - loss 0.30505434 - samples/sec: 108.61 - lr: 0.200667\n",
      "2022-08-30 20:20:01,341 epoch 7 - iter 12/37 - loss 0.30638007 - samples/sec: 113.45 - lr: 0.200667\n",
      "2022-08-30 20:20:04,719 epoch 7 - iter 15/37 - loss 0.30683329 - samples/sec: 82.80 - lr: 0.200667\n",
      "2022-08-30 20:20:07,229 epoch 7 - iter 18/37 - loss 0.30901057 - samples/sec: 110.29 - lr: 0.200667\n",
      "2022-08-30 20:20:09,586 epoch 7 - iter 21/37 - loss 0.30572206 - samples/sec: 117.54 - lr: 0.200667\n",
      "2022-08-30 20:20:12,012 epoch 7 - iter 24/37 - loss 0.30526060 - samples/sec: 114.16 - lr: 0.200667\n",
      "2022-08-30 20:20:14,957 epoch 7 - iter 27/37 - loss 0.30568251 - samples/sec: 93.72 - lr: 0.200667\n",
      "2022-08-30 20:20:17,879 epoch 7 - iter 30/37 - loss 0.30569086 - samples/sec: 94.44 - lr: 0.200667\n",
      "2022-08-30 20:20:20,443 epoch 7 - iter 33/37 - loss 0.30422216 - samples/sec: 107.70 - lr: 0.200667\n",
      "2022-08-30 20:20:22,973 epoch 7 - iter 36/37 - loss 0.30619513 - samples/sec: 110.43 - lr: 0.200667\n",
      "2022-08-30 20:20:23,748 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:20:23,749 EPOCH 7 done: loss 0.3061 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:20:24,599 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:20:24,632 DEV : loss 0.2455570250749588 - f1-score (micro avg)  0.9163\n",
      "2022-08-30 20:20:24,648 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:20:24,649 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:20:27,304 epoch 8 - iter 3/37 - loss 0.31489422 - samples/sec: 101.69 - lr: 0.200667\n",
      "2022-08-30 20:20:29,877 epoch 8 - iter 6/37 - loss 0.30299589 - samples/sec: 107.66 - lr: 0.200667\n",
      "2022-08-30 20:20:32,878 epoch 8 - iter 9/37 - loss 0.30499166 - samples/sec: 91.99 - lr: 0.200667\n",
      "2022-08-30 20:20:35,512 epoch 8 - iter 12/37 - loss 0.30734214 - samples/sec: 105.30 - lr: 0.200667\n",
      "2022-08-30 20:20:38,324 epoch 8 - iter 15/37 - loss 0.30915567 - samples/sec: 98.07 - lr: 0.200667\n",
      "2022-08-30 20:20:40,819 epoch 8 - iter 18/37 - loss 0.30893905 - samples/sec: 112.83 - lr: 0.200667\n",
      "2022-08-30 20:20:43,124 epoch 8 - iter 21/37 - loss 0.30891649 - samples/sec: 120.32 - lr: 0.200667\n",
      "2022-08-30 20:20:45,940 epoch 8 - iter 24/37 - loss 0.30864633 - samples/sec: 98.00 - lr: 0.200667\n",
      "2022-08-30 20:20:48,436 epoch 8 - iter 27/37 - loss 0.30770102 - samples/sec: 110.88 - lr: 0.200667\n",
      "2022-08-30 20:20:50,966 epoch 8 - iter 30/37 - loss 0.30796791 - samples/sec: 110.43 - lr: 0.200667\n",
      "2022-08-30 20:20:53,278 epoch 8 - iter 33/37 - loss 0.30665223 - samples/sec: 120.32 - lr: 0.200667\n",
      "2022-08-30 20:20:55,788 epoch 8 - iter 36/37 - loss 0.30694694 - samples/sec: 110.34 - lr: 0.200667\n",
      "2022-08-30 20:20:56,674 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:20:56,675 EPOCH 8 done: loss 0.3077 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:20:57,479 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:20:57,515 DEV : loss 0.24434635043144226 - f1-score (micro avg)  0.9181\n",
      "2022-08-30 20:20:57,532 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:20:57,533 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:21:00,345 epoch 9 - iter 3/37 - loss 0.30206580 - samples/sec: 96.05 - lr: 0.200667\n",
      "2022-08-30 20:21:02,737 epoch 9 - iter 6/37 - loss 0.29655189 - samples/sec: 118.21 - lr: 0.200667\n",
      "2022-08-30 20:21:05,195 epoch 9 - iter 9/37 - loss 0.29389562 - samples/sec: 112.83 - lr: 0.200667\n",
      "2022-08-30 20:21:07,717 epoch 9 - iter 12/37 - loss 0.29931376 - samples/sec: 109.44 - lr: 0.200667\n",
      "2022-08-30 20:21:10,210 epoch 9 - iter 15/37 - loss 0.29737417 - samples/sec: 111.11 - lr: 0.200667\n",
      "2022-08-30 20:21:12,763 epoch 9 - iter 18/37 - loss 0.29767032 - samples/sec: 108.26 - lr: 0.200667\n",
      "2022-08-30 20:21:15,569 epoch 9 - iter 21/37 - loss 0.29761537 - samples/sec: 99.26 - lr: 0.200667\n",
      "2022-08-30 20:21:17,855 epoch 9 - iter 24/37 - loss 0.29871986 - samples/sec: 122.01 - lr: 0.200667\n",
      "2022-08-30 20:21:20,313 epoch 9 - iter 27/37 - loss 0.29906942 - samples/sec: 112.50 - lr: 0.200667\n",
      "2022-08-30 20:21:23,013 epoch 9 - iter 30/37 - loss 0.30120237 - samples/sec: 104.65 - lr: 0.200667\n",
      "2022-08-30 20:21:25,624 epoch 9 - iter 33/37 - loss 0.30131489 - samples/sec: 105.97 - lr: 0.200667\n",
      "2022-08-30 20:21:28,792 epoch 9 - iter 36/37 - loss 0.30076132 - samples/sec: 86.96 - lr: 0.200667\n",
      "2022-08-30 20:21:29,617 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:21:29,618 EPOCH 9 done: loss 0.3008 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:21:30,394 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:21:30,424 DEV : loss 0.23705527186393738 - f1-score (micro avg)  0.9206\n",
      "2022-08-30 20:21:30,440 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 20:21:30,442 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:21:32,796 epoch 10 - iter 3/37 - loss 0.30264577 - samples/sec: 114.80 - lr: 0.200667\n",
      "2022-08-30 20:21:35,258 epoch 10 - iter 6/37 - loss 0.30346586 - samples/sec: 112.17 - lr: 0.200667\n",
      "2022-08-30 20:21:37,681 epoch 10 - iter 9/37 - loss 0.29844494 - samples/sec: 114.46 - lr: 0.200667\n",
      "2022-08-30 20:21:39,959 epoch 10 - iter 12/37 - loss 0.29819859 - samples/sec: 121.57 - lr: 0.200667\n",
      "2022-08-30 20:21:42,291 epoch 10 - iter 15/37 - loss 0.30072015 - samples/sec: 118.89 - lr: 0.200667\n",
      "2022-08-30 20:21:44,737 epoch 10 - iter 18/37 - loss 0.30100325 - samples/sec: 113.26 - lr: 0.200667\n",
      "2022-08-30 20:21:47,261 epoch 10 - iter 21/37 - loss 0.29850924 - samples/sec: 109.49 - lr: 0.200667\n",
      "2022-08-30 20:21:50,224 epoch 10 - iter 24/37 - loss 0.30088995 - samples/sec: 93.07 - lr: 0.200667\n",
      "2022-08-30 20:21:52,889 epoch 10 - iter 27/37 - loss 0.29988112 - samples/sec: 103.61 - lr: 0.200667\n",
      "2022-08-30 20:21:55,604 epoch 10 - iter 30/37 - loss 0.30100470 - samples/sec: 102.51 - lr: 0.200667\n",
      "2022-08-30 20:21:58,229 epoch 10 - iter 33/37 - loss 0.30043564 - samples/sec: 105.47 - lr: 0.200667\n",
      "2022-08-30 20:22:01,637 epoch 10 - iter 36/37 - loss 0.29935473 - samples/sec: 80.60 - lr: 0.200667\n",
      "2022-08-30 20:22:02,399 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:22:02,400 EPOCH 10 done: loss 0.2992 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:22:03,232 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:22:03,263 DEV : loss 0.241856649518013 - f1-score (micro avg)  0.918\n",
      "2022-08-30 20:22:03,284 Epoch    10: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 20:22:03,285 BAD EPOCHS (no improvement): 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:22:04,320 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:22:04,321 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 20:22:04,506 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:22:05,910 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:22:05,940 0.925\t0.925\t0.925\t0.925\n",
      "2022-08-30 20:22:05,941 \n",
      "Results:\n",
      "- F-score (micro) 0.925\n",
      "- F-score (macro) 0.8055\n",
      "- Accuracy 0.925\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8834    0.9350    0.9084      1353\n",
      "         ADJ     0.8891    0.8943    0.8917       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9922    0.9844    0.9883       514\n",
      "        VERB     0.8996    0.9176    0.9085       449\n",
      "       PROPN     0.8567    0.7180    0.7812       383\n",
      "         AUX     0.9910    0.9821    0.9865       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8910    0.8634    0.8770       161\n",
      "         ADV     0.8289    0.8344    0.8317       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9649    0.7746    0.8594        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9250      5264\n",
      "   macro avg     0.8235    0.7910    0.8055      5264\n",
      "weighted avg     0.9255    0.9250    0.9244      5264\n",
      "\n",
      "2022-08-30 20:22:05,942 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:22:05,947 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:22:06,455 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 7 #######################\n",
      "#######################################################\n",
      "2022-08-30 20:24:33,428 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:24:33,429 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 20:24:33,430 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:24:33,431 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 20:24:33,431 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:24:33,432 Parameters:\n",
      "2022-08-30 20:24:33,433  - learning_rate: \"0.200667\"\n",
      "2022-08-30 20:24:33,434  - mini_batch_size: \"90\"\n",
      "2022-08-30 20:24:33,434  - patience: \"3\"\n",
      "2022-08-30 20:24:33,435  - anneal_factor: \"0.5\"\n",
      "2022-08-30 20:24:33,435  - max_epochs: \"11\"\n",
      "2022-08-30 20:24:33,436  - shuffle: \"True\"\n",
      "2022-08-30 20:24:33,436  - train_with_dev: \"False\"\n",
      "2022-08-30 20:24:33,437  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 20:24:33,437 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:24:33,438 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 20:24:33,439 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:24:33,439 Device: cpu\n",
      "2022-08-30 20:24:33,440 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:24:33,442 Embeddings storage mode: cpu\n",
      "2022-08-30 20:24:33,443 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:24:35,833 epoch 1 - iter 3/37 - loss 0.27320944 - samples/sec: 113.02 - lr: 0.200667\n",
      "2022-08-30 20:24:38,721 epoch 1 - iter 6/37 - loss 0.27885071 - samples/sec: 95.61 - lr: 0.200667\n",
      "2022-08-30 20:24:41,034 epoch 1 - iter 9/37 - loss 0.28425723 - samples/sec: 120.05 - lr: 0.200667\n",
      "2022-08-30 20:24:43,275 epoch 1 - iter 12/37 - loss 0.28662372 - samples/sec: 123.51 - lr: 0.200667\n",
      "2022-08-30 20:24:45,776 epoch 1 - iter 15/37 - loss 0.28526300 - samples/sec: 110.52 - lr: 0.200667\n",
      "2022-08-30 20:24:48,104 epoch 1 - iter 18/37 - loss 0.28788657 - samples/sec: 119.10 - lr: 0.200667\n",
      "2022-08-30 20:24:50,830 epoch 1 - iter 21/37 - loss 0.28603900 - samples/sec: 101.35 - lr: 0.200667\n",
      "2022-08-30 20:24:53,283 epoch 1 - iter 24/37 - loss 0.28585478 - samples/sec: 112.78 - lr: 0.200667\n",
      "2022-08-30 20:24:55,774 epoch 1 - iter 27/37 - loss 0.28677401 - samples/sec: 110.88 - lr: 0.200667\n",
      "2022-08-30 20:24:57,840 epoch 1 - iter 30/37 - loss 0.28678185 - samples/sec: 134.33 - lr: 0.200667\n",
      "2022-08-30 20:25:00,520 epoch 1 - iter 33/37 - loss 0.29013191 - samples/sec: 103.25 - lr: 0.200667\n",
      "2022-08-30 20:25:03,328 epoch 1 - iter 36/37 - loss 0.29872782 - samples/sec: 99.05 - lr: 0.200667\n",
      "2022-08-30 20:25:04,467 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:25:04,468 EPOCH 1 done: loss 0.3028 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:25:05,213 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:25:05,244 DEV : loss 0.2610190510749817 - f1-score (micro avg)  0.9118\n",
      "2022-08-30 20:25:05,263 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:25:05,264 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:25:05,948 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:25:08,426 epoch 2 - iter 3/37 - loss 0.30200032 - samples/sec: 109.05 - lr: 0.200667\n",
      "2022-08-30 20:25:10,789 epoch 2 - iter 6/37 - loss 0.29745905 - samples/sec: 119.15 - lr: 0.200667\n",
      "2022-08-30 20:25:13,698 epoch 2 - iter 9/37 - loss 0.29638964 - samples/sec: 94.87 - lr: 0.200667\n",
      "2022-08-30 20:25:16,273 epoch 2 - iter 12/37 - loss 0.30470730 - samples/sec: 107.53 - lr: 0.200667\n",
      "2022-08-30 20:25:19,292 epoch 2 - iter 15/37 - loss 0.30673510 - samples/sec: 91.19 - lr: 0.200667\n",
      "2022-08-30 20:25:21,728 epoch 2 - iter 18/37 - loss 0.30482272 - samples/sec: 113.45 - lr: 0.200667\n",
      "2022-08-30 20:25:24,052 epoch 2 - iter 21/37 - loss 0.30427557 - samples/sec: 119.21 - lr: 0.200667\n",
      "2022-08-30 20:25:27,114 epoch 2 - iter 24/37 - loss 0.30501594 - samples/sec: 89.85 - lr: 0.200667\n",
      "2022-08-30 20:25:29,346 epoch 2 - iter 27/37 - loss 0.30512805 - samples/sec: 124.60 - lr: 0.200667\n",
      "2022-08-30 20:25:31,959 epoch 2 - iter 30/37 - loss 0.30369949 - samples/sec: 106.13 - lr: 0.200667\n",
      "2022-08-30 20:25:34,749 epoch 2 - iter 33/37 - loss 0.30472517 - samples/sec: 99.19 - lr: 0.200667\n",
      "2022-08-30 20:25:37,019 epoch 2 - iter 36/37 - loss 0.30461341 - samples/sec: 122.17 - lr: 0.200667\n",
      "2022-08-30 20:25:37,871 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:25:37,872 EPOCH 2 done: loss 0.3055 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:25:38,662 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:25:38,692 DEV : loss 0.24021050333976746 - f1-score (micro avg)  0.9199\n",
      "2022-08-30 20:25:38,708 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:25:38,709 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:25:39,432 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:25:41,888 epoch 3 - iter 3/37 - loss 0.29587723 - samples/sec: 110.02 - lr: 0.200667\n",
      "2022-08-30 20:25:44,259 epoch 3 - iter 6/37 - loss 0.29757958 - samples/sec: 116.68 - lr: 0.200667\n",
      "2022-08-30 20:25:46,977 epoch 3 - iter 9/37 - loss 0.29470951 - samples/sec: 101.43 - lr: 0.200667\n",
      "2022-08-30 20:25:49,316 epoch 3 - iter 12/37 - loss 0.29407704 - samples/sec: 118.37 - lr: 0.200667\n",
      "2022-08-30 20:25:51,512 epoch 3 - iter 15/37 - loss 0.29841265 - samples/sec: 126.88 - lr: 0.200667\n",
      "2022-08-30 20:25:54,039 epoch 3 - iter 18/37 - loss 0.29813149 - samples/sec: 109.98 - lr: 0.200667\n",
      "2022-08-30 20:25:56,168 epoch 3 - iter 21/37 - loss 0.30088802 - samples/sec: 130.50 - lr: 0.200667\n",
      "2022-08-30 20:25:58,911 epoch 3 - iter 24/37 - loss 0.29991474 - samples/sec: 100.60 - lr: 0.200667\n",
      "2022-08-30 20:26:01,253 epoch 3 - iter 27/37 - loss 0.30161843 - samples/sec: 118.37 - lr: 0.200667\n",
      "2022-08-30 20:26:03,594 epoch 3 - iter 30/37 - loss 0.30282269 - samples/sec: 118.27 - lr: 0.200667\n",
      "2022-08-30 20:26:06,567 epoch 3 - iter 33/37 - loss 0.30226559 - samples/sec: 93.04 - lr: 0.200667\n",
      "2022-08-30 20:26:09,328 epoch 3 - iter 36/37 - loss 0.30169175 - samples/sec: 101.28 - lr: 0.200667\n",
      "2022-08-30 20:26:10,105 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:26:10,105 EPOCH 3 done: loss 0.3015 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:26:10,899 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:26:10,927 DEV : loss 0.23892129957675934 - f1-score (micro avg)  0.9186\n",
      "2022-08-30 20:26:10,942 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:26:10,943 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:26:14,114 epoch 4 - iter 3/37 - loss 0.30312603 - samples/sec: 85.17 - lr: 0.200667\n",
      "2022-08-30 20:26:16,896 epoch 4 - iter 6/37 - loss 0.29569264 - samples/sec: 99.01 - lr: 0.200667\n",
      "2022-08-30 20:26:19,207 epoch 4 - iter 9/37 - loss 0.29370711 - samples/sec: 119.79 - lr: 0.200667\n",
      "2022-08-30 20:26:21,598 epoch 4 - iter 12/37 - loss 0.29875684 - samples/sec: 115.88 - lr: 0.200667\n",
      "2022-08-30 20:26:23,703 epoch 4 - iter 15/37 - loss 0.29607311 - samples/sec: 132.16 - lr: 0.200667\n",
      "2022-08-30 20:26:26,118 epoch 4 - iter 18/37 - loss 0.29614124 - samples/sec: 114.70 - lr: 0.200667\n",
      "2022-08-30 20:26:28,376 epoch 4 - iter 21/37 - loss 0.29651482 - samples/sec: 122.84 - lr: 0.200667\n",
      "2022-08-30 20:26:31,167 epoch 4 - iter 24/37 - loss 0.29670024 - samples/sec: 101.16 - lr: 0.200667\n",
      "2022-08-30 20:26:33,345 epoch 4 - iter 27/37 - loss 0.29603765 - samples/sec: 127.48 - lr: 0.200667\n",
      "2022-08-30 20:26:35,695 epoch 4 - iter 30/37 - loss 0.29806729 - samples/sec: 119.47 - lr: 0.200667\n",
      "2022-08-30 20:26:37,885 epoch 4 - iter 33/37 - loss 0.29919551 - samples/sec: 126.70 - lr: 0.200667\n",
      "2022-08-30 20:26:40,742 epoch 4 - iter 36/37 - loss 0.29894429 - samples/sec: 96.77 - lr: 0.200667\n",
      "2022-08-30 20:26:41,517 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:26:41,518 EPOCH 4 done: loss 0.2993 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:26:42,274 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:26:42,306 DEV : loss 0.2496337890625 - f1-score (micro avg)  0.9176\n",
      "2022-08-30 20:26:42,323 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:26:42,324 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:26:44,595 epoch 5 - iter 3/37 - loss 0.27158322 - samples/sec: 118.94 - lr: 0.200667\n",
      "2022-08-30 20:26:47,240 epoch 5 - iter 6/37 - loss 0.29046653 - samples/sec: 104.65 - lr: 0.200667\n",
      "2022-08-30 20:26:49,630 epoch 5 - iter 9/37 - loss 0.29234426 - samples/sec: 115.98 - lr: 0.200667\n",
      "2022-08-30 20:26:51,887 epoch 5 - iter 12/37 - loss 0.29658850 - samples/sec: 122.95 - lr: 0.200667\n",
      "2022-08-30 20:26:54,192 epoch 5 - iter 15/37 - loss 0.29452189 - samples/sec: 120.37 - lr: 0.200667\n",
      "2022-08-30 20:26:57,084 epoch 5 - iter 18/37 - loss 0.29648724 - samples/sec: 95.17 - lr: 0.200667\n",
      "2022-08-30 20:26:59,729 epoch 5 - iter 21/37 - loss 0.29922894 - samples/sec: 104.37 - lr: 0.200667\n",
      "2022-08-30 20:27:02,420 epoch 5 - iter 24/37 - loss 0.29951069 - samples/sec: 102.54 - lr: 0.200667\n",
      "2022-08-30 20:27:04,678 epoch 5 - iter 27/37 - loss 0.30092706 - samples/sec: 124.48 - lr: 0.200667\n",
      "2022-08-30 20:27:06,869 epoch 5 - iter 30/37 - loss 0.30228664 - samples/sec: 126.64 - lr: 0.200667\n",
      "2022-08-30 20:27:09,345 epoch 5 - iter 33/37 - loss 0.30166889 - samples/sec: 111.80 - lr: 0.200667\n",
      "2022-08-30 20:27:11,840 epoch 5 - iter 36/37 - loss 0.30200566 - samples/sec: 111.43 - lr: 0.200667\n",
      "2022-08-30 20:27:13,049 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:27:13,050 EPOCH 5 done: loss 0.3019 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:27:13,907 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:27:13,935 DEV : loss 0.24448415637016296 - f1-score (micro avg)  0.9209\n",
      "2022-08-30 20:27:13,949 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:27:13,951 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:27:14,857 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:27:17,242 epoch 6 - iter 3/37 - loss 0.27609982 - samples/sec: 113.26 - lr: 0.200667\n",
      "2022-08-30 20:27:19,501 epoch 6 - iter 6/37 - loss 0.28526682 - samples/sec: 122.95 - lr: 0.200667\n",
      "2022-08-30 20:27:22,043 epoch 6 - iter 9/37 - loss 0.29034278 - samples/sec: 109.89 - lr: 0.200667\n",
      "2022-08-30 20:27:24,539 epoch 6 - iter 12/37 - loss 0.29254259 - samples/sec: 112.92 - lr: 0.200667\n",
      "2022-08-30 20:27:27,087 epoch 6 - iter 15/37 - loss 0.29659627 - samples/sec: 108.56 - lr: 0.200667\n",
      "2022-08-30 20:27:29,263 epoch 6 - iter 18/37 - loss 0.29990812 - samples/sec: 127.54 - lr: 0.200667\n",
      "2022-08-30 20:27:31,757 epoch 6 - iter 21/37 - loss 0.30211785 - samples/sec: 110.75 - lr: 0.200667\n",
      "2022-08-30 20:27:34,982 epoch 6 - iter 24/37 - loss 0.30529397 - samples/sec: 85.25 - lr: 0.200667\n",
      "2022-08-30 20:27:37,275 epoch 6 - iter 27/37 - loss 0.30073956 - samples/sec: 121.08 - lr: 0.200667\n",
      "2022-08-30 20:27:39,789 epoch 6 - iter 30/37 - loss 0.30040244 - samples/sec: 110.02 - lr: 0.200667\n",
      "2022-08-30 20:27:42,239 epoch 6 - iter 33/37 - loss 0.29968760 - samples/sec: 113.26 - lr: 0.200667\n",
      "2022-08-30 20:27:44,631 epoch 6 - iter 36/37 - loss 0.29984111 - samples/sec: 116.13 - lr: 0.200667\n",
      "2022-08-30 20:27:45,394 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:27:45,395 EPOCH 6 done: loss 0.2998 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:27:46,186 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:27:46,214 DEV : loss 0.24909017980098724 - f1-score (micro avg)  0.9173\n",
      "2022-08-30 20:27:46,230 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:27:46,231 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:27:48,592 epoch 7 - iter 3/37 - loss 0.31104425 - samples/sec: 114.41 - lr: 0.200667\n",
      "2022-08-30 20:27:50,888 epoch 7 - iter 6/37 - loss 0.30712959 - samples/sec: 120.64 - lr: 0.200667\n",
      "2022-08-30 20:27:53,569 epoch 7 - iter 9/37 - loss 0.30183555 - samples/sec: 102.94 - lr: 0.200667\n",
      "2022-08-30 20:27:55,709 epoch 7 - iter 12/37 - loss 0.30113493 - samples/sec: 130.56 - lr: 0.200667\n",
      "2022-08-30 20:27:57,994 epoch 7 - iter 15/37 - loss 0.30329519 - samples/sec: 122.06 - lr: 0.200667\n",
      "2022-08-30 20:28:00,190 epoch 7 - iter 18/37 - loss 0.30108097 - samples/sec: 126.23 - lr: 0.200667\n",
      "2022-08-30 20:28:02,869 epoch 7 - iter 21/37 - loss 0.29961707 - samples/sec: 103.29 - lr: 0.200667\n",
      "2022-08-30 20:28:05,509 epoch 7 - iter 24/37 - loss 0.30102648 - samples/sec: 104.49 - lr: 0.200667\n",
      "2022-08-30 20:28:08,022 epoch 7 - iter 27/37 - loss 0.30117323 - samples/sec: 110.57 - lr: 0.200667\n",
      "2022-08-30 20:28:10,645 epoch 7 - iter 30/37 - loss 0.30094794 - samples/sec: 105.55 - lr: 0.200667\n",
      "2022-08-30 20:28:13,426 epoch 7 - iter 33/37 - loss 0.30146583 - samples/sec: 99.37 - lr: 0.200667\n",
      "2022-08-30 20:28:16,392 epoch 7 - iter 36/37 - loss 0.30145402 - samples/sec: 93.56 - lr: 0.200667\n",
      "2022-08-30 20:28:17,151 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:28:17,152 EPOCH 7 done: loss 0.3011 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:28:17,954 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:28:17,985 DEV : loss 0.24242378771305084 - f1-score (micro avg)  0.9186\n",
      "2022-08-30 20:28:18,002 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:28:18,003 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:28:20,139 epoch 8 - iter 3/37 - loss 0.28163757 - samples/sec: 126.46 - lr: 0.200667\n",
      "2022-08-30 20:28:22,860 epoch 8 - iter 6/37 - loss 0.29597046 - samples/sec: 101.31 - lr: 0.200667\n",
      "2022-08-30 20:28:25,656 epoch 8 - iter 9/37 - loss 0.30261770 - samples/sec: 98.58 - lr: 0.200667\n",
      "2022-08-30 20:28:28,821 epoch 8 - iter 12/37 - loss 0.30437153 - samples/sec: 86.96 - lr: 0.200667\n",
      "2022-08-30 20:28:30,964 epoch 8 - iter 15/37 - loss 0.29744603 - samples/sec: 129.62 - lr: 0.200667\n",
      "2022-08-30 20:28:33,489 epoch 8 - iter 18/37 - loss 0.30115688 - samples/sec: 109.58 - lr: 0.200667\n",
      "2022-08-30 20:28:35,812 epoch 8 - iter 21/37 - loss 0.29910919 - samples/sec: 119.57 - lr: 0.200667\n",
      "2022-08-30 20:28:38,090 epoch 8 - iter 24/37 - loss 0.29869533 - samples/sec: 121.62 - lr: 0.200667\n",
      "2022-08-30 20:28:40,778 epoch 8 - iter 27/37 - loss 0.29890656 - samples/sec: 102.94 - lr: 0.200667\n",
      "2022-08-30 20:28:43,334 epoch 8 - iter 30/37 - loss 0.29724717 - samples/sec: 108.22 - lr: 0.200667\n",
      "2022-08-30 20:28:46,056 epoch 8 - iter 33/37 - loss 0.29825842 - samples/sec: 102.27 - lr: 0.200667\n",
      "2022-08-30 20:28:48,338 epoch 8 - iter 36/37 - loss 0.29787436 - samples/sec: 121.51 - lr: 0.200667\n",
      "2022-08-30 20:28:49,164 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:28:49,165 EPOCH 8 done: loss 0.2978 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:28:50,055 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:28:50,089 DEV : loss 0.24219036102294922 - f1-score (micro avg)  0.9193\n",
      "2022-08-30 20:28:50,105 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 20:28:50,106 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:28:53,769 epoch 9 - iter 3/37 - loss 0.30638503 - samples/sec: 73.75 - lr: 0.200667\n",
      "2022-08-30 20:28:56,105 epoch 9 - iter 6/37 - loss 0.30476056 - samples/sec: 118.58 - lr: 0.200667\n",
      "2022-08-30 20:28:59,094 epoch 9 - iter 9/37 - loss 0.29705940 - samples/sec: 92.21 - lr: 0.200667\n",
      "2022-08-30 20:29:01,951 epoch 9 - iter 12/37 - loss 0.29810190 - samples/sec: 96.41 - lr: 0.200667\n",
      "2022-08-30 20:29:04,208 epoch 9 - iter 15/37 - loss 0.29813657 - samples/sec: 123.80 - lr: 0.200667\n",
      "2022-08-30 20:29:07,143 epoch 9 - iter 18/37 - loss 0.29924990 - samples/sec: 93.95 - lr: 0.200667\n",
      "2022-08-30 20:29:09,715 epoch 9 - iter 21/37 - loss 0.30215041 - samples/sec: 107.57 - lr: 0.200667\n",
      "2022-08-30 20:29:12,115 epoch 9 - iter 24/37 - loss 0.30168723 - samples/sec: 115.14 - lr: 0.200667\n",
      "2022-08-30 20:29:15,065 epoch 9 - iter 27/37 - loss 0.30040410 - samples/sec: 93.39 - lr: 0.200667\n",
      "2022-08-30 20:29:17,921 epoch 9 - iter 30/37 - loss 0.30036860 - samples/sec: 96.67 - lr: 0.200667\n",
      "2022-08-30 20:29:20,291 epoch 9 - iter 33/37 - loss 0.30247203 - samples/sec: 116.98 - lr: 0.200667\n",
      "2022-08-30 20:29:22,625 epoch 9 - iter 36/37 - loss 0.30322269 - samples/sec: 119.26 - lr: 0.200667\n",
      "2022-08-30 20:29:23,790 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:29:23,791 EPOCH 9 done: loss 0.3038 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:29:24,581 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:29:24,611 DEV : loss 0.23991109430789948 - f1-score (micro avg)  0.9222\n",
      "2022-08-30 20:29:24,632 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:29:24,634 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:29:25,639 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:29:27,745 epoch 10 - iter 3/37 - loss 0.30060643 - samples/sec: 128.27 - lr: 0.200667\n",
      "2022-08-30 20:29:30,091 epoch 10 - iter 6/37 - loss 0.29592407 - samples/sec: 118.16 - lr: 0.200667\n",
      "2022-08-30 20:29:33,085 epoch 10 - iter 9/37 - loss 0.29408055 - samples/sec: 91.96 - lr: 0.200667\n",
      "2022-08-30 20:29:35,513 epoch 10 - iter 12/37 - loss 0.29861879 - samples/sec: 113.97 - lr: 0.200667\n",
      "2022-08-30 20:29:37,845 epoch 10 - iter 15/37 - loss 0.29850201 - samples/sec: 119.36 - lr: 0.200667\n",
      "2022-08-30 20:29:40,099 epoch 10 - iter 18/37 - loss 0.29775494 - samples/sec: 123.06 - lr: 0.200667\n",
      "2022-08-30 20:29:42,625 epoch 10 - iter 21/37 - loss 0.29805876 - samples/sec: 110.61 - lr: 0.200667\n",
      "2022-08-30 20:29:45,191 epoch 10 - iter 24/37 - loss 0.29556424 - samples/sec: 107.74 - lr: 0.200667\n",
      "2022-08-30 20:29:47,694 epoch 10 - iter 27/37 - loss 0.29728498 - samples/sec: 110.66 - lr: 0.200667\n",
      "2022-08-30 20:29:50,282 epoch 10 - iter 30/37 - loss 0.29754735 - samples/sec: 107.06 - lr: 0.200667\n",
      "2022-08-30 20:29:52,911 epoch 10 - iter 33/37 - loss 0.29787989 - samples/sec: 105.26 - lr: 0.200667\n",
      "2022-08-30 20:29:55,708 epoch 10 - iter 36/37 - loss 0.29807319 - samples/sec: 98.79 - lr: 0.200667\n",
      "2022-08-30 20:29:56,517 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:29:56,518 EPOCH 10 done: loss 0.2982 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:29:57,335 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:29:57,367 DEV : loss 0.23678965866565704 - f1-score (micro avg)  0.9199\n",
      "2022-08-30 20:29:57,381 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:29:57,382 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:29:59,788 epoch 11 - iter 3/37 - loss 0.28250262 - samples/sec: 112.27 - lr: 0.200667\n",
      "2022-08-30 20:30:02,343 epoch 11 - iter 6/37 - loss 0.28980182 - samples/sec: 108.83 - lr: 0.200667\n",
      "2022-08-30 20:30:04,764 epoch 11 - iter 9/37 - loss 0.29415618 - samples/sec: 114.99 - lr: 0.200667\n",
      "2022-08-30 20:30:07,375 epoch 11 - iter 12/37 - loss 0.29312792 - samples/sec: 105.92 - lr: 0.200667\n",
      "2022-08-30 20:30:10,217 epoch 11 - iter 15/37 - loss 0.29517823 - samples/sec: 98.18 - lr: 0.200667\n",
      "2022-08-30 20:30:12,497 epoch 11 - iter 18/37 - loss 0.29296522 - samples/sec: 121.62 - lr: 0.200667\n",
      "2022-08-30 20:30:14,871 epoch 11 - iter 21/37 - loss 0.29395432 - samples/sec: 117.29 - lr: 0.200667\n",
      "2022-08-30 20:30:17,596 epoch 11 - iter 24/37 - loss 0.29352542 - samples/sec: 101.28 - lr: 0.200667\n",
      "2022-08-30 20:30:20,068 epoch 11 - iter 27/37 - loss 0.29287664 - samples/sec: 112.27 - lr: 0.200667\n",
      "2022-08-30 20:30:22,614 epoch 11 - iter 30/37 - loss 0.29178123 - samples/sec: 108.56 - lr: 0.200667\n",
      "2022-08-30 20:30:25,459 epoch 11 - iter 33/37 - loss 0.29164108 - samples/sec: 96.88 - lr: 0.200667\n",
      "2022-08-30 20:30:27,931 epoch 11 - iter 36/37 - loss 0.29369741 - samples/sec: 112.13 - lr: 0.200667\n",
      "2022-08-30 20:30:28,617 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:30:28,618 EPOCH 11 done: loss 0.2932 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:30:29,387 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:30:29,420 DEV : loss 0.24353916943073273 - f1-score (micro avg)  0.9199\n",
      "2022-08-30 20:30:29,435 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:30:30,125 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:30:30,126 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 20:30:30,305 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:30:31,700 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:30:31,725 0.9223\t0.9223\t0.9223\t0.9223\n",
      "2022-08-30 20:30:31,725 \n",
      "Results:\n",
      "- F-score (micro) 0.9223\n",
      "- F-score (macro) 0.8031\n",
      "- Accuracy 0.9223\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.9009    0.9135    0.9072      1353\n",
      "         ADJ     0.8514    0.9122    0.8807       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9941    0.9844    0.9892       514\n",
      "        VERB     0.9197    0.8931    0.9062       449\n",
      "       PROPN     0.8213    0.7441    0.7808       383\n",
      "         AUX     0.9881    0.9881    0.9881       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8521    0.8944    0.8727       161\n",
      "         ADV     0.8322    0.8212    0.8267       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9474    0.7606    0.8437        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9223      5264\n",
      "   macro avg     0.8179    0.7915    0.8031      5264\n",
      "weighted avg     0.9230    0.9223    0.9221      5264\n",
      "\n",
      "2022-08-30 20:30:31,726 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:30:31,728 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:30:32,219 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 8 #######################\n",
      "#######################################################\n",
      "2022-08-30 20:32:56,864 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:32:56,864 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 20:32:56,865 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:32:56,866 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 20:32:56,866 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:32:56,867 Parameters:\n",
      "2022-08-30 20:32:56,867  - learning_rate: \"0.200667\"\n",
      "2022-08-30 20:32:56,868  - mini_batch_size: \"90\"\n",
      "2022-08-30 20:32:56,868  - patience: \"3\"\n",
      "2022-08-30 20:32:56,869  - anneal_factor: \"0.5\"\n",
      "2022-08-30 20:32:56,869  - max_epochs: \"12\"\n",
      "2022-08-30 20:32:56,870  - shuffle: \"True\"\n",
      "2022-08-30 20:32:56,871  - train_with_dev: \"False\"\n",
      "2022-08-30 20:32:56,871  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 20:32:56,872 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:32:56,872 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 20:32:56,873 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:32:56,873 Device: cpu\n",
      "2022-08-30 20:32:56,874 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:32:56,875 Embeddings storage mode: cpu\n",
      "2022-08-30 20:32:56,875 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:32:59,066 epoch 1 - iter 3/37 - loss 0.27030085 - samples/sec: 123.29 - lr: 0.200667\n",
      "2022-08-30 20:33:01,676 epoch 1 - iter 6/37 - loss 0.28743714 - samples/sec: 105.72 - lr: 0.200667\n",
      "2022-08-30 20:33:03,987 epoch 1 - iter 9/37 - loss 0.28707041 - samples/sec: 120.16 - lr: 0.200667\n",
      "2022-08-30 20:33:06,461 epoch 1 - iter 12/37 - loss 0.28239898 - samples/sec: 111.89 - lr: 0.200667\n",
      "2022-08-30 20:33:08,793 epoch 1 - iter 15/37 - loss 0.28597725 - samples/sec: 118.84 - lr: 0.200667\n",
      "2022-08-30 20:33:11,073 epoch 1 - iter 18/37 - loss 0.28420386 - samples/sec: 121.29 - lr: 0.200667\n",
      "2022-08-30 20:33:13,751 epoch 1 - iter 21/37 - loss 0.28223874 - samples/sec: 103.17 - lr: 0.200667\n",
      "2022-08-30 20:33:16,216 epoch 1 - iter 24/37 - loss 0.28281919 - samples/sec: 112.08 - lr: 0.200667\n",
      "2022-08-30 20:33:18,679 epoch 1 - iter 27/37 - loss 0.28129590 - samples/sec: 112.27 - lr: 0.200667\n",
      "2022-08-30 20:33:20,790 epoch 1 - iter 30/37 - loss 0.28321695 - samples/sec: 131.84 - lr: 0.200667\n",
      "2022-08-30 20:33:23,585 epoch 1 - iter 33/37 - loss 0.28524800 - samples/sec: 98.76 - lr: 0.200667\n",
      "2022-08-30 20:33:26,478 epoch 1 - iter 36/37 - loss 0.29352153 - samples/sec: 95.61 - lr: 0.200667\n",
      "2022-08-30 20:33:27,683 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:33:27,683 EPOCH 1 done: loss 0.2950 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:33:28,465 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:33:28,496 DEV : loss 0.2525618076324463 - f1-score (micro avg)  0.9139\n",
      "2022-08-30 20:33:28,517 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:33:28,518 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:33:29,519 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:33:32,259 epoch 2 - iter 3/37 - loss 0.29131371 - samples/sec: 98.61 - lr: 0.200667\n",
      "2022-08-30 20:33:34,790 epoch 2 - iter 6/37 - loss 0.28969777 - samples/sec: 109.18 - lr: 0.200667\n",
      "2022-08-30 20:33:38,053 epoch 2 - iter 9/37 - loss 0.29445967 - samples/sec: 84.22 - lr: 0.200667\n",
      "2022-08-30 20:33:40,400 epoch 2 - iter 12/37 - loss 0.29666589 - samples/sec: 117.90 - lr: 0.200667\n",
      "2022-08-30 20:33:43,025 epoch 2 - iter 15/37 - loss 0.29674124 - samples/sec: 106.22 - lr: 0.200667\n",
      "2022-08-30 20:33:45,631 epoch 2 - iter 18/37 - loss 0.29801835 - samples/sec: 106.13 - lr: 0.200667\n",
      "2022-08-30 20:33:47,935 epoch 2 - iter 21/37 - loss 0.29814680 - samples/sec: 120.32 - lr: 0.200667\n",
      "2022-08-30 20:33:50,343 epoch 2 - iter 24/37 - loss 0.29770325 - samples/sec: 114.89 - lr: 0.200667\n",
      "2022-08-30 20:33:52,856 epoch 2 - iter 27/37 - loss 0.29609653 - samples/sec: 111.94 - lr: 0.200667\n",
      "2022-08-30 20:33:55,146 epoch 2 - iter 30/37 - loss 0.29591045 - samples/sec: 121.67 - lr: 0.200667\n",
      "2022-08-30 20:33:57,438 epoch 2 - iter 33/37 - loss 0.29673085 - samples/sec: 120.97 - lr: 0.200667\n",
      "2022-08-30 20:33:59,868 epoch 2 - iter 36/37 - loss 0.29576803 - samples/sec: 113.92 - lr: 0.200667\n",
      "2022-08-30 20:34:00,940 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:34:00,940 EPOCH 2 done: loss 0.2954 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:34:01,747 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:34:01,776 DEV : loss 0.24146045744419098 - f1-score (micro avg)  0.9189\n",
      "2022-08-30 20:34:01,797 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:34:01,799 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:34:02,673 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:34:05,833 epoch 3 - iter 3/37 - loss 0.28834334 - samples/sec: 85.52 - lr: 0.200667\n",
      "2022-08-30 20:34:08,128 epoch 3 - iter 6/37 - loss 0.28610260 - samples/sec: 120.75 - lr: 0.200667\n",
      "2022-08-30 20:34:10,969 epoch 3 - iter 9/37 - loss 0.29048502 - samples/sec: 97.44 - lr: 0.200667\n",
      "2022-08-30 20:34:13,671 epoch 3 - iter 12/37 - loss 0.29048541 - samples/sec: 102.16 - lr: 0.200667\n",
      "2022-08-30 20:34:16,481 epoch 3 - iter 15/37 - loss 0.29066033 - samples/sec: 98.25 - lr: 0.200667\n",
      "2022-08-30 20:34:18,835 epoch 3 - iter 18/37 - loss 0.29252471 - samples/sec: 117.96 - lr: 0.200667\n",
      "2022-08-30 20:34:21,346 epoch 3 - iter 21/37 - loss 0.29451499 - samples/sec: 110.11 - lr: 0.200667\n",
      "2022-08-30 20:34:24,058 epoch 3 - iter 24/37 - loss 0.29284094 - samples/sec: 104.37 - lr: 0.200667\n",
      "2022-08-30 20:34:26,678 epoch 3 - iter 27/37 - loss 0.29330118 - samples/sec: 105.18 - lr: 0.200667\n",
      "2022-08-30 20:34:29,127 epoch 3 - iter 30/37 - loss 0.29413624 - samples/sec: 113.26 - lr: 0.200667\n",
      "2022-08-30 20:34:31,428 epoch 3 - iter 33/37 - loss 0.29349088 - samples/sec: 120.86 - lr: 0.200667\n",
      "2022-08-30 20:34:34,041 epoch 3 - iter 36/37 - loss 0.29442423 - samples/sec: 105.84 - lr: 0.200667\n",
      "2022-08-30 20:34:34,976 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:34:34,977 EPOCH 3 done: loss 0.2956 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:34:35,787 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:34:35,819 DEV : loss 0.2385517656803131 - f1-score (micro avg)  0.9194\n",
      "2022-08-30 20:34:35,834 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:34:35,835 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:34:36,958 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:34:39,342 epoch 4 - iter 3/37 - loss 0.30383164 - samples/sec: 113.35 - lr: 0.200667\n",
      "2022-08-30 20:34:41,967 epoch 4 - iter 6/37 - loss 0.29488811 - samples/sec: 105.92 - lr: 0.200667\n",
      "2022-08-30 20:34:44,432 epoch 4 - iter 9/37 - loss 0.29217209 - samples/sec: 112.41 - lr: 0.200667\n",
      "2022-08-30 20:34:46,744 epoch 4 - iter 12/37 - loss 0.29638751 - samples/sec: 120.32 - lr: 0.200667\n",
      "2022-08-30 20:34:49,561 epoch 4 - iter 15/37 - loss 0.29408840 - samples/sec: 97.97 - lr: 0.200667\n",
      "2022-08-30 20:34:52,272 epoch 4 - iter 18/37 - loss 0.29621669 - samples/sec: 101.66 - lr: 0.200667\n",
      "2022-08-30 20:34:54,746 epoch 4 - iter 21/37 - loss 0.29668922 - samples/sec: 111.66 - lr: 0.200667\n",
      "2022-08-30 20:34:56,919 epoch 4 - iter 24/37 - loss 0.29855465 - samples/sec: 127.66 - lr: 0.200667\n",
      "2022-08-30 20:34:59,542 epoch 4 - iter 27/37 - loss 0.29871701 - samples/sec: 105.30 - lr: 0.200667\n",
      "2022-08-30 20:35:02,033 epoch 4 - iter 30/37 - loss 0.29820093 - samples/sec: 111.20 - lr: 0.200667\n",
      "2022-08-30 20:35:05,473 epoch 4 - iter 33/37 - loss 0.29705960 - samples/sec: 80.12 - lr: 0.200667\n",
      "2022-08-30 20:35:08,020 epoch 4 - iter 36/37 - loss 0.29545371 - samples/sec: 109.67 - lr: 0.200667\n",
      "2022-08-30 20:35:08,953 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:35:08,954 EPOCH 4 done: loss 0.2961 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:35:09,766 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:35:09,798 DEV : loss 0.24649927020072937 - f1-score (micro avg)  0.9157\n",
      "2022-08-30 20:35:09,817 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:35:09,818 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:35:12,258 epoch 5 - iter 3/37 - loss 0.29850490 - samples/sec: 110.70 - lr: 0.200667\n",
      "2022-08-30 20:35:14,743 epoch 5 - iter 6/37 - loss 0.30805307 - samples/sec: 111.11 - lr: 0.200667\n",
      "2022-08-30 20:35:17,620 epoch 5 - iter 9/37 - loss 0.30403295 - samples/sec: 95.81 - lr: 0.200667\n",
      "2022-08-30 20:35:20,033 epoch 5 - iter 12/37 - loss 0.30236229 - samples/sec: 115.63 - lr: 0.200667\n",
      "2022-08-30 20:35:22,560 epoch 5 - iter 15/37 - loss 0.29987384 - samples/sec: 109.53 - lr: 0.200667\n",
      "2022-08-30 20:35:24,760 epoch 5 - iter 18/37 - loss 0.30135695 - samples/sec: 126.64 - lr: 0.200667\n",
      "2022-08-30 20:35:26,989 epoch 5 - iter 21/37 - loss 0.29750816 - samples/sec: 124.71 - lr: 0.200667\n",
      "2022-08-30 20:35:29,210 epoch 5 - iter 24/37 - loss 0.29704740 - samples/sec: 124.71 - lr: 0.200667\n",
      "2022-08-30 20:35:31,582 epoch 5 - iter 27/37 - loss 0.29780044 - samples/sec: 116.78 - lr: 0.200667\n",
      "2022-08-30 20:35:34,346 epoch 5 - iter 30/37 - loss 0.29871290 - samples/sec: 99.89 - lr: 0.200667\n",
      "2022-08-30 20:35:37,459 epoch 5 - iter 33/37 - loss 0.29964267 - samples/sec: 88.93 - lr: 0.200667\n",
      "2022-08-30 20:35:40,384 epoch 5 - iter 36/37 - loss 0.29808591 - samples/sec: 95.07 - lr: 0.200667\n",
      "2022-08-30 20:35:41,244 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:35:41,245 EPOCH 5 done: loss 0.2974 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:35:42,108 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:35:42,136 DEV : loss 0.23966024816036224 - f1-score (micro avg)  0.9193\n",
      "2022-08-30 20:35:42,152 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:35:42,153 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:35:44,338 epoch 6 - iter 3/37 - loss 0.31355552 - samples/sec: 123.63 - lr: 0.200667\n",
      "2022-08-30 20:35:46,745 epoch 6 - iter 6/37 - loss 0.30343795 - samples/sec: 117.34 - lr: 0.200667\n",
      "2022-08-30 20:35:49,380 epoch 6 - iter 9/37 - loss 0.29784701 - samples/sec: 105.02 - lr: 0.200667\n",
      "2022-08-30 20:35:51,918 epoch 6 - iter 12/37 - loss 0.29778135 - samples/sec: 110.47 - lr: 0.200667\n",
      "2022-08-30 20:35:54,432 epoch 6 - iter 15/37 - loss 0.29838991 - samples/sec: 110.02 - lr: 0.200667\n",
      "2022-08-30 20:35:56,811 epoch 6 - iter 18/37 - loss 0.29883792 - samples/sec: 116.43 - lr: 0.200667\n",
      "2022-08-30 20:35:59,124 epoch 6 - iter 21/37 - loss 0.29979201 - samples/sec: 119.89 - lr: 0.200667\n",
      "2022-08-30 20:36:01,494 epoch 6 - iter 24/37 - loss 0.29881679 - samples/sec: 117.19 - lr: 0.200667\n",
      "2022-08-30 20:36:04,089 epoch 6 - iter 27/37 - loss 0.29924669 - samples/sec: 106.64 - lr: 0.200667\n",
      "2022-08-30 20:36:07,108 epoch 6 - iter 30/37 - loss 0.29856962 - samples/sec: 92.21 - lr: 0.200667\n",
      "2022-08-30 20:36:10,352 epoch 6 - iter 33/37 - loss 0.29629105 - samples/sec: 84.77 - lr: 0.200667\n",
      "2022-08-30 20:36:13,450 epoch 6 - iter 36/37 - loss 0.29587585 - samples/sec: 90.70 - lr: 0.200667\n",
      "2022-08-30 20:36:14,569 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:36:14,570 EPOCH 6 done: loss 0.2953 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:36:15,337 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:36:15,372 DEV : loss 0.24177728593349457 - f1-score (micro avg)  0.918\n",
      "2022-08-30 20:36:15,388 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 20:36:15,389 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:36:17,972 epoch 7 - iter 3/37 - loss 0.29515588 - samples/sec: 104.53 - lr: 0.200667\n",
      "2022-08-30 20:36:20,264 epoch 7 - iter 6/37 - loss 0.29467576 - samples/sec: 120.91 - lr: 0.200667\n",
      "2022-08-30 20:36:22,950 epoch 7 - iter 9/37 - loss 0.29227470 - samples/sec: 102.82 - lr: 0.200667\n",
      "2022-08-30 20:36:25,774 epoch 7 - iter 12/37 - loss 0.29536720 - samples/sec: 97.58 - lr: 0.200667\n",
      "2022-08-30 20:36:27,957 epoch 7 - iter 15/37 - loss 0.29245404 - samples/sec: 127.48 - lr: 0.200667\n",
      "2022-08-30 20:36:30,684 epoch 7 - iter 18/37 - loss 0.29324359 - samples/sec: 101.50 - lr: 0.200667\n",
      "2022-08-30 20:36:34,027 epoch 7 - iter 21/37 - loss 0.29474734 - samples/sec: 82.32 - lr: 0.200667\n",
      "2022-08-30 20:36:37,038 epoch 7 - iter 24/37 - loss 0.29567107 - samples/sec: 91.59 - lr: 0.200667\n",
      "2022-08-30 20:36:39,368 epoch 7 - iter 27/37 - loss 0.29477353 - samples/sec: 118.94 - lr: 0.200667\n",
      "2022-08-30 20:36:41,727 epoch 7 - iter 30/37 - loss 0.29588554 - samples/sec: 120.21 - lr: 0.200667\n",
      "2022-08-30 20:36:44,150 epoch 7 - iter 33/37 - loss 0.29601909 - samples/sec: 114.94 - lr: 0.200667\n",
      "2022-08-30 20:36:46,433 epoch 7 - iter 36/37 - loss 0.29512360 - samples/sec: 121.73 - lr: 0.200667\n",
      "2022-08-30 20:36:47,527 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:36:47,528 EPOCH 7 done: loss 0.2951 - lr 0.200667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:36:48,335 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:36:48,367 DEV : loss 0.24253050982952118 - f1-score (micro avg)  0.9189\n",
      "2022-08-30 20:36:48,383 Epoch     7: reducing learning rate of group 0 to 1.0033e-01.\n",
      "2022-08-30 20:36:48,383 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 20:36:48,384 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:36:50,709 epoch 8 - iter 3/37 - loss 0.29324136 - samples/sec: 116.18 - lr: 0.100333\n",
      "2022-08-30 20:36:53,056 epoch 8 - iter 6/37 - loss 0.29303306 - samples/sec: 118.06 - lr: 0.100333\n",
      "2022-08-30 20:36:55,737 epoch 8 - iter 9/37 - loss 0.28872548 - samples/sec: 103.13 - lr: 0.100333\n",
      "2022-08-30 20:36:58,256 epoch 8 - iter 12/37 - loss 0.28809935 - samples/sec: 110.02 - lr: 0.100333\n",
      "2022-08-30 20:37:00,709 epoch 8 - iter 15/37 - loss 0.29036356 - samples/sec: 112.88 - lr: 0.100333\n",
      "2022-08-30 20:37:03,292 epoch 8 - iter 18/37 - loss 0.29010260 - samples/sec: 107.02 - lr: 0.100333\n",
      "2022-08-30 20:37:05,881 epoch 8 - iter 21/37 - loss 0.29154508 - samples/sec: 106.64 - lr: 0.100333\n",
      "2022-08-30 20:37:08,560 epoch 8 - iter 24/37 - loss 0.29161198 - samples/sec: 103.01 - lr: 0.100333\n",
      "2022-08-30 20:37:11,015 epoch 8 - iter 27/37 - loss 0.29058146 - samples/sec: 112.64 - lr: 0.100333\n",
      "2022-08-30 20:37:13,470 epoch 8 - iter 30/37 - loss 0.29009753 - samples/sec: 112.50 - lr: 0.100333\n",
      "2022-08-30 20:37:16,044 epoch 8 - iter 33/37 - loss 0.28730343 - samples/sec: 108.30 - lr: 0.100333\n",
      "2022-08-30 20:37:19,177 epoch 8 - iter 36/37 - loss 0.28866291 - samples/sec: 87.89 - lr: 0.100333\n",
      "2022-08-30 20:37:20,007 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:37:20,008 EPOCH 8 done: loss 0.2883 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:37:20,848 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:37:20,878 DEV : loss 0.24099348485469818 - f1-score (micro avg)  0.9193\n",
      "2022-08-30 20:37:20,894 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:37:20,895 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:37:23,098 epoch 9 - iter 3/37 - loss 0.27525351 - samples/sec: 122.67 - lr: 0.100333\n",
      "2022-08-30 20:37:25,732 epoch 9 - iter 6/37 - loss 0.28630255 - samples/sec: 104.73 - lr: 0.100333\n",
      "2022-08-30 20:37:28,843 epoch 9 - iter 9/37 - loss 0.28483448 - samples/sec: 88.52 - lr: 0.100333\n",
      "2022-08-30 20:37:31,769 epoch 9 - iter 12/37 - loss 0.28999104 - samples/sec: 94.18 - lr: 0.100333\n",
      "2022-08-30 20:37:34,181 epoch 9 - iter 15/37 - loss 0.28946360 - samples/sec: 114.70 - lr: 0.100333\n",
      "2022-08-30 20:37:36,590 epoch 9 - iter 18/37 - loss 0.28842349 - samples/sec: 114.75 - lr: 0.100333\n",
      "2022-08-30 20:37:39,170 epoch 9 - iter 21/37 - loss 0.28764459 - samples/sec: 107.48 - lr: 0.100333\n",
      "2022-08-30 20:37:41,590 epoch 9 - iter 24/37 - loss 0.28621293 - samples/sec: 114.70 - lr: 0.100333\n",
      "2022-08-30 20:37:44,153 epoch 9 - iter 27/37 - loss 0.28522674 - samples/sec: 108.04 - lr: 0.100333\n",
      "2022-08-30 20:37:46,656 epoch 9 - iter 30/37 - loss 0.28534222 - samples/sec: 110.43 - lr: 0.100333\n",
      "2022-08-30 20:37:49,322 epoch 9 - iter 33/37 - loss 0.28562988 - samples/sec: 103.93 - lr: 0.100333\n",
      "2022-08-30 20:37:51,483 epoch 9 - iter 36/37 - loss 0.28525396 - samples/sec: 130.62 - lr: 0.100333\n",
      "2022-08-30 20:37:52,180 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:37:52,181 EPOCH 9 done: loss 0.2852 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:37:53,025 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:37:53,054 DEV : loss 0.24020953476428986 - f1-score (micro avg)  0.9217\n",
      "2022-08-30 20:37:53,071 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:37:53,072 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:37:53,794 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:37:56,669 epoch 10 - iter 3/37 - loss 0.26480085 - samples/sec: 93.95 - lr: 0.100333\n",
      "2022-08-30 20:37:59,081 epoch 10 - iter 6/37 - loss 0.26323149 - samples/sec: 114.80 - lr: 0.100333\n",
      "2022-08-30 20:38:01,806 epoch 10 - iter 9/37 - loss 0.26486742 - samples/sec: 101.58 - lr: 0.100333\n",
      "2022-08-30 20:38:04,420 epoch 10 - iter 12/37 - loss 0.27068306 - samples/sec: 105.97 - lr: 0.100333\n",
      "2022-08-30 20:38:06,947 epoch 10 - iter 15/37 - loss 0.27362927 - samples/sec: 109.71 - lr: 0.100333\n",
      "2022-08-30 20:38:09,397 epoch 10 - iter 18/37 - loss 0.27384270 - samples/sec: 112.83 - lr: 0.100333\n",
      "2022-08-30 20:38:11,977 epoch 10 - iter 21/37 - loss 0.27544129 - samples/sec: 108.56 - lr: 0.100333\n",
      "2022-08-30 20:38:14,622 epoch 10 - iter 24/37 - loss 0.27692232 - samples/sec: 104.69 - lr: 0.100333\n",
      "2022-08-30 20:38:17,208 epoch 10 - iter 27/37 - loss 0.27633343 - samples/sec: 107.61 - lr: 0.100333\n",
      "2022-08-30 20:38:19,639 epoch 10 - iter 30/37 - loss 0.27779691 - samples/sec: 113.97 - lr: 0.100333\n",
      "2022-08-30 20:38:22,250 epoch 10 - iter 33/37 - loss 0.27801901 - samples/sec: 106.01 - lr: 0.100333\n",
      "2022-08-30 20:38:25,303 epoch 10 - iter 36/37 - loss 0.27972748 - samples/sec: 90.12 - lr: 0.100333\n",
      "2022-08-30 20:38:26,094 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:38:26,095 EPOCH 10 done: loss 0.2796 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:38:26,905 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:38:26,941 DEV : loss 0.23722325265407562 - f1-score (micro avg)  0.9204\n",
      "2022-08-30 20:38:26,957 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:38:26,957 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:38:29,641 epoch 11 - iter 3/37 - loss 0.30359729 - samples/sec: 100.67 - lr: 0.100333\n",
      "2022-08-30 20:38:32,420 epoch 11 - iter 6/37 - loss 0.27846344 - samples/sec: 99.16 - lr: 0.100333\n",
      "2022-08-30 20:38:35,020 epoch 11 - iter 9/37 - loss 0.27827956 - samples/sec: 107.23 - lr: 0.100333\n",
      "2022-08-30 20:38:38,037 epoch 11 - iter 12/37 - loss 0.28130111 - samples/sec: 91.74 - lr: 0.100333\n",
      "2022-08-30 20:38:40,653 epoch 11 - iter 15/37 - loss 0.28300399 - samples/sec: 105.59 - lr: 0.100333\n",
      "2022-08-30 20:38:43,302 epoch 11 - iter 18/37 - loss 0.28186341 - samples/sec: 105.10 - lr: 0.100333\n",
      "2022-08-30 20:38:45,724 epoch 11 - iter 21/37 - loss 0.28141409 - samples/sec: 114.55 - lr: 0.100333\n",
      "2022-08-30 20:38:47,838 epoch 11 - iter 24/37 - loss 0.28306398 - samples/sec: 131.45 - lr: 0.100333\n",
      "2022-08-30 20:38:50,201 epoch 11 - iter 27/37 - loss 0.28150834 - samples/sec: 117.04 - lr: 0.100333\n",
      "2022-08-30 20:38:52,847 epoch 11 - iter 30/37 - loss 0.28142295 - samples/sec: 104.33 - lr: 0.100333\n",
      "2022-08-30 20:38:55,646 epoch 11 - iter 33/37 - loss 0.28029345 - samples/sec: 98.65 - lr: 0.100333\n",
      "2022-08-30 20:38:58,084 epoch 11 - iter 36/37 - loss 0.28019711 - samples/sec: 113.59 - lr: 0.100333\n",
      "2022-08-30 20:38:59,081 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:38:59,081 EPOCH 11 done: loss 0.2800 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:38:59,880 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:38:59,916 DEV : loss 0.2382463663816452 - f1-score (micro avg)  0.9212\n",
      "2022-08-30 20:38:59,938 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:38:59,939 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:39:02,150 epoch 12 - iter 3/37 - loss 0.26303206 - samples/sec: 122.23 - lr: 0.100333\n",
      "2022-08-30 20:39:04,837 epoch 12 - iter 6/37 - loss 0.27066952 - samples/sec: 103.01 - lr: 0.100333\n",
      "2022-08-30 20:39:07,689 epoch 12 - iter 9/37 - loss 0.27573029 - samples/sec: 96.70 - lr: 0.100333\n",
      "2022-08-30 20:39:10,243 epoch 12 - iter 12/37 - loss 0.27387278 - samples/sec: 108.74 - lr: 0.100333\n",
      "2022-08-30 20:39:12,632 epoch 12 - iter 15/37 - loss 0.27397150 - samples/sec: 116.18 - lr: 0.100333\n",
      "2022-08-30 20:39:15,255 epoch 12 - iter 18/37 - loss 0.27750050 - samples/sec: 105.30 - lr: 0.100333\n",
      "2022-08-30 20:39:17,994 epoch 12 - iter 21/37 - loss 0.27992519 - samples/sec: 100.75 - lr: 0.100333\n",
      "2022-08-30 20:39:20,394 epoch 12 - iter 24/37 - loss 0.28244606 - samples/sec: 115.34 - lr: 0.100333\n",
      "2022-08-30 20:39:22,946 epoch 12 - iter 27/37 - loss 0.28275113 - samples/sec: 109.18 - lr: 0.100333\n",
      "2022-08-30 20:39:25,849 epoch 12 - iter 30/37 - loss 0.28313131 - samples/sec: 94.97 - lr: 0.100333\n",
      "2022-08-30 20:39:29,039 epoch 12 - iter 33/37 - loss 0.28273060 - samples/sec: 86.51 - lr: 0.100333\n",
      "2022-08-30 20:39:31,626 epoch 12 - iter 36/37 - loss 0.28275046 - samples/sec: 106.89 - lr: 0.100333\n",
      "2022-08-30 20:39:32,386 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:39:32,387 EPOCH 12 done: loss 0.2828 - lr 0.100333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:39:34,587 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:39:34,622 DEV : loss 0.23999850451946259 - f1-score (micro avg)  0.9194\n",
      "2022-08-30 20:39:34,642 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:39:35,322 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:39:35,323 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 20:39:35,511 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:39:37,071 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:39:37,104 0.9278\t0.9278\t0.9278\t0.9278\n",
      "2022-08-30 20:39:37,105 \n",
      "Results:\n",
      "- F-score (micro) 0.9278\n",
      "- F-score (macro) 0.8077\n",
      "- Accuracy 0.9278\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8880    0.9320    0.9095      1353\n",
      "         ADJ     0.8932    0.8958    0.8945       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9961    0.9844    0.9902       514\n",
      "        VERB     0.9006    0.9287    0.9145       449\n",
      "       PROPN     0.8598    0.7363    0.7932       383\n",
      "         AUX     0.9881    0.9881    0.9881       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8720    0.8882    0.8800       161\n",
      "         ADV     0.8699    0.8411    0.8552       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9474    0.7606    0.8437        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9278      5264\n",
      "   macro avg     0.8246    0.7942    0.8077      5264\n",
      "weighted avg     0.9281    0.9278    0.9272      5264\n",
      "\n",
      "2022-08-30 20:39:37,106 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:39:37,109 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:39:37,674 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 3 #######################\n",
      "#######################################################\n",
      "2022-08-30 20:42:03,299 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:42:03,300 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 20:42:03,300 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:42:03,301 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 20:42:03,302 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:42:03,302 Parameters:\n",
      "2022-08-30 20:42:03,302  - learning_rate: \"0.400333\"\n",
      "2022-08-30 20:42:03,303  - mini_batch_size: \"10\"\n",
      "2022-08-30 20:42:03,303  - patience: \"3\"\n",
      "2022-08-30 20:42:03,304  - anneal_factor: \"0.5\"\n",
      "2022-08-30 20:42:03,305  - max_epochs: \"10\"\n",
      "2022-08-30 20:42:03,305  - shuffle: \"True\"\n",
      "2022-08-30 20:42:03,306  - train_with_dev: \"False\"\n",
      "2022-08-30 20:42:03,306  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 20:42:03,307 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:42:03,307 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 20:42:03,308 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:42:03,309 Device: cpu\n",
      "2022-08-30 20:42:03,310 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:42:03,310 Embeddings storage mode: cpu\n",
      "2022-08-30 20:42:03,311 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:42:07,515 epoch 1 - iter 33/333 - loss 0.33283550 - samples/sec: 78.63 - lr: 0.400333\n",
      "2022-08-30 20:42:11,941 epoch 1 - iter 66/333 - loss 0.36588754 - samples/sec: 75.67 - lr: 0.400333\n",
      "2022-08-30 20:42:15,655 epoch 1 - iter 99/333 - loss 0.37622689 - samples/sec: 90.51 - lr: 0.400333\n",
      "2022-08-30 20:42:19,633 epoch 1 - iter 132/333 - loss 0.37866837 - samples/sec: 84.16 - lr: 0.400333\n",
      "2022-08-30 20:42:24,426 epoch 1 - iter 165/333 - loss 0.38471210 - samples/sec: 69.83 - lr: 0.400333\n",
      "2022-08-30 20:42:28,192 epoch 1 - iter 198/333 - loss 0.38922264 - samples/sec: 89.24 - lr: 0.400333\n",
      "2022-08-30 20:42:32,548 epoch 1 - iter 231/333 - loss 0.39409421 - samples/sec: 76.89 - lr: 0.400333\n",
      "2022-08-30 20:42:36,316 epoch 1 - iter 264/333 - loss 0.39682374 - samples/sec: 89.12 - lr: 0.400333\n",
      "2022-08-30 20:42:40,499 epoch 1 - iter 297/333 - loss 0.40329275 - samples/sec: 80.14 - lr: 0.400333\n",
      "2022-08-30 20:42:44,954 epoch 1 - iter 330/333 - loss 0.41857892 - samples/sec: 75.12 - lr: 0.400333\n",
      "2022-08-30 20:42:45,422 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:42:45,423 EPOCH 1 done: loss 0.4196 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:42:46,426 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:42:46,455 DEV : loss 0.31568214297294617 - f1-score (micro avg)  0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:42:46,472 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:42:46,473 saving best model\n",
      "2022-08-30 20:42:47,212 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:42:51,072 epoch 2 - iter 33/333 - loss 0.41982407 - samples/sec: 85.51 - lr: 0.400333\n",
      "2022-08-30 20:42:55,231 epoch 2 - iter 66/333 - loss 0.42587919 - samples/sec: 80.53 - lr: 0.400333\n",
      "2022-08-30 20:42:59,178 epoch 2 - iter 99/333 - loss 0.43282928 - samples/sec: 84.83 - lr: 0.400333\n",
      "2022-08-30 20:43:03,296 epoch 2 - iter 132/333 - loss 0.43658435 - samples/sec: 81.28 - lr: 0.400333\n",
      "2022-08-30 20:43:07,311 epoch 2 - iter 165/333 - loss 0.44501952 - samples/sec: 83.31 - lr: 0.400333\n",
      "2022-08-30 20:43:11,185 epoch 2 - iter 198/333 - loss 0.45112328 - samples/sec: 86.64 - lr: 0.400333\n",
      "2022-08-30 20:43:15,239 epoch 2 - iter 231/333 - loss 0.45302019 - samples/sec: 82.69 - lr: 0.400333\n",
      "2022-08-30 20:43:19,562 epoch 2 - iter 264/333 - loss 0.45483437 - samples/sec: 77.45 - lr: 0.400333\n",
      "2022-08-30 20:43:23,600 epoch 2 - iter 297/333 - loss 0.45664372 - samples/sec: 83.06 - lr: 0.400333\n",
      "2022-08-30 20:43:28,353 epoch 2 - iter 330/333 - loss 0.45794476 - samples/sec: 70.35 - lr: 0.400333\n",
      "2022-08-30 20:43:28,697 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:43:28,698 EPOCH 2 done: loss 0.4576 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:43:29,672 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:43:29,703 DEV : loss 0.2786023020744324 - f1-score (micro avg)  0.9038\n",
      "2022-08-30 20:43:29,721 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:43:29,722 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:43:30,984 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:43:35,396 epoch 3 - iter 33/333 - loss 0.46721713 - samples/sec: 74.81 - lr: 0.400333\n",
      "2022-08-30 20:43:39,510 epoch 3 - iter 66/333 - loss 0.45980681 - samples/sec: 81.64 - lr: 0.400333\n",
      "2022-08-30 20:43:43,414 epoch 3 - iter 99/333 - loss 0.47268266 - samples/sec: 85.85 - lr: 0.400333\n",
      "2022-08-30 20:43:47,329 epoch 3 - iter 132/333 - loss 0.46671929 - samples/sec: 85.85 - lr: 0.400333\n",
      "2022-08-30 20:43:51,076 epoch 3 - iter 165/333 - loss 0.46601375 - samples/sec: 89.67 - lr: 0.400333\n",
      "2022-08-30 20:43:55,365 epoch 3 - iter 198/333 - loss 0.46828078 - samples/sec: 78.14 - lr: 0.400333\n",
      "2022-08-30 20:43:59,514 epoch 3 - iter 231/333 - loss 0.47144764 - samples/sec: 80.90 - lr: 0.400333\n",
      "2022-08-30 20:44:04,125 epoch 3 - iter 264/333 - loss 0.47112371 - samples/sec: 72.51 - lr: 0.400333\n",
      "2022-08-30 20:44:08,323 epoch 3 - iter 297/333 - loss 0.47356805 - samples/sec: 79.85 - lr: 0.400333\n",
      "2022-08-30 20:44:12,221 epoch 3 - iter 330/333 - loss 0.47337633 - samples/sec: 86.32 - lr: 0.400333\n",
      "2022-08-30 20:44:12,571 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:44:12,572 EPOCH 3 done: loss 0.4732 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:44:13,582 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:44:13,619 DEV : loss 0.2941090166568756 - f1-score (micro avg)  0.9009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:44:13,635 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:44:13,636 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:44:18,651 epoch 4 - iter 33/333 - loss 0.46647026 - samples/sec: 65.83 - lr: 0.400333\n",
      "2022-08-30 20:44:22,980 epoch 4 - iter 66/333 - loss 0.46858447 - samples/sec: 77.48 - lr: 0.400333\n",
      "2022-08-30 20:44:27,400 epoch 4 - iter 99/333 - loss 0.47324926 - samples/sec: 75.78 - lr: 0.400333\n",
      "2022-08-30 20:44:31,683 epoch 4 - iter 132/333 - loss 0.47503795 - samples/sec: 78.33 - lr: 0.400333\n",
      "2022-08-30 20:44:35,525 epoch 4 - iter 165/333 - loss 0.47596020 - samples/sec: 87.58 - lr: 0.400333\n",
      "2022-08-30 20:44:39,851 epoch 4 - iter 198/333 - loss 0.47676818 - samples/sec: 77.39 - lr: 0.400333\n",
      "2022-08-30 20:44:43,789 epoch 4 - iter 231/333 - loss 0.48171505 - samples/sec: 85.23 - lr: 0.400333\n",
      "2022-08-30 20:44:47,347 epoch 4 - iter 264/333 - loss 0.48131141 - samples/sec: 94.37 - lr: 0.400333\n",
      "2022-08-30 20:44:51,363 epoch 4 - iter 297/333 - loss 0.48230286 - samples/sec: 83.50 - lr: 0.400333\n",
      "2022-08-30 20:44:55,899 epoch 4 - iter 330/333 - loss 0.48224972 - samples/sec: 73.94 - lr: 0.400333\n",
      "2022-08-30 20:44:56,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:44:56,341 EPOCH 4 done: loss 0.4828 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:44:57,405 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:44:57,439 DEV : loss 0.2848798930644989 - f1-score (micro avg)  0.9046\n",
      "2022-08-30 20:44:57,454 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:44:57,456 saving best model\n",
      "2022-08-30 20:44:58,170 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:45:02,315 epoch 5 - iter 33/333 - loss 0.46797923 - samples/sec: 79.71 - lr: 0.400333\n",
      "2022-08-30 20:45:06,198 epoch 5 - iter 66/333 - loss 0.47090124 - samples/sec: 86.93 - lr: 0.400333\n",
      "2022-08-30 20:45:10,569 epoch 5 - iter 99/333 - loss 0.48129538 - samples/sec: 76.58 - lr: 0.400333\n",
      "2022-08-30 20:45:14,556 epoch 5 - iter 132/333 - loss 0.47680380 - samples/sec: 83.97 - lr: 0.400333\n",
      "2022-08-30 20:45:18,893 epoch 5 - iter 165/333 - loss 0.48213793 - samples/sec: 77.23 - lr: 0.400333\n",
      "2022-08-30 20:45:22,697 epoch 5 - iter 198/333 - loss 0.48527826 - samples/sec: 88.12 - lr: 0.400333\n",
      "2022-08-30 20:45:26,759 epoch 5 - iter 231/333 - loss 0.48594042 - samples/sec: 82.44 - lr: 0.400333\n",
      "2022-08-30 20:45:31,130 epoch 5 - iter 264/333 - loss 0.48606366 - samples/sec: 76.73 - lr: 0.400333\n",
      "2022-08-30 20:45:35,497 epoch 5 - iter 297/333 - loss 0.48798937 - samples/sec: 76.57 - lr: 0.400333\n",
      "2022-08-30 20:45:39,626 epoch 5 - iter 330/333 - loss 0.48874533 - samples/sec: 81.20 - lr: 0.400333\n",
      "2022-08-30 20:45:39,976 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:45:39,977 EPOCH 5 done: loss 0.4891 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:45:40,960 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:45:40,991 DEV : loss 0.2869768738746643 - f1-score (micro avg)  0.9048\n",
      "2022-08-30 20:45:41,009 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:45:41,010 saving best model\n",
      "2022-08-30 20:45:41,971 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:45:45,650 epoch 6 - iter 33/333 - loss 0.48157452 - samples/sec: 89.77 - lr: 0.400333\n",
      "2022-08-30 20:45:49,766 epoch 6 - iter 66/333 - loss 0.48754772 - samples/sec: 81.42 - lr: 0.400333\n",
      "2022-08-30 20:45:54,210 epoch 6 - iter 99/333 - loss 0.49056189 - samples/sec: 75.33 - lr: 0.400333\n",
      "2022-08-30 20:45:58,541 epoch 6 - iter 132/333 - loss 0.48746734 - samples/sec: 77.28 - lr: 0.400333\n",
      "2022-08-30 20:46:02,920 epoch 6 - iter 165/333 - loss 0.49258941 - samples/sec: 76.60 - lr: 0.400333\n",
      "2022-08-30 20:46:07,143 epoch 6 - iter 198/333 - loss 0.49043465 - samples/sec: 79.35 - lr: 0.400333\n",
      "2022-08-30 20:46:10,966 epoch 6 - iter 231/333 - loss 0.49384985 - samples/sec: 87.70 - lr: 0.400333\n",
      "2022-08-30 20:46:15,652 epoch 6 - iter 264/333 - loss 0.49210102 - samples/sec: 71.32 - lr: 0.400333\n",
      "2022-08-30 20:46:20,002 epoch 6 - iter 297/333 - loss 0.49333987 - samples/sec: 77.02 - lr: 0.400333\n",
      "2022-08-30 20:46:24,444 epoch 6 - iter 330/333 - loss 0.49429800 - samples/sec: 75.41 - lr: 0.400333\n",
      "2022-08-30 20:46:24,883 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:46:24,884 EPOCH 6 done: loss 0.4943 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 24.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:46:26,040 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:46:26,074 DEV : loss 0.31346458196640015 - f1-score (micro avg)  0.8959\n",
      "2022-08-30 20:46:26,089 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:46:26,090 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:46:30,010 epoch 7 - iter 33/333 - loss 0.48270851 - samples/sec: 84.23 - lr: 0.400333\n",
      "2022-08-30 20:46:33,875 epoch 7 - iter 66/333 - loss 0.49645560 - samples/sec: 86.77 - lr: 0.400333\n",
      "2022-08-30 20:46:38,634 epoch 7 - iter 99/333 - loss 0.51206035 - samples/sec: 70.32 - lr: 0.400333\n",
      "2022-08-30 20:46:43,167 epoch 7 - iter 132/333 - loss 0.50411656 - samples/sec: 73.79 - lr: 0.400333\n",
      "2022-08-30 20:46:47,836 epoch 7 - iter 165/333 - loss 0.50083837 - samples/sec: 71.63 - lr: 0.400333\n",
      "2022-08-30 20:46:51,819 epoch 7 - iter 198/333 - loss 0.49820604 - samples/sec: 84.12 - lr: 0.400333\n",
      "2022-08-30 20:46:56,206 epoch 7 - iter 231/333 - loss 0.50162065 - samples/sec: 76.32 - lr: 0.400333\n",
      "2022-08-30 20:47:00,480 epoch 7 - iter 264/333 - loss 0.49930625 - samples/sec: 78.35 - lr: 0.400333\n",
      "2022-08-30 20:47:04,599 epoch 7 - iter 297/333 - loss 0.50252706 - samples/sec: 81.40 - lr: 0.400333\n",
      "2022-08-30 20:47:08,366 epoch 7 - iter 330/333 - loss 0.50271412 - samples/sec: 89.17 - lr: 0.400333\n",
      "2022-08-30 20:47:08,859 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:47:08,860 EPOCH 7 done: loss 0.5031 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:47:09,879 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:47:09,908 DEV : loss 0.304798424243927 - f1-score (micro avg)  0.8949\n",
      "2022-08-30 20:47:09,926 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:47:09,927 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:47:14,284 epoch 8 - iter 33/333 - loss 0.50662605 - samples/sec: 75.79 - lr: 0.400333\n",
      "2022-08-30 20:47:18,531 epoch 8 - iter 66/333 - loss 0.50343454 - samples/sec: 78.93 - lr: 0.400333\n",
      "2022-08-30 20:47:22,415 epoch 8 - iter 99/333 - loss 0.49674467 - samples/sec: 86.36 - lr: 0.400333\n",
      "2022-08-30 20:47:26,478 epoch 8 - iter 132/333 - loss 0.49739374 - samples/sec: 82.62 - lr: 0.400333\n",
      "2022-08-30 20:47:30,648 epoch 8 - iter 165/333 - loss 0.50284844 - samples/sec: 80.38 - lr: 0.400333\n",
      "2022-08-30 20:47:35,015 epoch 8 - iter 198/333 - loss 0.50347684 - samples/sec: 76.74 - lr: 0.400333\n",
      "2022-08-30 20:47:39,434 epoch 8 - iter 231/333 - loss 0.50486486 - samples/sec: 75.79 - lr: 0.400333\n",
      "2022-08-30 20:47:44,138 epoch 8 - iter 264/333 - loss 0.50702504 - samples/sec: 71.23 - lr: 0.400333\n",
      "2022-08-30 20:47:48,829 epoch 8 - iter 297/333 - loss 0.50708589 - samples/sec: 71.34 - lr: 0.400333\n",
      "2022-08-30 20:47:52,885 epoch 8 - iter 330/333 - loss 0.50580846 - samples/sec: 82.60 - lr: 0.400333\n",
      "2022-08-30 20:47:53,259 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:47:53,260 EPOCH 8 done: loss 0.5057 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:47:54,316 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:47:54,350 DEV : loss 0.3079773187637329 - f1-score (micro avg)  0.8949\n",
      "2022-08-30 20:47:54,368 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 20:47:54,369 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:47:59,274 epoch 9 - iter 33/333 - loss 0.50506829 - samples/sec: 67.29 - lr: 0.400333\n",
      "2022-08-30 20:48:03,514 epoch 9 - iter 66/333 - loss 0.51128605 - samples/sec: 79.00 - lr: 0.400333\n",
      "2022-08-30 20:48:07,690 epoch 9 - iter 99/333 - loss 0.50298806 - samples/sec: 80.27 - lr: 0.400333\n",
      "2022-08-30 20:48:12,192 epoch 9 - iter 132/333 - loss 0.50200077 - samples/sec: 74.46 - lr: 0.400333\n",
      "2022-08-30 20:48:16,061 epoch 9 - iter 165/333 - loss 0.49723190 - samples/sec: 86.68 - lr: 0.400333\n",
      "2022-08-30 20:48:20,236 epoch 9 - iter 198/333 - loss 0.49726953 - samples/sec: 80.23 - lr: 0.400333\n",
      "2022-08-30 20:48:24,082 epoch 9 - iter 231/333 - loss 0.50086063 - samples/sec: 87.07 - lr: 0.400333\n",
      "2022-08-30 20:48:28,331 epoch 9 - iter 264/333 - loss 0.50253279 - samples/sec: 78.82 - lr: 0.400333\n",
      "2022-08-30 20:48:32,375 epoch 9 - iter 297/333 - loss 0.50104233 - samples/sec: 82.98 - lr: 0.400333\n",
      "2022-08-30 20:48:36,665 epoch 9 - iter 330/333 - loss 0.50201720 - samples/sec: 78.31 - lr: 0.400333\n",
      "2022-08-30 20:48:37,035 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:48:37,036 EPOCH 9 done: loss 0.5023 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 28.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:48:38,049 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:48:38,080 DEV : loss 0.3100457787513733 - f1-score (micro avg)  0.8895\n",
      "2022-08-30 20:48:38,095 Epoch     9: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 20:48:38,096 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 20:48:38,097 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:48:42,405 epoch 10 - iter 33/333 - loss 0.45920872 - samples/sec: 76.62 - lr: 0.200167\n",
      "2022-08-30 20:48:46,429 epoch 10 - iter 66/333 - loss 0.47185118 - samples/sec: 83.46 - lr: 0.200167\n",
      "2022-08-30 20:48:50,778 epoch 10 - iter 99/333 - loss 0.45862223 - samples/sec: 76.98 - lr: 0.200167\n",
      "2022-08-30 20:48:54,510 epoch 10 - iter 132/333 - loss 0.45916486 - samples/sec: 89.97 - lr: 0.200167\n",
      "2022-08-30 20:48:58,346 epoch 10 - iter 165/333 - loss 0.46243999 - samples/sec: 87.44 - lr: 0.200167\n",
      "2022-08-30 20:49:03,026 epoch 10 - iter 198/333 - loss 0.45976479 - samples/sec: 71.63 - lr: 0.200167\n",
      "2022-08-30 20:49:07,567 epoch 10 - iter 231/333 - loss 0.45621397 - samples/sec: 73.76 - lr: 0.200167\n",
      "2022-08-30 20:49:11,983 epoch 10 - iter 264/333 - loss 0.45074744 - samples/sec: 75.74 - lr: 0.200167\n",
      "2022-08-30 20:49:16,302 epoch 10 - iter 297/333 - loss 0.45023433 - samples/sec: 77.46 - lr: 0.200167\n",
      "2022-08-30 20:49:20,937 epoch 10 - iter 330/333 - loss 0.44731871 - samples/sec: 72.19 - lr: 0.200167\n",
      "2022-08-30 20:49:21,307 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:49:21,308 EPOCH 10 done: loss 0.4471 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:49:22,316 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:49:22,346 DEV : loss 0.2763970196247101 - f1-score (micro avg)  0.9079\n",
      "2022-08-30 20:49:22,363 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:49:22,363 saving best model\n",
      "2022-08-30 20:49:24,269 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:49:24,270 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 20:49:24,456 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:49:26,067 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:49:26,094 0.9157\t0.9157\t0.9157\t0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:49:26,095 \n",
      "Results:\n",
      "- F-score (micro) 0.9157\n",
      "- F-score (macro) 0.8589\n",
      "- Accuracy 0.9157\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8676    0.9254    0.8956      1353\n",
      "         ADJ     0.8759    0.8824    0.8792       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9902    0.9864    0.9883       514\n",
      "        VERB     0.8634    0.9287    0.8948       449\n",
      "       PROPN     0.8595    0.6710    0.7537       383\n",
      "         AUX     0.9910    0.9821    0.9865       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8645    0.8323    0.8481       161\n",
      "         ADV     0.8182    0.7748    0.7959       151\n",
      "        PRON     0.9908    0.9391    0.9643       115\n",
      "         NUM     1.0000    0.7465    0.8548        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9157      5264\n",
      "   macro avg     0.8813    0.8421    0.8589      5264\n",
      "weighted avg     0.9160    0.9157    0.9143      5264\n",
      "\n",
      "2022-08-30 20:49:26,095 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:49:26,097 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 20:49:26,632 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 20:51:53,704 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:51:53,705 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 20:51:53,706 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:51:53,707 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 20:51:53,707 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:51:53,708 Parameters:\n",
      "2022-08-30 20:51:53,708  - learning_rate: \"0.400333\"\n",
      "2022-08-30 20:51:53,709  - mini_batch_size: \"10\"\n",
      "2022-08-30 20:51:53,709  - patience: \"3\"\n",
      "2022-08-30 20:51:53,710  - anneal_factor: \"0.5\"\n",
      "2022-08-30 20:51:53,711  - max_epochs: \"11\"\n",
      "2022-08-30 20:51:53,712  - shuffle: \"True\"\n",
      "2022-08-30 20:51:53,712  - train_with_dev: \"False\"\n",
      "2022-08-30 20:51:53,713  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 20:51:53,713 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:51:53,714 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 20:51:53,715 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:51:53,715 Device: cpu\n",
      "2022-08-30 20:51:53,716 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:51:53,716 Embeddings storage mode: cpu\n",
      "2022-08-30 20:51:53,717 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:51:57,950 epoch 1 - iter 33/333 - loss 0.41336248 - samples/sec: 78.00 - lr: 0.400333\n",
      "2022-08-30 20:52:02,305 epoch 1 - iter 66/333 - loss 0.44676900 - samples/sec: 76.87 - lr: 0.400333\n",
      "2022-08-30 20:52:06,020 epoch 1 - iter 99/333 - loss 0.45412674 - samples/sec: 90.44 - lr: 0.400333\n",
      "2022-08-30 20:52:09,897 epoch 1 - iter 132/333 - loss 0.45603084 - samples/sec: 86.50 - lr: 0.400333\n",
      "2022-08-30 20:52:14,523 epoch 1 - iter 165/333 - loss 0.46249643 - samples/sec: 72.26 - lr: 0.400333\n",
      "2022-08-30 20:52:18,177 epoch 1 - iter 198/333 - loss 0.46217136 - samples/sec: 91.87 - lr: 0.400333\n",
      "2022-08-30 20:52:22,330 epoch 1 - iter 231/333 - loss 0.46451691 - samples/sec: 80.61 - lr: 0.400333\n",
      "2022-08-30 20:52:26,068 epoch 1 - iter 264/333 - loss 0.46639274 - samples/sec: 89.87 - lr: 0.400333\n",
      "2022-08-30 20:52:30,344 epoch 1 - iter 297/333 - loss 0.47004428 - samples/sec: 78.37 - lr: 0.400333\n",
      "2022-08-30 20:52:34,887 epoch 1 - iter 330/333 - loss 0.48827444 - samples/sec: 73.84 - lr: 0.400333\n",
      "2022-08-30 20:52:35,364 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:52:35,365 EPOCH 1 done: loss 0.4889 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:52:36,381 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:52:36,413 DEV : loss 0.3354719579219818 - f1-score (micro avg)  0.88\n",
      "2022-08-30 20:52:36,428 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:52:36,429 saving best model\n",
      "2022-08-30 20:52:37,105 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:52:41,114 epoch 2 - iter 33/333 - loss 0.53584978 - samples/sec: 82.38 - lr: 0.400333\n",
      "2022-08-30 20:52:45,242 epoch 2 - iter 66/333 - loss 0.52997273 - samples/sec: 81.08 - lr: 0.400333\n",
      "2022-08-30 20:52:49,686 epoch 2 - iter 99/333 - loss 0.51071339 - samples/sec: 75.29 - lr: 0.400333\n",
      "2022-08-30 20:52:54,013 epoch 2 - iter 132/333 - loss 0.51685471 - samples/sec: 77.41 - lr: 0.400333\n",
      "2022-08-30 20:52:58,215 epoch 2 - iter 165/333 - loss 0.51526106 - samples/sec: 79.69 - lr: 0.400333\n",
      "2022-08-30 20:53:02,229 epoch 2 - iter 198/333 - loss 0.51375095 - samples/sec: 83.50 - lr: 0.400333\n",
      "2022-08-30 20:53:05,679 epoch 2 - iter 231/333 - loss 0.51200769 - samples/sec: 97.32 - lr: 0.400333\n",
      "2022-08-30 20:53:09,762 epoch 2 - iter 264/333 - loss 0.51178366 - samples/sec: 82.21 - lr: 0.400333\n",
      "2022-08-30 20:53:13,797 epoch 2 - iter 297/333 - loss 0.51161119 - samples/sec: 82.96 - lr: 0.400333\n",
      "2022-08-30 20:53:17,712 epoch 2 - iter 330/333 - loss 0.51121181 - samples/sec: 85.63 - lr: 0.400333\n",
      "2022-08-30 20:53:18,037 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:53:18,037 EPOCH 2 done: loss 0.5115 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:53:19,053 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:53:19,081 DEV : loss 0.2929031252861023 - f1-score (micro avg)  0.9056\n",
      "2022-08-30 20:53:19,098 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:53:19,099 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:53:19,795 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:53:23,688 epoch 3 - iter 33/333 - loss 0.51221452 - samples/sec: 84.81 - lr: 0.400333\n",
      "2022-08-30 20:53:27,826 epoch 3 - iter 66/333 - loss 0.51913430 - samples/sec: 80.80 - lr: 0.400333\n",
      "2022-08-30 20:53:31,883 epoch 3 - iter 99/333 - loss 0.50976457 - samples/sec: 82.62 - lr: 0.400333\n",
      "2022-08-30 20:53:35,849 epoch 3 - iter 132/333 - loss 0.51448581 - samples/sec: 84.53 - lr: 0.400333\n",
      "2022-08-30 20:53:39,529 epoch 3 - iter 165/333 - loss 0.51072447 - samples/sec: 91.11 - lr: 0.400333\n",
      "2022-08-30 20:53:43,731 epoch 3 - iter 198/333 - loss 0.51571518 - samples/sec: 79.75 - lr: 0.400333\n",
      "2022-08-30 20:53:47,423 epoch 3 - iter 231/333 - loss 0.51436842 - samples/sec: 90.83 - lr: 0.400333\n",
      "2022-08-30 20:53:51,972 epoch 3 - iter 264/333 - loss 0.51578787 - samples/sec: 73.68 - lr: 0.400333\n",
      "2022-08-30 20:53:56,275 epoch 3 - iter 297/333 - loss 0.51922566 - samples/sec: 77.74 - lr: 0.400333\n",
      "2022-08-30 20:54:00,178 epoch 3 - iter 330/333 - loss 0.51670302 - samples/sec: 85.80 - lr: 0.400333\n",
      "2022-08-30 20:54:00,608 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:54:00,609 EPOCH 3 done: loss 0.5170 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:54:01,601 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:54:01,637 DEV : loss 0.30710670351982117 - f1-score (micro avg)  0.9007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:54:01,652 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:54:01,653 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:54:05,782 epoch 4 - iter 33/333 - loss 0.52714754 - samples/sec: 80.00 - lr: 0.400333\n",
      "2022-08-30 20:54:09,344 epoch 4 - iter 66/333 - loss 0.52651513 - samples/sec: 94.07 - lr: 0.400333\n",
      "2022-08-30 20:54:13,363 epoch 4 - iter 99/333 - loss 0.51524323 - samples/sec: 83.57 - lr: 0.400333\n",
      "2022-08-30 20:54:17,851 epoch 4 - iter 132/333 - loss 0.51044670 - samples/sec: 74.69 - lr: 0.400333\n",
      "2022-08-30 20:54:21,779 epoch 4 - iter 165/333 - loss 0.51098124 - samples/sec: 85.35 - lr: 0.400333\n",
      "2022-08-30 20:54:25,897 epoch 4 - iter 198/333 - loss 0.51550713 - samples/sec: 81.42 - lr: 0.400333\n",
      "2022-08-30 20:54:30,044 epoch 4 - iter 231/333 - loss 0.51616246 - samples/sec: 80.84 - lr: 0.400333\n",
      "2022-08-30 20:54:34,829 epoch 4 - iter 264/333 - loss 0.51794081 - samples/sec: 69.80 - lr: 0.400333\n",
      "2022-08-30 20:54:39,078 epoch 4 - iter 297/333 - loss 0.51798246 - samples/sec: 78.87 - lr: 0.400333\n",
      "2022-08-30 20:54:43,276 epoch 4 - iter 330/333 - loss 0.51894874 - samples/sec: 79.75 - lr: 0.400333\n",
      "2022-08-30 20:54:43,740 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:54:43,741 EPOCH 4 done: loss 0.5184 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:54:44,791 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:54:44,828 DEV : loss 0.31822410225868225 - f1-score (micro avg)  0.8907\n",
      "2022-08-30 20:54:44,848 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:54:44,849 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:54:49,038 epoch 5 - iter 33/333 - loss 0.50152573 - samples/sec: 78.83 - lr: 0.400333\n",
      "2022-08-30 20:54:53,509 epoch 5 - iter 66/333 - loss 0.51610316 - samples/sec: 74.78 - lr: 0.400333\n",
      "2022-08-30 20:54:57,868 epoch 5 - iter 99/333 - loss 0.51673096 - samples/sec: 76.76 - lr: 0.400333\n",
      "2022-08-30 20:55:01,636 epoch 5 - iter 132/333 - loss 0.51533038 - samples/sec: 88.92 - lr: 0.400333\n",
      "2022-08-30 20:55:05,561 epoch 5 - iter 165/333 - loss 0.52067826 - samples/sec: 85.47 - lr: 0.400333\n",
      "2022-08-30 20:55:09,613 epoch 5 - iter 198/333 - loss 0.52041566 - samples/sec: 82.69 - lr: 0.400333\n",
      "2022-08-30 20:55:14,035 epoch 5 - iter 231/333 - loss 0.51919118 - samples/sec: 75.81 - lr: 0.400333\n",
      "2022-08-30 20:55:18,342 epoch 5 - iter 264/333 - loss 0.51847892 - samples/sec: 77.78 - lr: 0.400333\n",
      "2022-08-30 20:55:22,900 epoch 5 - iter 297/333 - loss 0.51912426 - samples/sec: 73.53 - lr: 0.400333\n",
      "2022-08-30 20:55:27,083 epoch 5 - iter 330/333 - loss 0.51978813 - samples/sec: 80.27 - lr: 0.400333\n",
      "2022-08-30 20:55:27,440 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:55:27,441 EPOCH 5 done: loss 0.5199 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:55:28,447 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:55:28,475 DEV : loss 0.3152603507041931 - f1-score (micro avg)  0.8962\n",
      "2022-08-30 20:55:28,491 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 20:55:28,492 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:55:32,851 epoch 6 - iter 33/333 - loss 0.53590377 - samples/sec: 75.72 - lr: 0.400333\n",
      "2022-08-30 20:55:37,028 epoch 6 - iter 66/333 - loss 0.52777045 - samples/sec: 80.25 - lr: 0.400333\n",
      "2022-08-30 20:55:40,943 epoch 6 - iter 99/333 - loss 0.53145438 - samples/sec: 85.67 - lr: 0.400333\n",
      "2022-08-30 20:55:45,115 epoch 6 - iter 132/333 - loss 0.52709359 - samples/sec: 80.29 - lr: 0.400333\n",
      "2022-08-30 20:55:49,628 epoch 6 - iter 165/333 - loss 0.52224815 - samples/sec: 74.07 - lr: 0.400333\n",
      "2022-08-30 20:55:54,298 epoch 6 - iter 198/333 - loss 0.52393338 - samples/sec: 71.68 - lr: 0.400333\n",
      "2022-08-30 20:55:58,139 epoch 6 - iter 231/333 - loss 0.52003253 - samples/sec: 87.23 - lr: 0.400333\n",
      "2022-08-30 20:56:02,294 epoch 6 - iter 264/333 - loss 0.52212699 - samples/sec: 80.68 - lr: 0.400333\n",
      "2022-08-30 20:56:06,618 epoch 6 - iter 297/333 - loss 0.52461849 - samples/sec: 77.50 - lr: 0.400333\n",
      "2022-08-30 20:56:10,919 epoch 6 - iter 330/333 - loss 0.52359850 - samples/sec: 77.94 - lr: 0.400333\n",
      "2022-08-30 20:56:11,302 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:56:11,303 EPOCH 6 done: loss 0.5234 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:56:12,314 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:56:12,347 DEV : loss 0.3113842010498047 - f1-score (micro avg)  0.8991\n",
      "2022-08-30 20:56:12,370 Epoch     6: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 20:56:12,371 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 20:56:12,372 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:56:16,619 epoch 7 - iter 33/333 - loss 0.53780025 - samples/sec: 77.74 - lr: 0.200167\n",
      "2022-08-30 20:56:20,827 epoch 7 - iter 66/333 - loss 0.50578312 - samples/sec: 79.96 - lr: 0.200167\n",
      "2022-08-30 20:56:25,053 epoch 7 - iter 99/333 - loss 0.49343890 - samples/sec: 79.35 - lr: 0.200167\n",
      "2022-08-30 20:56:29,125 epoch 7 - iter 132/333 - loss 0.48725283 - samples/sec: 82.34 - lr: 0.200167\n",
      "2022-08-30 20:56:33,308 epoch 7 - iter 165/333 - loss 0.48329355 - samples/sec: 80.14 - lr: 0.200167\n",
      "2022-08-30 20:56:37,673 epoch 7 - iter 198/333 - loss 0.47913773 - samples/sec: 76.76 - lr: 0.200167\n",
      "2022-08-30 20:56:42,013 epoch 7 - iter 231/333 - loss 0.48148223 - samples/sec: 77.14 - lr: 0.200167\n",
      "2022-08-30 20:56:45,808 epoch 7 - iter 264/333 - loss 0.47918710 - samples/sec: 88.88 - lr: 0.200167\n",
      "2022-08-30 20:56:49,776 epoch 7 - iter 297/333 - loss 0.47726882 - samples/sec: 84.36 - lr: 0.200167\n",
      "2022-08-30 20:56:53,952 epoch 7 - iter 330/333 - loss 0.47319938 - samples/sec: 80.12 - lr: 0.200167\n",
      "2022-08-30 20:56:54,327 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:56:54,328 EPOCH 7 done: loss 0.4734 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:56:55,331 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:56:55,361 DEV : loss 0.27515462040901184 - f1-score (micro avg)  0.9103\n",
      "2022-08-30 20:56:55,376 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 20:56:55,377 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:56:56,547 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:57:00,482 epoch 8 - iter 33/333 - loss 0.46041918 - samples/sec: 83.88 - lr: 0.200167\n",
      "2022-08-30 20:57:04,719 epoch 8 - iter 66/333 - loss 0.45778423 - samples/sec: 79.00 - lr: 0.200167\n",
      "2022-08-30 20:57:08,926 epoch 8 - iter 99/333 - loss 0.45680662 - samples/sec: 79.59 - lr: 0.200167\n",
      "2022-08-30 20:57:12,964 epoch 8 - iter 132/333 - loss 0.45587907 - samples/sec: 83.17 - lr: 0.200167\n",
      "2022-08-30 20:57:16,885 epoch 8 - iter 165/333 - loss 0.45179167 - samples/sec: 85.56 - lr: 0.200167\n",
      "2022-08-30 20:57:21,487 epoch 8 - iter 198/333 - loss 0.45138336 - samples/sec: 72.67 - lr: 0.200167\n",
      "2022-08-30 20:57:26,131 epoch 8 - iter 231/333 - loss 0.45400071 - samples/sec: 72.16 - lr: 0.200167\n",
      "2022-08-30 20:57:30,235 epoch 8 - iter 264/333 - loss 0.45354451 - samples/sec: 81.54 - lr: 0.200167\n",
      "2022-08-30 20:57:34,181 epoch 8 - iter 297/333 - loss 0.45336600 - samples/sec: 84.90 - lr: 0.200167\n",
      "2022-08-30 20:57:38,156 epoch 8 - iter 330/333 - loss 0.45264233 - samples/sec: 84.36 - lr: 0.200167\n",
      "2022-08-30 20:57:38,540 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:57:38,541 EPOCH 8 done: loss 0.4529 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:57:39,556 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:57:39,588 DEV : loss 0.2744799852371216 - f1-score (micro avg)  0.909\n",
      "2022-08-30 20:57:39,609 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 20:57:39,610 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:57:43,372 epoch 9 - iter 33/333 - loss 0.45215670 - samples/sec: 87.79 - lr: 0.200167\n",
      "2022-08-30 20:57:47,636 epoch 9 - iter 66/333 - loss 0.45020361 - samples/sec: 78.82 - lr: 0.200167\n",
      "2022-08-30 20:57:51,460 epoch 9 - iter 99/333 - loss 0.45588383 - samples/sec: 87.60 - lr: 0.200167\n",
      "2022-08-30 20:57:55,533 epoch 9 - iter 132/333 - loss 0.45876333 - samples/sec: 82.48 - lr: 0.200167\n",
      "2022-08-30 20:57:59,559 epoch 9 - iter 165/333 - loss 0.44842945 - samples/sec: 83.29 - lr: 0.200167\n",
      "2022-08-30 20:58:03,254 epoch 9 - iter 198/333 - loss 0.44511823 - samples/sec: 90.78 - lr: 0.200167\n",
      "2022-08-30 20:58:07,449 epoch 9 - iter 231/333 - loss 0.44617920 - samples/sec: 79.83 - lr: 0.200167\n",
      "2022-08-30 20:58:12,441 epoch 9 - iter 264/333 - loss 0.44369937 - samples/sec: 67.01 - lr: 0.200167\n",
      "2022-08-30 20:58:16,400 epoch 9 - iter 297/333 - loss 0.44082190 - samples/sec: 84.72 - lr: 0.200167\n",
      "2022-08-30 20:58:20,334 epoch 9 - iter 330/333 - loss 0.44073299 - samples/sec: 85.49 - lr: 0.200167\n",
      "2022-08-30 20:58:20,753 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:58:20,754 EPOCH 9 done: loss 0.4408 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:58:21,732 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:58:21,763 DEV : loss 0.2811194956302643 - f1-score (micro avg)  0.9069\n",
      "2022-08-30 20:58:21,783 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 20:58:21,784 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:58:25,881 epoch 10 - iter 33/333 - loss 0.42761880 - samples/sec: 80.59 - lr: 0.200167\n",
      "2022-08-30 20:58:29,620 epoch 10 - iter 66/333 - loss 0.43385232 - samples/sec: 89.82 - lr: 0.200167\n",
      "2022-08-30 20:58:33,506 epoch 10 - iter 99/333 - loss 0.43514894 - samples/sec: 86.34 - lr: 0.200167\n",
      "2022-08-30 20:58:37,456 epoch 10 - iter 132/333 - loss 0.43398214 - samples/sec: 84.92 - lr: 0.200167\n",
      "2022-08-30 20:58:41,922 epoch 10 - iter 165/333 - loss 0.43238140 - samples/sec: 75.00 - lr: 0.200167\n",
      "2022-08-30 20:58:45,834 epoch 10 - iter 198/333 - loss 0.43658955 - samples/sec: 85.69 - lr: 0.200167\n",
      "2022-08-30 20:58:49,576 epoch 10 - iter 231/333 - loss 0.43557714 - samples/sec: 89.70 - lr: 0.200167\n",
      "2022-08-30 20:58:54,050 epoch 10 - iter 264/333 - loss 0.43295872 - samples/sec: 74.78 - lr: 0.200167\n",
      "2022-08-30 20:58:58,271 epoch 10 - iter 297/333 - loss 0.43275176 - samples/sec: 79.29 - lr: 0.200167\n",
      "2022-08-30 20:59:02,568 epoch 10 - iter 330/333 - loss 0.43541888 - samples/sec: 78.01 - lr: 0.200167\n",
      "2022-08-30 20:59:02,952 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:59:02,953 EPOCH 10 done: loss 0.4360 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:59:05,241 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:59:05,275 DEV : loss 0.27079537510871887 - f1-score (micro avg)  0.9068\n",
      "2022-08-30 20:59:05,295 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 20:59:05,296 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:59:09,261 epoch 11 - iter 33/333 - loss 0.43966477 - samples/sec: 83.31 - lr: 0.200167\n",
      "2022-08-30 20:59:13,330 epoch 11 - iter 66/333 - loss 0.42620763 - samples/sec: 82.29 - lr: 0.200167\n",
      "2022-08-30 20:59:16,995 epoch 11 - iter 99/333 - loss 0.42951905 - samples/sec: 91.74 - lr: 0.200167\n",
      "2022-08-30 20:59:20,764 epoch 11 - iter 132/333 - loss 0.43022379 - samples/sec: 88.92 - lr: 0.200167\n",
      "2022-08-30 20:59:24,959 epoch 11 - iter 165/333 - loss 0.42435344 - samples/sec: 79.83 - lr: 0.200167\n",
      "2022-08-30 20:59:28,748 epoch 11 - iter 198/333 - loss 0.42743893 - samples/sec: 88.40 - lr: 0.200167\n",
      "2022-08-30 20:59:32,990 epoch 11 - iter 231/333 - loss 0.42800528 - samples/sec: 79.04 - lr: 0.200167\n",
      "2022-08-30 20:59:37,244 epoch 11 - iter 264/333 - loss 0.42708977 - samples/sec: 78.85 - lr: 0.200167\n",
      "2022-08-30 20:59:41,444 epoch 11 - iter 297/333 - loss 0.42911996 - samples/sec: 79.85 - lr: 0.200167\n",
      "2022-08-30 20:59:45,906 epoch 11 - iter 330/333 - loss 0.43051552 - samples/sec: 75.07 - lr: 0.200167\n",
      "2022-08-30 20:59:46,641 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:59:46,642 EPOCH 11 done: loss 0.4308 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:59:47,654 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:59:47,687 DEV : loss 0.2676347494125366 - f1-score (micro avg)  0.909\n",
      "2022-08-30 20:59:47,703 Epoch    11: reducing learning rate of group 0 to 1.0008e-01.\n",
      "2022-08-30 20:59:47,704 BAD EPOCHS (no improvement): 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:59:48,683 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:59:48,684 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 20:59:48,867 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:59:50,432 Evaluating as a multi-label problem: False\n",
      "2022-08-30 20:59:50,456 0.9101\t0.9101\t0.9101\t0.9101\n",
      "2022-08-30 20:59:50,457 \n",
      "Results:\n",
      "- F-score (micro) 0.9101\n",
      "- F-score (macro) 0.7894\n",
      "- Accuracy 0.9101\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8694    0.9150    0.8916      1353\n",
      "         ADJ     0.8684    0.8839    0.8761       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9902    0.9825    0.9863       514\n",
      "        VERB     0.8568    0.9065    0.8810       449\n",
      "       PROPN     0.8226    0.6658    0.7359       383\n",
      "         AUX     0.9849    0.9731    0.9790       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9945    0.9891    0.9918       184\n",
      "         DET     0.9110    0.8261    0.8664       161\n",
      "         ADV     0.7697    0.7748    0.7723       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9194    0.8028    0.8571        71\n",
      "        PART     0.8500    0.8095    0.8293        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9101      5264\n",
      "   macro avg     0.8017    0.7793    0.7894      5264\n",
      "weighted avg     0.9104    0.9101    0.9093      5264\n",
      "\n",
      "2022-08-30 20:59:50,458 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 20:59:50,460 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 20:59:50,958 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 21:02:15,710 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:02:15,711 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 21:02:15,712 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:02:15,712 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 21:02:15,713 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:02:15,713 Parameters:\n",
      "2022-08-30 21:02:15,714  - learning_rate: \"0.400333\"\n",
      "2022-08-30 21:02:15,714  - mini_batch_size: \"10\"\n",
      "2022-08-30 21:02:15,715  - patience: \"3\"\n",
      "2022-08-30 21:02:15,715  - anneal_factor: \"0.5\"\n",
      "2022-08-30 21:02:15,716  - max_epochs: \"12\"\n",
      "2022-08-30 21:02:15,716  - shuffle: \"True\"\n",
      "2022-08-30 21:02:15,717  - train_with_dev: \"False\"\n",
      "2022-08-30 21:02:15,717  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 21:02:15,718 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:02:15,718 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 21:02:15,719 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:02:15,719 Device: cpu\n",
      "2022-08-30 21:02:15,720 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:02:15,721 Embeddings storage mode: cpu\n",
      "2022-08-30 21:02:15,721 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:02:19,824 epoch 1 - iter 33/333 - loss 0.44139354 - samples/sec: 80.49 - lr: 0.400333\n",
      "2022-08-30 21:02:24,255 epoch 1 - iter 66/333 - loss 0.46595690 - samples/sec: 75.60 - lr: 0.400333\n",
      "2022-08-30 21:02:28,010 epoch 1 - iter 99/333 - loss 0.46726386 - samples/sec: 89.41 - lr: 0.400333\n",
      "2022-08-30 21:02:31,922 epoch 1 - iter 132/333 - loss 0.46786011 - samples/sec: 85.76 - lr: 0.400333\n",
      "2022-08-30 21:02:36,564 epoch 1 - iter 165/333 - loss 0.47604797 - samples/sec: 72.05 - lr: 0.400333\n",
      "2022-08-30 21:02:40,212 epoch 1 - iter 198/333 - loss 0.47779818 - samples/sec: 92.05 - lr: 0.400333\n",
      "2022-08-30 21:02:44,358 epoch 1 - iter 231/333 - loss 0.48374938 - samples/sec: 80.76 - lr: 0.400333\n",
      "2022-08-30 21:02:48,090 epoch 1 - iter 264/333 - loss 0.48399866 - samples/sec: 90.24 - lr: 0.400333\n",
      "2022-08-30 21:02:52,387 epoch 1 - iter 297/333 - loss 0.48659918 - samples/sec: 77.90 - lr: 0.400333\n",
      "2022-08-30 21:02:56,845 epoch 1 - iter 330/333 - loss 0.50419835 - samples/sec: 75.24 - lr: 0.400333\n",
      "2022-08-30 21:02:57,283 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:02:57,284 EPOCH 1 done: loss 0.5052 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:02:58,289 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:02:58,320 DEV : loss 0.329595148563385 - f1-score (micro avg)  0.8874\n",
      "2022-08-30 21:02:58,335 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:02:58,336 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:02:59,062 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:03:03,715 epoch 2 - iter 33/333 - loss 0.51769582 - samples/sec: 70.97 - lr: 0.400333\n",
      "2022-08-30 21:03:07,927 epoch 2 - iter 66/333 - loss 0.52048116 - samples/sec: 79.56 - lr: 0.400333\n",
      "2022-08-30 21:03:11,829 epoch 2 - iter 99/333 - loss 0.52338388 - samples/sec: 85.87 - lr: 0.400333\n",
      "2022-08-30 21:03:15,770 epoch 2 - iter 132/333 - loss 0.51948843 - samples/sec: 85.16 - lr: 0.400333\n",
      "2022-08-30 21:03:20,359 epoch 2 - iter 165/333 - loss 0.51829500 - samples/sec: 72.88 - lr: 0.400333\n",
      "2022-08-30 21:03:24,231 epoch 2 - iter 198/333 - loss 0.52113703 - samples/sec: 86.86 - lr: 0.400333\n",
      "2022-08-30 21:03:28,639 epoch 2 - iter 231/333 - loss 0.52173085 - samples/sec: 75.88 - lr: 0.400333\n",
      "2022-08-30 21:03:32,989 epoch 2 - iter 264/333 - loss 0.52351088 - samples/sec: 76.99 - lr: 0.400333\n",
      "2022-08-30 21:03:37,029 epoch 2 - iter 297/333 - loss 0.52280121 - samples/sec: 82.96 - lr: 0.400333\n",
      "2022-08-30 21:03:41,222 epoch 2 - iter 330/333 - loss 0.52431514 - samples/sec: 79.94 - lr: 0.400333\n",
      "2022-08-30 21:03:41,660 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:03:41,661 EPOCH 2 done: loss 0.5243 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:03:42,725 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:03:42,754 DEV : loss 0.321265310049057 - f1-score (micro avg)  0.8837\n",
      "2022-08-30 21:03:42,770 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:03:42,771 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:03:47,060 epoch 3 - iter 33/333 - loss 0.51864864 - samples/sec: 77.05 - lr: 0.400333\n",
      "2022-08-30 21:03:50,702 epoch 3 - iter 66/333 - loss 0.52164152 - samples/sec: 92.08 - lr: 0.400333\n",
      "2022-08-30 21:03:54,615 epoch 3 - iter 99/333 - loss 0.52318029 - samples/sec: 85.63 - lr: 0.400333\n",
      "2022-08-30 21:03:58,693 epoch 3 - iter 132/333 - loss 0.52213970 - samples/sec: 82.25 - lr: 0.400333\n",
      "2022-08-30 21:04:03,193 epoch 3 - iter 165/333 - loss 0.52323688 - samples/sec: 74.59 - lr: 0.400333\n",
      "2022-08-30 21:04:07,344 epoch 3 - iter 198/333 - loss 0.52382714 - samples/sec: 80.86 - lr: 0.400333\n",
      "2022-08-30 21:04:11,662 epoch 3 - iter 231/333 - loss 0.52506938 - samples/sec: 77.72 - lr: 0.400333\n",
      "2022-08-30 21:04:15,783 epoch 3 - iter 264/333 - loss 0.52403207 - samples/sec: 81.24 - lr: 0.400333\n",
      "2022-08-30 21:04:19,733 epoch 3 - iter 297/333 - loss 0.52602711 - samples/sec: 84.92 - lr: 0.400333\n",
      "2022-08-30 21:04:24,037 epoch 3 - iter 330/333 - loss 0.52689582 - samples/sec: 77.76 - lr: 0.400333\n",
      "2022-08-30 21:04:24,406 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:04:24,407 EPOCH 3 done: loss 0.5275 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:04:25,388 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:04:25,417 DEV : loss 0.3231714069843292 - f1-score (micro avg)  0.8874\n",
      "2022-08-30 21:04:25,433 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:04:25,434 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:04:29,141 epoch 4 - iter 33/333 - loss 0.50319670 - samples/sec: 89.07 - lr: 0.400333\n",
      "2022-08-30 21:04:33,341 epoch 4 - iter 66/333 - loss 0.50722469 - samples/sec: 79.86 - lr: 0.400333\n",
      "2022-08-30 21:04:37,494 epoch 4 - iter 99/333 - loss 0.50961748 - samples/sec: 80.84 - lr: 0.400333\n",
      "2022-08-30 21:04:41,463 epoch 4 - iter 132/333 - loss 0.50963241 - samples/sec: 84.55 - lr: 0.400333\n",
      "2022-08-30 21:04:45,640 epoch 4 - iter 165/333 - loss 0.51745600 - samples/sec: 80.29 - lr: 0.400333\n",
      "2022-08-30 21:04:49,944 epoch 4 - iter 198/333 - loss 0.51604256 - samples/sec: 77.74 - lr: 0.400333\n",
      "2022-08-30 21:04:53,961 epoch 4 - iter 231/333 - loss 0.51609071 - samples/sec: 83.35 - lr: 0.400333\n",
      "2022-08-30 21:04:57,968 epoch 4 - iter 264/333 - loss 0.51893932 - samples/sec: 83.63 - lr: 0.400333\n",
      "2022-08-30 21:05:02,218 epoch 4 - iter 297/333 - loss 0.52338269 - samples/sec: 78.72 - lr: 0.400333\n",
      "2022-08-30 21:05:06,095 epoch 4 - iter 330/333 - loss 0.52512471 - samples/sec: 86.48 - lr: 0.400333\n",
      "2022-08-30 21:05:06,541 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:05:06,542 EPOCH 4 done: loss 0.5251 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:05:07,536 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:05:07,564 DEV : loss 0.32464855909347534 - f1-score (micro avg)  0.8939\n",
      "2022-08-30 21:05:07,579 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:05:07,580 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:05:08,745 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:05:12,969 epoch 5 - iter 33/333 - loss 0.52756125 - samples/sec: 78.14 - lr: 0.400333\n",
      "2022-08-30 21:05:16,903 epoch 5 - iter 66/333 - loss 0.51538273 - samples/sec: 85.16 - lr: 0.400333\n",
      "2022-08-30 21:05:21,000 epoch 5 - iter 99/333 - loss 0.52074309 - samples/sec: 81.72 - lr: 0.400333\n",
      "2022-08-30 21:05:25,091 epoch 5 - iter 132/333 - loss 0.52195858 - samples/sec: 81.91 - lr: 0.400333\n",
      "2022-08-30 21:05:29,421 epoch 5 - iter 165/333 - loss 0.52460848 - samples/sec: 77.34 - lr: 0.400333\n",
      "2022-08-30 21:05:33,771 epoch 5 - iter 198/333 - loss 0.52424550 - samples/sec: 77.21 - lr: 0.400333\n",
      "2022-08-30 21:05:37,460 epoch 5 - iter 231/333 - loss 0.52428813 - samples/sec: 90.93 - lr: 0.400333\n",
      "2022-08-30 21:05:41,369 epoch 5 - iter 264/333 - loss 0.52537710 - samples/sec: 85.89 - lr: 0.400333\n",
      "2022-08-30 21:05:45,105 epoch 5 - iter 297/333 - loss 0.52472722 - samples/sec: 90.07 - lr: 0.400333\n",
      "2022-08-30 21:05:49,210 epoch 5 - iter 330/333 - loss 0.52631286 - samples/sec: 81.60 - lr: 0.400333\n",
      "2022-08-30 21:05:49,677 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:05:49,678 EPOCH 5 done: loss 0.5263 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:05:50,669 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:05:50,701 DEV : loss 0.3084583878517151 - f1-score (micro avg)  0.8928\n",
      "2022-08-30 21:05:50,716 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:05:50,717 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:05:54,835 epoch 6 - iter 33/333 - loss 0.53372505 - samples/sec: 80.23 - lr: 0.400333\n",
      "2022-08-30 21:05:58,549 epoch 6 - iter 66/333 - loss 0.53828671 - samples/sec: 90.29 - lr: 0.400333\n",
      "2022-08-30 21:06:02,724 epoch 6 - iter 99/333 - loss 0.53846466 - samples/sec: 80.31 - lr: 0.400333\n",
      "2022-08-30 21:06:06,764 epoch 6 - iter 132/333 - loss 0.53647236 - samples/sec: 82.89 - lr: 0.400333\n",
      "2022-08-30 21:06:10,644 epoch 6 - iter 165/333 - loss 0.53788649 - samples/sec: 86.52 - lr: 0.400333\n",
      "2022-08-30 21:06:14,541 epoch 6 - iter 198/333 - loss 0.53583065 - samples/sec: 86.03 - lr: 0.400333\n",
      "2022-08-30 21:06:19,007 epoch 6 - iter 231/333 - loss 0.53723818 - samples/sec: 74.97 - lr: 0.400333\n",
      "2022-08-30 21:06:23,275 epoch 6 - iter 264/333 - loss 0.53515424 - samples/sec: 78.53 - lr: 0.400333\n",
      "2022-08-30 21:06:27,543 epoch 6 - iter 297/333 - loss 0.53565107 - samples/sec: 78.52 - lr: 0.400333\n",
      "2022-08-30 21:06:31,426 epoch 6 - iter 330/333 - loss 0.53479880 - samples/sec: 86.25 - lr: 0.400333\n",
      "2022-08-30 21:06:31,825 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:06:31,825 EPOCH 6 done: loss 0.5349 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:06:32,795 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:06:32,821 DEV : loss 0.3192152678966522 - f1-score (micro avg)  0.8878\n",
      "2022-08-30 21:06:32,838 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 21:06:32,839 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:06:37,085 epoch 7 - iter 33/333 - loss 0.48982796 - samples/sec: 77.78 - lr: 0.400333\n",
      "2022-08-30 21:06:40,783 epoch 7 - iter 66/333 - loss 0.50796892 - samples/sec: 90.76 - lr: 0.400333\n",
      "2022-08-30 21:06:44,850 epoch 7 - iter 99/333 - loss 0.51939702 - samples/sec: 82.42 - lr: 0.400333\n",
      "2022-08-30 21:06:48,690 epoch 7 - iter 132/333 - loss 0.52908227 - samples/sec: 87.30 - lr: 0.400333\n",
      "2022-08-30 21:06:52,615 epoch 7 - iter 165/333 - loss 0.53383720 - samples/sec: 85.40 - lr: 0.400333\n",
      "2022-08-30 21:06:56,850 epoch 7 - iter 198/333 - loss 0.53219720 - samples/sec: 79.12 - lr: 0.400333\n",
      "2022-08-30 21:07:00,781 epoch 7 - iter 231/333 - loss 0.53219537 - samples/sec: 85.18 - lr: 0.400333\n",
      "2022-08-30 21:07:05,004 epoch 7 - iter 264/333 - loss 0.53016913 - samples/sec: 79.25 - lr: 0.400333\n",
      "2022-08-30 21:07:09,014 epoch 7 - iter 297/333 - loss 0.53069891 - samples/sec: 83.69 - lr: 0.400333\n",
      "2022-08-30 21:07:13,551 epoch 7 - iter 330/333 - loss 0.53503012 - samples/sec: 73.81 - lr: 0.400333\n",
      "2022-08-30 21:07:13,998 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:07:13,999 EPOCH 7 done: loss 0.5345 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:07:14,998 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:07:15,033 DEV : loss 0.3210486173629761 - f1-score (micro avg)  0.8856\n",
      "2022-08-30 21:07:15,049 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 21:07:15,050 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:07:18,718 epoch 8 - iter 33/333 - loss 0.52748610 - samples/sec: 90.07 - lr: 0.400333\n",
      "2022-08-30 21:07:23,090 epoch 8 - iter 66/333 - loss 0.52948628 - samples/sec: 76.60 - lr: 0.400333\n",
      "2022-08-30 21:07:27,125 epoch 8 - iter 99/333 - loss 0.53409394 - samples/sec: 83.06 - lr: 0.400333\n",
      "2022-08-30 21:07:31,145 epoch 8 - iter 132/333 - loss 0.53397571 - samples/sec: 83.33 - lr: 0.400333\n",
      "2022-08-30 21:07:35,309 epoch 8 - iter 165/333 - loss 0.53386221 - samples/sec: 80.53 - lr: 0.400333\n",
      "2022-08-30 21:07:39,874 epoch 8 - iter 198/333 - loss 0.53338299 - samples/sec: 73.33 - lr: 0.400333\n",
      "2022-08-30 21:07:43,727 epoch 8 - iter 231/333 - loss 0.53190772 - samples/sec: 86.98 - lr: 0.400333\n",
      "2022-08-30 21:07:47,331 epoch 8 - iter 264/333 - loss 0.53325913 - samples/sec: 93.12 - lr: 0.400333\n",
      "2022-08-30 21:07:51,475 epoch 8 - iter 297/333 - loss 0.53284775 - samples/sec: 81.02 - lr: 0.400333\n",
      "2022-08-30 21:07:56,034 epoch 8 - iter 330/333 - loss 0.53322049 - samples/sec: 73.41 - lr: 0.400333\n",
      "2022-08-30 21:07:56,428 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:07:56,429 EPOCH 8 done: loss 0.5334 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:07:57,422 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:07:57,454 DEV : loss 0.3054921329021454 - f1-score (micro avg)  0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:07:57,474 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:07:57,475 saving best model\n",
      "2022-08-30 21:07:58,315 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:08:02,855 epoch 9 - iter 33/333 - loss 0.53368098 - samples/sec: 72.74 - lr: 0.400333\n",
      "2022-08-30 21:08:06,918 epoch 9 - iter 66/333 - loss 0.51665151 - samples/sec: 82.42 - lr: 0.400333\n",
      "2022-08-30 21:08:11,506 epoch 9 - iter 99/333 - loss 0.52140515 - samples/sec: 72.94 - lr: 0.400333\n",
      "2022-08-30 21:08:15,466 epoch 9 - iter 132/333 - loss 0.53158817 - samples/sec: 84.75 - lr: 0.400333\n",
      "2022-08-30 21:08:19,278 epoch 9 - iter 165/333 - loss 0.53119180 - samples/sec: 88.16 - lr: 0.400333\n",
      "2022-08-30 21:08:23,806 epoch 9 - iter 198/333 - loss 0.53442704 - samples/sec: 73.84 - lr: 0.400333\n",
      "2022-08-30 21:08:28,064 epoch 9 - iter 231/333 - loss 0.53516721 - samples/sec: 78.87 - lr: 0.400333\n",
      "2022-08-30 21:08:31,973 epoch 9 - iter 264/333 - loss 0.53721092 - samples/sec: 85.78 - lr: 0.400333\n",
      "2022-08-30 21:08:35,788 epoch 9 - iter 297/333 - loss 0.53693534 - samples/sec: 87.95 - lr: 0.400333\n",
      "2022-08-30 21:08:39,779 epoch 9 - iter 330/333 - loss 0.53699786 - samples/sec: 84.10 - lr: 0.400333\n",
      "2022-08-30 21:08:40,133 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:08:40,134 EPOCH 9 done: loss 0.5371 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:08:41,124 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:08:41,159 DEV : loss 0.32417139410972595 - f1-score (micro avg)  0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:08:41,179 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:08:41,180 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:08:44,855 epoch 10 - iter 33/333 - loss 0.51881040 - samples/sec: 89.82 - lr: 0.400333\n",
      "2022-08-30 21:08:48,975 epoch 10 - iter 66/333 - loss 0.53071515 - samples/sec: 81.44 - lr: 0.400333\n",
      "2022-08-30 21:08:52,950 epoch 10 - iter 99/333 - loss 0.52233393 - samples/sec: 84.21 - lr: 0.400333\n",
      "2022-08-30 21:08:56,983 epoch 10 - iter 132/333 - loss 0.52714440 - samples/sec: 83.06 - lr: 0.400333\n",
      "2022-08-30 21:09:01,124 epoch 10 - iter 165/333 - loss 0.53385105 - samples/sec: 80.88 - lr: 0.400333\n",
      "2022-08-30 21:09:05,711 epoch 10 - iter 198/333 - loss 0.53693461 - samples/sec: 72.98 - lr: 0.400333\n",
      "2022-08-30 21:09:09,516 epoch 10 - iter 231/333 - loss 0.53430047 - samples/sec: 88.09 - lr: 0.400333\n",
      "2022-08-30 21:09:13,690 epoch 10 - iter 264/333 - loss 0.53463529 - samples/sec: 80.38 - lr: 0.400333\n",
      "2022-08-30 21:09:17,614 epoch 10 - iter 297/333 - loss 0.53790408 - samples/sec: 85.34 - lr: 0.400333\n",
      "2022-08-30 21:09:21,824 epoch 10 - iter 330/333 - loss 0.53941011 - samples/sec: 79.53 - lr: 0.400333\n",
      "2022-08-30 21:09:22,178 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:09:22,178 EPOCH 10 done: loss 0.5397 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:09:23,178 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:09:23,209 DEV : loss 0.33388471603393555 - f1-score (micro avg)  0.8824\n",
      "2022-08-30 21:09:23,226 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 21:09:23,227 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:09:27,170 epoch 11 - iter 33/333 - loss 0.56005021 - samples/sec: 83.76 - lr: 0.400333\n",
      "2022-08-30 21:09:31,352 epoch 11 - iter 66/333 - loss 0.55192334 - samples/sec: 80.16 - lr: 0.400333\n",
      "2022-08-30 21:09:35,518 epoch 11 - iter 99/333 - loss 0.54664192 - samples/sec: 80.61 - lr: 0.400333\n",
      "2022-08-30 21:09:39,321 epoch 11 - iter 132/333 - loss 0.54450518 - samples/sec: 88.24 - lr: 0.400333\n",
      "2022-08-30 21:09:43,256 epoch 11 - iter 165/333 - loss 0.54529020 - samples/sec: 85.36 - lr: 0.400333\n",
      "2022-08-30 21:09:47,102 epoch 11 - iter 198/333 - loss 0.54462685 - samples/sec: 87.12 - lr: 0.400333\n",
      "2022-08-30 21:09:50,864 epoch 11 - iter 231/333 - loss 0.54399911 - samples/sec: 89.16 - lr: 0.400333\n",
      "2022-08-30 21:09:54,911 epoch 11 - iter 264/333 - loss 0.54390050 - samples/sec: 82.78 - lr: 0.400333\n",
      "2022-08-30 21:09:59,263 epoch 11 - iter 297/333 - loss 0.54642488 - samples/sec: 76.87 - lr: 0.400333\n",
      "2022-08-30 21:10:03,656 epoch 11 - iter 330/333 - loss 0.54558419 - samples/sec: 76.18 - lr: 0.400333\n",
      "2022-08-30 21:10:04,123 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:10:04,124 EPOCH 11 done: loss 0.5454 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:10:05,124 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:10:05,152 DEV : loss 0.31954193115234375 - f1-score (micro avg)  0.8866\n",
      "2022-08-30 21:10:05,170 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 21:10:05,172 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:10:09,021 epoch 12 - iter 33/333 - loss 0.55929231 - samples/sec: 85.80 - lr: 0.400333\n",
      "2022-08-30 21:10:13,299 epoch 12 - iter 66/333 - loss 0.55233852 - samples/sec: 78.24 - lr: 0.400333\n",
      "2022-08-30 21:10:17,363 epoch 12 - iter 99/333 - loss 0.54612322 - samples/sec: 82.44 - lr: 0.400333\n",
      "2022-08-30 21:10:21,500 epoch 12 - iter 132/333 - loss 0.54659826 - samples/sec: 81.24 - lr: 0.400333\n",
      "2022-08-30 21:10:25,328 epoch 12 - iter 165/333 - loss 0.54741178 - samples/sec: 87.70 - lr: 0.400333\n",
      "2022-08-30 21:10:29,333 epoch 12 - iter 198/333 - loss 0.54440113 - samples/sec: 83.82 - lr: 0.400333\n",
      "2022-08-30 21:10:33,819 epoch 12 - iter 231/333 - loss 0.54504199 - samples/sec: 74.71 - lr: 0.400333\n",
      "2022-08-30 21:10:38,073 epoch 12 - iter 264/333 - loss 0.54188551 - samples/sec: 78.99 - lr: 0.400333\n",
      "2022-08-30 21:10:41,955 epoch 12 - iter 297/333 - loss 0.54295788 - samples/sec: 86.45 - lr: 0.400333\n",
      "2022-08-30 21:10:46,022 epoch 12 - iter 330/333 - loss 0.54362317 - samples/sec: 82.40 - lr: 0.400333\n",
      "2022-08-30 21:10:46,489 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:10:46,490 EPOCH 12 done: loss 0.5432 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:10:47,502 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:10:47,530 DEV : loss 0.32865652441978455 - f1-score (micro avg)  0.8874\n",
      "2022-08-30 21:10:47,550 Epoch    12: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 21:10:47,551 BAD EPOCHS (no improvement): 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:10:48,269 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:10:48,270 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 21:10:48,463 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:10:50,048 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:10:50,074 0.9022\t0.9022\t0.9022\t0.9022\n",
      "2022-08-30 21:10:50,074 \n",
      "Results:\n",
      "- F-score (micro) 0.9022\n",
      "- F-score (macro) 0.7845\n",
      "- Accuracy 0.9022\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8545    0.9069    0.8799      1353\n",
      "         ADJ     0.8431    0.8795    0.8609       672\n",
      "       PUNCT     0.9985    1.0000    0.9992       660\n",
      "         ADP     0.9863    0.9825    0.9844       514\n",
      "        VERB     0.8171    0.9154    0.8634       449\n",
      "       PROPN     0.8378    0.6475    0.7305       383\n",
      "         AUX     0.9850    0.9791    0.9820       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.8841    0.7578    0.8161       161\n",
      "         ADV     0.8605    0.7351    0.7929       151\n",
      "        PRON     1.0000    0.9217    0.9593       115\n",
      "         NUM     0.9796    0.6761    0.8000        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9022      5264\n",
      "   macro avg     0.8144    0.7628    0.7845      5264\n",
      "weighted avg     0.9037    0.9022    0.9008      5264\n",
      "\n",
      "2022-08-30 21:10:50,075 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:10:50,077 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:10:50,586 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 21:13:21,573 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:13:21,574 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 21:13:21,574 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:13:21,575 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 21:13:21,576 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:13:21,577 Parameters:\n",
      "2022-08-30 21:13:21,577  - learning_rate: \"0.400333\"\n",
      "2022-08-30 21:13:21,577  - mini_batch_size: \"30\"\n",
      "2022-08-30 21:13:21,578  - patience: \"3\"\n",
      "2022-08-30 21:13:21,579  - anneal_factor: \"0.5\"\n",
      "2022-08-30 21:13:21,579  - max_epochs: \"10\"\n",
      "2022-08-30 21:13:21,579  - shuffle: \"True\"\n",
      "2022-08-30 21:13:21,580  - train_with_dev: \"False\"\n",
      "2022-08-30 21:13:21,581  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 21:13:21,581 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:13:21,582 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 21:13:21,583 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:13:21,584 Device: cpu\n",
      "2022-08-30 21:13:21,584 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:13:21,584 Embeddings storage mode: cpu\n",
      "2022-08-30 21:13:21,585 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:13:25,811 epoch 1 - iter 11/111 - loss 0.48259159 - samples/sec: 78.11 - lr: 0.400333\n",
      "2022-08-30 21:13:30,079 epoch 1 - iter 22/111 - loss 0.48929299 - samples/sec: 78.48 - lr: 0.400333\n",
      "2022-08-30 21:13:33,733 epoch 1 - iter 33/111 - loss 0.48592407 - samples/sec: 91.69 - lr: 0.400333\n",
      "2022-08-30 21:13:37,655 epoch 1 - iter 44/111 - loss 0.48362569 - samples/sec: 85.40 - lr: 0.400333\n",
      "2022-08-30 21:13:42,057 epoch 1 - iter 55/111 - loss 0.48188949 - samples/sec: 76.07 - lr: 0.400333\n",
      "2022-08-30 21:13:45,896 epoch 1 - iter 66/111 - loss 0.47885526 - samples/sec: 87.35 - lr: 0.400333\n",
      "2022-08-30 21:13:50,024 epoch 1 - iter 77/111 - loss 0.48012183 - samples/sec: 81.02 - lr: 0.400333\n",
      "2022-08-30 21:13:53,681 epoch 1 - iter 88/111 - loss 0.48064129 - samples/sec: 91.59 - lr: 0.400333\n",
      "2022-08-30 21:13:57,923 epoch 1 - iter 99/111 - loss 0.48055935 - samples/sec: 78.95 - lr: 0.400333\n",
      "2022-08-30 21:14:02,545 epoch 1 - iter 110/111 - loss 0.49610015 - samples/sec: 72.31 - lr: 0.400333\n",
      "2022-08-30 21:14:02,992 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:14:02,993 EPOCH 1 done: loss 0.4961 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:14:03,908 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:14:03,939 DEV : loss 0.32263922691345215 - f1-score (micro avg)  0.8887\n",
      "2022-08-30 21:14:03,955 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:14:03,957 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:14:04,669 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:14:09,260 epoch 2 - iter 11/111 - loss 0.47846090 - samples/sec: 71.91 - lr: 0.400333\n",
      "2022-08-30 21:14:13,529 epoch 2 - iter 22/111 - loss 0.47942396 - samples/sec: 78.33 - lr: 0.400333\n",
      "2022-08-30 21:14:17,981 epoch 2 - iter 33/111 - loss 0.48654603 - samples/sec: 75.12 - lr: 0.400333\n",
      "2022-08-30 21:14:21,786 epoch 2 - iter 44/111 - loss 0.48459875 - samples/sec: 88.21 - lr: 0.400333\n",
      "2022-08-30 21:14:26,041 epoch 2 - iter 55/111 - loss 0.48398098 - samples/sec: 78.65 - lr: 0.400333\n",
      "2022-08-30 21:14:30,197 epoch 2 - iter 66/111 - loss 0.48320164 - samples/sec: 80.59 - lr: 0.400333\n",
      "2022-08-30 21:14:34,505 epoch 2 - iter 77/111 - loss 0.48345335 - samples/sec: 77.70 - lr: 0.400333\n",
      "2022-08-30 21:14:38,267 epoch 2 - iter 88/111 - loss 0.48453695 - samples/sec: 89.19 - lr: 0.400333\n",
      "2022-08-30 21:14:42,175 epoch 2 - iter 99/111 - loss 0.48475905 - samples/sec: 85.78 - lr: 0.400333\n",
      "2022-08-30 21:14:46,120 epoch 2 - iter 110/111 - loss 0.48218695 - samples/sec: 84.85 - lr: 0.400333\n",
      "2022-08-30 21:14:46,533 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:14:46,534 EPOCH 2 done: loss 0.4822 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:14:47,410 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:14:47,443 DEV : loss 0.28585559129714966 - f1-score (micro avg)  0.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:14:47,463 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:14:47,464 saving best model\n",
      "2022-08-30 21:14:48,518 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:14:52,751 epoch 3 - iter 11/111 - loss 0.47118412 - samples/sec: 77.98 - lr: 0.400333\n",
      "2022-08-30 21:14:56,822 epoch 3 - iter 22/111 - loss 0.47164412 - samples/sec: 82.62 - lr: 0.400333\n",
      "2022-08-30 21:15:01,055 epoch 3 - iter 33/111 - loss 0.47022119 - samples/sec: 79.02 - lr: 0.400333\n",
      "2022-08-30 21:15:05,058 epoch 3 - iter 44/111 - loss 0.47173880 - samples/sec: 83.78 - lr: 0.400333\n",
      "2022-08-30 21:15:08,851 epoch 3 - iter 55/111 - loss 0.47218110 - samples/sec: 88.28 - lr: 0.400333\n",
      "2022-08-30 21:15:13,191 epoch 3 - iter 66/111 - loss 0.47551772 - samples/sec: 77.12 - lr: 0.400333\n",
      "2022-08-30 21:15:17,303 epoch 3 - iter 77/111 - loss 0.47103349 - samples/sec: 81.44 - lr: 0.400333\n",
      "2022-08-30 21:15:21,752 epoch 3 - iter 88/111 - loss 0.47183901 - samples/sec: 75.27 - lr: 0.400333\n",
      "2022-08-30 21:15:25,904 epoch 3 - iter 99/111 - loss 0.46894436 - samples/sec: 80.65 - lr: 0.400333\n",
      "2022-08-30 21:15:30,029 epoch 3 - iter 110/111 - loss 0.46848818 - samples/sec: 81.16 - lr: 0.400333\n",
      "2022-08-30 21:15:30,410 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:15:30,411 EPOCH 3 done: loss 0.4684 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:15:31,299 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:15:31,327 DEV : loss 0.2866016924381256 - f1-score (micro avg)  0.8998\n",
      "2022-08-30 21:15:31,342 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:15:31,343 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:15:35,544 epoch 4 - iter 11/111 - loss 0.46720978 - samples/sec: 78.59 - lr: 0.400333\n",
      "2022-08-30 21:15:39,378 epoch 4 - iter 22/111 - loss 0.46173609 - samples/sec: 87.49 - lr: 0.400333\n",
      "2022-08-30 21:15:43,372 epoch 4 - iter 33/111 - loss 0.46156828 - samples/sec: 84.08 - lr: 0.400333\n",
      "2022-08-30 21:15:47,347 epoch 4 - iter 44/111 - loss 0.46658853 - samples/sec: 84.38 - lr: 0.400333\n",
      "2022-08-30 21:15:51,295 epoch 4 - iter 55/111 - loss 0.46428936 - samples/sec: 85.34 - lr: 0.400333\n",
      "2022-08-30 21:15:55,634 epoch 4 - iter 66/111 - loss 0.46659356 - samples/sec: 77.23 - lr: 0.400333\n",
      "2022-08-30 21:15:59,481 epoch 4 - iter 77/111 - loss 0.46355065 - samples/sec: 87.12 - lr: 0.400333\n",
      "2022-08-30 21:16:03,359 epoch 4 - iter 88/111 - loss 0.46550505 - samples/sec: 86.52 - lr: 0.400333\n",
      "2022-08-30 21:16:08,018 epoch 4 - iter 99/111 - loss 0.46377390 - samples/sec: 71.97 - lr: 0.400333\n",
      "2022-08-30 21:16:12,277 epoch 4 - iter 110/111 - loss 0.46527671 - samples/sec: 78.74 - lr: 0.400333\n",
      "2022-08-30 21:16:12,688 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:16:12,689 EPOCH 4 done: loss 0.4653 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:16:13,552 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:16:13,583 DEV : loss 0.2820529043674469 - f1-score (micro avg)  0.9077\n",
      "2022-08-30 21:16:13,601 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:16:13,603 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:16:14,575 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:16:18,788 epoch 5 - iter 11/111 - loss 0.43762168 - samples/sec: 78.35 - lr: 0.400333\n",
      "2022-08-30 21:16:22,734 epoch 5 - iter 22/111 - loss 0.45459767 - samples/sec: 85.16 - lr: 0.400333\n",
      "2022-08-30 21:16:26,872 epoch 5 - iter 33/111 - loss 0.45357156 - samples/sec: 80.96 - lr: 0.400333\n",
      "2022-08-30 21:16:31,245 epoch 5 - iter 44/111 - loss 0.46095928 - samples/sec: 76.48 - lr: 0.400333\n",
      "2022-08-30 21:16:35,298 epoch 5 - iter 55/111 - loss 0.46201503 - samples/sec: 82.73 - lr: 0.400333\n",
      "2022-08-30 21:16:39,262 epoch 5 - iter 66/111 - loss 0.46279852 - samples/sec: 84.62 - lr: 0.400333\n",
      "2022-08-30 21:16:43,596 epoch 5 - iter 77/111 - loss 0.46366128 - samples/sec: 77.19 - lr: 0.400333\n",
      "2022-08-30 21:16:47,658 epoch 5 - iter 88/111 - loss 0.46300909 - samples/sec: 82.58 - lr: 0.400333\n",
      "2022-08-30 21:16:51,736 epoch 5 - iter 99/111 - loss 0.46164060 - samples/sec: 82.07 - lr: 0.400333\n",
      "2022-08-30 21:16:55,661 epoch 5 - iter 110/111 - loss 0.46257782 - samples/sec: 85.40 - lr: 0.400333\n",
      "2022-08-30 21:16:56,024 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:16:56,025 EPOCH 5 done: loss 0.4626 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:16:56,904 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:16:56,935 DEV : loss 0.2841300666332245 - f1-score (micro avg)  0.9029\n",
      "2022-08-30 21:16:56,950 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:16:56,951 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:17:00,962 epoch 6 - iter 11/111 - loss 0.45964582 - samples/sec: 82.29 - lr: 0.400333\n",
      "2022-08-30 21:17:06,285 epoch 6 - iter 22/111 - loss 0.45931432 - samples/sec: 62.65 - lr: 0.400333\n",
      "2022-08-30 21:17:10,497 epoch 6 - iter 33/111 - loss 0.45489225 - samples/sec: 79.59 - lr: 0.400333\n",
      "2022-08-30 21:17:14,706 epoch 6 - iter 44/111 - loss 0.45939078 - samples/sec: 79.63 - lr: 0.400333\n",
      "2022-08-30 21:17:18,858 epoch 6 - iter 55/111 - loss 0.45765534 - samples/sec: 80.63 - lr: 0.400333\n",
      "2022-08-30 21:17:23,003 epoch 6 - iter 66/111 - loss 0.46043238 - samples/sec: 80.88 - lr: 0.400333\n",
      "2022-08-30 21:17:27,183 epoch 6 - iter 77/111 - loss 0.46026690 - samples/sec: 80.04 - lr: 0.400333\n",
      "2022-08-30 21:17:31,033 epoch 6 - iter 88/111 - loss 0.46161826 - samples/sec: 87.09 - lr: 0.400333\n",
      "2022-08-30 21:17:35,073 epoch 6 - iter 99/111 - loss 0.46057555 - samples/sec: 82.83 - lr: 0.400333\n",
      "2022-08-30 21:17:39,730 epoch 6 - iter 110/111 - loss 0.46019146 - samples/sec: 71.80 - lr: 0.400333\n",
      "2022-08-30 21:17:40,209 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:17:40,210 EPOCH 6 done: loss 0.4601 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:17:41,118 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:17:41,149 DEV : loss 0.27787989377975464 - f1-score (micro avg)  0.9074\n",
      "2022-08-30 21:17:41,164 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 21:17:41,165 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:17:45,226 epoch 7 - iter 11/111 - loss 0.45742501 - samples/sec: 81.28 - lr: 0.400333\n",
      "2022-08-30 21:17:49,575 epoch 7 - iter 22/111 - loss 0.44824323 - samples/sec: 76.96 - lr: 0.400333\n",
      "2022-08-30 21:17:54,027 epoch 7 - iter 33/111 - loss 0.45045940 - samples/sec: 75.27 - lr: 0.400333\n",
      "2022-08-30 21:17:58,084 epoch 7 - iter 44/111 - loss 0.45058928 - samples/sec: 82.62 - lr: 0.400333\n",
      "2022-08-30 21:18:02,067 epoch 7 - iter 55/111 - loss 0.45284384 - samples/sec: 84.08 - lr: 0.400333\n",
      "2022-08-30 21:18:06,017 epoch 7 - iter 66/111 - loss 0.45190192 - samples/sec: 84.88 - lr: 0.400333\n",
      "2022-08-30 21:18:10,166 epoch 7 - iter 77/111 - loss 0.45031024 - samples/sec: 80.61 - lr: 0.400333\n",
      "2022-08-30 21:18:14,469 epoch 7 - iter 88/111 - loss 0.45182440 - samples/sec: 77.85 - lr: 0.400333\n",
      "2022-08-30 21:18:18,946 epoch 7 - iter 99/111 - loss 0.45144850 - samples/sec: 74.76 - lr: 0.400333\n",
      "2022-08-30 21:18:23,066 epoch 7 - iter 110/111 - loss 0.45276999 - samples/sec: 81.56 - lr: 0.400333\n",
      "2022-08-30 21:18:23,441 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:18:23,442 EPOCH 7 done: loss 0.4532 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:18:24,333 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:18:24,368 DEV : loss 0.28414297103881836 - f1-score (micro avg)  0.9035\n",
      "2022-08-30 21:18:24,391 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 21:18:24,392 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:18:28,727 epoch 8 - iter 11/111 - loss 0.44677159 - samples/sec: 76.18 - lr: 0.400333\n",
      "2022-08-30 21:18:33,105 epoch 8 - iter 22/111 - loss 0.44655864 - samples/sec: 76.42 - lr: 0.400333\n",
      "2022-08-30 21:18:37,110 epoch 8 - iter 33/111 - loss 0.44553674 - samples/sec: 83.71 - lr: 0.400333\n",
      "2022-08-30 21:18:41,483 epoch 8 - iter 44/111 - loss 0.44328091 - samples/sec: 76.55 - lr: 0.400333\n",
      "2022-08-30 21:18:45,627 epoch 8 - iter 55/111 - loss 0.44676076 - samples/sec: 81.00 - lr: 0.400333\n",
      "2022-08-30 21:18:50,094 epoch 8 - iter 66/111 - loss 0.45162677 - samples/sec: 74.95 - lr: 0.400333\n",
      "2022-08-30 21:18:53,997 epoch 8 - iter 77/111 - loss 0.44953013 - samples/sec: 85.98 - lr: 0.400333\n",
      "2022-08-30 21:18:58,235 epoch 8 - iter 88/111 - loss 0.45213592 - samples/sec: 79.04 - lr: 0.400333\n",
      "2022-08-30 21:19:02,435 epoch 8 - iter 99/111 - loss 0.45201446 - samples/sec: 79.77 - lr: 0.400333\n",
      "2022-08-30 21:19:06,514 epoch 8 - iter 110/111 - loss 0.45216794 - samples/sec: 82.27 - lr: 0.400333\n",
      "2022-08-30 21:19:06,885 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:19:06,886 EPOCH 8 done: loss 0.4516 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:19:07,768 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:19:07,804 DEV : loss 0.2785583734512329 - f1-score (micro avg)  0.9055\n",
      "2022-08-30 21:19:07,821 Epoch     8: reducing learning rate of group 0 to 2.0017e-01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:19:07,821 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 21:19:07,822 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:19:11,732 epoch 9 - iter 11/111 - loss 0.44234364 - samples/sec: 84.44 - lr: 0.200167\n",
      "2022-08-30 21:19:15,932 epoch 9 - iter 22/111 - loss 0.42093234 - samples/sec: 79.65 - lr: 0.200167\n",
      "2022-08-30 21:19:19,994 epoch 9 - iter 33/111 - loss 0.42360015 - samples/sec: 82.52 - lr: 0.200167\n",
      "2022-08-30 21:19:24,314 epoch 9 - iter 44/111 - loss 0.42660793 - samples/sec: 77.48 - lr: 0.200167\n",
      "2022-08-30 21:19:28,731 epoch 9 - iter 55/111 - loss 0.42534542 - samples/sec: 75.90 - lr: 0.200167\n",
      "2022-08-30 21:19:32,796 epoch 9 - iter 66/111 - loss 0.42789139 - samples/sec: 82.50 - lr: 0.200167\n",
      "2022-08-30 21:19:37,310 epoch 9 - iter 77/111 - loss 0.42991614 - samples/sec: 74.07 - lr: 0.200167\n",
      "2022-08-30 21:19:41,142 epoch 9 - iter 88/111 - loss 0.42775753 - samples/sec: 87.63 - lr: 0.200167\n",
      "2022-08-30 21:19:45,416 epoch 9 - iter 99/111 - loss 0.42915862 - samples/sec: 78.35 - lr: 0.200167\n",
      "2022-08-30 21:19:49,476 epoch 9 - iter 110/111 - loss 0.42908311 - samples/sec: 82.67 - lr: 0.200167\n",
      "2022-08-30 21:19:49,932 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:19:49,933 EPOCH 9 done: loss 0.4288 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:19:50,803 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:19:50,835 DEV : loss 0.2661310136318207 - f1-score (micro avg)  0.9118\n",
      "2022-08-30 21:19:50,849 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:19:50,851 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:19:51,579 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:19:55,617 epoch 10 - iter 11/111 - loss 0.41715917 - samples/sec: 81.78 - lr: 0.200167\n",
      "2022-08-30 21:19:59,865 epoch 10 - iter 22/111 - loss 0.41546809 - samples/sec: 79.00 - lr: 0.200167\n",
      "2022-08-30 21:20:04,030 epoch 10 - iter 33/111 - loss 0.41559451 - samples/sec: 80.33 - lr: 0.200167\n",
      "2022-08-30 21:20:08,214 epoch 10 - iter 44/111 - loss 0.41419461 - samples/sec: 80.02 - lr: 0.200167\n",
      "2022-08-30 21:20:12,274 epoch 10 - iter 55/111 - loss 0.41339922 - samples/sec: 82.54 - lr: 0.200167\n",
      "2022-08-30 21:20:16,688 epoch 10 - iter 66/111 - loss 0.41384282 - samples/sec: 75.79 - lr: 0.200167\n",
      "2022-08-30 21:20:20,639 epoch 10 - iter 77/111 - loss 0.41087317 - samples/sec: 84.83 - lr: 0.200167\n",
      "2022-08-30 21:20:24,593 epoch 10 - iter 88/111 - loss 0.41049144 - samples/sec: 84.90 - lr: 0.200167\n",
      "2022-08-30 21:20:29,045 epoch 10 - iter 99/111 - loss 0.40940390 - samples/sec: 75.27 - lr: 0.200167\n",
      "2022-08-30 21:20:33,046 epoch 10 - iter 110/111 - loss 0.41038802 - samples/sec: 83.74 - lr: 0.200167\n",
      "2022-08-30 21:20:33,349 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:20:33,350 EPOCH 10 done: loss 0.4105 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:20:34,264 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:20:34,296 DEV : loss 0.25952109694480896 - f1-score (micro avg)  0.9123\n",
      "2022-08-30 21:20:34,313 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:20:34,314 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:20:36,041 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:20:36,042 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 21:20:36,226 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:20:37,656 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:20:37,684 0.9204\t0.9204\t0.9204\t0.9204\n",
      "2022-08-30 21:20:37,685 \n",
      "Results:\n",
      "- F-score (micro) 0.9204\n",
      "- F-score (macro) 0.8625\n",
      "- Accuracy 0.9204\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8760    0.9298    0.9021      1353\n",
      "         ADJ     0.8871    0.9003    0.8936       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9902    0.9864    0.9883       514\n",
      "        VERB     0.8799    0.8976    0.8886       449\n",
      "       PROPN     0.8438    0.7050    0.7681       383\n",
      "         AUX     0.9880    0.9791    0.9835       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.9133    0.8509    0.8810       161\n",
      "         ADV     0.8200    0.8146    0.8173       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9815    0.7465    0.8480        71\n",
      "        PART     0.9444    0.8095    0.8718        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9204      5264\n",
      "   macro avg     0.8818    0.8471    0.8625      5264\n",
      "weighted avg     0.9212    0.9204    0.9198      5264\n",
      "\n",
      "2022-08-30 21:20:37,685 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:20:37,687 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 21:20:38,177 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 21:23:08,623 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:23:08,624 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 21:23:08,624 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:23:08,625 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 21:23:08,625 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:23:08,626 Parameters:\n",
      "2022-08-30 21:23:08,627  - learning_rate: \"0.400333\"\n",
      "2022-08-30 21:23:08,627  - mini_batch_size: \"30\"\n",
      "2022-08-30 21:23:08,628  - patience: \"3\"\n",
      "2022-08-30 21:23:08,628  - anneal_factor: \"0.5\"\n",
      "2022-08-30 21:23:08,629  - max_epochs: \"11\"\n",
      "2022-08-30 21:23:08,629  - shuffle: \"True\"\n",
      "2022-08-30 21:23:08,629  - train_with_dev: \"False\"\n",
      "2022-08-30 21:23:08,630  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 21:23:08,630 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:23:08,631 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 21:23:08,631 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:23:08,632 Device: cpu\n",
      "2022-08-30 21:23:08,632 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:23:08,633 Embeddings storage mode: cpu\n",
      "2022-08-30 21:23:08,634 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:23:12,631 epoch 1 - iter 11/111 - loss 0.38394566 - samples/sec: 82.60 - lr: 0.400333\n",
      "2022-08-30 21:23:16,792 epoch 1 - iter 22/111 - loss 0.40817873 - samples/sec: 80.49 - lr: 0.400333\n",
      "2022-08-30 21:23:20,469 epoch 1 - iter 33/111 - loss 0.40918201 - samples/sec: 91.34 - lr: 0.400333\n",
      "2022-08-30 21:23:24,195 epoch 1 - iter 44/111 - loss 0.40889156 - samples/sec: 89.94 - lr: 0.400333\n",
      "2022-08-30 21:23:28,475 epoch 1 - iter 55/111 - loss 0.41539856 - samples/sec: 78.22 - lr: 0.400333\n",
      "2022-08-30 21:23:32,258 epoch 1 - iter 66/111 - loss 0.41545915 - samples/sec: 88.59 - lr: 0.400333\n",
      "2022-08-30 21:23:36,670 epoch 1 - iter 77/111 - loss 0.41833695 - samples/sec: 75.77 - lr: 0.400333\n",
      "2022-08-30 21:23:40,488 epoch 1 - iter 88/111 - loss 0.41849924 - samples/sec: 87.98 - lr: 0.400333\n",
      "2022-08-30 21:23:44,631 epoch 1 - iter 99/111 - loss 0.41967162 - samples/sec: 80.94 - lr: 0.400333\n",
      "2022-08-30 21:23:49,085 epoch 1 - iter 110/111 - loss 0.43480209 - samples/sec: 75.38 - lr: 0.400333\n",
      "2022-08-30 21:23:49,582 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:23:49,583 EPOCH 1 done: loss 0.4355 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:23:50,488 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:23:50,514 DEV : loss 0.3072047829627991 - f1-score (micro avg)  0.8928\n",
      "2022-08-30 21:23:50,529 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:23:50,530 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:23:51,537 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:23:55,744 epoch 2 - iter 11/111 - loss 0.43252522 - samples/sec: 78.50 - lr: 0.400333\n",
      "2022-08-30 21:23:59,979 epoch 2 - iter 22/111 - loss 0.43877974 - samples/sec: 79.04 - lr: 0.400333\n",
      "2022-08-30 21:24:03,954 epoch 2 - iter 33/111 - loss 0.43769684 - samples/sec: 84.62 - lr: 0.400333\n",
      "2022-08-30 21:24:08,155 epoch 2 - iter 44/111 - loss 0.43492337 - samples/sec: 79.79 - lr: 0.400333\n",
      "2022-08-30 21:24:12,679 epoch 2 - iter 55/111 - loss 0.43581894 - samples/sec: 74.07 - lr: 0.400333\n",
      "2022-08-30 21:24:17,204 epoch 2 - iter 66/111 - loss 0.43590290 - samples/sec: 74.17 - lr: 0.400333\n",
      "2022-08-30 21:24:21,822 epoch 2 - iter 77/111 - loss 0.43922463 - samples/sec: 72.48 - lr: 0.400333\n",
      "2022-08-30 21:24:25,928 epoch 2 - iter 88/111 - loss 0.43636643 - samples/sec: 81.52 - lr: 0.400333\n",
      "2022-08-30 21:24:30,009 epoch 2 - iter 99/111 - loss 0.43793598 - samples/sec: 82.27 - lr: 0.400333\n",
      "2022-08-30 21:24:34,202 epoch 2 - iter 110/111 - loss 0.43767381 - samples/sec: 79.92 - lr: 0.400333\n",
      "2022-08-30 21:24:34,630 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:24:34,631 EPOCH 2 done: loss 0.4376 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:24:35,525 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:24:35,556 DEV : loss 0.2814178466796875 - f1-score (micro avg)  0.9076\n",
      "2022-08-30 21:24:35,573 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:24:35,574 saving best model\n",
      "2022-08-30 21:24:36,376 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:24:40,484 epoch 3 - iter 11/111 - loss 0.44668192 - samples/sec: 80.35 - lr: 0.400333\n",
      "2022-08-30 21:24:45,002 epoch 3 - iter 22/111 - loss 0.43816576 - samples/sec: 74.02 - lr: 0.400333\n",
      "2022-08-30 21:24:49,151 epoch 3 - iter 33/111 - loss 0.44484860 - samples/sec: 80.65 - lr: 0.400333\n",
      "2022-08-30 21:24:53,282 epoch 3 - iter 44/111 - loss 0.44381352 - samples/sec: 81.02 - lr: 0.400333\n",
      "2022-08-30 21:24:57,465 epoch 3 - iter 55/111 - loss 0.44226392 - samples/sec: 80.41 - lr: 0.400333\n",
      "2022-08-30 21:25:01,499 epoch 3 - iter 66/111 - loss 0.44055832 - samples/sec: 83.63 - lr: 0.400333\n",
      "2022-08-30 21:25:05,665 epoch 3 - iter 77/111 - loss 0.44128290 - samples/sec: 80.57 - lr: 0.400333\n",
      "2022-08-30 21:25:09,816 epoch 3 - iter 88/111 - loss 0.44395882 - samples/sec: 80.65 - lr: 0.400333\n",
      "2022-08-30 21:25:13,951 epoch 3 - iter 99/111 - loss 0.44498999 - samples/sec: 80.94 - lr: 0.400333\n",
      "2022-08-30 21:25:18,095 epoch 3 - iter 110/111 - loss 0.44496202 - samples/sec: 80.88 - lr: 0.400333\n",
      "2022-08-30 21:25:18,429 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:25:18,430 EPOCH 3 done: loss 0.4450 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:25:19,495 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:25:19,538 DEV : loss 0.2735942602157593 - f1-score (micro avg)  0.9098\n",
      "2022-08-30 21:25:19,558 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:25:19,559 saving best model\n",
      "2022-08-30 21:25:20,280 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:25:24,718 epoch 4 - iter 11/111 - loss 0.42615003 - samples/sec: 74.39 - lr: 0.400333\n",
      "2022-08-30 21:25:28,888 epoch 4 - iter 22/111 - loss 0.43006530 - samples/sec: 80.33 - lr: 0.400333\n",
      "2022-08-30 21:25:33,054 epoch 4 - iter 33/111 - loss 0.43215150 - samples/sec: 80.55 - lr: 0.400333\n",
      "2022-08-30 21:25:37,539 epoch 4 - iter 44/111 - loss 0.43300380 - samples/sec: 74.61 - lr: 0.400333\n",
      "2022-08-30 21:25:41,805 epoch 4 - iter 55/111 - loss 0.43625566 - samples/sec: 78.52 - lr: 0.400333\n",
      "2022-08-30 21:25:46,013 epoch 4 - iter 66/111 - loss 0.43661775 - samples/sec: 79.73 - lr: 0.400333\n",
      "2022-08-30 21:25:49,884 epoch 4 - iter 77/111 - loss 0.44040009 - samples/sec: 86.66 - lr: 0.400333\n",
      "2022-08-30 21:25:53,975 epoch 4 - iter 88/111 - loss 0.44102533 - samples/sec: 81.99 - lr: 0.400333\n",
      "2022-08-30 21:25:58,104 epoch 4 - iter 99/111 - loss 0.44427325 - samples/sec: 81.16 - lr: 0.400333\n",
      "2022-08-30 21:26:02,733 epoch 4 - iter 110/111 - loss 0.44548214 - samples/sec: 72.23 - lr: 0.400333\n",
      "2022-08-30 21:26:03,067 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:26:03,068 EPOCH 4 done: loss 0.4455 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:26:03,960 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:26:03,991 DEV : loss 0.2884822487831116 - f1-score (micro avg)  0.9076\n",
      "2022-08-30 21:26:04,010 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:26:04,011 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:26:07,775 epoch 5 - iter 11/111 - loss 0.45905262 - samples/sec: 87.74 - lr: 0.400333\n",
      "2022-08-30 21:26:12,103 epoch 5 - iter 22/111 - loss 0.44785103 - samples/sec: 77.27 - lr: 0.400333\n",
      "2022-08-30 21:26:16,525 epoch 5 - iter 33/111 - loss 0.44522486 - samples/sec: 75.67 - lr: 0.400333\n",
      "2022-08-30 21:26:20,896 epoch 5 - iter 44/111 - loss 0.44379824 - samples/sec: 77.01 - lr: 0.400333\n",
      "2022-08-30 21:26:24,834 epoch 5 - iter 55/111 - loss 0.44502946 - samples/sec: 85.01 - lr: 0.400333\n",
      "2022-08-30 21:26:28,849 epoch 5 - iter 66/111 - loss 0.44138473 - samples/sec: 83.40 - lr: 0.400333\n",
      "2022-08-30 21:26:32,722 epoch 5 - iter 77/111 - loss 0.44366024 - samples/sec: 86.75 - lr: 0.400333\n",
      "2022-08-30 21:26:37,014 epoch 5 - iter 88/111 - loss 0.44400624 - samples/sec: 78.09 - lr: 0.400333\n",
      "2022-08-30 21:26:41,201 epoch 5 - iter 99/111 - loss 0.44557655 - samples/sec: 79.90 - lr: 0.400333\n",
      "2022-08-30 21:26:45,225 epoch 5 - iter 110/111 - loss 0.44522717 - samples/sec: 83.33 - lr: 0.400333\n",
      "2022-08-30 21:26:45,654 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:26:45,655 EPOCH 5 done: loss 0.4452 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:26:46,535 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:26:46,565 DEV : loss 0.28126755356788635 - f1-score (micro avg)  0.9076\n",
      "2022-08-30 21:26:46,581 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 21:26:46,582 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:26:50,870 epoch 6 - iter 11/111 - loss 0.42260513 - samples/sec: 76.99 - lr: 0.400333\n",
      "2022-08-30 21:26:55,096 epoch 6 - iter 22/111 - loss 0.42652506 - samples/sec: 79.31 - lr: 0.400333\n",
      "2022-08-30 21:26:59,272 epoch 6 - iter 33/111 - loss 0.42903051 - samples/sec: 80.16 - lr: 0.400333\n",
      "2022-08-30 21:27:03,502 epoch 6 - iter 44/111 - loss 0.42819841 - samples/sec: 79.14 - lr: 0.400333\n",
      "2022-08-30 21:27:07,485 epoch 6 - iter 55/111 - loss 0.43295225 - samples/sec: 84.27 - lr: 0.400333\n",
      "2022-08-30 21:27:11,862 epoch 6 - iter 66/111 - loss 0.43581920 - samples/sec: 76.69 - lr: 0.400333\n",
      "2022-08-30 21:27:15,584 epoch 6 - iter 77/111 - loss 0.43720484 - samples/sec: 90.02 - lr: 0.400333\n",
      "2022-08-30 21:27:19,859 epoch 6 - iter 88/111 - loss 0.43824679 - samples/sec: 78.37 - lr: 0.400333\n",
      "2022-08-30 21:27:24,037 epoch 6 - iter 99/111 - loss 0.43936662 - samples/sec: 80.12 - lr: 0.400333\n",
      "2022-08-30 21:27:28,403 epoch 6 - iter 110/111 - loss 0.44087044 - samples/sec: 76.73 - lr: 0.400333\n",
      "2022-08-30 21:27:28,812 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:27:28,813 EPOCH 6 done: loss 0.4408 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:27:29,692 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:27:29,725 DEV : loss 0.2817406952381134 - f1-score (micro avg)  0.9017\n",
      "2022-08-30 21:27:29,741 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:27:29,742 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:27:34,188 epoch 7 - iter 11/111 - loss 0.43736245 - samples/sec: 74.29 - lr: 0.400333\n",
      "2022-08-30 21:27:38,444 epoch 7 - iter 22/111 - loss 0.43778172 - samples/sec: 78.68 - lr: 0.400333\n",
      "2022-08-30 21:27:42,170 epoch 7 - iter 33/111 - loss 0.44081274 - samples/sec: 90.21 - lr: 0.400333\n",
      "2022-08-30 21:27:46,114 epoch 7 - iter 44/111 - loss 0.44399689 - samples/sec: 84.90 - lr: 0.400333\n",
      "2022-08-30 21:27:50,588 epoch 7 - iter 55/111 - loss 0.44157226 - samples/sec: 74.86 - lr: 0.400333\n",
      "2022-08-30 21:27:54,547 epoch 7 - iter 66/111 - loss 0.44328591 - samples/sec: 84.81 - lr: 0.400333\n",
      "2022-08-30 21:27:58,792 epoch 7 - iter 77/111 - loss 0.44431472 - samples/sec: 79.10 - lr: 0.400333\n",
      "2022-08-30 21:28:02,691 epoch 7 - iter 88/111 - loss 0.44311017 - samples/sec: 86.03 - lr: 0.400333\n",
      "2022-08-30 21:28:07,014 epoch 7 - iter 99/111 - loss 0.44080685 - samples/sec: 77.37 - lr: 0.400333\n",
      "2022-08-30 21:28:11,085 epoch 7 - iter 110/111 - loss 0.44105584 - samples/sec: 82.40 - lr: 0.400333\n",
      "2022-08-30 21:28:11,445 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:28:11,446 EPOCH 7 done: loss 0.4411 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:28:12,411 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:28:12,441 DEV : loss 0.27738335728645325 - f1-score (micro avg)  0.8981\n",
      "2022-08-30 21:28:12,457 Epoch     7: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 21:28:12,458 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 21:28:12,459 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:28:16,841 epoch 8 - iter 11/111 - loss 0.42440664 - samples/sec: 75.33 - lr: 0.200167\n",
      "2022-08-30 21:28:21,024 epoch 8 - iter 22/111 - loss 0.41532266 - samples/sec: 80.06 - lr: 0.200167\n",
      "2022-08-30 21:28:25,208 epoch 8 - iter 33/111 - loss 0.41737621 - samples/sec: 80.06 - lr: 0.200167\n",
      "2022-08-30 21:28:29,207 epoch 8 - iter 44/111 - loss 0.41861467 - samples/sec: 83.65 - lr: 0.200167\n",
      "2022-08-30 21:28:33,106 epoch 8 - iter 55/111 - loss 0.41921849 - samples/sec: 85.98 - lr: 0.200167\n",
      "2022-08-30 21:28:37,221 epoch 8 - iter 66/111 - loss 0.41525401 - samples/sec: 81.28 - lr: 0.200167\n",
      "2022-08-30 21:28:41,100 epoch 8 - iter 77/111 - loss 0.41428316 - samples/sec: 86.39 - lr: 0.200167\n",
      "2022-08-30 21:28:45,467 epoch 8 - iter 88/111 - loss 0.41095434 - samples/sec: 76.67 - lr: 0.200167\n",
      "2022-08-30 21:28:49,838 epoch 8 - iter 99/111 - loss 0.41012808 - samples/sec: 76.73 - lr: 0.200167\n",
      "2022-08-30 21:28:53,990 epoch 8 - iter 110/111 - loss 0.41064410 - samples/sec: 80.63 - lr: 0.200167\n",
      "2022-08-30 21:28:54,367 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:28:54,368 EPOCH 8 done: loss 0.4103 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:28:55,260 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:28:55,292 DEV : loss 0.2599211633205414 - f1-score (micro avg)  0.909\n",
      "2022-08-30 21:28:55,310 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:28:55,311 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:28:59,190 epoch 9 - iter 11/111 - loss 0.39799433 - samples/sec: 85.14 - lr: 0.200167\n",
      "2022-08-30 21:29:03,351 epoch 9 - iter 22/111 - loss 0.40547615 - samples/sec: 80.59 - lr: 0.200167\n",
      "2022-08-30 21:29:07,862 epoch 9 - iter 33/111 - loss 0.40700832 - samples/sec: 74.29 - lr: 0.200167\n",
      "2022-08-30 21:29:12,186 epoch 9 - iter 44/111 - loss 0.40123388 - samples/sec: 77.50 - lr: 0.200167\n",
      "2022-08-30 21:29:16,346 epoch 9 - iter 55/111 - loss 0.39780138 - samples/sec: 80.68 - lr: 0.200167\n",
      "2022-08-30 21:29:20,254 epoch 9 - iter 66/111 - loss 0.40194843 - samples/sec: 86.00 - lr: 0.200167\n",
      "2022-08-30 21:29:24,561 epoch 9 - iter 77/111 - loss 0.39991350 - samples/sec: 77.67 - lr: 0.200167\n",
      "2022-08-30 21:29:28,902 epoch 9 - iter 88/111 - loss 0.40257565 - samples/sec: 77.04 - lr: 0.200167\n",
      "2022-08-30 21:29:33,223 epoch 9 - iter 99/111 - loss 0.40273870 - samples/sec: 77.54 - lr: 0.200167\n",
      "2022-08-30 21:29:37,665 epoch 9 - iter 110/111 - loss 0.40087075 - samples/sec: 75.36 - lr: 0.200167\n",
      "2022-08-30 21:29:38,029 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:29:38,030 EPOCH 9 done: loss 0.4006 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:29:38,975 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:29:39,011 DEV : loss 0.26341161131858826 - f1-score (micro avg)  0.9092\n",
      "2022-08-30 21:29:39,030 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:29:39,032 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:29:42,887 epoch 10 - iter 11/111 - loss 0.41056091 - samples/sec: 85.63 - lr: 0.200167\n",
      "2022-08-30 21:29:46,885 epoch 10 - iter 22/111 - loss 0.41722654 - samples/sec: 83.93 - lr: 0.200167\n",
      "2022-08-30 21:29:51,034 epoch 10 - iter 33/111 - loss 0.41183760 - samples/sec: 80.80 - lr: 0.200167\n",
      "2022-08-30 21:29:55,316 epoch 10 - iter 44/111 - loss 0.40227833 - samples/sec: 78.09 - lr: 0.200167\n",
      "2022-08-30 21:29:59,463 epoch 10 - iter 55/111 - loss 0.39662763 - samples/sec: 80.88 - lr: 0.200167\n",
      "2022-08-30 21:30:03,326 epoch 10 - iter 66/111 - loss 0.39623117 - samples/sec: 87.12 - lr: 0.200167\n",
      "2022-08-30 21:30:08,029 epoch 10 - iter 77/111 - loss 0.39643108 - samples/sec: 71.21 - lr: 0.200167\n",
      "2022-08-30 21:30:12,027 epoch 10 - iter 88/111 - loss 0.39675948 - samples/sec: 84.12 - lr: 0.200167\n",
      "2022-08-30 21:30:16,280 epoch 10 - iter 99/111 - loss 0.39463620 - samples/sec: 78.76 - lr: 0.200167\n",
      "2022-08-30 21:30:20,729 epoch 10 - iter 110/111 - loss 0.39552649 - samples/sec: 75.33 - lr: 0.200167\n",
      "2022-08-30 21:30:21,062 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:30:21,063 EPOCH 10 done: loss 0.3954 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:30:22,013 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:30:22,045 DEV : loss 0.26348230242729187 - f1-score (micro avg)  0.9092\n",
      "2022-08-30 21:30:22,062 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 21:30:22,064 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:30:26,335 epoch 11 - iter 11/111 - loss 0.38100791 - samples/sec: 77.30 - lr: 0.200167\n",
      "2022-08-30 21:30:30,333 epoch 11 - iter 22/111 - loss 0.37540207 - samples/sec: 84.20 - lr: 0.200167\n",
      "2022-08-30 21:30:34,898 epoch 11 - iter 33/111 - loss 0.37923099 - samples/sec: 73.40 - lr: 0.200167\n",
      "2022-08-30 21:30:39,012 epoch 11 - iter 44/111 - loss 0.37787565 - samples/sec: 81.41 - lr: 0.200167\n",
      "2022-08-30 21:30:43,367 epoch 11 - iter 55/111 - loss 0.38260245 - samples/sec: 77.12 - lr: 0.200167\n",
      "2022-08-30 21:30:47,310 epoch 11 - iter 66/111 - loss 0.38240844 - samples/sec: 85.71 - lr: 0.200167\n",
      "2022-08-30 21:30:51,319 epoch 11 - iter 77/111 - loss 0.38511283 - samples/sec: 83.67 - lr: 0.200167\n",
      "2022-08-30 21:30:55,730 epoch 11 - iter 88/111 - loss 0.38456533 - samples/sec: 75.98 - lr: 0.200167\n",
      "2022-08-30 21:30:59,981 epoch 11 - iter 99/111 - loss 0.38710440 - samples/sec: 78.72 - lr: 0.200167\n",
      "2022-08-30 21:31:03,823 epoch 11 - iter 110/111 - loss 0.38686934 - samples/sec: 87.44 - lr: 0.200167\n",
      "2022-08-30 21:31:04,299 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:31:04,300 EPOCH 11 done: loss 0.3868 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:31:05,226 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:31:05,253 DEV : loss 0.2576354146003723 - f1-score (micro avg)  0.9136\n",
      "2022-08-30 21:31:05,272 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:31:05,274 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:31:07,108 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:31:07,109 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 21:31:07,280 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:31:08,730 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:31:08,758 0.9257\t0.9257\t0.9257\t0.9257\n",
      "2022-08-30 21:31:08,759 \n",
      "Results:\n",
      "- F-score (micro) 0.9257\n",
      "- F-score (macro) 0.8667\n",
      "- Accuracy 0.9257\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8996    0.9202    0.9098      1353\n",
      "         ADJ     0.8814    0.9182    0.8994       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9844    0.9844    0.9844       514\n",
      "        VERB     0.8937    0.9176    0.9055       449\n",
      "       PROPN     0.8378    0.7415    0.7867       383\n",
      "         AUX     0.9910    0.9881    0.9895       335\n",
      "       CCONJ     0.9846    1.0000    0.9922       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.8774    0.8447    0.8608       161\n",
      "         ADV     0.8493    0.8212    0.8350       151\n",
      "        PRON     0.9909    0.9478    0.9689       115\n",
      "         NUM     0.9655    0.7887    0.8682        71\n",
      "        PART     0.9444    0.8095    0.8718        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9257      5264\n",
      "   macro avg     0.8809    0.8548    0.8667      5264\n",
      "weighted avg     0.9260    0.9257    0.9254      5264\n",
      "\n",
      "2022-08-30 21:31:08,760 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:31:08,762 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 21:31:09,258 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 21:33:32,800 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:33:32,801 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 21:33:32,802 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:33:32,802 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 21:33:32,803 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:33:32,804 Parameters:\n",
      "2022-08-30 21:33:32,804  - learning_rate: \"0.400333\"\n",
      "2022-08-30 21:33:32,805  - mini_batch_size: \"30\"\n",
      "2022-08-30 21:33:32,805  - patience: \"3\"\n",
      "2022-08-30 21:33:32,806  - anneal_factor: \"0.5\"\n",
      "2022-08-30 21:33:32,806  - max_epochs: \"12\"\n",
      "2022-08-30 21:33:32,807  - shuffle: \"True\"\n",
      "2022-08-30 21:33:32,808  - train_with_dev: \"False\"\n",
      "2022-08-30 21:33:32,808  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 21:33:32,809 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:33:32,809 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 21:33:32,810 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:33:32,810 Device: cpu\n",
      "2022-08-30 21:33:32,811 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:33:32,812 Embeddings storage mode: cpu\n",
      "2022-08-30 21:33:32,812 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:33:36,934 epoch 1 - iter 11/111 - loss 0.35622251 - samples/sec: 80.08 - lr: 0.400333\n",
      "2022-08-30 21:33:41,193 epoch 1 - iter 22/111 - loss 0.38109524 - samples/sec: 78.65 - lr: 0.400333\n",
      "2022-08-30 21:33:44,943 epoch 1 - iter 33/111 - loss 0.38264540 - samples/sec: 89.53 - lr: 0.400333\n",
      "2022-08-30 21:33:50,195 epoch 1 - iter 44/111 - loss 0.38781792 - samples/sec: 63.67 - lr: 0.400333\n",
      "2022-08-30 21:33:54,754 epoch 1 - iter 55/111 - loss 0.39460929 - samples/sec: 73.40 - lr: 0.400333\n",
      "2022-08-30 21:33:58,725 epoch 1 - iter 66/111 - loss 0.39423833 - samples/sec: 84.44 - lr: 0.400333\n",
      "2022-08-30 21:34:02,995 epoch 1 - iter 77/111 - loss 0.40050597 - samples/sec: 78.46 - lr: 0.400333\n",
      "2022-08-30 21:34:06,786 epoch 1 - iter 88/111 - loss 0.40154968 - samples/sec: 88.38 - lr: 0.400333\n",
      "2022-08-30 21:34:10,864 epoch 1 - iter 99/111 - loss 0.40440118 - samples/sec: 82.17 - lr: 0.400333\n",
      "2022-08-30 21:34:15,347 epoch 1 - iter 110/111 - loss 0.42147463 - samples/sec: 74.64 - lr: 0.400333\n",
      "2022-08-30 21:34:15,849 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:34:15,850 EPOCH 1 done: loss 0.4222 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:34:16,757 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:34:16,789 DEV : loss 0.2878090739250183 - f1-score (micro avg)  0.8999\n",
      "2022-08-30 21:34:16,809 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:34:16,810 saving best model\n",
      "2022-08-30 21:34:17,831 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:34:21,777 epoch 2 - iter 11/111 - loss 0.43135104 - samples/sec: 83.68 - lr: 0.400333\n",
      "2022-08-30 21:34:25,880 epoch 2 - iter 22/111 - loss 0.43473769 - samples/sec: 81.77 - lr: 0.400333\n",
      "2022-08-30 21:34:29,937 epoch 2 - iter 33/111 - loss 0.43515470 - samples/sec: 82.58 - lr: 0.400333\n",
      "2022-08-30 21:34:34,287 epoch 2 - iter 44/111 - loss 0.42839645 - samples/sec: 76.91 - lr: 0.400333\n",
      "2022-08-30 21:34:38,517 epoch 2 - iter 55/111 - loss 0.42979676 - samples/sec: 79.14 - lr: 0.400333\n",
      "2022-08-30 21:34:42,799 epoch 2 - iter 66/111 - loss 0.43063086 - samples/sec: 78.25 - lr: 0.400333\n",
      "2022-08-30 21:34:47,167 epoch 2 - iter 77/111 - loss 0.42749296 - samples/sec: 76.60 - lr: 0.400333\n",
      "2022-08-30 21:34:51,522 epoch 2 - iter 88/111 - loss 0.42769772 - samples/sec: 76.91 - lr: 0.400333\n",
      "2022-08-30 21:34:55,877 epoch 2 - iter 99/111 - loss 0.42540967 - samples/sec: 77.32 - lr: 0.400333\n",
      "2022-08-30 21:34:59,869 epoch 2 - iter 110/111 - loss 0.42629970 - samples/sec: 84.03 - lr: 0.400333\n",
      "2022-08-30 21:35:00,205 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:35:00,206 EPOCH 2 done: loss 0.4264 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:35:01,103 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:35:01,131 DEV : loss 0.27322763204574585 - f1-score (micro avg)  0.9069\n",
      "2022-08-30 21:35:01,147 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:35:01,148 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:35:02,084 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:35:06,559 epoch 3 - iter 11/111 - loss 0.40133554 - samples/sec: 73.79 - lr: 0.400333\n",
      "2022-08-30 21:35:10,336 epoch 3 - iter 22/111 - loss 0.40690585 - samples/sec: 88.76 - lr: 0.400333\n",
      "2022-08-30 21:35:14,489 epoch 3 - iter 33/111 - loss 0.41850893 - samples/sec: 81.04 - lr: 0.400333\n",
      "2022-08-30 21:35:19,051 epoch 3 - iter 44/111 - loss 0.41626777 - samples/sec: 73.37 - lr: 0.400333\n",
      "2022-08-30 21:35:23,183 epoch 3 - iter 55/111 - loss 0.41349187 - samples/sec: 81.04 - lr: 0.400333\n",
      "2022-08-30 21:35:27,484 epoch 3 - iter 66/111 - loss 0.41460496 - samples/sec: 77.87 - lr: 0.400333\n",
      "2022-08-30 21:35:31,608 epoch 3 - iter 77/111 - loss 0.41832642 - samples/sec: 81.36 - lr: 0.400333\n",
      "2022-08-30 21:35:35,470 epoch 3 - iter 88/111 - loss 0.41842691 - samples/sec: 87.21 - lr: 0.400333\n",
      "2022-08-30 21:35:39,746 epoch 3 - iter 99/111 - loss 0.42128225 - samples/sec: 78.35 - lr: 0.400333\n",
      "2022-08-30 21:35:43,919 epoch 3 - iter 110/111 - loss 0.42234883 - samples/sec: 80.21 - lr: 0.400333\n",
      "2022-08-30 21:35:44,387 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:35:44,388 EPOCH 3 done: loss 0.4232 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:35:45,393 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:35:45,423 DEV : loss 0.2650187611579895 - f1-score (micro avg)  0.9074\n",
      "2022-08-30 21:35:45,440 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:35:45,441 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:35:46,332 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:35:50,868 epoch 4 - iter 11/111 - loss 0.43009174 - samples/sec: 72.78 - lr: 0.400333\n",
      "2022-08-30 21:35:55,182 epoch 4 - iter 22/111 - loss 0.43066294 - samples/sec: 77.52 - lr: 0.400333\n",
      "2022-08-30 21:35:59,434 epoch 4 - iter 33/111 - loss 0.43064697 - samples/sec: 78.83 - lr: 0.400333\n",
      "2022-08-30 21:36:03,653 epoch 4 - iter 44/111 - loss 0.42366212 - samples/sec: 79.44 - lr: 0.400333\n",
      "2022-08-30 21:36:07,427 epoch 4 - iter 55/111 - loss 0.42644319 - samples/sec: 88.90 - lr: 0.400333\n",
      "2022-08-30 21:36:11,375 epoch 4 - iter 66/111 - loss 0.42896381 - samples/sec: 85.27 - lr: 0.400333\n",
      "2022-08-30 21:36:15,413 epoch 4 - iter 77/111 - loss 0.43275168 - samples/sec: 83.29 - lr: 0.400333\n",
      "2022-08-30 21:36:19,257 epoch 4 - iter 88/111 - loss 0.43252759 - samples/sec: 87.35 - lr: 0.400333\n",
      "2022-08-30 21:36:23,675 epoch 4 - iter 99/111 - loss 0.43152320 - samples/sec: 75.71 - lr: 0.400333\n",
      "2022-08-30 21:36:28,293 epoch 4 - iter 110/111 - loss 0.43198855 - samples/sec: 72.45 - lr: 0.400333\n",
      "2022-08-30 21:36:28,631 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:36:28,631 EPOCH 4 done: loss 0.4327 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:36:29,501 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:36:29,531 DEV : loss 0.26386016607284546 - f1-score (micro avg)  0.9105\n",
      "2022-08-30 21:36:29,550 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:36:29,551 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:36:30,370 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:36:34,797 epoch 5 - iter 11/111 - loss 0.43142134 - samples/sec: 74.56 - lr: 0.400333\n",
      "2022-08-30 21:36:39,076 epoch 5 - iter 22/111 - loss 0.43616598 - samples/sec: 78.48 - lr: 0.400333\n",
      "2022-08-30 21:36:43,317 epoch 5 - iter 33/111 - loss 0.43395835 - samples/sec: 79.02 - lr: 0.400333\n",
      "2022-08-30 21:36:47,348 epoch 5 - iter 44/111 - loss 0.43227998 - samples/sec: 83.27 - lr: 0.400333\n",
      "2022-08-30 21:36:51,362 epoch 5 - iter 55/111 - loss 0.43153437 - samples/sec: 83.99 - lr: 0.400333\n",
      "2022-08-30 21:36:55,405 epoch 5 - iter 66/111 - loss 0.42717648 - samples/sec: 83.10 - lr: 0.400333\n",
      "2022-08-30 21:36:59,951 epoch 5 - iter 77/111 - loss 0.42855642 - samples/sec: 73.99 - lr: 0.400333\n",
      "2022-08-30 21:37:04,229 epoch 5 - iter 88/111 - loss 0.42922896 - samples/sec: 78.57 - lr: 0.400333\n",
      "2022-08-30 21:37:08,459 epoch 5 - iter 99/111 - loss 0.43070559 - samples/sec: 79.19 - lr: 0.400333\n",
      "2022-08-30 21:37:12,858 epoch 5 - iter 110/111 - loss 0.42880465 - samples/sec: 76.53 - lr: 0.400333\n",
      "2022-08-30 21:37:13,284 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:37:13,285 EPOCH 5 done: loss 0.4287 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:37:14,250 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:37:14,279 DEV : loss 0.27027586102485657 - f1-score (micro avg)  0.9079\n",
      "2022-08-30 21:37:14,294 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:37:14,295 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:37:18,316 epoch 6 - iter 11/111 - loss 0.44115073 - samples/sec: 82.11 - lr: 0.400333\n",
      "2022-08-30 21:37:22,399 epoch 6 - iter 22/111 - loss 0.42965698 - samples/sec: 82.23 - lr: 0.400333\n",
      "2022-08-30 21:37:26,683 epoch 6 - iter 33/111 - loss 0.42148962 - samples/sec: 78.67 - lr: 0.400333\n",
      "2022-08-30 21:37:30,772 epoch 6 - iter 44/111 - loss 0.42326851 - samples/sec: 81.85 - lr: 0.400333\n",
      "2022-08-30 21:37:34,838 epoch 6 - iter 55/111 - loss 0.42644718 - samples/sec: 82.40 - lr: 0.400333\n",
      "2022-08-30 21:37:39,057 epoch 6 - iter 66/111 - loss 0.42716244 - samples/sec: 79.29 - lr: 0.400333\n",
      "2022-08-30 21:37:43,470 epoch 6 - iter 77/111 - loss 0.42450351 - samples/sec: 75.84 - lr: 0.400333\n",
      "2022-08-30 21:37:47,755 epoch 6 - iter 88/111 - loss 0.42762588 - samples/sec: 78.38 - lr: 0.400333\n",
      "2022-08-30 21:37:51,938 epoch 6 - iter 99/111 - loss 0.43085455 - samples/sec: 79.96 - lr: 0.400333\n",
      "2022-08-30 21:37:55,979 epoch 6 - iter 110/111 - loss 0.42761529 - samples/sec: 83.02 - lr: 0.400333\n",
      "2022-08-30 21:37:56,319 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:37:56,320 EPOCH 6 done: loss 0.4279 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:37:57,265 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:37:57,294 DEV : loss 0.26616474986076355 - f1-score (micro avg)  0.9085\n",
      "2022-08-30 21:37:57,310 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 21:37:57,311 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:38:01,487 epoch 7 - iter 11/111 - loss 0.42331960 - samples/sec: 79.06 - lr: 0.400333\n",
      "2022-08-30 21:38:06,112 epoch 7 - iter 22/111 - loss 0.42850044 - samples/sec: 72.42 - lr: 0.400333\n",
      "2022-08-30 21:38:10,539 epoch 7 - iter 33/111 - loss 0.42653952 - samples/sec: 75.67 - lr: 0.400333\n",
      "2022-08-30 21:38:14,651 epoch 7 - iter 44/111 - loss 0.43107634 - samples/sec: 81.76 - lr: 0.400333\n",
      "2022-08-30 21:38:19,039 epoch 7 - iter 55/111 - loss 0.43337101 - samples/sec: 76.35 - lr: 0.400333\n",
      "2022-08-30 21:38:23,087 epoch 7 - iter 66/111 - loss 0.43321417 - samples/sec: 82.91 - lr: 0.400333\n",
      "2022-08-30 21:38:27,312 epoch 7 - iter 77/111 - loss 0.43255913 - samples/sec: 79.25 - lr: 0.400333\n",
      "2022-08-30 21:38:31,423 epoch 7 - iter 88/111 - loss 0.43209029 - samples/sec: 81.58 - lr: 0.400333\n",
      "2022-08-30 21:38:35,620 epoch 7 - iter 99/111 - loss 0.43101295 - samples/sec: 79.90 - lr: 0.400333\n",
      "2022-08-30 21:38:40,086 epoch 7 - iter 110/111 - loss 0.42872205 - samples/sec: 75.00 - lr: 0.400333\n",
      "2022-08-30 21:38:40,577 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:38:40,578 EPOCH 7 done: loss 0.4284 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:38:41,594 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:38:41,627 DEV : loss 0.2799345552921295 - f1-score (micro avg)  0.9092\n",
      "2022-08-30 21:38:41,645 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:38:41,647 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:38:45,927 epoch 8 - iter 11/111 - loss 0.43147097 - samples/sec: 77.14 - lr: 0.400333\n",
      "2022-08-30 21:38:49,984 epoch 8 - iter 22/111 - loss 0.42162537 - samples/sec: 82.67 - lr: 0.400333\n",
      "2022-08-30 21:38:54,400 epoch 8 - iter 33/111 - loss 0.42457919 - samples/sec: 75.88 - lr: 0.400333\n",
      "2022-08-30 21:38:58,431 epoch 8 - iter 44/111 - loss 0.42949688 - samples/sec: 83.17 - lr: 0.400333\n",
      "2022-08-30 21:39:02,802 epoch 8 - iter 55/111 - loss 0.42967483 - samples/sec: 76.62 - lr: 0.400333\n",
      "2022-08-30 21:39:06,739 epoch 8 - iter 66/111 - loss 0.42772949 - samples/sec: 85.05 - lr: 0.400333\n",
      "2022-08-30 21:39:10,622 epoch 8 - iter 77/111 - loss 0.42704143 - samples/sec: 86.21 - lr: 0.400333\n",
      "2022-08-30 21:39:14,979 epoch 8 - iter 88/111 - loss 0.42887365 - samples/sec: 76.98 - lr: 0.400333\n",
      "2022-08-30 21:39:19,045 epoch 8 - iter 99/111 - loss 0.42864231 - samples/sec: 82.31 - lr: 0.400333\n",
      "2022-08-30 21:39:22,909 epoch 8 - iter 110/111 - loss 0.42805907 - samples/sec: 86.93 - lr: 0.400333\n",
      "2022-08-30 21:39:23,253 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:39:23,254 EPOCH 8 done: loss 0.4280 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:39:24,193 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:39:24,221 DEV : loss 0.26860466599464417 - f1-score (micro avg)  0.9136\n",
      "2022-08-30 21:39:24,239 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:39:24,240 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:39:25,139 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:39:29,126 epoch 9 - iter 11/111 - loss 0.43869167 - samples/sec: 82.79 - lr: 0.400333\n",
      "2022-08-30 21:39:33,146 epoch 9 - iter 22/111 - loss 0.43736110 - samples/sec: 83.38 - lr: 0.400333\n",
      "2022-08-30 21:39:37,417 epoch 9 - iter 33/111 - loss 0.43945686 - samples/sec: 78.24 - lr: 0.400333\n",
      "2022-08-30 21:39:41,696 epoch 9 - iter 44/111 - loss 0.43793206 - samples/sec: 78.87 - lr: 0.400333\n",
      "2022-08-30 21:39:45,884 epoch 9 - iter 55/111 - loss 0.43565894 - samples/sec: 80.12 - lr: 0.400333\n",
      "2022-08-30 21:39:50,306 epoch 9 - iter 66/111 - loss 0.43328696 - samples/sec: 75.64 - lr: 0.400333\n",
      "2022-08-30 21:39:54,793 epoch 9 - iter 77/111 - loss 0.43382994 - samples/sec: 74.73 - lr: 0.400333\n",
      "2022-08-30 21:39:58,896 epoch 9 - iter 88/111 - loss 0.43271251 - samples/sec: 81.58 - lr: 0.400333\n",
      "2022-08-30 21:40:03,205 epoch 9 - iter 99/111 - loss 0.43142888 - samples/sec: 77.67 - lr: 0.400333\n",
      "2022-08-30 21:40:07,477 epoch 9 - iter 110/111 - loss 0.43290003 - samples/sec: 78.29 - lr: 0.400333\n",
      "2022-08-30 21:40:07,882 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:40:07,883 EPOCH 9 done: loss 0.4329 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:40:08,783 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:40:08,814 DEV : loss 0.2566159963607788 - f1-score (micro avg)  0.9111\n",
      "2022-08-30 21:40:08,829 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:40:08,830 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:40:13,113 epoch 10 - iter 11/111 - loss 0.43060862 - samples/sec: 77.08 - lr: 0.400333\n",
      "2022-08-30 21:40:17,482 epoch 10 - iter 22/111 - loss 0.42360716 - samples/sec: 76.69 - lr: 0.400333\n",
      "2022-08-30 21:40:21,728 epoch 10 - iter 33/111 - loss 0.42601211 - samples/sec: 78.91 - lr: 0.400333\n",
      "2022-08-30 21:40:26,062 epoch 10 - iter 44/111 - loss 0.42858217 - samples/sec: 77.28 - lr: 0.400333\n",
      "2022-08-30 21:40:30,562 epoch 10 - iter 55/111 - loss 0.42312830 - samples/sec: 74.27 - lr: 0.400333\n",
      "2022-08-30 21:40:34,684 epoch 10 - iter 66/111 - loss 0.42420622 - samples/sec: 81.34 - lr: 0.400333\n",
      "2022-08-30 21:40:38,552 epoch 10 - iter 77/111 - loss 0.42415142 - samples/sec: 86.61 - lr: 0.400333\n",
      "2022-08-30 21:40:42,889 epoch 10 - iter 88/111 - loss 0.42769105 - samples/sec: 77.23 - lr: 0.400333\n",
      "2022-08-30 21:40:46,921 epoch 10 - iter 99/111 - loss 0.42858743 - samples/sec: 83.04 - lr: 0.400333\n",
      "2022-08-30 21:40:51,335 epoch 10 - iter 110/111 - loss 0.42976295 - samples/sec: 75.88 - lr: 0.400333\n",
      "2022-08-30 21:40:51,820 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:40:51,821 EPOCH 10 done: loss 0.4300 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:40:52,752 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:40:52,782 DEV : loss 0.2762555181980133 - f1-score (micro avg)  0.9051\n",
      "2022-08-30 21:40:52,798 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 21:40:52,799 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:40:56,609 epoch 11 - iter 11/111 - loss 0.44205955 - samples/sec: 86.68 - lr: 0.400333\n",
      "2022-08-30 21:41:00,830 epoch 11 - iter 22/111 - loss 0.43555677 - samples/sec: 79.35 - lr: 0.400333\n",
      "2022-08-30 21:41:04,731 epoch 11 - iter 33/111 - loss 0.43795766 - samples/sec: 85.87 - lr: 0.400333\n",
      "2022-08-30 21:41:08,821 epoch 11 - iter 44/111 - loss 0.43695145 - samples/sec: 81.95 - lr: 0.400333\n",
      "2022-08-30 21:41:13,038 epoch 11 - iter 55/111 - loss 0.43358165 - samples/sec: 79.31 - lr: 0.400333\n",
      "2022-08-30 21:41:17,399 epoch 11 - iter 66/111 - loss 0.43183972 - samples/sec: 76.64 - lr: 0.400333\n",
      "2022-08-30 21:41:21,742 epoch 11 - iter 77/111 - loss 0.43044626 - samples/sec: 77.37 - lr: 0.400333\n",
      "2022-08-30 21:41:25,974 epoch 11 - iter 88/111 - loss 0.42912763 - samples/sec: 79.29 - lr: 0.400333\n",
      "2022-08-30 21:41:29,944 epoch 11 - iter 99/111 - loss 0.42925426 - samples/sec: 84.40 - lr: 0.400333\n",
      "2022-08-30 21:41:34,213 epoch 11 - iter 110/111 - loss 0.42852897 - samples/sec: 78.40 - lr: 0.400333\n",
      "2022-08-30 21:41:34,555 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:41:34,556 EPOCH 11 done: loss 0.4289 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:41:35,523 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:41:35,560 DEV : loss 0.2628836929798126 - f1-score (micro avg)  0.9144\n",
      "2022-08-30 21:41:35,580 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:41:35,581 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:41:36,298 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:41:40,289 epoch 12 - iter 11/111 - loss 0.41526119 - samples/sec: 82.73 - lr: 0.400333\n",
      "2022-08-30 21:41:44,646 epoch 12 - iter 22/111 - loss 0.42980071 - samples/sec: 76.89 - lr: 0.400333\n",
      "2022-08-30 21:41:48,833 epoch 12 - iter 33/111 - loss 0.42780144 - samples/sec: 80.02 - lr: 0.400333\n",
      "2022-08-30 21:41:53,033 epoch 12 - iter 44/111 - loss 0.42371753 - samples/sec: 79.94 - lr: 0.400333\n",
      "2022-08-30 21:41:57,479 epoch 12 - iter 55/111 - loss 0.42327077 - samples/sec: 75.26 - lr: 0.400333\n",
      "2022-08-30 21:42:01,594 epoch 12 - iter 66/111 - loss 0.42363494 - samples/sec: 81.40 - lr: 0.400333\n",
      "2022-08-30 21:42:05,737 epoch 12 - iter 77/111 - loss 0.42220691 - samples/sec: 81.30 - lr: 0.400333\n",
      "2022-08-30 21:42:09,728 epoch 12 - iter 88/111 - loss 0.42053503 - samples/sec: 83.86 - lr: 0.400333\n",
      "2022-08-30 21:42:13,913 epoch 12 - iter 99/111 - loss 0.42276759 - samples/sec: 79.98 - lr: 0.400333\n",
      "2022-08-30 21:42:18,210 epoch 12 - iter 110/111 - loss 0.42160378 - samples/sec: 77.89 - lr: 0.400333\n",
      "2022-08-30 21:42:18,672 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:42:18,673 EPOCH 12 done: loss 0.4209 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:42:19,574 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:42:19,605 DEV : loss 0.26655250787734985 - f1-score (micro avg)  0.9071\n",
      "2022-08-30 21:42:19,621 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:42:20,317 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:42:20,318 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 21:42:20,506 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:42:21,938 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:42:21,963 0.9181\t0.9181\t0.9181\t0.9181\n",
      "2022-08-30 21:42:21,963 \n",
      "Results:\n",
      "- F-score (micro) 0.9181\n",
      "- F-score (macro) 0.7968\n",
      "- Accuracy 0.9181\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8809    0.9239    0.9019      1353\n",
      "         ADJ     0.8755    0.8899    0.8827       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9902    0.9825    0.9863       514\n",
      "        VERB     0.8810    0.9065    0.8935       449\n",
      "       PROPN     0.8481    0.6997    0.7668       383\n",
      "         AUX     0.9881    0.9881    0.9881       335\n",
      "       CCONJ     0.9846    1.0000    0.9922       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.8571    0.8571    0.8571       161\n",
      "         ADV     0.8212    0.8212    0.8212       151\n",
      "        PRON     1.0000    0.9304    0.9640       115\n",
      "         NUM     0.9298    0.7465    0.8281        71\n",
      "        PART     0.9444    0.8095    0.8718        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9181      5264\n",
      "   macro avg     0.8122    0.7844    0.7968      5264\n",
      "weighted avg     0.9186    0.9181    0.9175      5264\n",
      "\n",
      "2022-08-30 21:42:21,964 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:42:21,966 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 21:42:22,473 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 21:44:47,207 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:44:47,208 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 21:44:47,208 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:44:47,209 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 21:44:47,210 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:44:47,210 Parameters:\n",
      "2022-08-30 21:44:47,211  - learning_rate: \"0.400333\"\n",
      "2022-08-30 21:44:47,211  - mini_batch_size: \"50\"\n",
      "2022-08-30 21:44:47,212  - patience: \"3\"\n",
      "2022-08-30 21:44:47,212  - anneal_factor: \"0.5\"\n",
      "2022-08-30 21:44:47,213  - max_epochs: \"10\"\n",
      "2022-08-30 21:44:47,213  - shuffle: \"True\"\n",
      "2022-08-30 21:44:47,214  - train_with_dev: \"False\"\n",
      "2022-08-30 21:44:47,215  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 21:44:47,215 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:44:47,216 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 21:44:47,216 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:44:47,217 Device: cpu\n",
      "2022-08-30 21:44:47,218 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:44:47,218 Embeddings storage mode: cpu\n",
      "2022-08-30 21:44:47,219 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:44:50,071 epoch 1 - iter 6/67 - loss 0.37264849 - samples/sec: 105.26 - lr: 0.400333\n",
      "2022-08-30 21:44:53,453 epoch 1 - iter 12/67 - loss 0.39086435 - samples/sec: 90.47 - lr: 0.400333\n",
      "2022-08-30 21:44:56,347 epoch 1 - iter 18/67 - loss 0.39536589 - samples/sec: 105.86 - lr: 0.400333\n",
      "2022-08-30 21:44:59,125 epoch 1 - iter 24/67 - loss 0.39780078 - samples/sec: 110.62 - lr: 0.400333\n",
      "2022-08-30 21:45:02,234 epoch 1 - iter 30/67 - loss 0.40012657 - samples/sec: 98.55 - lr: 0.400333\n",
      "2022-08-30 21:45:05,333 epoch 1 - iter 36/67 - loss 0.39878760 - samples/sec: 98.55 - lr: 0.400333\n",
      "2022-08-30 21:45:08,393 epoch 1 - iter 42/67 - loss 0.39983057 - samples/sec: 100.23 - lr: 0.400333\n",
      "2022-08-30 21:45:11,243 epoch 1 - iter 48/67 - loss 0.40033017 - samples/sec: 108.23 - lr: 0.400333\n",
      "2022-08-30 21:45:14,039 epoch 1 - iter 54/67 - loss 0.40063242 - samples/sec: 109.41 - lr: 0.400333\n",
      "2022-08-30 21:45:17,288 epoch 1 - iter 60/67 - loss 0.40406794 - samples/sec: 94.10 - lr: 0.400333\n",
      "2022-08-30 21:45:20,740 epoch 1 - iter 66/67 - loss 0.41582572 - samples/sec: 88.29 - lr: 0.400333\n",
      "2022-08-30 21:45:21,182 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:45:21,183 EPOCH 1 done: loss 0.4165 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:45:22,029 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:45:22,056 DEV : loss 0.2742806375026703 - f1-score (micro avg)  0.9063\n",
      "2022-08-30 21:45:22,073 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:45:22,074 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:45:22,911 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:45:25,897 epoch 2 - iter 6/67 - loss 0.40741247 - samples/sec: 100.50 - lr: 0.400333\n",
      "2022-08-30 21:45:28,896 epoch 2 - iter 12/67 - loss 0.41422803 - samples/sec: 101.97 - lr: 0.400333\n",
      "2022-08-30 21:45:31,824 epoch 2 - iter 18/67 - loss 0.41103347 - samples/sec: 104.75 - lr: 0.400333\n",
      "2022-08-30 21:45:34,975 epoch 2 - iter 24/67 - loss 0.41307448 - samples/sec: 96.96 - lr: 0.400333\n",
      "2022-08-30 21:45:38,283 epoch 2 - iter 30/67 - loss 0.41039338 - samples/sec: 92.39 - lr: 0.400333\n",
      "2022-08-30 21:45:41,618 epoch 2 - iter 36/67 - loss 0.40771046 - samples/sec: 91.55 - lr: 0.400333\n",
      "2022-08-30 21:45:44,935 epoch 2 - iter 42/67 - loss 0.40462680 - samples/sec: 92.08 - lr: 0.400333\n",
      "2022-08-30 21:45:48,054 epoch 2 - iter 48/67 - loss 0.40613419 - samples/sec: 97.94 - lr: 0.400333\n",
      "2022-08-30 21:45:50,915 epoch 2 - iter 54/67 - loss 0.40784014 - samples/sec: 107.10 - lr: 0.400333\n",
      "2022-08-30 21:45:53,798 epoch 2 - iter 60/67 - loss 0.41219972 - samples/sec: 106.38 - lr: 0.400333\n",
      "2022-08-30 21:45:56,877 epoch 2 - iter 66/67 - loss 0.41535715 - samples/sec: 99.27 - lr: 0.400333\n",
      "2022-08-30 21:45:57,329 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:45:57,330 EPOCH 2 done: loss 0.4147 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:45:58,218 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:45:58,248 DEV : loss 0.27114981412887573 - f1-score (micro avg)  0.9074\n",
      "2022-08-30 21:45:58,263 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:45:58,264 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:45:59,027 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:46:02,257 epoch 3 - iter 6/67 - loss 0.40437689 - samples/sec: 92.91 - lr: 0.400333\n",
      "2022-08-30 21:46:05,263 epoch 3 - iter 12/67 - loss 0.40768841 - samples/sec: 101.83 - lr: 0.400333\n",
      "2022-08-30 21:46:08,496 epoch 3 - iter 18/67 - loss 0.40669147 - samples/sec: 94.49 - lr: 0.400333\n",
      "2022-08-30 21:46:11,495 epoch 3 - iter 24/67 - loss 0.40801910 - samples/sec: 102.81 - lr: 0.400333\n",
      "2022-08-30 21:46:14,270 epoch 3 - iter 30/67 - loss 0.40866368 - samples/sec: 111.36 - lr: 0.400333\n",
      "2022-08-30 21:46:17,694 epoch 3 - iter 36/67 - loss 0.40912193 - samples/sec: 89.21 - lr: 0.400333\n",
      "2022-08-30 21:46:20,893 epoch 3 - iter 42/67 - loss 0.41004432 - samples/sec: 95.75 - lr: 0.400333\n",
      "2022-08-30 21:46:23,815 epoch 3 - iter 48/67 - loss 0.40972707 - samples/sec: 104.79 - lr: 0.400333\n",
      "2022-08-30 21:46:26,769 epoch 3 - iter 54/67 - loss 0.40767261 - samples/sec: 103.45 - lr: 0.400333\n",
      "2022-08-30 21:46:29,690 epoch 3 - iter 60/67 - loss 0.40740247 - samples/sec: 104.86 - lr: 0.400333\n",
      "2022-08-30 21:46:33,206 epoch 3 - iter 66/67 - loss 0.40712865 - samples/sec: 86.83 - lr: 0.400333\n",
      "2022-08-30 21:46:33,698 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:46:33,699 EPOCH 3 done: loss 0.4071 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:46:34,579 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:46:34,614 DEV : loss 0.25870388746261597 - f1-score (micro avg)  0.9129\n",
      "2022-08-30 21:46:34,635 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:46:34,636 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:46:35,473 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:46:38,223 epoch 4 - iter 6/67 - loss 0.41258354 - samples/sec: 109.25 - lr: 0.400333\n",
      "2022-08-30 21:46:41,458 epoch 4 - iter 12/67 - loss 0.41055081 - samples/sec: 94.37 - lr: 0.400333\n",
      "2022-08-30 21:46:44,323 epoch 4 - iter 18/67 - loss 0.40703943 - samples/sec: 107.72 - lr: 0.400333\n",
      "2022-08-30 21:46:47,486 epoch 4 - iter 24/67 - loss 0.40567106 - samples/sec: 96.71 - lr: 0.400333\n",
      "2022-08-30 21:46:50,369 epoch 4 - iter 30/67 - loss 0.40311573 - samples/sec: 106.72 - lr: 0.400333\n",
      "2022-08-30 21:46:53,306 epoch 4 - iter 36/67 - loss 0.40343752 - samples/sec: 105.71 - lr: 0.400333\n",
      "2022-08-30 21:46:56,294 epoch 4 - iter 42/67 - loss 0.40556470 - samples/sec: 102.63 - lr: 0.400333\n",
      "2022-08-30 21:46:59,658 epoch 4 - iter 48/67 - loss 0.40549800 - samples/sec: 90.69 - lr: 0.400333\n",
      "2022-08-30 21:47:02,949 epoch 4 - iter 54/67 - loss 0.40373587 - samples/sec: 92.82 - lr: 0.400333\n",
      "2022-08-30 21:47:06,483 epoch 4 - iter 60/67 - loss 0.40604795 - samples/sec: 86.43 - lr: 0.400333\n",
      "2022-08-30 21:47:09,414 epoch 4 - iter 66/67 - loss 0.40543029 - samples/sec: 104.82 - lr: 0.400333\n",
      "2022-08-30 21:47:09,897 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:47:09,898 EPOCH 4 done: loss 0.4055 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:47:10,752 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:47:10,780 DEV : loss 0.2694484293460846 - f1-score (micro avg)  0.91\n",
      "2022-08-30 21:47:10,801 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:47:10,802 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:47:13,985 epoch 5 - iter 6/67 - loss 0.41253921 - samples/sec: 94.28 - lr: 0.400333\n",
      "2022-08-30 21:47:16,800 epoch 5 - iter 12/67 - loss 0.40478175 - samples/sec: 108.85 - lr: 0.400333\n",
      "2022-08-30 21:47:20,190 epoch 5 - iter 18/67 - loss 0.40455948 - samples/sec: 89.93 - lr: 0.400333\n",
      "2022-08-30 21:47:23,226 epoch 5 - iter 24/67 - loss 0.40604645 - samples/sec: 100.67 - lr: 0.400333\n",
      "2022-08-30 21:47:26,279 epoch 5 - iter 30/67 - loss 0.40344771 - samples/sec: 100.10 - lr: 0.400333\n",
      "2022-08-30 21:47:29,277 epoch 5 - iter 36/67 - loss 0.40255794 - samples/sec: 102.04 - lr: 0.400333\n",
      "2022-08-30 21:47:32,278 epoch 5 - iter 42/67 - loss 0.39933210 - samples/sec: 101.97 - lr: 0.400333\n",
      "2022-08-30 21:47:35,536 epoch 5 - iter 48/67 - loss 0.39968991 - samples/sec: 93.69 - lr: 0.400333\n",
      "2022-08-30 21:47:38,754 epoch 5 - iter 54/67 - loss 0.40032853 - samples/sec: 95.27 - lr: 0.400333\n",
      "2022-08-30 21:47:41,920 epoch 5 - iter 60/67 - loss 0.40039921 - samples/sec: 96.68 - lr: 0.400333\n",
      "2022-08-30 21:47:45,271 epoch 5 - iter 66/67 - loss 0.40129270 - samples/sec: 91.24 - lr: 0.400333\n",
      "2022-08-30 21:47:45,730 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:47:45,730 EPOCH 5 done: loss 0.4018 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:47:47,883 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:47:47,911 DEV : loss 0.2554589807987213 - f1-score (micro avg)  0.9121\n",
      "2022-08-30 21:47:47,930 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 21:47:47,931 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:47:51,300 epoch 6 - iter 6/67 - loss 0.39387977 - samples/sec: 89.13 - lr: 0.400333\n",
      "2022-08-30 21:47:54,504 epoch 6 - iter 12/67 - loss 0.39396890 - samples/sec: 95.42 - lr: 0.400333\n",
      "2022-08-30 21:47:57,789 epoch 6 - iter 18/67 - loss 0.39971513 - samples/sec: 93.49 - lr: 0.400333\n",
      "2022-08-30 21:48:00,916 epoch 6 - iter 24/67 - loss 0.39941544 - samples/sec: 97.82 - lr: 0.400333\n",
      "2022-08-30 21:48:04,332 epoch 6 - iter 30/67 - loss 0.40086177 - samples/sec: 89.37 - lr: 0.400333\n",
      "2022-08-30 21:48:07,581 epoch 6 - iter 36/67 - loss 0.40326500 - samples/sec: 94.94 - lr: 0.400333\n",
      "2022-08-30 21:48:11,333 epoch 6 - iter 42/67 - loss 0.40347784 - samples/sec: 81.74 - lr: 0.400333\n",
      "2022-08-30 21:48:14,579 epoch 6 - iter 48/67 - loss 0.40298745 - samples/sec: 95.30 - lr: 0.400333\n",
      "2022-08-30 21:48:17,854 epoch 6 - iter 54/67 - loss 0.40542641 - samples/sec: 93.43 - lr: 0.400333\n",
      "2022-08-30 21:48:20,825 epoch 6 - iter 60/67 - loss 0.40645085 - samples/sec: 103.27 - lr: 0.400333\n",
      "2022-08-30 21:48:24,104 epoch 6 - iter 66/67 - loss 0.40524204 - samples/sec: 93.28 - lr: 0.400333\n",
      "2022-08-30 21:48:24,524 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:48:24,525 EPOCH 6 done: loss 0.4056 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:48:25,424 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:48:25,455 DEV : loss 0.2582903206348419 - f1-score (micro avg)  0.9102\n",
      "2022-08-30 21:48:25,474 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 21:48:25,475 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:48:28,829 epoch 7 - iter 6/67 - loss 0.42160461 - samples/sec: 89.50 - lr: 0.400333\n",
      "2022-08-30 21:48:32,089 epoch 7 - iter 12/67 - loss 0.40847408 - samples/sec: 93.96 - lr: 0.400333\n",
      "2022-08-30 21:48:35,330 epoch 7 - iter 18/67 - loss 0.40723312 - samples/sec: 94.55 - lr: 0.400333\n",
      "2022-08-30 21:48:38,594 epoch 7 - iter 24/67 - loss 0.40471986 - samples/sec: 93.78 - lr: 0.400333\n",
      "2022-08-30 21:48:41,996 epoch 7 - iter 30/67 - loss 0.40737740 - samples/sec: 90.28 - lr: 0.400333\n",
      "2022-08-30 21:48:45,091 epoch 7 - iter 36/67 - loss 0.40607211 - samples/sec: 98.75 - lr: 0.400333\n",
      "2022-08-30 21:48:47,960 epoch 7 - iter 42/67 - loss 0.40497505 - samples/sec: 106.88 - lr: 0.400333\n",
      "2022-08-30 21:48:51,225 epoch 7 - iter 48/67 - loss 0.40539959 - samples/sec: 93.60 - lr: 0.400333\n",
      "2022-08-30 21:48:54,329 epoch 7 - iter 54/67 - loss 0.40562309 - samples/sec: 98.85 - lr: 0.400333\n",
      "2022-08-30 21:48:57,183 epoch 7 - iter 60/67 - loss 0.40479215 - samples/sec: 108.34 - lr: 0.400333\n",
      "2022-08-30 21:49:00,300 epoch 7 - iter 66/67 - loss 0.40422754 - samples/sec: 98.01 - lr: 0.400333\n",
      "2022-08-30 21:49:00,748 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:49:00,749 EPOCH 7 done: loss 0.4039 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:49:01,668 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:49:01,703 DEV : loss 0.260214239358902 - f1-score (micro avg)  0.9115\n",
      "2022-08-30 21:49:01,723 Epoch     7: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 21:49:01,724 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 21:49:01,725 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:49:04,752 epoch 8 - iter 6/67 - loss 0.38810419 - samples/sec: 99.17 - lr: 0.200167\n",
      "2022-08-30 21:49:07,873 epoch 8 - iter 12/67 - loss 0.38044132 - samples/sec: 98.17 - lr: 0.200167\n",
      "2022-08-30 21:49:10,936 epoch 8 - iter 18/67 - loss 0.38076211 - samples/sec: 99.87 - lr: 0.200167\n",
      "2022-08-30 21:49:14,064 epoch 8 - iter 24/67 - loss 0.38164046 - samples/sec: 97.75 - lr: 0.200167\n",
      "2022-08-30 21:49:17,804 epoch 8 - iter 30/67 - loss 0.38171809 - samples/sec: 81.59 - lr: 0.200167\n",
      "2022-08-30 21:49:20,990 epoch 8 - iter 36/67 - loss 0.37906879 - samples/sec: 96.18 - lr: 0.200167\n",
      "2022-08-30 21:49:23,813 epoch 8 - iter 42/67 - loss 0.37808512 - samples/sec: 108.93 - lr: 0.200167\n",
      "2022-08-30 21:49:27,006 epoch 8 - iter 48/67 - loss 0.38015422 - samples/sec: 95.88 - lr: 0.200167\n",
      "2022-08-30 21:49:30,603 epoch 8 - iter 54/67 - loss 0.37919454 - samples/sec: 84.96 - lr: 0.200167\n",
      "2022-08-30 21:49:33,493 epoch 8 - iter 60/67 - loss 0.37683177 - samples/sec: 106.08 - lr: 0.200167\n",
      "2022-08-30 21:49:36,580 epoch 8 - iter 66/67 - loss 0.37848143 - samples/sec: 99.37 - lr: 0.200167\n",
      "2022-08-30 21:49:37,009 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:49:37,010 EPOCH 8 done: loss 0.3784 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:49:37,870 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:49:37,900 DEV : loss 0.24360553920269012 - f1-score (micro avg)  0.9121\n",
      "2022-08-30 21:49:37,915 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:49:37,916 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:49:40,870 epoch 9 - iter 6/67 - loss 0.37187804 - samples/sec: 101.59 - lr: 0.200167\n",
      "2022-08-30 21:49:43,850 epoch 9 - iter 12/67 - loss 0.36642345 - samples/sec: 102.70 - lr: 0.200167\n",
      "2022-08-30 21:49:46,938 epoch 9 - iter 18/67 - loss 0.36596033 - samples/sec: 100.44 - lr: 0.200167\n",
      "2022-08-30 21:49:50,081 epoch 9 - iter 24/67 - loss 0.36597372 - samples/sec: 97.37 - lr: 0.200167\n",
      "2022-08-30 21:49:53,128 epoch 9 - iter 30/67 - loss 0.36754167 - samples/sec: 100.57 - lr: 0.200167\n",
      "2022-08-30 21:49:56,236 epoch 9 - iter 36/67 - loss 0.36774121 - samples/sec: 98.55 - lr: 0.200167\n",
      "2022-08-30 21:49:59,975 epoch 9 - iter 42/67 - loss 0.36788739 - samples/sec: 81.52 - lr: 0.200167\n",
      "2022-08-30 21:50:03,467 epoch 9 - iter 48/67 - loss 0.36939008 - samples/sec: 87.51 - lr: 0.200167\n",
      "2022-08-30 21:50:06,744 epoch 9 - iter 54/67 - loss 0.36934139 - samples/sec: 93.55 - lr: 0.200167\n",
      "2022-08-30 21:50:09,922 epoch 9 - iter 60/67 - loss 0.36868693 - samples/sec: 96.53 - lr: 0.200167\n",
      "2022-08-30 21:50:12,958 epoch 9 - iter 66/67 - loss 0.36847375 - samples/sec: 100.91 - lr: 0.200167\n",
      "2022-08-30 21:50:13,280 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:50:13,281 EPOCH 9 done: loss 0.3689 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:50:14,167 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:50:14,203 DEV : loss 0.2487429678440094 - f1-score (micro avg)  0.9144\n",
      "2022-08-30 21:50:14,223 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:50:14,224 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:50:15,467 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:50:18,814 epoch 10 - iter 6/67 - loss 0.35317158 - samples/sec: 89.66 - lr: 0.200167\n",
      "2022-08-30 21:50:22,116 epoch 10 - iter 12/67 - loss 0.37160505 - samples/sec: 92.79 - lr: 0.200167\n",
      "2022-08-30 21:50:25,207 epoch 10 - iter 18/67 - loss 0.37141126 - samples/sec: 99.30 - lr: 0.200167\n",
      "2022-08-30 21:50:28,625 epoch 10 - iter 24/67 - loss 0.36672770 - samples/sec: 89.55 - lr: 0.200167\n",
      "2022-08-30 21:50:31,972 epoch 10 - iter 30/67 - loss 0.36762571 - samples/sec: 91.32 - lr: 0.200167\n",
      "2022-08-30 21:50:34,931 epoch 10 - iter 36/67 - loss 0.36641029 - samples/sec: 103.48 - lr: 0.200167\n",
      "2022-08-30 21:50:37,932 epoch 10 - iter 42/67 - loss 0.36790046 - samples/sec: 101.90 - lr: 0.200167\n",
      "2022-08-30 21:50:40,943 epoch 10 - iter 48/67 - loss 0.37005979 - samples/sec: 101.63 - lr: 0.200167\n",
      "2022-08-30 21:50:44,038 epoch 10 - iter 54/67 - loss 0.36745988 - samples/sec: 98.98 - lr: 0.200167\n",
      "2022-08-30 21:50:46,991 epoch 10 - iter 60/67 - loss 0.36697971 - samples/sec: 103.70 - lr: 0.200167\n",
      "2022-08-30 21:50:49,798 epoch 10 - iter 66/67 - loss 0.36816172 - samples/sec: 109.09 - lr: 0.200167\n",
      "2022-08-30 21:50:50,114 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:50:50,115 EPOCH 10 done: loss 0.3683 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:50:51,040 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:50:51,073 DEV : loss 0.2465985268354416 - f1-score (micro avg)  0.915\n",
      "2022-08-30 21:50:51,091 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:50:51,092 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:50:52,747 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:50:52,748 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 21:50:52,927 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:50:54,313 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:50:54,337 0.9261\t0.9261\t0.9261\t0.9261\n",
      "2022-08-30 21:50:54,338 \n",
      "Results:\n",
      "- F-score (micro) 0.9261\n",
      "- F-score (macro) 0.87\n",
      "- Accuracy 0.9261\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8950    0.9194    0.9070      1353\n",
      "         ADJ     0.8816    0.9196    0.9002       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9883    0.9883    0.9883       514\n",
      "        VERB     0.9182    0.8998    0.9089       449\n",
      "       PROPN     0.8319    0.7363    0.7812       383\n",
      "         AUX     0.9852    0.9910    0.9881       335\n",
      "       CCONJ     0.9846    1.0000    0.9922       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.8782    0.8509    0.8644       161\n",
      "         ADV     0.8397    0.8675    0.8534       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9661    0.8028    0.8769        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9261      5264\n",
      "   macro avg     0.8849    0.8580    0.8700      5264\n",
      "weighted avg     0.9265    0.9261    0.9258      5264\n",
      "\n",
      "2022-08-30 21:50:54,338 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:50:54,340 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:50:54,832 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 21:53:26,753 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:53:26,754 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 21:53:26,754 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:53:26,755 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 21:53:26,756 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:53:26,757 Parameters:\n",
      "2022-08-30 21:53:26,757  - learning_rate: \"0.400333\"\n",
      "2022-08-30 21:53:26,758  - mini_batch_size: \"50\"\n",
      "2022-08-30 21:53:26,758  - patience: \"3\"\n",
      "2022-08-30 21:53:26,759  - anneal_factor: \"0.5\"\n",
      "2022-08-30 21:53:26,760  - max_epochs: \"11\"\n",
      "2022-08-30 21:53:26,760  - shuffle: \"True\"\n",
      "2022-08-30 21:53:26,762  - train_with_dev: \"False\"\n",
      "2022-08-30 21:53:26,762  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 21:53:26,763 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:53:26,764 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 21:53:26,764 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:53:26,766 Device: cpu\n",
      "2022-08-30 21:53:26,767 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:53:26,767 Embeddings storage mode: cpu\n",
      "2022-08-30 21:53:26,768 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:53:29,894 epoch 1 - iter 6/67 - loss 0.35067843 - samples/sec: 96.03 - lr: 0.400333\n",
      "2022-08-30 21:53:33,218 epoch 1 - iter 12/67 - loss 0.36821131 - samples/sec: 92.01 - lr: 0.400333\n",
      "2022-08-30 21:53:36,370 epoch 1 - iter 18/67 - loss 0.37286011 - samples/sec: 97.01 - lr: 0.400333\n",
      "2022-08-30 21:53:39,432 epoch 1 - iter 24/67 - loss 0.37421312 - samples/sec: 100.63 - lr: 0.400333\n",
      "2022-08-30 21:53:42,719 epoch 1 - iter 30/67 - loss 0.37875697 - samples/sec: 93.56 - lr: 0.400333\n",
      "2022-08-30 21:53:45,932 epoch 1 - iter 36/67 - loss 0.37826063 - samples/sec: 95.20 - lr: 0.400333\n",
      "2022-08-30 21:53:49,159 epoch 1 - iter 42/67 - loss 0.37834354 - samples/sec: 94.94 - lr: 0.400333\n",
      "2022-08-30 21:53:52,154 epoch 1 - iter 48/67 - loss 0.37915334 - samples/sec: 102.74 - lr: 0.400333\n",
      "2022-08-30 21:53:55,010 epoch 1 - iter 54/67 - loss 0.37731268 - samples/sec: 107.45 - lr: 0.400333\n",
      "2022-08-30 21:53:58,249 epoch 1 - iter 60/67 - loss 0.38201804 - samples/sec: 94.40 - lr: 0.400333\n",
      "2022-08-30 21:54:01,728 epoch 1 - iter 66/67 - loss 0.39486360 - samples/sec: 87.72 - lr: 0.400333\n",
      "2022-08-30 21:54:02,239 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:54:02,240 EPOCH 1 done: loss 0.3956 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:54:03,100 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:54:03,134 DEV : loss 0.27253058552742004 - f1-score (micro avg)  0.9072\n",
      "2022-08-30 21:54:03,151 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:54:03,152 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:54:03,999 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:54:07,017 epoch 2 - iter 6/67 - loss 0.38324669 - samples/sec: 99.50 - lr: 0.400333\n",
      "2022-08-30 21:54:10,536 epoch 2 - iter 12/67 - loss 0.38434708 - samples/sec: 86.78 - lr: 0.400333\n",
      "2022-08-30 21:54:13,591 epoch 2 - iter 18/67 - loss 0.38939349 - samples/sec: 100.23 - lr: 0.400333\n",
      "2022-08-30 21:54:17,492 epoch 2 - iter 24/67 - loss 0.39092588 - samples/sec: 78.17 - lr: 0.400333\n",
      "2022-08-30 21:54:20,658 epoch 2 - iter 30/67 - loss 0.39324715 - samples/sec: 96.76 - lr: 0.400333\n",
      "2022-08-30 21:54:23,807 epoch 2 - iter 36/67 - loss 0.39289567 - samples/sec: 97.46 - lr: 0.400333\n",
      "2022-08-30 21:54:26,782 epoch 2 - iter 42/67 - loss 0.39290132 - samples/sec: 102.77 - lr: 0.400333\n",
      "2022-08-30 21:54:29,689 epoch 2 - iter 48/67 - loss 0.39355383 - samples/sec: 105.33 - lr: 0.400333\n",
      "2022-08-30 21:54:33,093 epoch 2 - iter 54/67 - loss 0.39351773 - samples/sec: 89.92 - lr: 0.400333\n",
      "2022-08-30 21:54:36,325 epoch 2 - iter 60/67 - loss 0.39334992 - samples/sec: 94.92 - lr: 0.400333\n",
      "2022-08-30 21:54:39,625 epoch 2 - iter 66/67 - loss 0.39307041 - samples/sec: 93.61 - lr: 0.400333\n",
      "2022-08-30 21:54:39,965 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:54:39,966 EPOCH 2 done: loss 0.3929 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:54:40,873 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:54:40,906 DEV : loss 0.25871697068214417 - f1-score (micro avg)  0.9116\n",
      "2022-08-30 21:54:40,924 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:54:40,925 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:54:41,797 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:54:44,833 epoch 3 - iter 6/67 - loss 0.38780292 - samples/sec: 98.92 - lr: 0.400333\n",
      "2022-08-30 21:54:48,063 epoch 3 - iter 12/67 - loss 0.39626423 - samples/sec: 95.09 - lr: 0.400333\n",
      "2022-08-30 21:54:51,450 epoch 3 - iter 18/67 - loss 0.39129950 - samples/sec: 90.29 - lr: 0.400333\n",
      "2022-08-30 21:54:54,718 epoch 3 - iter 24/67 - loss 0.39101253 - samples/sec: 94.31 - lr: 0.400333\n",
      "2022-08-30 21:54:57,883 epoch 3 - iter 30/67 - loss 0.39215788 - samples/sec: 96.55 - lr: 0.400333\n",
      "2022-08-30 21:55:00,849 epoch 3 - iter 36/67 - loss 0.39284073 - samples/sec: 103.23 - lr: 0.400333\n",
      "2022-08-30 21:55:03,990 epoch 3 - iter 42/67 - loss 0.39518509 - samples/sec: 97.34 - lr: 0.400333\n",
      "2022-08-30 21:55:07,142 epoch 3 - iter 48/67 - loss 0.39271601 - samples/sec: 97.18 - lr: 0.400333\n",
      "2022-08-30 21:55:10,578 epoch 3 - iter 54/67 - loss 0.39419764 - samples/sec: 88.78 - lr: 0.400333\n",
      "2022-08-30 21:55:13,590 epoch 3 - iter 60/67 - loss 0.39572221 - samples/sec: 102.46 - lr: 0.400333\n",
      "2022-08-30 21:55:16,780 epoch 3 - iter 66/67 - loss 0.39436186 - samples/sec: 95.97 - lr: 0.400333\n",
      "2022-08-30 21:55:17,311 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:55:17,312 EPOCH 3 done: loss 0.3945 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:55:18,211 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:55:18,242 DEV : loss 0.2582418620586395 - f1-score (micro avg)  0.9079\n",
      "2022-08-30 21:55:18,257 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:55:18,258 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:55:21,309 epoch 4 - iter 6/67 - loss 0.41057221 - samples/sec: 98.39 - lr: 0.400333\n",
      "2022-08-30 21:55:24,602 epoch 4 - iter 12/67 - loss 0.38921555 - samples/sec: 93.34 - lr: 0.400333\n",
      "2022-08-30 21:55:27,888 epoch 4 - iter 18/67 - loss 0.38988425 - samples/sec: 93.34 - lr: 0.400333\n",
      "2022-08-30 21:55:31,175 epoch 4 - iter 24/67 - loss 0.39340040 - samples/sec: 92.82 - lr: 0.400333\n",
      "2022-08-30 21:55:34,801 epoch 4 - iter 30/67 - loss 0.39096705 - samples/sec: 84.10 - lr: 0.400333\n",
      "2022-08-30 21:55:38,135 epoch 4 - iter 36/67 - loss 0.39186808 - samples/sec: 91.74 - lr: 0.400333\n",
      "2022-08-30 21:55:41,512 epoch 4 - iter 42/67 - loss 0.39120477 - samples/sec: 90.74 - lr: 0.400333\n",
      "2022-08-30 21:55:44,530 epoch 4 - iter 48/67 - loss 0.39031725 - samples/sec: 101.73 - lr: 0.400333\n",
      "2022-08-30 21:55:47,945 epoch 4 - iter 54/67 - loss 0.39334117 - samples/sec: 89.45 - lr: 0.400333\n",
      "2022-08-30 21:55:51,122 epoch 4 - iter 60/67 - loss 0.39110835 - samples/sec: 96.53 - lr: 0.400333\n",
      "2022-08-30 21:55:54,214 epoch 4 - iter 66/67 - loss 0.38986537 - samples/sec: 99.24 - lr: 0.400333\n",
      "2022-08-30 21:55:54,639 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:55:54,640 EPOCH 4 done: loss 0.3901 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:55:55,614 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:55:55,649 DEV : loss 0.2642558217048645 - f1-score (micro avg)  0.9095\n",
      "2022-08-30 21:55:55,669 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 21:55:55,670 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:55:58,685 epoch 5 - iter 6/67 - loss 0.42284916 - samples/sec: 99.54 - lr: 0.400333\n",
      "2022-08-30 21:56:01,784 epoch 5 - iter 12/67 - loss 0.40777509 - samples/sec: 98.72 - lr: 0.400333\n",
      "2022-08-30 21:56:05,277 epoch 5 - iter 18/67 - loss 0.40116224 - samples/sec: 87.29 - lr: 0.400333\n",
      "2022-08-30 21:56:08,865 epoch 5 - iter 24/67 - loss 0.39771723 - samples/sec: 85.15 - lr: 0.400333\n",
      "2022-08-30 21:56:12,180 epoch 5 - iter 30/67 - loss 0.39713685 - samples/sec: 92.36 - lr: 0.400333\n",
      "2022-08-30 21:56:15,285 epoch 5 - iter 36/67 - loss 0.39394277 - samples/sec: 98.55 - lr: 0.400333\n",
      "2022-08-30 21:56:18,928 epoch 5 - iter 42/67 - loss 0.39315840 - samples/sec: 83.92 - lr: 0.400333\n",
      "2022-08-30 21:56:22,295 epoch 5 - iter 48/67 - loss 0.39290261 - samples/sec: 90.82 - lr: 0.400333\n",
      "2022-08-30 21:56:25,585 epoch 5 - iter 54/67 - loss 0.39550686 - samples/sec: 92.93 - lr: 0.400333\n",
      "2022-08-30 21:56:28,489 epoch 5 - iter 60/67 - loss 0.39450888 - samples/sec: 105.49 - lr: 0.400333\n",
      "2022-08-30 21:56:31,448 epoch 5 - iter 66/67 - loss 0.39272815 - samples/sec: 103.41 - lr: 0.400333\n",
      "2022-08-30 21:56:31,870 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:56:31,871 EPOCH 5 done: loss 0.3926 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:56:32,750 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:56:32,780 DEV : loss 0.26784393191337585 - f1-score (micro avg)  0.9134\n",
      "2022-08-30 21:56:32,800 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:56:32,801 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:56:33,661 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:56:36,686 epoch 6 - iter 6/67 - loss 0.39756763 - samples/sec: 99.27 - lr: 0.400333\n",
      "2022-08-30 21:56:39,622 epoch 6 - iter 12/67 - loss 0.39652774 - samples/sec: 105.37 - lr: 0.400333\n",
      "2022-08-30 21:56:42,753 epoch 6 - iter 18/67 - loss 0.39035061 - samples/sec: 97.94 - lr: 0.400333\n",
      "2022-08-30 21:56:45,769 epoch 6 - iter 24/67 - loss 0.39317917 - samples/sec: 101.40 - lr: 0.400333\n",
      "2022-08-30 21:56:48,888 epoch 6 - iter 30/67 - loss 0.39312631 - samples/sec: 98.01 - lr: 0.400333\n",
      "2022-08-30 21:56:52,500 epoch 6 - iter 36/67 - loss 0.39283908 - samples/sec: 84.36 - lr: 0.400333\n",
      "2022-08-30 21:56:55,811 epoch 6 - iter 42/67 - loss 0.39394831 - samples/sec: 92.76 - lr: 0.400333\n",
      "2022-08-30 21:56:58,817 epoch 6 - iter 48/67 - loss 0.39191631 - samples/sec: 102.11 - lr: 0.400333\n",
      "2022-08-30 21:57:02,153 epoch 6 - iter 54/67 - loss 0.39199626 - samples/sec: 91.80 - lr: 0.400333\n",
      "2022-08-30 21:57:05,213 epoch 6 - iter 60/67 - loss 0.39356405 - samples/sec: 99.90 - lr: 0.400333\n",
      "2022-08-30 21:57:08,509 epoch 6 - iter 66/67 - loss 0.39321723 - samples/sec: 92.74 - lr: 0.400333\n",
      "2022-08-30 21:57:08,882 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:57:08,883 EPOCH 6 done: loss 0.3935 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:57:09,790 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:57:09,822 DEV : loss 0.2585921287536621 - f1-score (micro avg)  0.9139\n",
      "2022-08-30 21:57:09,839 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:57:09,840 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:57:10,790 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:57:13,810 epoch 7 - iter 6/67 - loss 0.39000763 - samples/sec: 99.40 - lr: 0.400333\n",
      "2022-08-30 21:57:16,704 epoch 7 - iter 12/67 - loss 0.38665248 - samples/sec: 105.86 - lr: 0.400333\n",
      "2022-08-30 21:57:19,847 epoch 7 - iter 18/67 - loss 0.38671608 - samples/sec: 97.37 - lr: 0.400333\n",
      "2022-08-30 21:57:22,856 epoch 7 - iter 24/67 - loss 0.39088966 - samples/sec: 102.25 - lr: 0.400333\n",
      "2022-08-30 21:57:26,175 epoch 7 - iter 30/67 - loss 0.39281988 - samples/sec: 92.05 - lr: 0.400333\n",
      "2022-08-30 21:57:29,813 epoch 7 - iter 36/67 - loss 0.39274423 - samples/sec: 83.94 - lr: 0.400333\n",
      "2022-08-30 21:57:32,781 epoch 7 - iter 42/67 - loss 0.39385176 - samples/sec: 103.16 - lr: 0.400333\n",
      "2022-08-30 21:57:36,109 epoch 7 - iter 48/67 - loss 0.39083391 - samples/sec: 91.94 - lr: 0.400333\n",
      "2022-08-30 21:57:39,356 epoch 7 - iter 54/67 - loss 0.39229043 - samples/sec: 94.13 - lr: 0.400333\n",
      "2022-08-30 21:57:42,736 epoch 7 - iter 60/67 - loss 0.39383763 - samples/sec: 90.83 - lr: 0.400333\n",
      "2022-08-30 21:57:45,987 epoch 7 - iter 66/67 - loss 0.39279159 - samples/sec: 94.04 - lr: 0.400333\n",
      "2022-08-30 21:57:46,343 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:57:46,344 EPOCH 7 done: loss 0.3928 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:57:47,174 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:57:47,207 DEV : loss 0.257855087518692 - f1-score (micro avg)  0.9139\n",
      "2022-08-30 21:57:47,225 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:57:47,226 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:57:50,501 epoch 8 - iter 6/67 - loss 0.38215671 - samples/sec: 91.69 - lr: 0.400333\n",
      "2022-08-30 21:57:53,766 epoch 8 - iter 12/67 - loss 0.38513040 - samples/sec: 93.78 - lr: 0.400333\n",
      "2022-08-30 21:57:56,950 epoch 8 - iter 18/67 - loss 0.38829451 - samples/sec: 96.03 - lr: 0.400333\n",
      "2022-08-30 21:58:00,481 epoch 8 - iter 24/67 - loss 0.38721798 - samples/sec: 86.46 - lr: 0.400333\n",
      "2022-08-30 21:58:03,848 epoch 8 - iter 30/67 - loss 0.38834125 - samples/sec: 90.61 - lr: 0.400333\n",
      "2022-08-30 21:58:06,974 epoch 8 - iter 36/67 - loss 0.38873882 - samples/sec: 97.98 - lr: 0.400333\n",
      "2022-08-30 21:58:10,472 epoch 8 - iter 42/67 - loss 0.39142595 - samples/sec: 87.29 - lr: 0.400333\n",
      "2022-08-30 21:58:13,547 epoch 8 - iter 48/67 - loss 0.39155627 - samples/sec: 100.64 - lr: 0.400333\n",
      "2022-08-30 21:58:17,157 epoch 8 - iter 54/67 - loss 0.39073567 - samples/sec: 84.72 - lr: 0.400333\n",
      "2022-08-30 21:58:20,293 epoch 8 - iter 60/67 - loss 0.39035335 - samples/sec: 97.56 - lr: 0.400333\n",
      "2022-08-30 21:58:23,682 epoch 8 - iter 66/67 - loss 0.39001127 - samples/sec: 90.55 - lr: 0.400333\n",
      "2022-08-30 21:58:24,006 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:58:24,007 EPOCH 8 done: loss 0.3901 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:58:24,907 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:58:24,943 DEV : loss 0.25005051493644714 - f1-score (micro avg)  0.915\n",
      "2022-08-30 21:58:24,966 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:58:24,967 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:58:26,007 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:58:29,346 epoch 9 - iter 6/67 - loss 0.40536880 - samples/sec: 89.90 - lr: 0.400333\n",
      "2022-08-30 21:58:32,595 epoch 9 - iter 12/67 - loss 0.40385582 - samples/sec: 94.40 - lr: 0.400333\n",
      "2022-08-30 21:58:35,547 epoch 9 - iter 18/67 - loss 0.39684594 - samples/sec: 103.81 - lr: 0.400333\n",
      "2022-08-30 21:58:38,922 epoch 9 - iter 24/67 - loss 0.40232594 - samples/sec: 90.83 - lr: 0.400333\n",
      "2022-08-30 21:58:42,030 epoch 9 - iter 30/67 - loss 0.40162083 - samples/sec: 98.36 - lr: 0.400333\n",
      "2022-08-30 21:58:45,381 epoch 9 - iter 36/67 - loss 0.39585920 - samples/sec: 91.27 - lr: 0.400333\n",
      "2022-08-30 21:58:48,548 epoch 9 - iter 42/67 - loss 0.39208439 - samples/sec: 97.47 - lr: 0.400333\n",
      "2022-08-30 21:58:51,775 epoch 9 - iter 48/67 - loss 0.39276084 - samples/sec: 95.60 - lr: 0.400333\n",
      "2022-08-30 21:58:55,183 epoch 9 - iter 54/67 - loss 0.39286962 - samples/sec: 89.63 - lr: 0.400333\n",
      "2022-08-30 21:58:58,248 epoch 9 - iter 60/67 - loss 0.39421985 - samples/sec: 100.17 - lr: 0.400333\n",
      "2022-08-30 21:59:01,093 epoch 9 - iter 66/67 - loss 0.39489344 - samples/sec: 108.23 - lr: 0.400333\n",
      "2022-08-30 21:59:01,492 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:59:01,493 EPOCH 9 done: loss 0.3943 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:59:02,310 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:59:02,343 DEV : loss 0.2584694027900696 - f1-score (micro avg)  0.9133\n",
      "2022-08-30 21:59:02,361 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 21:59:02,363 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:59:05,722 epoch 10 - iter 6/67 - loss 0.38263253 - samples/sec: 89.37 - lr: 0.400333\n",
      "2022-08-30 21:59:08,662 epoch 10 - iter 12/67 - loss 0.38151835 - samples/sec: 104.24 - lr: 0.400333\n",
      "2022-08-30 21:59:11,738 epoch 10 - iter 18/67 - loss 0.37769764 - samples/sec: 99.60 - lr: 0.400333\n",
      "2022-08-30 21:59:14,948 epoch 10 - iter 24/67 - loss 0.38194965 - samples/sec: 95.24 - lr: 0.400333\n",
      "2022-08-30 21:59:18,659 epoch 10 - iter 30/67 - loss 0.38323126 - samples/sec: 82.21 - lr: 0.400333\n",
      "2022-08-30 21:59:21,501 epoch 10 - iter 36/67 - loss 0.38220516 - samples/sec: 108.38 - lr: 0.400333\n",
      "2022-08-30 21:59:24,272 epoch 10 - iter 42/67 - loss 0.38826246 - samples/sec: 110.95 - lr: 0.400333\n",
      "2022-08-30 21:59:27,317 epoch 10 - iter 48/67 - loss 0.38708335 - samples/sec: 100.40 - lr: 0.400333\n",
      "2022-08-30 21:59:30,349 epoch 10 - iter 54/67 - loss 0.38780742 - samples/sec: 101.04 - lr: 0.400333\n",
      "2022-08-30 21:59:33,703 epoch 10 - iter 60/67 - loss 0.38872972 - samples/sec: 91.63 - lr: 0.400333\n",
      "2022-08-30 21:59:36,330 epoch 10 - iter 66/67 - loss 0.39070428 - samples/sec: 116.96 - lr: 0.400333\n",
      "2022-08-30 21:59:36,856 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:59:36,857 EPOCH 10 done: loss 0.3907 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:59:37,706 Evaluating as a multi-label problem: False\n",
      "2022-08-30 21:59:37,738 DEV : loss 0.25458940863609314 - f1-score (micro avg)  0.9163\n",
      "2022-08-30 21:59:37,754 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 21:59:37,755 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 21:59:38,774 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 21:59:41,599 epoch 11 - iter 6/67 - loss 0.39082994 - samples/sec: 106.27 - lr: 0.400333\n",
      "2022-08-30 21:59:45,012 epoch 11 - iter 12/67 - loss 0.39516438 - samples/sec: 90.20 - lr: 0.400333\n",
      "2022-08-30 21:59:47,926 epoch 11 - iter 18/67 - loss 0.38762168 - samples/sec: 105.23 - lr: 0.400333\n",
      "2022-08-30 21:59:51,082 epoch 11 - iter 24/67 - loss 0.38654153 - samples/sec: 97.09 - lr: 0.400333\n",
      "2022-08-30 21:59:53,884 epoch 11 - iter 30/67 - loss 0.38647820 - samples/sec: 109.41 - lr: 0.400333\n",
      "2022-08-30 21:59:57,325 epoch 11 - iter 36/67 - loss 0.38197858 - samples/sec: 88.73 - lr: 0.400333\n",
      "2022-08-30 22:00:00,658 epoch 11 - iter 42/67 - loss 0.38387162 - samples/sec: 92.54 - lr: 0.400333\n",
      "2022-08-30 22:00:03,762 epoch 11 - iter 48/67 - loss 0.38661885 - samples/sec: 99.08 - lr: 0.400333\n",
      "2022-08-30 22:00:06,715 epoch 11 - iter 54/67 - loss 0.38639842 - samples/sec: 103.73 - lr: 0.400333\n",
      "2022-08-30 22:00:10,161 epoch 11 - iter 60/67 - loss 0.38835621 - samples/sec: 88.65 - lr: 0.400333\n",
      "2022-08-30 22:00:13,263 epoch 11 - iter 66/67 - loss 0.38787438 - samples/sec: 98.62 - lr: 0.400333\n",
      "2022-08-30 22:00:13,702 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:00:13,703 EPOCH 11 done: loss 0.3879 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:00:15,884 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:00:15,918 DEV : loss 0.26723578572273254 - f1-score (micro avg)  0.9126\n",
      "2022-08-30 22:00:15,939 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:00:17,062 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:00:17,063 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 22:00:17,251 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:00:18,654 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:00:18,683 0.9229\t0.9229\t0.9229\t0.9229\n",
      "2022-08-30 22:00:18,683 \n",
      "Results:\n",
      "- F-score (micro) 0.9229\n",
      "- F-score (macro) 0.803\n",
      "- Accuracy 0.9229\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8922    0.9180    0.9049      1353\n",
      "         ADJ     0.8855    0.8973    0.8914       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9941    0.9883    0.9912       514\n",
      "        VERB     0.8991    0.9131    0.9061       449\n",
      "       PROPN     0.8353    0.7415    0.7856       383\n",
      "         AUX     0.9940    0.9881    0.9910       335\n",
      "       CCONJ     0.9846    1.0000    0.9922       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.7877    0.8758    0.8294       161\n",
      "         ADV     0.8493    0.8212    0.8350       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9821    0.7746    0.8661        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9229      5264\n",
      "   macro avg     0.8183    0.7913    0.8030      5264\n",
      "weighted avg     0.9236    0.9229    0.9227      5264\n",
      "\n",
      "2022-08-30 22:00:18,684 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:00:18,686 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:00:19,177 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 7 #######################\n",
      "#######################################################\n",
      "2022-08-30 22:02:43,081 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:02:43,082 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 22:02:43,082 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:02:43,083 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 22:02:43,084 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:02:43,085 Parameters:\n",
      "2022-08-30 22:02:43,085  - learning_rate: \"0.400333\"\n",
      "2022-08-30 22:02:43,086  - mini_batch_size: \"50\"\n",
      "2022-08-30 22:02:43,086  - patience: \"3\"\n",
      "2022-08-30 22:02:43,087  - anneal_factor: \"0.5\"\n",
      "2022-08-30 22:02:43,087  - max_epochs: \"12\"\n",
      "2022-08-30 22:02:43,088  - shuffle: \"True\"\n",
      "2022-08-30 22:02:43,088  - train_with_dev: \"False\"\n",
      "2022-08-30 22:02:43,089  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 22:02:43,089 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:02:43,090 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 22:02:43,090 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:02:43,091 Device: cpu\n",
      "2022-08-30 22:02:43,091 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:02:43,092 Embeddings storage mode: cpu\n",
      "2022-08-30 22:02:43,093 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:02:45,952 epoch 1 - iter 6/67 - loss 0.35150628 - samples/sec: 104.93 - lr: 0.400333\n",
      "2022-08-30 22:02:49,236 epoch 1 - iter 12/67 - loss 0.36674138 - samples/sec: 93.25 - lr: 0.400333\n",
      "2022-08-30 22:02:52,066 epoch 1 - iter 18/67 - loss 0.36665247 - samples/sec: 108.42 - lr: 0.400333\n",
      "2022-08-30 22:02:54,919 epoch 1 - iter 24/67 - loss 0.36917730 - samples/sec: 107.49 - lr: 0.400333\n",
      "2022-08-30 22:02:58,070 epoch 1 - iter 30/67 - loss 0.37727180 - samples/sec: 97.21 - lr: 0.400333\n",
      "2022-08-30 22:03:01,145 epoch 1 - iter 36/67 - loss 0.37518369 - samples/sec: 99.50 - lr: 0.400333\n",
      "2022-08-30 22:03:04,180 epoch 1 - iter 42/67 - loss 0.37435081 - samples/sec: 100.77 - lr: 0.400333\n",
      "2022-08-30 22:03:07,093 epoch 1 - iter 48/67 - loss 0.37479603 - samples/sec: 105.19 - lr: 0.400333\n",
      "2022-08-30 22:03:09,883 epoch 1 - iter 54/67 - loss 0.37498719 - samples/sec: 109.73 - lr: 0.400333\n",
      "2022-08-30 22:03:13,081 epoch 1 - iter 60/67 - loss 0.37826094 - samples/sec: 95.45 - lr: 0.400333\n",
      "2022-08-30 22:03:16,632 epoch 1 - iter 66/67 - loss 0.39286895 - samples/sec: 85.96 - lr: 0.400333\n",
      "2022-08-30 22:03:17,078 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:03:17,079 EPOCH 1 done: loss 0.3937 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:03:17,976 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:03:18,010 DEV : loss 0.2728314995765686 - f1-score (micro avg)  0.9055\n",
      "2022-08-30 22:03:18,027 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:03:18,028 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:03:19,009 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:03:22,591 epoch 2 - iter 6/67 - loss 0.39418886 - samples/sec: 83.80 - lr: 0.400333\n",
      "2022-08-30 22:03:25,748 epoch 2 - iter 12/67 - loss 0.39398589 - samples/sec: 97.02 - lr: 0.400333\n",
      "2022-08-30 22:03:29,091 epoch 2 - iter 18/67 - loss 0.39207597 - samples/sec: 91.27 - lr: 0.400333\n",
      "2022-08-30 22:03:32,119 epoch 2 - iter 24/67 - loss 0.39052763 - samples/sec: 101.01 - lr: 0.400333\n",
      "2022-08-30 22:03:35,101 epoch 2 - iter 30/67 - loss 0.38783704 - samples/sec: 102.77 - lr: 0.400333\n",
      "2022-08-30 22:03:38,270 epoch 2 - iter 36/67 - loss 0.39050851 - samples/sec: 96.87 - lr: 0.400333\n",
      "2022-08-30 22:03:41,659 epoch 2 - iter 42/67 - loss 0.39107436 - samples/sec: 90.28 - lr: 0.400333\n",
      "2022-08-30 22:03:44,776 epoch 2 - iter 48/67 - loss 0.39057838 - samples/sec: 98.52 - lr: 0.400333\n",
      "2022-08-30 22:03:47,822 epoch 2 - iter 54/67 - loss 0.39201472 - samples/sec: 100.67 - lr: 0.400333\n",
      "2022-08-30 22:03:50,832 epoch 2 - iter 60/67 - loss 0.39406455 - samples/sec: 101.80 - lr: 0.400333\n",
      "2022-08-30 22:03:54,155 epoch 2 - iter 66/67 - loss 0.39502282 - samples/sec: 92.02 - lr: 0.400333\n",
      "2022-08-30 22:03:54,515 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:03:54,515 EPOCH 2 done: loss 0.3948 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:03:55,348 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:03:55,386 DEV : loss 0.2594538927078247 - f1-score (micro avg)  0.9139\n",
      "2022-08-30 22:03:55,406 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:03:55,407 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:03:56,366 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:03:59,459 epoch 3 - iter 6/67 - loss 0.40454801 - samples/sec: 97.09 - lr: 0.400333\n",
      "2022-08-30 22:04:02,715 epoch 3 - iter 12/67 - loss 0.40988721 - samples/sec: 93.93 - lr: 0.400333\n",
      "2022-08-30 22:04:05,954 epoch 3 - iter 18/67 - loss 0.40223009 - samples/sec: 94.43 - lr: 0.400333\n",
      "2022-08-30 22:04:08,913 epoch 3 - iter 24/67 - loss 0.39299359 - samples/sec: 103.59 - lr: 0.400333\n",
      "2022-08-30 22:04:12,159 epoch 3 - iter 30/67 - loss 0.38944383 - samples/sec: 94.10 - lr: 0.400333\n",
      "2022-08-30 22:04:15,244 epoch 3 - iter 36/67 - loss 0.39003794 - samples/sec: 99.08 - lr: 0.400333\n",
      "2022-08-30 22:04:18,536 epoch 3 - iter 42/67 - loss 0.39002801 - samples/sec: 92.82 - lr: 0.400333\n",
      "2022-08-30 22:04:22,517 epoch 3 - iter 48/67 - loss 0.39228417 - samples/sec: 76.71 - lr: 0.400333\n",
      "2022-08-30 22:04:25,407 epoch 3 - iter 54/67 - loss 0.39047077 - samples/sec: 106.23 - lr: 0.400333\n",
      "2022-08-30 22:04:28,428 epoch 3 - iter 60/67 - loss 0.39030159 - samples/sec: 101.59 - lr: 0.400333\n",
      "2022-08-30 22:04:31,502 epoch 3 - iter 66/67 - loss 0.39007718 - samples/sec: 99.67 - lr: 0.400333\n",
      "2022-08-30 22:04:31,935 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:04:31,936 EPOCH 3 done: loss 0.3904 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:04:32,782 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:04:32,815 DEV : loss 0.25692176818847656 - f1-score (micro avg)  0.9154\n",
      "2022-08-30 22:04:32,831 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:04:32,833 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:04:33,530 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:04:37,232 epoch 4 - iter 6/67 - loss 0.39143664 - samples/sec: 81.06 - lr: 0.400333\n",
      "2022-08-30 22:04:40,561 epoch 4 - iter 12/67 - loss 0.39116786 - samples/sec: 91.91 - lr: 0.400333\n",
      "2022-08-30 22:04:43,762 epoch 4 - iter 18/67 - loss 0.38982055 - samples/sec: 95.48 - lr: 0.400333\n",
      "2022-08-30 22:04:46,809 epoch 4 - iter 24/67 - loss 0.38914302 - samples/sec: 100.37 - lr: 0.400333\n",
      "2022-08-30 22:04:49,912 epoch 4 - iter 30/67 - loss 0.38823568 - samples/sec: 98.55 - lr: 0.400333\n",
      "2022-08-30 22:04:52,727 epoch 4 - iter 36/67 - loss 0.39031321 - samples/sec: 108.77 - lr: 0.400333\n",
      "2022-08-30 22:04:56,049 epoch 4 - iter 42/67 - loss 0.38919264 - samples/sec: 91.91 - lr: 0.400333\n",
      "2022-08-30 22:04:58,937 epoch 4 - iter 48/67 - loss 0.39061550 - samples/sec: 105.93 - lr: 0.400333\n",
      "2022-08-30 22:05:02,285 epoch 4 - iter 54/67 - loss 0.38876329 - samples/sec: 91.44 - lr: 0.400333\n",
      "2022-08-30 22:05:05,538 epoch 4 - iter 60/67 - loss 0.38816202 - samples/sec: 93.96 - lr: 0.400333\n",
      "2022-08-30 22:05:08,325 epoch 4 - iter 66/67 - loss 0.38920635 - samples/sec: 110.42 - lr: 0.400333\n",
      "2022-08-30 22:05:08,752 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:05:08,752 EPOCH 4 done: loss 0.3896 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:05:09,615 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:05:09,646 DEV : loss 0.2551251947879791 - f1-score (micro avg)  0.9173\n",
      "2022-08-30 22:05:09,661 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:05:09,662 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:05:10,399 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:05:13,886 epoch 5 - iter 6/67 - loss 0.40419498 - samples/sec: 86.06 - lr: 0.400333\n",
      "2022-08-30 22:05:16,974 epoch 5 - iter 12/67 - loss 0.40420888 - samples/sec: 99.34 - lr: 0.400333\n",
      "2022-08-30 22:05:20,076 epoch 5 - iter 18/67 - loss 0.40237395 - samples/sec: 98.68 - lr: 0.400333\n",
      "2022-08-30 22:05:23,245 epoch 5 - iter 24/67 - loss 0.39349240 - samples/sec: 96.59 - lr: 0.400333\n",
      "2022-08-30 22:05:26,560 epoch 5 - iter 30/67 - loss 0.39231180 - samples/sec: 92.22 - lr: 0.400333\n",
      "2022-08-30 22:05:29,722 epoch 5 - iter 36/67 - loss 0.39424409 - samples/sec: 96.84 - lr: 0.400333\n",
      "2022-08-30 22:05:33,259 epoch 5 - iter 42/67 - loss 0.39390104 - samples/sec: 86.58 - lr: 0.400333\n",
      "2022-08-30 22:05:36,483 epoch 5 - iter 48/67 - loss 0.39290638 - samples/sec: 94.91 - lr: 0.400333\n",
      "2022-08-30 22:05:39,385 epoch 5 - iter 54/67 - loss 0.39234403 - samples/sec: 106.27 - lr: 0.400333\n",
      "2022-08-30 22:05:42,489 epoch 5 - iter 60/67 - loss 0.39121679 - samples/sec: 99.17 - lr: 0.400333\n",
      "2022-08-30 22:05:45,429 epoch 5 - iter 66/67 - loss 0.39218648 - samples/sec: 104.06 - lr: 0.400333\n",
      "2022-08-30 22:05:45,864 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:05:45,865 EPOCH 5 done: loss 0.3918 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:05:46,757 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:05:46,785 DEV : loss 0.2558406591415405 - f1-score (micro avg)  0.912\n",
      "2022-08-30 22:05:46,803 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:05:46,804 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:05:49,844 epoch 6 - iter 6/67 - loss 0.38337671 - samples/sec: 98.75 - lr: 0.400333\n",
      "2022-08-30 22:05:52,786 epoch 6 - iter 12/67 - loss 0.37571750 - samples/sec: 103.91 - lr: 0.400333\n",
      "2022-08-30 22:05:55,679 epoch 6 - iter 18/67 - loss 0.37743256 - samples/sec: 105.82 - lr: 0.400333\n",
      "2022-08-30 22:05:58,893 epoch 6 - iter 24/67 - loss 0.37486791 - samples/sec: 95.24 - lr: 0.400333\n",
      "2022-08-30 22:06:02,032 epoch 6 - iter 30/67 - loss 0.37849048 - samples/sec: 97.40 - lr: 0.400333\n",
      "2022-08-30 22:06:05,963 epoch 6 - iter 36/67 - loss 0.37944216 - samples/sec: 77.42 - lr: 0.400333\n",
      "2022-08-30 22:06:08,978 epoch 6 - iter 42/67 - loss 0.37993303 - samples/sec: 101.52 - lr: 0.400333\n",
      "2022-08-30 22:06:12,207 epoch 6 - iter 48/67 - loss 0.38070799 - samples/sec: 94.70 - lr: 0.400333\n",
      "2022-08-30 22:06:15,145 epoch 6 - iter 54/67 - loss 0.38400875 - samples/sec: 104.31 - lr: 0.400333\n",
      "2022-08-30 22:06:18,330 epoch 6 - iter 60/67 - loss 0.38628370 - samples/sec: 96.00 - lr: 0.400333\n",
      "2022-08-30 22:06:21,703 epoch 6 - iter 66/67 - loss 0.38518021 - samples/sec: 90.74 - lr: 0.400333\n",
      "2022-08-30 22:06:22,087 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:06:22,088 EPOCH 6 done: loss 0.3851 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:06:22,961 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:06:22,993 DEV : loss 0.2520170509815216 - f1-score (micro avg)  0.9173\n",
      "2022-08-30 22:06:23,008 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:06:23,009 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:06:26,078 epoch 7 - iter 6/67 - loss 0.39298254 - samples/sec: 97.82 - lr: 0.400333\n",
      "2022-08-30 22:06:28,879 epoch 7 - iter 12/67 - loss 0.39873354 - samples/sec: 109.69 - lr: 0.400333\n",
      "2022-08-30 22:06:31,818 epoch 7 - iter 18/67 - loss 0.39117233 - samples/sec: 104.13 - lr: 0.400333\n",
      "2022-08-30 22:06:34,807 epoch 7 - iter 24/67 - loss 0.39109120 - samples/sec: 102.32 - lr: 0.400333\n",
      "2022-08-30 22:06:37,880 epoch 7 - iter 30/67 - loss 0.38955498 - samples/sec: 100.07 - lr: 0.400333\n",
      "2022-08-30 22:06:40,957 epoch 7 - iter 36/67 - loss 0.38897961 - samples/sec: 99.57 - lr: 0.400333\n",
      "2022-08-30 22:06:44,088 epoch 7 - iter 42/67 - loss 0.38718389 - samples/sec: 97.53 - lr: 0.400333\n",
      "2022-08-30 22:06:47,230 epoch 7 - iter 48/67 - loss 0.38708495 - samples/sec: 97.43 - lr: 0.400333\n",
      "2022-08-30 22:06:50,884 epoch 7 - iter 54/67 - loss 0.38995576 - samples/sec: 83.52 - lr: 0.400333\n",
      "2022-08-30 22:06:54,098 epoch 7 - iter 60/67 - loss 0.38941008 - samples/sec: 95.06 - lr: 0.400333\n",
      "2022-08-30 22:06:57,365 epoch 7 - iter 66/67 - loss 0.39035229 - samples/sec: 93.49 - lr: 0.400333\n",
      "2022-08-30 22:06:57,873 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:06:57,874 EPOCH 7 done: loss 0.3905 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:06:58,712 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:06:58,741 DEV : loss 0.2519652545452118 - f1-score (micro avg)  0.9168\n",
      "2022-08-30 22:06:58,755 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:06:58,756 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:07:01,787 epoch 8 - iter 6/67 - loss 0.38464009 - samples/sec: 99.01 - lr: 0.400333\n",
      "2022-08-30 22:07:05,218 epoch 8 - iter 12/67 - loss 0.38476448 - samples/sec: 89.07 - lr: 0.400333\n",
      "2022-08-30 22:07:08,307 epoch 8 - iter 18/67 - loss 0.38710118 - samples/sec: 98.91 - lr: 0.400333\n",
      "2022-08-30 22:07:11,401 epoch 8 - iter 24/67 - loss 0.39396037 - samples/sec: 99.11 - lr: 0.400333\n",
      "2022-08-30 22:07:14,507 epoch 8 - iter 30/67 - loss 0.39360500 - samples/sec: 98.94 - lr: 0.400333\n",
      "2022-08-30 22:07:17,528 epoch 8 - iter 36/67 - loss 0.39086622 - samples/sec: 101.39 - lr: 0.400333\n",
      "2022-08-30 22:07:20,584 epoch 8 - iter 42/67 - loss 0.38932047 - samples/sec: 100.17 - lr: 0.400333\n",
      "2022-08-30 22:07:23,940 epoch 8 - iter 48/67 - loss 0.38732197 - samples/sec: 91.58 - lr: 0.400333\n",
      "2022-08-30 22:07:27,294 epoch 8 - iter 54/67 - loss 0.38595305 - samples/sec: 91.24 - lr: 0.400333\n",
      "2022-08-30 22:07:30,321 epoch 8 - iter 60/67 - loss 0.38629633 - samples/sec: 101.25 - lr: 0.400333\n",
      "2022-08-30 22:07:33,438 epoch 8 - iter 66/67 - loss 0.38680706 - samples/sec: 98.39 - lr: 0.400333\n",
      "2022-08-30 22:07:33,909 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:07:33,909 EPOCH 8 done: loss 0.3871 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:07:34,767 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:07:34,796 DEV : loss 0.25528067350387573 - f1-score (micro avg)  0.9124\n",
      "2022-08-30 22:07:34,811 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:07:34,812 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:07:37,848 epoch 9 - iter 6/67 - loss 0.37839205 - samples/sec: 98.88 - lr: 0.400333\n",
      "2022-08-30 22:07:41,104 epoch 9 - iter 12/67 - loss 0.38586387 - samples/sec: 93.87 - lr: 0.400333\n",
      "2022-08-30 22:07:44,170 epoch 9 - iter 18/67 - loss 0.38001261 - samples/sec: 99.73 - lr: 0.400333\n",
      "2022-08-30 22:07:47,551 epoch 9 - iter 24/67 - loss 0.37867927 - samples/sec: 90.47 - lr: 0.400333\n",
      "2022-08-30 22:07:50,680 epoch 9 - iter 30/67 - loss 0.38275759 - samples/sec: 98.14 - lr: 0.400333\n",
      "2022-08-30 22:07:53,952 epoch 9 - iter 36/67 - loss 0.38330191 - samples/sec: 93.43 - lr: 0.400333\n",
      "2022-08-30 22:07:57,397 epoch 9 - iter 42/67 - loss 0.38320714 - samples/sec: 88.55 - lr: 0.400333\n",
      "2022-08-30 22:08:00,317 epoch 9 - iter 48/67 - loss 0.38497709 - samples/sec: 105.19 - lr: 0.400333\n",
      "2022-08-30 22:08:03,326 epoch 9 - iter 54/67 - loss 0.38453213 - samples/sec: 102.53 - lr: 0.400333\n",
      "2022-08-30 22:08:06,305 epoch 9 - iter 60/67 - loss 0.38425649 - samples/sec: 103.99 - lr: 0.400333\n",
      "2022-08-30 22:08:09,540 epoch 9 - iter 66/67 - loss 0.38596668 - samples/sec: 94.88 - lr: 0.400333\n",
      "2022-08-30 22:08:09,942 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:08:09,942 EPOCH 9 done: loss 0.3861 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:08:10,811 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:08:10,845 DEV : loss 0.25228753685951233 - f1-score (micro avg)  0.9116\n",
      "2022-08-30 22:08:10,861 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 22:08:10,863 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:08:13,942 epoch 10 - iter 6/67 - loss 0.39646585 - samples/sec: 97.47 - lr: 0.400333\n",
      "2022-08-30 22:08:17,348 epoch 10 - iter 12/67 - loss 0.38109183 - samples/sec: 89.71 - lr: 0.400333\n",
      "2022-08-30 22:08:20,227 epoch 10 - iter 18/67 - loss 0.37864097 - samples/sec: 107.37 - lr: 0.400333\n",
      "2022-08-30 22:08:23,239 epoch 10 - iter 24/67 - loss 0.38226593 - samples/sec: 101.69 - lr: 0.400333\n",
      "2022-08-30 22:08:26,371 epoch 10 - iter 30/67 - loss 0.38605138 - samples/sec: 97.69 - lr: 0.400333\n",
      "2022-08-30 22:08:29,526 epoch 10 - iter 36/67 - loss 0.38461522 - samples/sec: 97.24 - lr: 0.400333\n",
      "2022-08-30 22:08:32,638 epoch 10 - iter 42/67 - loss 0.38519826 - samples/sec: 98.43 - lr: 0.400333\n",
      "2022-08-30 22:08:36,076 epoch 10 - iter 48/67 - loss 0.38428733 - samples/sec: 88.89 - lr: 0.400333\n",
      "2022-08-30 22:08:39,545 epoch 10 - iter 54/67 - loss 0.38395674 - samples/sec: 87.90 - lr: 0.400333\n",
      "2022-08-30 22:08:42,609 epoch 10 - iter 60/67 - loss 0.38292083 - samples/sec: 100.50 - lr: 0.400333\n",
      "2022-08-30 22:08:45,678 epoch 10 - iter 66/67 - loss 0.38359912 - samples/sec: 99.83 - lr: 0.400333\n",
      "2022-08-30 22:08:46,024 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:08:46,025 EPOCH 10 done: loss 0.3837 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:08:46,891 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:08:46,928 DEV : loss 0.25662845373153687 - f1-score (micro avg)  0.917\n",
      "2022-08-30 22:08:46,947 Epoch    10: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 22:08:46,947 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 22:08:46,949 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:08:49,851 epoch 11 - iter 6/67 - loss 0.38463765 - samples/sec: 103.41 - lr: 0.200167\n",
      "2022-08-30 22:08:53,361 epoch 11 - iter 12/67 - loss 0.37588031 - samples/sec: 86.91 - lr: 0.200167\n",
      "2022-08-30 22:08:56,552 epoch 11 - iter 18/67 - loss 0.37429700 - samples/sec: 96.52 - lr: 0.200167\n",
      "2022-08-30 22:08:59,644 epoch 11 - iter 24/67 - loss 0.37686140 - samples/sec: 98.91 - lr: 0.200167\n",
      "2022-08-30 22:09:03,077 epoch 11 - iter 30/67 - loss 0.36855918 - samples/sec: 88.94 - lr: 0.200167\n",
      "2022-08-30 22:09:06,375 epoch 11 - iter 36/67 - loss 0.36661642 - samples/sec: 92.71 - lr: 0.200167\n",
      "2022-08-30 22:09:09,729 epoch 11 - iter 42/67 - loss 0.36561512 - samples/sec: 91.86 - lr: 0.200167\n",
      "2022-08-30 22:09:12,685 epoch 11 - iter 48/67 - loss 0.36602404 - samples/sec: 103.59 - lr: 0.200167\n",
      "2022-08-30 22:09:16,094 epoch 11 - iter 54/67 - loss 0.36565952 - samples/sec: 90.44 - lr: 0.200167\n",
      "2022-08-30 22:09:19,165 epoch 11 - iter 60/67 - loss 0.36723245 - samples/sec: 99.54 - lr: 0.200167\n",
      "2022-08-30 22:09:22,061 epoch 11 - iter 66/67 - loss 0.36535762 - samples/sec: 106.01 - lr: 0.200167\n",
      "2022-08-30 22:09:22,637 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:09:22,638 EPOCH 11 done: loss 0.3658 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:09:23,488 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:09:23,514 DEV : loss 0.2494017779827118 - f1-score (micro avg)  0.9185\n",
      "2022-08-30 22:09:23,530 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:09:23,531 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:09:24,634 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:09:27,595 epoch 12 - iter 6/67 - loss 0.35434902 - samples/sec: 101.42 - lr: 0.200167\n",
      "2022-08-30 22:09:30,667 epoch 12 - iter 12/67 - loss 0.35252424 - samples/sec: 100.00 - lr: 0.200167\n",
      "2022-08-30 22:09:33,934 epoch 12 - iter 18/67 - loss 0.34924292 - samples/sec: 93.49 - lr: 0.200167\n",
      "2022-08-30 22:09:37,314 epoch 12 - iter 24/67 - loss 0.35694831 - samples/sec: 90.44 - lr: 0.200167\n",
      "2022-08-30 22:09:40,537 epoch 12 - iter 30/67 - loss 0.35825512 - samples/sec: 95.48 - lr: 0.200167\n",
      "2022-08-30 22:09:43,592 epoch 12 - iter 36/67 - loss 0.35996402 - samples/sec: 100.10 - lr: 0.200167\n",
      "2022-08-30 22:09:46,698 epoch 12 - iter 42/67 - loss 0.35791500 - samples/sec: 99.14 - lr: 0.200167\n",
      "2022-08-30 22:09:49,870 epoch 12 - iter 48/67 - loss 0.35890249 - samples/sec: 96.84 - lr: 0.200167\n",
      "2022-08-30 22:09:53,287 epoch 12 - iter 54/67 - loss 0.35923626 - samples/sec: 89.29 - lr: 0.200167\n",
      "2022-08-30 22:09:56,378 epoch 12 - iter 60/67 - loss 0.35826142 - samples/sec: 99.04 - lr: 0.200167\n",
      "2022-08-30 22:09:59,708 epoch 12 - iter 66/67 - loss 0.35732451 - samples/sec: 92.31 - lr: 0.200167\n",
      "2022-08-30 22:10:00,146 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:10:00,147 EPOCH 12 done: loss 0.3568 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:10:01,007 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:10:01,036 DEV : loss 0.2490813434123993 - f1-score (micro avg)  0.9181\n",
      "2022-08-30 22:10:01,051 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:10:01,914 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:10:01,915 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 22:10:02,094 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:10:03,486 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:10:03,511 0.9276\t0.9276\t0.9276\t0.9276\n",
      "2022-08-30 22:10:03,512 \n",
      "Results:\n",
      "- F-score (micro) 0.9276\n",
      "- F-score (macro) 0.8718\n",
      "- Accuracy 0.9276\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8850    0.9327    0.9082      1353\n",
      "         ADJ     0.8752    0.9182    0.8962       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9941    0.9883    0.9912       514\n",
      "        VERB     0.9146    0.9065    0.9105       449\n",
      "       PROPN     0.8856    0.7076    0.7866       383\n",
      "         AUX     0.9910    0.9910    0.9910       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.8667    0.8882    0.8773       161\n",
      "         ADV     0.8671    0.8212    0.8435       151\n",
      "        PRON     0.9909    0.9478    0.9689       115\n",
      "         NUM     1.0000    0.8028    0.8906        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9276      5264\n",
      "   macro avg     0.8909    0.8568    0.8718      5264\n",
      "weighted avg     0.9287    0.9276    0.9270      5264\n",
      "\n",
      "2022-08-30 22:10:03,513 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:10:03,515 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:10:03,989 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 22:12:32,853 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:12:32,854 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 22:12:32,855 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:12:32,855 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 22:12:32,856 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:12:32,857 Parameters:\n",
      "2022-08-30 22:12:32,857  - learning_rate: \"0.400333\"\n",
      "2022-08-30 22:12:32,858  - mini_batch_size: \"70\"\n",
      "2022-08-30 22:12:32,858  - patience: \"3\"\n",
      "2022-08-30 22:12:32,859  - anneal_factor: \"0.5\"\n",
      "2022-08-30 22:12:32,859  - max_epochs: \"10\"\n",
      "2022-08-30 22:12:32,859  - shuffle: \"True\"\n",
      "2022-08-30 22:12:32,860  - train_with_dev: \"False\"\n",
      "2022-08-30 22:12:32,861  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 22:12:32,861 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:12:32,862 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 22:12:32,862 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:12:32,863 Device: cpu\n",
      "2022-08-30 22:12:32,863 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:12:32,864 Embeddings storage mode: cpu\n",
      "2022-08-30 22:12:32,865 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:12:35,314 epoch 1 - iter 4/48 - loss 0.34265128 - samples/sec: 114.47 - lr: 0.400333\n",
      "2022-08-30 22:12:38,232 epoch 1 - iter 8/48 - loss 0.35007700 - samples/sec: 98.42 - lr: 0.400333\n",
      "2022-08-30 22:12:40,807 epoch 1 - iter 12/48 - loss 0.35556137 - samples/sec: 111.33 - lr: 0.400333\n",
      "2022-08-30 22:12:43,359 epoch 1 - iter 16/48 - loss 0.36076954 - samples/sec: 112.45 - lr: 0.400333\n",
      "2022-08-30 22:12:46,015 epoch 1 - iter 20/48 - loss 0.36055782 - samples/sec: 108.61 - lr: 0.400333\n",
      "2022-08-30 22:12:48,901 epoch 1 - iter 24/48 - loss 0.36958744 - samples/sec: 98.94 - lr: 0.400333\n",
      "2022-08-30 22:12:51,478 epoch 1 - iter 28/48 - loss 0.36807738 - samples/sec: 111.16 - lr: 0.400333\n",
      "2022-08-30 22:12:54,210 epoch 1 - iter 32/48 - loss 0.36688026 - samples/sec: 105.38 - lr: 0.400333\n",
      "2022-08-30 22:12:56,690 epoch 1 - iter 36/48 - loss 0.36807308 - samples/sec: 115.75 - lr: 0.400333\n",
      "2022-08-30 22:12:59,293 epoch 1 - iter 40/48 - loss 0.36457793 - samples/sec: 110.58 - lr: 0.400333\n",
      "2022-08-30 22:13:01,995 epoch 1 - iter 44/48 - loss 0.36827617 - samples/sec: 105.82 - lr: 0.400333\n",
      "2022-08-30 22:13:05,077 epoch 1 - iter 48/48 - loss 0.37731773 - samples/sec: 92.56 - lr: 0.400333\n",
      "2022-08-30 22:13:05,134 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:13:05,134 EPOCH 1 done: loss 0.3773 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:13:05,954 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:13:05,986 DEV : loss 0.2715414762496948 - f1-score (micro avg)  0.9107\n",
      "2022-08-30 22:13:06,003 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:13:06,004 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:13:06,928 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:13:09,351 epoch 2 - iter 4/48 - loss 0.39593391 - samples/sec: 115.65 - lr: 0.400333\n",
      "2022-08-30 22:13:12,219 epoch 2 - iter 8/48 - loss 0.37610099 - samples/sec: 100.39 - lr: 0.400333\n",
      "2022-08-30 22:13:14,838 epoch 2 - iter 12/48 - loss 0.37737035 - samples/sec: 109.38 - lr: 0.400333\n",
      "2022-08-30 22:13:17,472 epoch 2 - iter 16/48 - loss 0.37486227 - samples/sec: 108.65 - lr: 0.400333\n",
      "2022-08-30 22:13:20,218 epoch 2 - iter 20/48 - loss 0.37118474 - samples/sec: 106.38 - lr: 0.400333\n",
      "2022-08-30 22:13:23,273 epoch 2 - iter 24/48 - loss 0.37361609 - samples/sec: 93.49 - lr: 0.400333\n",
      "2022-08-30 22:13:25,909 epoch 2 - iter 28/48 - loss 0.37452389 - samples/sec: 108.53 - lr: 0.400333\n",
      "2022-08-30 22:13:28,674 epoch 2 - iter 32/48 - loss 0.37401994 - samples/sec: 103.55 - lr: 0.400333\n",
      "2022-08-30 22:13:31,699 epoch 2 - iter 36/48 - loss 0.37470922 - samples/sec: 94.53 - lr: 0.400333\n",
      "2022-08-30 22:13:34,238 epoch 2 - iter 40/48 - loss 0.37539022 - samples/sec: 113.09 - lr: 0.400333\n",
      "2022-08-30 22:13:37,236 epoch 2 - iter 44/48 - loss 0.37399161 - samples/sec: 95.17 - lr: 0.400333\n",
      "2022-08-30 22:13:40,017 epoch 2 - iter 48/48 - loss 0.37468378 - samples/sec: 102.79 - lr: 0.400333\n",
      "2022-08-30 22:13:40,078 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:13:40,079 EPOCH 2 done: loss 0.3747 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:13:40,952 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:13:40,986 DEV : loss 0.26979395747184753 - f1-score (micro avg)  0.9152\n",
      "2022-08-30 22:13:41,009 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:13:41,010 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:13:41,997 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:13:44,504 epoch 3 - iter 4/48 - loss 0.38959101 - samples/sec: 111.73 - lr: 0.400333\n",
      "2022-08-30 22:13:47,392 epoch 3 - iter 8/48 - loss 0.37978620 - samples/sec: 99.15 - lr: 0.400333\n",
      "2022-08-30 22:13:50,350 epoch 3 - iter 12/48 - loss 0.37167684 - samples/sec: 97.59 - lr: 0.400333\n",
      "2022-08-30 22:13:53,121 epoch 3 - iter 16/48 - loss 0.37247116 - samples/sec: 104.24 - lr: 0.400333\n",
      "2022-08-30 22:13:55,716 epoch 3 - iter 20/48 - loss 0.37376460 - samples/sec: 110.54 - lr: 0.400333\n",
      "2022-08-30 22:13:58,262 epoch 3 - iter 24/48 - loss 0.37125700 - samples/sec: 112.99 - lr: 0.400333\n",
      "2022-08-30 22:14:00,952 epoch 3 - iter 28/48 - loss 0.37267982 - samples/sec: 106.50 - lr: 0.400333\n",
      "2022-08-30 22:14:03,725 epoch 3 - iter 32/48 - loss 0.37100142 - samples/sec: 103.05 - lr: 0.400333\n",
      "2022-08-30 22:14:06,731 epoch 3 - iter 36/48 - loss 0.37078082 - samples/sec: 94.92 - lr: 0.400333\n",
      "2022-08-30 22:14:09,599 epoch 3 - iter 40/48 - loss 0.37057929 - samples/sec: 99.68 - lr: 0.400333\n",
      "2022-08-30 22:14:12,837 epoch 3 - iter 44/48 - loss 0.37033484 - samples/sec: 88.24 - lr: 0.400333\n",
      "2022-08-30 22:14:15,152 epoch 3 - iter 48/48 - loss 0.37095849 - samples/sec: 124.33 - lr: 0.400333\n",
      "2022-08-30 22:14:15,218 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:14:15,219 EPOCH 3 done: loss 0.3710 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:14:17,420 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:14:17,451 DEV : loss 0.2604626715183258 - f1-score (micro avg)  0.9168\n",
      "2022-08-30 22:14:17,466 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:14:17,467 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:14:18,316 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:14:20,812 epoch 4 - iter 4/48 - loss 0.38607377 - samples/sec: 112.36 - lr: 0.400333\n",
      "2022-08-30 22:14:23,760 epoch 4 - iter 8/48 - loss 0.38175128 - samples/sec: 97.32 - lr: 0.400333\n",
      "2022-08-30 22:14:26,802 epoch 4 - iter 12/48 - loss 0.38000283 - samples/sec: 93.87 - lr: 0.400333\n",
      "2022-08-30 22:14:29,531 epoch 4 - iter 16/48 - loss 0.37510230 - samples/sec: 104.79 - lr: 0.400333\n",
      "2022-08-30 22:14:32,039 epoch 4 - iter 20/48 - loss 0.37528029 - samples/sec: 114.31 - lr: 0.400333\n",
      "2022-08-30 22:14:34,879 epoch 4 - iter 24/48 - loss 0.37221852 - samples/sec: 100.76 - lr: 0.400333\n",
      "2022-08-30 22:14:37,513 epoch 4 - iter 28/48 - loss 0.37268952 - samples/sec: 108.97 - lr: 0.400333\n",
      "2022-08-30 22:14:40,537 epoch 4 - iter 32/48 - loss 0.37056432 - samples/sec: 94.82 - lr: 0.400333\n",
      "2022-08-30 22:14:43,554 epoch 4 - iter 36/48 - loss 0.37089867 - samples/sec: 95.47 - lr: 0.400333\n",
      "2022-08-30 22:14:46,510 epoch 4 - iter 40/48 - loss 0.37236350 - samples/sec: 96.67 - lr: 0.400333\n",
      "2022-08-30 22:14:49,203 epoch 4 - iter 44/48 - loss 0.37132428 - samples/sec: 107.26 - lr: 0.400333\n",
      "2022-08-30 22:14:51,522 epoch 4 - iter 48/48 - loss 0.37105273 - samples/sec: 123.95 - lr: 0.400333\n",
      "2022-08-30 22:14:51,592 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:14:51,593 EPOCH 4 done: loss 0.3711 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:14:52,406 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:14:52,436 DEV : loss 0.2569999694824219 - f1-score (micro avg)  0.9152\n",
      "2022-08-30 22:14:52,452 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:14:52,453 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:14:54,936 epoch 5 - iter 4/48 - loss 0.37175479 - samples/sec: 112.86 - lr: 0.400333\n",
      "2022-08-30 22:14:57,854 epoch 5 - iter 8/48 - loss 0.37410723 - samples/sec: 98.14 - lr: 0.400333\n",
      "2022-08-30 22:15:00,771 epoch 5 - iter 12/48 - loss 0.37001768 - samples/sec: 98.18 - lr: 0.400333\n",
      "2022-08-30 22:15:04,060 epoch 5 - iter 16/48 - loss 0.38067766 - samples/sec: 86.65 - lr: 0.400333\n",
      "2022-08-30 22:15:06,760 epoch 5 - iter 20/48 - loss 0.37890556 - samples/sec: 106.20 - lr: 0.400333\n",
      "2022-08-30 22:15:09,449 epoch 5 - iter 24/48 - loss 0.37656150 - samples/sec: 106.86 - lr: 0.400333\n",
      "2022-08-30 22:15:12,472 epoch 5 - iter 28/48 - loss 0.37832236 - samples/sec: 94.84 - lr: 0.400333\n",
      "2022-08-30 22:15:15,001 epoch 5 - iter 32/48 - loss 0.37429213 - samples/sec: 113.89 - lr: 0.400333\n",
      "2022-08-30 22:15:18,249 epoch 5 - iter 36/48 - loss 0.37779451 - samples/sec: 87.81 - lr: 0.400333\n",
      "2022-08-30 22:15:20,918 epoch 5 - iter 40/48 - loss 0.37743791 - samples/sec: 107.11 - lr: 0.400333\n",
      "2022-08-30 22:15:23,656 epoch 5 - iter 44/48 - loss 0.37722639 - samples/sec: 104.48 - lr: 0.400333\n",
      "2022-08-30 22:15:26,119 epoch 5 - iter 48/48 - loss 0.37753714 - samples/sec: 116.89 - lr: 0.400333\n",
      "2022-08-30 22:15:26,178 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:15:26,179 EPOCH 5 done: loss 0.3775 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:15:27,024 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:15:27,052 DEV : loss 0.25382694602012634 - f1-score (micro avg)  0.9159\n",
      "2022-08-30 22:15:27,071 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:15:27,072 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:15:29,625 epoch 6 - iter 4/48 - loss 0.34950313 - samples/sec: 109.72 - lr: 0.400333\n",
      "2022-08-30 22:15:32,464 epoch 6 - iter 8/48 - loss 0.35840510 - samples/sec: 100.76 - lr: 0.400333\n",
      "2022-08-30 22:15:35,254 epoch 6 - iter 12/48 - loss 0.36685260 - samples/sec: 103.55 - lr: 0.400333\n",
      "2022-08-30 22:15:37,856 epoch 6 - iter 16/48 - loss 0.36884130 - samples/sec: 110.11 - lr: 0.400333\n",
      "2022-08-30 22:15:40,269 epoch 6 - iter 20/48 - loss 0.36734112 - samples/sec: 118.95 - lr: 0.400333\n",
      "2022-08-30 22:15:43,145 epoch 6 - iter 24/48 - loss 0.36921487 - samples/sec: 99.40 - lr: 0.400333\n",
      "2022-08-30 22:15:45,779 epoch 6 - iter 28/48 - loss 0.36998168 - samples/sec: 109.16 - lr: 0.400333\n",
      "2022-08-30 22:15:48,578 epoch 6 - iter 32/48 - loss 0.37114223 - samples/sec: 102.23 - lr: 0.400333\n",
      "2022-08-30 22:15:51,881 epoch 6 - iter 36/48 - loss 0.37256736 - samples/sec: 86.29 - lr: 0.400333\n",
      "2022-08-30 22:15:54,539 epoch 6 - iter 40/48 - loss 0.37576978 - samples/sec: 107.73 - lr: 0.400333\n",
      "2022-08-30 22:15:57,492 epoch 6 - iter 44/48 - loss 0.37518897 - samples/sec: 96.85 - lr: 0.400333\n",
      "2022-08-30 22:15:59,686 epoch 6 - iter 48/48 - loss 0.37437969 - samples/sec: 132.51 - lr: 0.400333\n",
      "2022-08-30 22:15:59,744 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:15:59,745 EPOCH 6 done: loss 0.3744 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:16:00,551 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:16:00,581 DEV : loss 0.24959072470664978 - f1-score (micro avg)  0.9152\n",
      "2022-08-30 22:16:00,599 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 22:16:00,600 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:16:03,268 epoch 7 - iter 4/48 - loss 0.36989917 - samples/sec: 104.99 - lr: 0.400333\n",
      "2022-08-30 22:16:06,439 epoch 7 - iter 8/48 - loss 0.37881073 - samples/sec: 89.97 - lr: 0.400333\n",
      "2022-08-30 22:16:08,870 epoch 7 - iter 12/48 - loss 0.38196224 - samples/sec: 118.54 - lr: 0.400333\n",
      "2022-08-30 22:16:11,589 epoch 7 - iter 16/48 - loss 0.37692164 - samples/sec: 105.26 - lr: 0.400333\n",
      "2022-08-30 22:16:14,266 epoch 7 - iter 20/48 - loss 0.37187012 - samples/sec: 108.15 - lr: 0.400333\n",
      "2022-08-30 22:16:17,219 epoch 7 - iter 24/48 - loss 0.37570202 - samples/sec: 96.79 - lr: 0.400333\n",
      "2022-08-30 22:16:19,960 epoch 7 - iter 28/48 - loss 0.37421605 - samples/sec: 104.52 - lr: 0.400333\n",
      "2022-08-30 22:16:22,840 epoch 7 - iter 32/48 - loss 0.37541476 - samples/sec: 99.11 - lr: 0.400333\n",
      "2022-08-30 22:16:25,337 epoch 7 - iter 36/48 - loss 0.37532476 - samples/sec: 114.85 - lr: 0.400333\n",
      "2022-08-30 22:16:28,175 epoch 7 - iter 40/48 - loss 0.37291048 - samples/sec: 101.34 - lr: 0.400333\n",
      "2022-08-30 22:16:30,930 epoch 7 - iter 44/48 - loss 0.37064564 - samples/sec: 104.28 - lr: 0.400333\n",
      "2022-08-30 22:16:33,194 epoch 7 - iter 48/48 - loss 0.36961635 - samples/sec: 127.16 - lr: 0.400333\n",
      "2022-08-30 22:16:33,254 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:16:33,255 EPOCH 7 done: loss 0.3696 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:16:34,110 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:16:34,139 DEV : loss 0.2538983225822449 - f1-score (micro avg)  0.9144\n",
      "2022-08-30 22:16:34,154 Epoch     7: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 22:16:34,154 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 22:16:34,155 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:16:37,365 epoch 8 - iter 4/48 - loss 0.34841231 - samples/sec: 87.29 - lr: 0.200167\n",
      "2022-08-30 22:16:39,918 epoch 8 - iter 8/48 - loss 0.35562862 - samples/sec: 113.21 - lr: 0.200167\n",
      "2022-08-30 22:16:42,628 epoch 8 - iter 12/48 - loss 0.36053148 - samples/sec: 105.78 - lr: 0.200167\n",
      "2022-08-30 22:16:45,620 epoch 8 - iter 16/48 - loss 0.36205664 - samples/sec: 95.66 - lr: 0.200167\n",
      "2022-08-30 22:16:48,232 epoch 8 - iter 20/48 - loss 0.35992915 - samples/sec: 110.32 - lr: 0.200167\n",
      "2022-08-30 22:16:51,428 epoch 8 - iter 24/48 - loss 0.35661520 - samples/sec: 89.14 - lr: 0.200167\n",
      "2022-08-30 22:16:53,912 epoch 8 - iter 28/48 - loss 0.35362560 - samples/sec: 116.62 - lr: 0.200167\n",
      "2022-08-30 22:16:56,422 epoch 8 - iter 32/48 - loss 0.35293138 - samples/sec: 114.19 - lr: 0.200167\n",
      "2022-08-30 22:16:59,074 epoch 8 - iter 36/48 - loss 0.34925769 - samples/sec: 108.32 - lr: 0.200167\n",
      "2022-08-30 22:17:01,896 epoch 8 - iter 40/48 - loss 0.34945766 - samples/sec: 101.49 - lr: 0.200167\n",
      "2022-08-30 22:17:04,752 epoch 8 - iter 44/48 - loss 0.34999586 - samples/sec: 100.43 - lr: 0.200167\n",
      "2022-08-30 22:17:07,278 epoch 8 - iter 48/48 - loss 0.34994443 - samples/sec: 113.50 - lr: 0.200167\n",
      "2022-08-30 22:17:07,334 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:17:07,334 EPOCH 8 done: loss 0.3499 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:17:08,181 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:17:08,212 DEV : loss 0.2426922768354416 - f1-score (micro avg)  0.9201\n",
      "2022-08-30 22:17:08,227 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:17:08,228 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:17:08,935 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:17:11,771 epoch 9 - iter 4/48 - loss 0.35495696 - samples/sec: 98.82 - lr: 0.200167\n",
      "2022-08-30 22:17:14,092 epoch 9 - iter 8/48 - loss 0.35120045 - samples/sec: 124.22 - lr: 0.200167\n",
      "2022-08-30 22:17:16,866 epoch 9 - iter 12/48 - loss 0.34457738 - samples/sec: 103.35 - lr: 0.200167\n",
      "2022-08-30 22:17:19,185 epoch 9 - iter 16/48 - loss 0.34747271 - samples/sec: 123.67 - lr: 0.200167\n",
      "2022-08-30 22:17:21,814 epoch 9 - iter 20/48 - loss 0.34813940 - samples/sec: 109.12 - lr: 0.200167\n",
      "2022-08-30 22:17:24,505 epoch 9 - iter 24/48 - loss 0.34947679 - samples/sec: 106.46 - lr: 0.200167\n",
      "2022-08-30 22:17:27,548 epoch 9 - iter 28/48 - loss 0.34877430 - samples/sec: 94.15 - lr: 0.200167\n",
      "2022-08-30 22:17:30,594 epoch 9 - iter 32/48 - loss 0.34831293 - samples/sec: 94.72 - lr: 0.200167\n",
      "2022-08-30 22:17:33,969 epoch 9 - iter 36/48 - loss 0.34819976 - samples/sec: 84.40 - lr: 0.200167\n",
      "2022-08-30 22:17:36,579 epoch 9 - iter 40/48 - loss 0.34753132 - samples/sec: 110.75 - lr: 0.200167\n",
      "2022-08-30 22:17:39,043 epoch 9 - iter 44/48 - loss 0.35059061 - samples/sec: 116.95 - lr: 0.200167\n",
      "2022-08-30 22:17:41,709 epoch 9 - iter 48/48 - loss 0.35137947 - samples/sec: 107.19 - lr: 0.200167\n",
      "2022-08-30 22:17:41,766 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:17:41,767 EPOCH 9 done: loss 0.3514 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:17:42,561 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:17:42,591 DEV : loss 0.24209104478359222 - f1-score (micro avg)  0.9204\n",
      "2022-08-30 22:17:42,612 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:17:42,614 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:17:43,302 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:17:45,909 epoch 10 - iter 4/48 - loss 0.35591028 - samples/sec: 107.49 - lr: 0.200167\n",
      "2022-08-30 22:17:48,550 epoch 10 - iter 8/48 - loss 0.34340609 - samples/sec: 108.41 - lr: 0.200167\n",
      "2022-08-30 22:17:51,498 epoch 10 - iter 12/48 - loss 0.34132396 - samples/sec: 97.39 - lr: 0.200167\n",
      "2022-08-30 22:17:54,717 epoch 10 - iter 16/48 - loss 0.34514425 - samples/sec: 89.10 - lr: 0.200167\n",
      "2022-08-30 22:17:57,694 epoch 10 - iter 20/48 - loss 0.34656221 - samples/sec: 96.35 - lr: 0.200167\n",
      "2022-08-30 22:18:00,243 epoch 10 - iter 24/48 - loss 0.34145012 - samples/sec: 112.99 - lr: 0.200167\n",
      "2022-08-30 22:18:03,144 epoch 10 - iter 28/48 - loss 0.34103078 - samples/sec: 98.94 - lr: 0.200167\n",
      "2022-08-30 22:18:05,656 epoch 10 - iter 32/48 - loss 0.34358516 - samples/sec: 114.15 - lr: 0.200167\n",
      "2022-08-30 22:18:08,180 epoch 10 - iter 36/48 - loss 0.34603204 - samples/sec: 113.45 - lr: 0.200167\n",
      "2022-08-30 22:18:10,832 epoch 10 - iter 40/48 - loss 0.34656254 - samples/sec: 107.94 - lr: 0.200167\n",
      "2022-08-30 22:18:13,737 epoch 10 - iter 44/48 - loss 0.34414402 - samples/sec: 98.52 - lr: 0.200167\n",
      "2022-08-30 22:18:16,315 epoch 10 - iter 48/48 - loss 0.34503323 - samples/sec: 111.11 - lr: 0.200167\n",
      "2022-08-30 22:18:16,396 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:18:16,398 EPOCH 10 done: loss 0.3450 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:18:17,197 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:18:17,227 DEV : loss 0.23824888467788696 - f1-score (micro avg)  0.9209\n",
      "2022-08-30 22:18:17,244 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:18:17,244 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:18:18,638 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:18:18,639 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 22:18:18,821 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:18:20,207 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:18:20,234 0.9248\t0.9248\t0.9248\t0.9248\n",
      "2022-08-30 22:18:20,237 \n",
      "Results:\n",
      "- F-score (micro) 0.9248\n",
      "- F-score (macro) 0.8686\n",
      "- Accuracy 0.9248\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.9120    0.9039    0.9079      1353\n",
      "         ADJ     0.8722    0.9241    0.8974       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9902    0.9844    0.9873       514\n",
      "        VERB     0.8996    0.9176    0.9085       449\n",
      "       PROPN     0.7817    0.7572    0.7692       383\n",
      "         AUX     0.9910    0.9910    0.9910       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9945    0.9891    0.9918       184\n",
      "         DET     0.8947    0.8447    0.8690       161\n",
      "         ADV     0.8365    0.8808    0.8581       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9649    0.7746    0.8594        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9248      5264\n",
      "   macro avg     0.8829    0.8573    0.8686      5264\n",
      "weighted avg     0.9258    0.9248    0.9249      5264\n",
      "\n",
      "2022-08-30 22:18:20,238 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:18:20,239 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 22:18:20,749 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 7 #######################\n",
      "#######################################################\n",
      "2022-08-30 22:20:44,770 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:20:44,771 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 22:20:44,772 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:20:44,772 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 22:20:44,773 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:20:44,774 Parameters:\n",
      "2022-08-30 22:20:44,774  - learning_rate: \"0.400333\"\n",
      "2022-08-30 22:20:44,775  - mini_batch_size: \"70\"\n",
      "2022-08-30 22:20:44,775  - patience: \"3\"\n",
      "2022-08-30 22:20:44,776  - anneal_factor: \"0.5\"\n",
      "2022-08-30 22:20:44,776  - max_epochs: \"11\"\n",
      "2022-08-30 22:20:44,778  - shuffle: \"True\"\n",
      "2022-08-30 22:20:44,778  - train_with_dev: \"False\"\n",
      "2022-08-30 22:20:44,778  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 22:20:44,779 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:20:44,779 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 22:20:44,780 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:20:44,781 Device: cpu\n",
      "2022-08-30 22:20:44,781 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:20:44,782 Embeddings storage mode: cpu\n",
      "2022-08-30 22:20:44,782 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:20:47,273 epoch 1 - iter 4/48 - loss 0.31915456 - samples/sec: 112.45 - lr: 0.400333\n",
      "2022-08-30 22:20:50,511 epoch 1 - iter 8/48 - loss 0.34221998 - samples/sec: 88.66 - lr: 0.400333\n",
      "2022-08-30 22:20:52,940 epoch 1 - iter 12/48 - loss 0.34232488 - samples/sec: 118.54 - lr: 0.400333\n",
      "2022-08-30 22:20:55,768 epoch 1 - iter 16/48 - loss 0.34095872 - samples/sec: 101.78 - lr: 0.400333\n",
      "2022-08-30 22:20:58,374 epoch 1 - iter 20/48 - loss 0.33835740 - samples/sec: 110.32 - lr: 0.400333\n",
      "2022-08-30 22:21:01,190 epoch 1 - iter 24/48 - loss 0.34270743 - samples/sec: 102.15 - lr: 0.400333\n",
      "2022-08-30 22:21:04,109 epoch 1 - iter 28/48 - loss 0.34337774 - samples/sec: 97.94 - lr: 0.400333\n",
      "2022-08-30 22:21:06,942 epoch 1 - iter 32/48 - loss 0.34336266 - samples/sec: 101.34 - lr: 0.400333\n",
      "2022-08-30 22:21:09,549 epoch 1 - iter 36/48 - loss 0.34499843 - samples/sec: 109.80 - lr: 0.400333\n",
      "2022-08-30 22:21:12,248 epoch 1 - iter 40/48 - loss 0.34284474 - samples/sec: 106.50 - lr: 0.400333\n",
      "2022-08-30 22:21:14,935 epoch 1 - iter 44/48 - loss 0.35094623 - samples/sec: 106.87 - lr: 0.400333\n",
      "2022-08-30 22:21:17,894 epoch 1 - iter 48/48 - loss 0.36260430 - samples/sec: 96.62 - lr: 0.400333\n",
      "2022-08-30 22:21:17,955 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:21:17,956 EPOCH 1 done: loss 0.3626 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:21:18,759 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:21:18,788 DEV : loss 0.26958104968070984 - f1-score (micro avg)  0.9103\n",
      "2022-08-30 22:21:18,804 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:21:18,805 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:21:19,624 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:21:22,326 epoch 2 - iter 4/48 - loss 0.38081097 - samples/sec: 103.70 - lr: 0.400333\n",
      "2022-08-30 22:21:25,273 epoch 2 - iter 8/48 - loss 0.36421120 - samples/sec: 97.56 - lr: 0.400333\n",
      "2022-08-30 22:21:28,166 epoch 2 - iter 12/48 - loss 0.35946235 - samples/sec: 98.77 - lr: 0.400333\n",
      "2022-08-30 22:21:30,731 epoch 2 - iter 16/48 - loss 0.35892628 - samples/sec: 111.87 - lr: 0.400333\n",
      "2022-08-30 22:21:33,241 epoch 2 - iter 20/48 - loss 0.36156879 - samples/sec: 114.24 - lr: 0.400333\n",
      "2022-08-30 22:21:35,963 epoch 2 - iter 24/48 - loss 0.36581561 - samples/sec: 105.26 - lr: 0.400333\n",
      "2022-08-30 22:21:38,814 epoch 2 - iter 28/48 - loss 0.36986037 - samples/sec: 100.61 - lr: 0.400333\n",
      "2022-08-30 22:21:41,392 epoch 2 - iter 32/48 - loss 0.36930338 - samples/sec: 112.59 - lr: 0.400333\n",
      "2022-08-30 22:21:43,920 epoch 2 - iter 36/48 - loss 0.36972958 - samples/sec: 115.27 - lr: 0.400333\n",
      "2022-08-30 22:21:46,973 epoch 2 - iter 40/48 - loss 0.36888239 - samples/sec: 93.61 - lr: 0.400333\n",
      "2022-08-30 22:21:50,204 epoch 2 - iter 44/48 - loss 0.36761307 - samples/sec: 88.47 - lr: 0.400333\n",
      "2022-08-30 22:21:52,831 epoch 2 - iter 48/48 - loss 0.36914224 - samples/sec: 109.03 - lr: 0.400333\n",
      "2022-08-30 22:21:52,896 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:21:52,896 EPOCH 2 done: loss 0.3691 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:21:53,696 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:21:53,725 DEV : loss 0.2544725835323334 - f1-score (micro avg)  0.9162\n",
      "2022-08-30 22:21:53,739 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:21:53,740 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:21:54,611 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:21:57,056 epoch 3 - iter 4/48 - loss 0.36973936 - samples/sec: 114.66 - lr: 0.400333\n",
      "2022-08-30 22:21:59,734 epoch 3 - iter 8/48 - loss 0.37004649 - samples/sec: 107.24 - lr: 0.400333\n",
      "2022-08-30 22:22:02,596 epoch 3 - iter 12/48 - loss 0.37201511 - samples/sec: 100.00 - lr: 0.400333\n",
      "2022-08-30 22:22:05,050 epoch 3 - iter 16/48 - loss 0.36979665 - samples/sec: 117.01 - lr: 0.400333\n",
      "2022-08-30 22:22:07,555 epoch 3 - iter 20/48 - loss 0.37253701 - samples/sec: 114.61 - lr: 0.400333\n",
      "2022-08-30 22:22:10,282 epoch 3 - iter 24/48 - loss 0.37242177 - samples/sec: 105.38 - lr: 0.400333\n",
      "2022-08-30 22:22:12,911 epoch 3 - iter 28/48 - loss 0.37236932 - samples/sec: 108.99 - lr: 0.400333\n",
      "2022-08-30 22:22:15,841 epoch 3 - iter 32/48 - loss 0.37252251 - samples/sec: 97.94 - lr: 0.400333\n",
      "2022-08-30 22:22:19,080 epoch 3 - iter 36/48 - loss 0.37277809 - samples/sec: 88.11 - lr: 0.400333\n",
      "2022-08-30 22:22:21,882 epoch 3 - iter 40/48 - loss 0.37501876 - samples/sec: 102.08 - lr: 0.400333\n",
      "2022-08-30 22:22:24,982 epoch 3 - iter 44/48 - loss 0.37412384 - samples/sec: 92.17 - lr: 0.400333\n",
      "2022-08-30 22:22:27,817 epoch 3 - iter 48/48 - loss 0.37316980 - samples/sec: 100.79 - lr: 0.400333\n",
      "2022-08-30 22:22:27,876 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:22:27,877 EPOCH 3 done: loss 0.3732 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:22:28,710 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:22:28,742 DEV : loss 0.25242680311203003 - f1-score (micro avg)  0.9154\n",
      "2022-08-30 22:22:28,764 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:22:28,765 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:22:31,799 epoch 4 - iter 4/48 - loss 0.36273783 - samples/sec: 92.32 - lr: 0.400333\n",
      "2022-08-30 22:22:34,247 epoch 4 - iter 8/48 - loss 0.36978555 - samples/sec: 117.15 - lr: 0.400333\n",
      "2022-08-30 22:22:36,907 epoch 4 - iter 12/48 - loss 0.36355428 - samples/sec: 107.78 - lr: 0.400333\n",
      "2022-08-30 22:22:39,495 epoch 4 - iter 16/48 - loss 0.36712423 - samples/sec: 110.76 - lr: 0.400333\n",
      "2022-08-30 22:22:42,163 epoch 4 - iter 20/48 - loss 0.36983405 - samples/sec: 107.61 - lr: 0.400333\n",
      "2022-08-30 22:22:45,048 epoch 4 - iter 24/48 - loss 0.36817759 - samples/sec: 99.01 - lr: 0.400333\n",
      "2022-08-30 22:22:48,236 epoch 4 - iter 28/48 - loss 0.36526767 - samples/sec: 89.46 - lr: 0.400333\n",
      "2022-08-30 22:22:50,902 epoch 4 - iter 32/48 - loss 0.36503027 - samples/sec: 107.32 - lr: 0.400333\n",
      "2022-08-30 22:22:53,720 epoch 4 - iter 36/48 - loss 0.36571860 - samples/sec: 101.86 - lr: 0.400333\n",
      "2022-08-30 22:22:56,494 epoch 4 - iter 40/48 - loss 0.36586530 - samples/sec: 103.13 - lr: 0.400333\n",
      "2022-08-30 22:22:59,228 epoch 4 - iter 44/48 - loss 0.36639862 - samples/sec: 105.42 - lr: 0.400333\n",
      "2022-08-30 22:23:01,758 epoch 4 - iter 48/48 - loss 0.36716729 - samples/sec: 113.27 - lr: 0.400333\n",
      "2022-08-30 22:23:01,826 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:23:01,826 EPOCH 4 done: loss 0.3672 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:23:02,606 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:23:02,635 DEV : loss 0.2619665265083313 - f1-score (micro avg)  0.9133\n",
      "2022-08-30 22:23:02,653 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:23:02,655 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:23:05,117 epoch 5 - iter 4/48 - loss 0.37136752 - samples/sec: 113.82 - lr: 0.400333\n",
      "2022-08-30 22:23:08,109 epoch 5 - iter 8/48 - loss 0.36276444 - samples/sec: 95.50 - lr: 0.400333\n",
      "2022-08-30 22:23:10,913 epoch 5 - iter 12/48 - loss 0.35506901 - samples/sec: 102.26 - lr: 0.400333\n",
      "2022-08-30 22:23:13,547 epoch 5 - iter 16/48 - loss 0.35941605 - samples/sec: 108.74 - lr: 0.400333\n",
      "2022-08-30 22:23:16,482 epoch 5 - iter 20/48 - loss 0.35973354 - samples/sec: 97.63 - lr: 0.400333\n",
      "2022-08-30 22:23:19,040 epoch 5 - iter 24/48 - loss 0.35935527 - samples/sec: 112.59 - lr: 0.400333\n",
      "2022-08-30 22:23:21,742 epoch 5 - iter 28/48 - loss 0.35852996 - samples/sec: 106.14 - lr: 0.400333\n",
      "2022-08-30 22:23:24,679 epoch 5 - iter 32/48 - loss 0.35829642 - samples/sec: 97.63 - lr: 0.400333\n",
      "2022-08-30 22:23:27,207 epoch 5 - iter 36/48 - loss 0.36047892 - samples/sec: 113.87 - lr: 0.400333\n",
      "2022-08-30 22:23:30,267 epoch 5 - iter 40/48 - loss 0.36107835 - samples/sec: 93.46 - lr: 0.400333\n",
      "2022-08-30 22:23:32,967 epoch 5 - iter 44/48 - loss 0.36324787 - samples/sec: 106.06 - lr: 0.400333\n",
      "2022-08-30 22:23:35,388 epoch 5 - iter 48/48 - loss 0.36326012 - samples/sec: 118.44 - lr: 0.400333\n",
      "2022-08-30 22:23:35,461 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:23:35,461 EPOCH 5 done: loss 0.3633 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:23:36,319 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:23:36,348 DEV : loss 0.25483426451683044 - f1-score (micro avg)  0.9181\n",
      "2022-08-30 22:23:36,373 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:23:36,375 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:23:37,377 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:23:40,050 epoch 6 - iter 4/48 - loss 0.37048382 - samples/sec: 104.83 - lr: 0.400333\n",
      "2022-08-30 22:23:42,932 epoch 6 - iter 8/48 - loss 0.37186609 - samples/sec: 99.33 - lr: 0.400333\n",
      "2022-08-30 22:23:45,731 epoch 6 - iter 12/48 - loss 0.37490850 - samples/sec: 102.83 - lr: 0.400333\n",
      "2022-08-30 22:23:48,584 epoch 6 - iter 16/48 - loss 0.37223741 - samples/sec: 100.29 - lr: 0.400333\n",
      "2022-08-30 22:23:51,745 epoch 6 - iter 20/48 - loss 0.37297768 - samples/sec: 90.38 - lr: 0.400333\n",
      "2022-08-30 22:23:54,907 epoch 6 - iter 24/48 - loss 0.37372181 - samples/sec: 90.53 - lr: 0.400333\n",
      "2022-08-30 22:23:57,370 epoch 6 - iter 28/48 - loss 0.37181861 - samples/sec: 116.42 - lr: 0.400333\n",
      "2022-08-30 22:23:59,856 epoch 6 - iter 32/48 - loss 0.36950869 - samples/sec: 115.80 - lr: 0.400333\n",
      "2022-08-30 22:24:02,508 epoch 6 - iter 36/48 - loss 0.36936823 - samples/sec: 108.28 - lr: 0.400333\n",
      "2022-08-30 22:24:05,151 epoch 6 - iter 40/48 - loss 0.36918191 - samples/sec: 109.85 - lr: 0.400333\n",
      "2022-08-30 22:24:07,767 epoch 6 - iter 44/48 - loss 0.36773739 - samples/sec: 109.59 - lr: 0.400333\n",
      "2022-08-30 22:24:10,722 epoch 6 - iter 48/48 - loss 0.36732754 - samples/sec: 96.89 - lr: 0.400333\n",
      "2022-08-30 22:24:10,803 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:24:10,804 EPOCH 6 done: loss 0.3673 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:24:11,691 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:24:11,720 DEV : loss 0.24587641656398773 - f1-score (micro avg)  0.9167\n",
      "2022-08-30 22:24:11,741 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:24:11,743 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:24:14,244 epoch 7 - iter 4/48 - loss 0.35870716 - samples/sec: 112.00 - lr: 0.400333\n",
      "2022-08-30 22:24:17,159 epoch 7 - iter 8/48 - loss 0.35987857 - samples/sec: 98.14 - lr: 0.400333\n",
      "2022-08-30 22:24:19,862 epoch 7 - iter 12/48 - loss 0.36096767 - samples/sec: 106.22 - lr: 0.400333\n",
      "2022-08-30 22:24:23,277 epoch 7 - iter 16/48 - loss 0.36152417 - samples/sec: 83.48 - lr: 0.400333\n",
      "2022-08-30 22:24:26,227 epoch 7 - iter 20/48 - loss 0.36304212 - samples/sec: 97.02 - lr: 0.400333\n",
      "2022-08-30 22:24:28,790 epoch 7 - iter 24/48 - loss 0.36365848 - samples/sec: 111.64 - lr: 0.400333\n",
      "2022-08-30 22:24:31,241 epoch 7 - iter 28/48 - loss 0.36296589 - samples/sec: 118.04 - lr: 0.400333\n",
      "2022-08-30 22:24:33,965 epoch 7 - iter 32/48 - loss 0.36296089 - samples/sec: 105.26 - lr: 0.400333\n",
      "2022-08-30 22:24:36,521 epoch 7 - iter 36/48 - loss 0.36396560 - samples/sec: 112.40 - lr: 0.400333\n",
      "2022-08-30 22:24:39,243 epoch 7 - iter 40/48 - loss 0.36439295 - samples/sec: 105.70 - lr: 0.400333\n",
      "2022-08-30 22:24:41,851 epoch 7 - iter 44/48 - loss 0.36506069 - samples/sec: 109.76 - lr: 0.400333\n",
      "2022-08-30 22:24:44,454 epoch 7 - iter 48/48 - loss 0.36396168 - samples/sec: 109.98 - lr: 0.400333\n",
      "2022-08-30 22:24:44,517 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:24:44,518 EPOCH 7 done: loss 0.3640 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:24:45,328 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:24:45,358 DEV : loss 0.24552710354328156 - f1-score (micro avg)  0.9159\n",
      "2022-08-30 22:24:45,378 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:24:45,381 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:24:48,047 epoch 8 - iter 4/48 - loss 0.37070945 - samples/sec: 105.18 - lr: 0.400333\n",
      "2022-08-30 22:24:51,190 epoch 8 - iter 8/48 - loss 0.37842925 - samples/sec: 90.85 - lr: 0.400333\n",
      "2022-08-30 22:24:53,865 epoch 8 - iter 12/48 - loss 0.36973887 - samples/sec: 107.24 - lr: 0.400333\n",
      "2022-08-30 22:24:56,311 epoch 8 - iter 16/48 - loss 0.36107730 - samples/sec: 117.15 - lr: 0.400333\n",
      "2022-08-30 22:24:59,236 epoch 8 - iter 20/48 - loss 0.36234014 - samples/sec: 98.21 - lr: 0.400333\n",
      "2022-08-30 22:25:01,511 epoch 8 - iter 24/48 - loss 0.36012529 - samples/sec: 126.18 - lr: 0.400333\n",
      "2022-08-30 22:25:04,288 epoch 8 - iter 28/48 - loss 0.36045921 - samples/sec: 103.32 - lr: 0.400333\n",
      "2022-08-30 22:25:06,969 epoch 8 - iter 32/48 - loss 0.36000190 - samples/sec: 106.79 - lr: 0.400333\n",
      "2022-08-30 22:25:09,721 epoch 8 - iter 36/48 - loss 0.36343712 - samples/sec: 104.21 - lr: 0.400333\n",
      "2022-08-30 22:25:12,698 epoch 8 - iter 40/48 - loss 0.36315561 - samples/sec: 95.86 - lr: 0.400333\n",
      "2022-08-30 22:25:15,410 epoch 8 - iter 44/48 - loss 0.36743236 - samples/sec: 105.70 - lr: 0.400333\n",
      "2022-08-30 22:25:17,874 epoch 8 - iter 48/48 - loss 0.36659063 - samples/sec: 118.80 - lr: 0.400333\n",
      "2022-08-30 22:25:17,943 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:25:17,944 EPOCH 8 done: loss 0.3666 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:25:18,763 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:25:18,793 DEV : loss 0.24491508305072784 - f1-score (micro avg)  0.9233\n",
      "2022-08-30 22:25:18,813 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:25:18,814 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:25:19,621 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:25:22,577 epoch 9 - iter 4/48 - loss 0.34526740 - samples/sec: 94.79 - lr: 0.400333\n",
      "2022-08-30 22:25:26,622 epoch 9 - iter 8/48 - loss 0.36921437 - samples/sec: 70.32 - lr: 0.400333\n",
      "2022-08-30 22:25:29,622 epoch 9 - iter 12/48 - loss 0.37071110 - samples/sec: 95.34 - lr: 0.400333\n",
      "2022-08-30 22:25:32,240 epoch 9 - iter 16/48 - loss 0.36493750 - samples/sec: 109.76 - lr: 0.400333\n",
      "2022-08-30 22:25:35,453 epoch 9 - iter 20/48 - loss 0.36321605 - samples/sec: 88.89 - lr: 0.400333\n",
      "2022-08-30 22:25:38,242 epoch 9 - iter 24/48 - loss 0.36361521 - samples/sec: 102.90 - lr: 0.400333\n",
      "2022-08-30 22:25:40,881 epoch 9 - iter 28/48 - loss 0.36358894 - samples/sec: 108.65 - lr: 0.400333\n",
      "2022-08-30 22:25:43,691 epoch 9 - iter 32/48 - loss 0.36596460 - samples/sec: 101.97 - lr: 0.400333\n",
      "2022-08-30 22:25:46,413 epoch 9 - iter 36/48 - loss 0.36392242 - samples/sec: 105.50 - lr: 0.400333\n",
      "2022-08-30 22:25:49,278 epoch 9 - iter 40/48 - loss 0.36244678 - samples/sec: 100.47 - lr: 0.400333\n",
      "2022-08-30 22:25:51,631 epoch 9 - iter 44/48 - loss 0.36380882 - samples/sec: 122.48 - lr: 0.400333\n",
      "2022-08-30 22:25:53,961 epoch 9 - iter 48/48 - loss 0.36338437 - samples/sec: 123.62 - lr: 0.400333\n",
      "2022-08-30 22:25:54,024 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:25:54,024 EPOCH 9 done: loss 0.3634 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:25:54,885 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:25:54,926 DEV : loss 0.24767345190048218 - f1-score (micro avg)  0.9175\n",
      "2022-08-30 22:25:54,948 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:25:54,949 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:25:57,659 epoch 10 - iter 4/48 - loss 0.38977708 - samples/sec: 103.40 - lr: 0.400333\n",
      "2022-08-30 22:26:00,335 epoch 10 - iter 8/48 - loss 0.38532517 - samples/sec: 107.03 - lr: 0.400333\n",
      "2022-08-30 22:26:03,075 epoch 10 - iter 12/48 - loss 0.38009375 - samples/sec: 104.87 - lr: 0.400333\n",
      "2022-08-30 22:26:05,831 epoch 10 - iter 16/48 - loss 0.37169956 - samples/sec: 103.82 - lr: 0.400333\n",
      "2022-08-30 22:26:08,651 epoch 10 - iter 20/48 - loss 0.36976010 - samples/sec: 101.63 - lr: 0.400333\n",
      "2022-08-30 22:26:11,564 epoch 10 - iter 24/48 - loss 0.36764606 - samples/sec: 98.66 - lr: 0.400333\n",
      "2022-08-30 22:26:14,682 epoch 10 - iter 28/48 - loss 0.36753005 - samples/sec: 91.68 - lr: 0.400333\n",
      "2022-08-30 22:26:17,389 epoch 10 - iter 32/48 - loss 0.36661408 - samples/sec: 105.82 - lr: 0.400333\n",
      "2022-08-30 22:26:19,862 epoch 10 - iter 36/48 - loss 0.36529164 - samples/sec: 116.62 - lr: 0.400333\n",
      "2022-08-30 22:26:22,806 epoch 10 - iter 40/48 - loss 0.36338114 - samples/sec: 97.19 - lr: 0.400333\n",
      "2022-08-30 22:26:25,409 epoch 10 - iter 44/48 - loss 0.36283837 - samples/sec: 110.19 - lr: 0.400333\n",
      "2022-08-30 22:26:27,890 epoch 10 - iter 48/48 - loss 0.36289196 - samples/sec: 116.71 - lr: 0.400333\n",
      "2022-08-30 22:26:27,950 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:26:27,951 EPOCH 10 done: loss 0.3629 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:26:28,758 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:26:28,792 DEV : loss 0.25012722611427307 - f1-score (micro avg)  0.9186\n",
      "2022-08-30 22:26:28,807 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:26:28,808 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:26:31,451 epoch 11 - iter 4/48 - loss 0.37228611 - samples/sec: 105.98 - lr: 0.400333\n",
      "2022-08-30 22:26:34,193 epoch 11 - iter 8/48 - loss 0.36477132 - samples/sec: 104.91 - lr: 0.400333\n",
      "2022-08-30 22:26:37,003 epoch 11 - iter 12/48 - loss 0.36224644 - samples/sec: 101.93 - lr: 0.400333\n",
      "2022-08-30 22:26:39,855 epoch 11 - iter 16/48 - loss 0.35914406 - samples/sec: 100.14 - lr: 0.400333\n",
      "2022-08-30 22:26:42,786 epoch 11 - iter 20/48 - loss 0.35895602 - samples/sec: 97.83 - lr: 0.400333\n",
      "2022-08-30 22:26:45,857 epoch 11 - iter 24/48 - loss 0.35588564 - samples/sec: 93.40 - lr: 0.400333\n",
      "2022-08-30 22:26:48,613 epoch 11 - iter 28/48 - loss 0.35987623 - samples/sec: 104.13 - lr: 0.400333\n",
      "2022-08-30 22:26:51,466 epoch 11 - iter 32/48 - loss 0.36210235 - samples/sec: 100.36 - lr: 0.400333\n",
      "2022-08-30 22:26:54,030 epoch 11 - iter 36/48 - loss 0.36413502 - samples/sec: 112.31 - lr: 0.400333\n",
      "2022-08-30 22:26:56,834 epoch 11 - iter 40/48 - loss 0.36507826 - samples/sec: 102.15 - lr: 0.400333\n",
      "2022-08-30 22:26:59,592 epoch 11 - iter 44/48 - loss 0.36516738 - samples/sec: 103.70 - lr: 0.400333\n",
      "2022-08-30 22:27:02,326 epoch 11 - iter 48/48 - loss 0.36315694 - samples/sec: 105.18 - lr: 0.400333\n",
      "2022-08-30 22:27:02,417 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:27:02,418 EPOCH 11 done: loss 0.3632 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:27:03,236 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:27:03,267 DEV : loss 0.2444651871919632 - f1-score (micro avg)  0.924\n",
      "2022-08-30 22:27:03,284 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:27:03,285 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:27:05,532 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:27:05,533 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 22:27:05,718 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:27:07,060 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:27:07,086 0.9219\t0.9219\t0.9219\t0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:27:07,087 \n",
      "Results:\n",
      "- F-score (micro) 0.9219\n",
      "- F-score (macro) 0.8048\n",
      "- Accuracy 0.9219\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8996    0.9069    0.9032      1353\n",
      "         ADJ     0.8799    0.9048    0.8921       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9863    0.9825    0.9844       514\n",
      "        VERB     0.8814    0.9265    0.9034       449\n",
      "       PROPN     0.8040    0.7285    0.7644       383\n",
      "         AUX     0.9852    0.9910    0.9881       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.8726    0.8509    0.8616       161\n",
      "         ADV     0.8344    0.8675    0.8506       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     1.0000    0.8169    0.8992        71\n",
      "        PART     0.9444    0.8095    0.8718        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9219      5264\n",
      "   macro avg     0.8170    0.7949    0.8048      5264\n",
      "weighted avg     0.9222    0.9219    0.9217      5264\n",
      "\n",
      "2022-08-30 22:27:07,088 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:27:07,090 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 22:27:07,593 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 8 #######################\n",
      "#######################################################\n",
      "2022-08-30 22:29:39,831 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:29:39,832 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 22:29:39,832 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:29:39,833 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 22:29:39,834 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:29:39,835 Parameters:\n",
      "2022-08-30 22:29:39,835  - learning_rate: \"0.400333\"\n",
      "2022-08-30 22:29:39,836  - mini_batch_size: \"70\"\n",
      "2022-08-30 22:29:39,836  - patience: \"3\"\n",
      "2022-08-30 22:29:39,837  - anneal_factor: \"0.5\"\n",
      "2022-08-30 22:29:39,837  - max_epochs: \"12\"\n",
      "2022-08-30 22:29:39,838  - shuffle: \"True\"\n",
      "2022-08-30 22:29:39,838  - train_with_dev: \"False\"\n",
      "2022-08-30 22:29:39,839  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 22:29:39,839 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:29:39,840 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 22:29:39,841 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:29:39,841 Device: cpu\n",
      "2022-08-30 22:29:39,842 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:29:39,842 Embeddings storage mode: cpu\n",
      "2022-08-30 22:29:39,843 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:29:42,428 epoch 1 - iter 4/48 - loss 0.32500148 - samples/sec: 108.36 - lr: 0.400333\n",
      "2022-08-30 22:29:45,670 epoch 1 - iter 8/48 - loss 0.34204658 - samples/sec: 88.08 - lr: 0.400333\n",
      "2022-08-30 22:29:48,085 epoch 1 - iter 12/48 - loss 0.34864589 - samples/sec: 119.25 - lr: 0.400333\n",
      "2022-08-30 22:29:50,693 epoch 1 - iter 16/48 - loss 0.34263001 - samples/sec: 110.02 - lr: 0.400333\n",
      "2022-08-30 22:29:53,321 epoch 1 - iter 20/48 - loss 0.34070038 - samples/sec: 109.16 - lr: 0.400333\n",
      "2022-08-30 22:29:56,166 epoch 1 - iter 24/48 - loss 0.34862666 - samples/sec: 100.79 - lr: 0.400333\n",
      "2022-08-30 22:29:58,818 epoch 1 - iter 28/48 - loss 0.34784142 - samples/sec: 108.11 - lr: 0.400333\n",
      "2022-08-30 22:30:01,607 epoch 1 - iter 32/48 - loss 0.34868089 - samples/sec: 102.45 - lr: 0.400333\n",
      "2022-08-30 22:30:04,039 epoch 1 - iter 36/48 - loss 0.35095915 - samples/sec: 118.04 - lr: 0.400333\n",
      "2022-08-30 22:30:06,745 epoch 1 - iter 40/48 - loss 0.34905917 - samples/sec: 105.74 - lr: 0.400333\n",
      "2022-08-30 22:30:09,653 epoch 1 - iter 44/48 - loss 0.35676217 - samples/sec: 98.35 - lr: 0.400333\n",
      "2022-08-30 22:30:12,745 epoch 1 - iter 48/48 - loss 0.36589002 - samples/sec: 92.62 - lr: 0.400333\n",
      "2022-08-30 22:30:12,804 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:30:12,805 EPOCH 1 done: loss 0.3659 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:30:13,655 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:30:13,691 DEV : loss 0.25542375445365906 - f1-score (micro avg)  0.9159\n",
      "2022-08-30 22:30:13,707 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:30:13,708 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:30:14,467 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:30:17,427 epoch 2 - iter 4/48 - loss 0.33980753 - samples/sec: 94.66 - lr: 0.400333\n",
      "2022-08-30 22:30:20,609 epoch 2 - iter 8/48 - loss 0.34617222 - samples/sec: 91.15 - lr: 0.400333\n",
      "2022-08-30 22:30:23,323 epoch 2 - iter 12/48 - loss 0.35722166 - samples/sec: 105.78 - lr: 0.400333\n",
      "2022-08-30 22:30:26,028 epoch 2 - iter 16/48 - loss 0.36200349 - samples/sec: 106.30 - lr: 0.400333\n",
      "2022-08-30 22:30:28,822 epoch 2 - iter 20/48 - loss 0.36565880 - samples/sec: 103.13 - lr: 0.400333\n",
      "2022-08-30 22:30:31,478 epoch 2 - iter 24/48 - loss 0.36704319 - samples/sec: 107.82 - lr: 0.400333\n",
      "2022-08-30 22:30:34,107 epoch 2 - iter 28/48 - loss 0.36630531 - samples/sec: 109.80 - lr: 0.400333\n",
      "2022-08-30 22:30:36,715 epoch 2 - iter 32/48 - loss 0.36455271 - samples/sec: 110.11 - lr: 0.400333\n",
      "2022-08-30 22:30:39,737 epoch 2 - iter 36/48 - loss 0.36557076 - samples/sec: 94.59 - lr: 0.400333\n",
      "2022-08-30 22:30:42,549 epoch 2 - iter 40/48 - loss 0.36670573 - samples/sec: 101.86 - lr: 0.400333\n",
      "2022-08-30 22:30:45,498 epoch 2 - iter 44/48 - loss 0.36650265 - samples/sec: 97.90 - lr: 0.400333\n",
      "2022-08-30 22:30:48,073 epoch 2 - iter 48/48 - loss 0.36678451 - samples/sec: 111.60 - lr: 0.400333\n",
      "2022-08-30 22:30:48,138 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:30:48,139 EPOCH 2 done: loss 0.3668 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:30:48,973 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:30:49,006 DEV : loss 0.24314914643764496 - f1-score (micro avg)  0.9245\n",
      "2022-08-30 22:30:49,021 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:30:49,022 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:30:49,745 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:30:52,610 epoch 3 - iter 4/48 - loss 0.35958602 - samples/sec: 97.80 - lr: 0.400333\n",
      "2022-08-30 22:30:55,396 epoch 3 - iter 8/48 - loss 0.35439744 - samples/sec: 102.87 - lr: 0.400333\n",
      "2022-08-30 22:30:58,002 epoch 3 - iter 12/48 - loss 0.35811457 - samples/sec: 110.58 - lr: 0.400333\n",
      "2022-08-30 22:31:00,511 epoch 3 - iter 16/48 - loss 0.35821895 - samples/sec: 114.33 - lr: 0.400333\n",
      "2022-08-30 22:31:03,448 epoch 3 - iter 20/48 - loss 0.36475303 - samples/sec: 98.21 - lr: 0.400333\n",
      "2022-08-30 22:31:05,887 epoch 3 - iter 24/48 - loss 0.36305206 - samples/sec: 118.69 - lr: 0.400333\n",
      "2022-08-30 22:31:08,503 epoch 3 - iter 28/48 - loss 0.36294112 - samples/sec: 109.55 - lr: 0.400333\n",
      "2022-08-30 22:31:11,027 epoch 3 - iter 32/48 - loss 0.36304040 - samples/sec: 113.87 - lr: 0.400333\n",
      "2022-08-30 22:31:13,739 epoch 3 - iter 36/48 - loss 0.36406445 - samples/sec: 105.54 - lr: 0.400333\n",
      "2022-08-30 22:31:16,785 epoch 3 - iter 40/48 - loss 0.36560762 - samples/sec: 93.93 - lr: 0.400333\n",
      "2022-08-30 22:31:19,719 epoch 3 - iter 44/48 - loss 0.36332692 - samples/sec: 97.32 - lr: 0.400333\n",
      "2022-08-30 22:31:22,095 epoch 3 - iter 48/48 - loss 0.36307134 - samples/sec: 121.05 - lr: 0.400333\n",
      "2022-08-30 22:31:22,158 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:31:22,158 EPOCH 3 done: loss 0.3631 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:31:22,982 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:31:23,011 DEV : loss 0.24612674117088318 - f1-score (micro avg)  0.9172\n",
      "2022-08-30 22:31:23,029 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:31:23,030 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:31:25,358 epoch 4 - iter 4/48 - loss 0.37365249 - samples/sec: 120.38 - lr: 0.400333\n",
      "2022-08-30 22:31:27,997 epoch 4 - iter 8/48 - loss 0.37572299 - samples/sec: 109.33 - lr: 0.400333\n",
      "2022-08-30 22:31:30,772 epoch 4 - iter 12/48 - loss 0.37252053 - samples/sec: 103.05 - lr: 0.400333\n",
      "2022-08-30 22:31:33,589 epoch 4 - iter 16/48 - loss 0.37247969 - samples/sec: 102.60 - lr: 0.400333\n",
      "2022-08-30 22:31:36,244 epoch 4 - iter 20/48 - loss 0.37133442 - samples/sec: 108.61 - lr: 0.400333\n",
      "2022-08-30 22:31:38,642 epoch 4 - iter 24/48 - loss 0.37295448 - samples/sec: 119.81 - lr: 0.400333\n",
      "2022-08-30 22:31:41,482 epoch 4 - iter 28/48 - loss 0.36854880 - samples/sec: 100.79 - lr: 0.400333\n",
      "2022-08-30 22:31:44,858 epoch 4 - iter 32/48 - loss 0.36719070 - samples/sec: 84.62 - lr: 0.400333\n",
      "2022-08-30 22:31:47,706 epoch 4 - iter 36/48 - loss 0.36697830 - samples/sec: 100.65 - lr: 0.400333\n",
      "2022-08-30 22:31:50,454 epoch 4 - iter 40/48 - loss 0.36873115 - samples/sec: 104.24 - lr: 0.400333\n",
      "2022-08-30 22:31:53,868 epoch 4 - iter 44/48 - loss 0.36898745 - samples/sec: 83.76 - lr: 0.400333\n",
      "2022-08-30 22:31:56,279 epoch 4 - iter 48/48 - loss 0.36663029 - samples/sec: 119.30 - lr: 0.400333\n",
      "2022-08-30 22:31:56,347 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:31:56,348 EPOCH 4 done: loss 0.3666 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:31:57,190 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:31:57,225 DEV : loss 0.25339195132255554 - f1-score (micro avg)  0.9189\n",
      "2022-08-30 22:31:57,244 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:31:57,246 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:31:59,834 epoch 5 - iter 4/48 - loss 0.36599901 - samples/sec: 108.28 - lr: 0.400333\n",
      "2022-08-30 22:32:02,808 epoch 5 - iter 8/48 - loss 0.37033623 - samples/sec: 95.96 - lr: 0.400333\n",
      "2022-08-30 22:32:06,050 epoch 5 - iter 12/48 - loss 0.37258924 - samples/sec: 87.88 - lr: 0.400333\n",
      "2022-08-30 22:32:08,818 epoch 5 - iter 16/48 - loss 0.36688523 - samples/sec: 103.44 - lr: 0.400333\n",
      "2022-08-30 22:32:11,590 epoch 5 - iter 20/48 - loss 0.36244340 - samples/sec: 103.40 - lr: 0.400333\n",
      "2022-08-30 22:32:14,536 epoch 5 - iter 24/48 - loss 0.36120001 - samples/sec: 97.46 - lr: 0.400333\n",
      "2022-08-30 22:32:17,124 epoch 5 - iter 28/48 - loss 0.36146776 - samples/sec: 110.89 - lr: 0.400333\n",
      "2022-08-30 22:32:20,159 epoch 5 - iter 32/48 - loss 0.35878771 - samples/sec: 94.31 - lr: 0.400333\n",
      "2022-08-30 22:32:22,715 epoch 5 - iter 36/48 - loss 0.35919565 - samples/sec: 112.49 - lr: 0.400333\n",
      "2022-08-30 22:32:25,310 epoch 5 - iter 40/48 - loss 0.35853813 - samples/sec: 110.76 - lr: 0.400333\n",
      "2022-08-30 22:32:28,480 epoch 5 - iter 44/48 - loss 0.36146392 - samples/sec: 91.53 - lr: 0.400333\n",
      "2022-08-30 22:32:31,180 epoch 5 - iter 48/48 - loss 0.36196880 - samples/sec: 106.22 - lr: 0.400333\n",
      "2022-08-30 22:32:31,240 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:32:31,240 EPOCH 5 done: loss 0.3620 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:32:32,102 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:32:32,135 DEV : loss 0.27401334047317505 - f1-score (micro avg)  0.9069\n",
      "2022-08-30 22:32:32,156 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 22:32:32,157 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:32:34,984 epoch 6 - iter 4/48 - loss 0.36274176 - samples/sec: 99.12 - lr: 0.400333\n",
      "2022-08-30 22:32:37,868 epoch 6 - iter 8/48 - loss 0.36267058 - samples/sec: 99.19 - lr: 0.400333\n",
      "2022-08-30 22:32:40,538 epoch 6 - iter 12/48 - loss 0.35465625 - samples/sec: 107.69 - lr: 0.400333\n",
      "2022-08-30 22:32:43,295 epoch 6 - iter 16/48 - loss 0.35310179 - samples/sec: 103.97 - lr: 0.400333\n",
      "2022-08-30 22:32:46,166 epoch 6 - iter 20/48 - loss 0.35350122 - samples/sec: 100.07 - lr: 0.400333\n",
      "2022-08-30 22:32:48,971 epoch 6 - iter 24/48 - loss 0.35666214 - samples/sec: 102.00 - lr: 0.400333\n",
      "2022-08-30 22:32:52,056 epoch 6 - iter 28/48 - loss 0.36015927 - samples/sec: 92.72 - lr: 0.400333\n",
      "2022-08-30 22:32:54,769 epoch 6 - iter 32/48 - loss 0.36296253 - samples/sec: 105.46 - lr: 0.400333\n",
      "2022-08-30 22:32:57,485 epoch 6 - iter 36/48 - loss 0.36215939 - samples/sec: 105.34 - lr: 0.400333\n",
      "2022-08-30 22:33:00,359 epoch 6 - iter 40/48 - loss 0.36179924 - samples/sec: 99.79 - lr: 0.400333\n",
      "2022-08-30 22:33:03,094 epoch 6 - iter 44/48 - loss 0.36348248 - samples/sec: 105.54 - lr: 0.400333\n",
      "2022-08-30 22:33:05,872 epoch 6 - iter 48/48 - loss 0.36372638 - samples/sec: 103.21 - lr: 0.400333\n",
      "2022-08-30 22:33:05,928 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:33:05,929 EPOCH 6 done: loss 0.3637 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:33:06,763 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:33:06,792 DEV : loss 0.25383931398391724 - f1-score (micro avg)  0.9168\n",
      "2022-08-30 22:33:06,807 Epoch     6: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 22:33:06,807 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 22:33:06,808 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:33:09,726 epoch 7 - iter 4/48 - loss 0.36141433 - samples/sec: 96.02 - lr: 0.200167\n",
      "2022-08-30 22:33:12,319 epoch 7 - iter 8/48 - loss 0.34664218 - samples/sec: 110.54 - lr: 0.200167\n",
      "2022-08-30 22:33:15,249 epoch 7 - iter 12/48 - loss 0.34477257 - samples/sec: 98.00 - lr: 0.200167\n",
      "2022-08-30 22:33:18,548 epoch 7 - iter 16/48 - loss 0.34325186 - samples/sec: 86.50 - lr: 0.200167\n",
      "2022-08-30 22:33:21,312 epoch 7 - iter 20/48 - loss 0.34078250 - samples/sec: 103.74 - lr: 0.200167\n",
      "2022-08-30 22:33:23,894 epoch 7 - iter 24/48 - loss 0.34023958 - samples/sec: 111.60 - lr: 0.200167\n",
      "2022-08-30 22:33:26,949 epoch 7 - iter 28/48 - loss 0.33949617 - samples/sec: 93.61 - lr: 0.200167\n",
      "2022-08-30 22:33:29,943 epoch 7 - iter 32/48 - loss 0.34186643 - samples/sec: 95.30 - lr: 0.200167\n",
      "2022-08-30 22:33:32,912 epoch 7 - iter 36/48 - loss 0.34261552 - samples/sec: 96.35 - lr: 0.200167\n",
      "2022-08-30 22:33:35,737 epoch 7 - iter 40/48 - loss 0.34244210 - samples/sec: 101.12 - lr: 0.200167\n",
      "2022-08-30 22:33:38,567 epoch 7 - iter 44/48 - loss 0.34125830 - samples/sec: 101.01 - lr: 0.200167\n",
      "2022-08-30 22:33:41,034 epoch 7 - iter 48/48 - loss 0.33973841 - samples/sec: 116.67 - lr: 0.200167\n",
      "2022-08-30 22:33:41,097 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:33:41,098 EPOCH 7 done: loss 0.3397 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:33:41,870 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:33:41,900 DEV : loss 0.23691634833812714 - f1-score (micro avg)  0.9248\n",
      "2022-08-30 22:33:41,915 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:33:41,916 saving best model\n",
      "2022-08-30 22:33:42,887 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:33:45,524 epoch 8 - iter 4/48 - loss 0.32391946 - samples/sec: 106.26 - lr: 0.200167\n",
      "2022-08-30 22:33:48,298 epoch 8 - iter 8/48 - loss 0.34379088 - samples/sec: 103.17 - lr: 0.200167\n",
      "2022-08-30 22:33:50,946 epoch 8 - iter 12/48 - loss 0.34794193 - samples/sec: 108.32 - lr: 0.200167\n",
      "2022-08-30 22:33:53,671 epoch 8 - iter 16/48 - loss 0.34413034 - samples/sec: 104.93 - lr: 0.200167\n",
      "2022-08-30 22:33:56,266 epoch 8 - iter 20/48 - loss 0.34157781 - samples/sec: 110.54 - lr: 0.200167\n",
      "2022-08-30 22:33:58,880 epoch 8 - iter 24/48 - loss 0.33799764 - samples/sec: 109.72 - lr: 0.200167\n",
      "2022-08-30 22:34:01,770 epoch 8 - iter 28/48 - loss 0.33722678 - samples/sec: 99.33 - lr: 0.200167\n",
      "2022-08-30 22:34:04,746 epoch 8 - iter 32/48 - loss 0.33829058 - samples/sec: 96.55 - lr: 0.200167\n",
      "2022-08-30 22:34:08,241 epoch 8 - iter 36/48 - loss 0.33925436 - samples/sec: 81.49 - lr: 0.200167\n",
      "2022-08-30 22:34:10,944 epoch 8 - iter 40/48 - loss 0.33802789 - samples/sec: 105.98 - lr: 0.200167\n",
      "2022-08-30 22:34:14,086 epoch 8 - iter 44/48 - loss 0.33655334 - samples/sec: 90.88 - lr: 0.200167\n",
      "2022-08-30 22:34:16,409 epoch 8 - iter 48/48 - loss 0.33713250 - samples/sec: 123.68 - lr: 0.200167\n",
      "2022-08-30 22:34:16,480 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:34:16,480 EPOCH 8 done: loss 0.3371 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:34:17,317 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:34:17,351 DEV : loss 0.23074540495872498 - f1-score (micro avg)  0.9237\n",
      "2022-08-30 22:34:17,367 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:34:17,368 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:34:19,809 epoch 9 - iter 4/48 - loss 0.32776506 - samples/sec: 114.75 - lr: 0.200167\n",
      "2022-08-30 22:34:22,828 epoch 9 - iter 8/48 - loss 0.32895135 - samples/sec: 94.79 - lr: 0.200167\n",
      "2022-08-30 22:34:25,807 epoch 9 - iter 12/48 - loss 0.33074628 - samples/sec: 96.15 - lr: 0.200167\n",
      "2022-08-30 22:34:28,613 epoch 9 - iter 16/48 - loss 0.33362757 - samples/sec: 101.97 - lr: 0.200167\n",
      "2022-08-30 22:34:31,598 epoch 9 - iter 20/48 - loss 0.33598302 - samples/sec: 95.69 - lr: 0.200167\n",
      "2022-08-30 22:34:34,461 epoch 9 - iter 24/48 - loss 0.33782597 - samples/sec: 100.68 - lr: 0.200167\n",
      "2022-08-30 22:34:37,901 epoch 9 - iter 28/48 - loss 0.33590187 - samples/sec: 83.04 - lr: 0.200167\n",
      "2022-08-30 22:34:40,389 epoch 9 - iter 32/48 - loss 0.33695567 - samples/sec: 115.23 - lr: 0.200167\n",
      "2022-08-30 22:34:43,069 epoch 9 - iter 36/48 - loss 0.33686103 - samples/sec: 109.03 - lr: 0.200167\n",
      "2022-08-30 22:34:46,319 epoch 9 - iter 40/48 - loss 0.33583920 - samples/sec: 88.08 - lr: 0.200167\n",
      "2022-08-30 22:34:49,127 epoch 9 - iter 44/48 - loss 0.33686734 - samples/sec: 104.44 - lr: 0.200167\n",
      "2022-08-30 22:34:51,670 epoch 9 - iter 48/48 - loss 0.33612890 - samples/sec: 113.04 - lr: 0.200167\n",
      "2022-08-30 22:34:51,736 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:34:51,737 EPOCH 9 done: loss 0.3361 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:34:52,553 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:34:52,585 DEV : loss 0.2325088083744049 - f1-score (micro avg)  0.9248\n",
      "2022-08-30 22:34:52,601 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:34:52,602 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:34:55,182 epoch 10 - iter 4/48 - loss 0.34154781 - samples/sec: 108.53 - lr: 0.200167\n",
      "2022-08-30 22:34:57,995 epoch 10 - iter 8/48 - loss 0.33414858 - samples/sec: 101.78 - lr: 0.200167\n",
      "2022-08-30 22:35:01,067 epoch 10 - iter 12/48 - loss 0.33501957 - samples/sec: 92.98 - lr: 0.200167\n",
      "2022-08-30 22:35:04,202 epoch 10 - iter 16/48 - loss 0.33441628 - samples/sec: 91.21 - lr: 0.200167\n",
      "2022-08-30 22:35:07,310 epoch 10 - iter 20/48 - loss 0.33873484 - samples/sec: 92.10 - lr: 0.200167\n",
      "2022-08-30 22:35:10,228 epoch 10 - iter 24/48 - loss 0.33677415 - samples/sec: 98.45 - lr: 0.200167\n",
      "2022-08-30 22:35:13,113 epoch 10 - iter 28/48 - loss 0.33580853 - samples/sec: 99.29 - lr: 0.200167\n",
      "2022-08-30 22:35:15,588 epoch 10 - iter 32/48 - loss 0.33418284 - samples/sec: 116.09 - lr: 0.200167\n",
      "2022-08-30 22:35:18,024 epoch 10 - iter 36/48 - loss 0.33369586 - samples/sec: 117.94 - lr: 0.200167\n",
      "2022-08-30 22:35:20,550 epoch 10 - iter 40/48 - loss 0.33416547 - samples/sec: 113.59 - lr: 0.200167\n",
      "2022-08-30 22:35:23,494 epoch 10 - iter 44/48 - loss 0.33373127 - samples/sec: 97.05 - lr: 0.200167\n",
      "2022-08-30 22:35:26,193 epoch 10 - iter 48/48 - loss 0.33214690 - samples/sec: 106.34 - lr: 0.200167\n",
      "2022-08-30 22:35:26,266 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:35:26,267 EPOCH 10 done: loss 0.3321 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:35:27,186 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:35:27,219 DEV : loss 0.23687319457530975 - f1-score (micro avg)  0.9237\n",
      "2022-08-30 22:35:27,239 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:35:27,240 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:35:29,807 epoch 11 - iter 4/48 - loss 0.33138835 - samples/sec: 109.16 - lr: 0.200167\n",
      "2022-08-30 22:35:32,640 epoch 11 - iter 8/48 - loss 0.31866900 - samples/sec: 100.83 - lr: 0.200167\n",
      "2022-08-30 22:35:35,192 epoch 11 - iter 12/48 - loss 0.31736687 - samples/sec: 112.49 - lr: 0.200167\n",
      "2022-08-30 22:35:37,790 epoch 11 - iter 16/48 - loss 0.31486535 - samples/sec: 110.11 - lr: 0.200167\n",
      "2022-08-30 22:35:40,540 epoch 11 - iter 20/48 - loss 0.32072465 - samples/sec: 104.17 - lr: 0.200167\n",
      "2022-08-30 22:35:43,620 epoch 11 - iter 24/48 - loss 0.32178286 - samples/sec: 93.12 - lr: 0.200167\n",
      "2022-08-30 22:35:46,840 epoch 11 - iter 28/48 - loss 0.32375222 - samples/sec: 88.83 - lr: 0.200167\n",
      "2022-08-30 22:35:49,489 epoch 11 - iter 32/48 - loss 0.32358319 - samples/sec: 108.19 - lr: 0.200167\n",
      "2022-08-30 22:35:52,063 epoch 11 - iter 36/48 - loss 0.32388321 - samples/sec: 111.73 - lr: 0.200167\n",
      "2022-08-30 22:35:54,567 epoch 11 - iter 40/48 - loss 0.32574148 - samples/sec: 114.66 - lr: 0.200167\n",
      "2022-08-30 22:35:57,293 epoch 11 - iter 44/48 - loss 0.32784190 - samples/sec: 105.11 - lr: 0.200167\n",
      "2022-08-30 22:35:59,950 epoch 11 - iter 48/48 - loss 0.32768968 - samples/sec: 107.69 - lr: 0.200167\n",
      "2022-08-30 22:36:00,005 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:36:00,006 EPOCH 11 done: loss 0.3277 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:36:00,838 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:36:00,872 DEV : loss 0.22805209457874298 - f1-score (micro avg)  0.9235\n",
      "2022-08-30 22:36:00,887 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:36:00,888 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:36:03,289 epoch 12 - iter 4/48 - loss 0.33133248 - samples/sec: 116.67 - lr: 0.200167\n",
      "2022-08-30 22:36:06,742 epoch 12 - iter 8/48 - loss 0.33017502 - samples/sec: 82.45 - lr: 0.200167\n",
      "2022-08-30 22:36:09,055 epoch 12 - iter 12/48 - loss 0.33016661 - samples/sec: 124.17 - lr: 0.200167\n",
      "2022-08-30 22:36:11,599 epoch 12 - iter 16/48 - loss 0.32794139 - samples/sec: 112.72 - lr: 0.200167\n",
      "2022-08-30 22:36:14,584 epoch 12 - iter 20/48 - loss 0.32740168 - samples/sec: 95.92 - lr: 0.200167\n",
      "2022-08-30 22:36:17,288 epoch 12 - iter 24/48 - loss 0.32589315 - samples/sec: 106.18 - lr: 0.200167\n",
      "2022-08-30 22:36:19,979 epoch 12 - iter 28/48 - loss 0.32575001 - samples/sec: 106.42 - lr: 0.200167\n",
      "2022-08-30 22:36:22,600 epoch 12 - iter 32/48 - loss 0.32567177 - samples/sec: 109.29 - lr: 0.200167\n",
      "2022-08-30 22:36:25,102 epoch 12 - iter 36/48 - loss 0.32612907 - samples/sec: 114.99 - lr: 0.200167\n",
      "2022-08-30 22:36:27,461 epoch 12 - iter 40/48 - loss 0.32776240 - samples/sec: 121.84 - lr: 0.200167\n",
      "2022-08-30 22:36:30,292 epoch 12 - iter 44/48 - loss 0.32900510 - samples/sec: 101.23 - lr: 0.200167\n",
      "2022-08-30 22:36:32,828 epoch 12 - iter 48/48 - loss 0.32894870 - samples/sec: 113.06 - lr: 0.200167\n",
      "2022-08-30 22:36:32,885 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:36:32,886 EPOCH 12 done: loss 0.3289 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:36:33,681 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:36:33,712 DEV : loss 0.23497305810451508 - f1-score (micro avg)  0.9219\n",
      "2022-08-30 22:36:33,731 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:36:34,859 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:36:34,860 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 22:36:35,033 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:36:37,650 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:36:37,676 0.9293\t0.9293\t0.9293\t0.9293\n",
      "2022-08-30 22:36:37,676 \n",
      "Results:\n",
      "- F-score (micro) 0.9293\n",
      "- F-score (macro) 0.8101\n",
      "- Accuracy 0.9293\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.9025    0.9239    0.9131      1353\n",
      "         ADJ     0.8805    0.9211    0.9004       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9922    0.9883    0.9903       514\n",
      "        VERB     0.8970    0.9310    0.9137       449\n",
      "       PROPN     0.8408    0.7311    0.7821       383\n",
      "         AUX     0.9910    0.9881    0.9895       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9945    0.9891    0.9918       184\n",
      "         DET     0.8780    0.8944    0.8862       161\n",
      "         ADV     0.9000    0.8344    0.8660       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9500    0.8028    0.8702        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9293      5264\n",
      "   macro avg     0.8260    0.7971    0.8101      5264\n",
      "weighted avg     0.9296    0.9293    0.9289      5264\n",
      "\n",
      "2022-08-30 22:36:37,677 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:36:37,679 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 22:36:38,160 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 7 #######################\n",
      "#######################################################\n",
      "2022-08-30 22:39:05,823 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:39:05,823 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 22:39:05,824 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:39:05,825 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 22:39:05,825 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:39:05,826 Parameters:\n",
      "2022-08-30 22:39:05,827  - learning_rate: \"0.400333\"\n",
      "2022-08-30 22:39:05,827  - mini_batch_size: \"90\"\n",
      "2022-08-30 22:39:05,828  - patience: \"3\"\n",
      "2022-08-30 22:39:05,828  - anneal_factor: \"0.5\"\n",
      "2022-08-30 22:39:05,829  - max_epochs: \"10\"\n",
      "2022-08-30 22:39:05,829  - shuffle: \"True\"\n",
      "2022-08-30 22:39:05,830  - train_with_dev: \"False\"\n",
      "2022-08-30 22:39:05,830  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 22:39:05,831 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:39:05,831 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 22:39:05,832 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:39:05,832 Device: cpu\n",
      "2022-08-30 22:39:05,833 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:39:05,833 Embeddings storage mode: cpu\n",
      "2022-08-30 22:39:05,834 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:39:08,134 epoch 1 - iter 3/37 - loss 0.30966359 - samples/sec: 117.44 - lr: 0.400333\n",
      "2022-08-30 22:39:10,966 epoch 1 - iter 6/37 - loss 0.34304143 - samples/sec: 97.34 - lr: 0.400333\n",
      "2022-08-30 22:39:13,200 epoch 1 - iter 9/37 - loss 0.34333029 - samples/sec: 124.37 - lr: 0.400333\n",
      "2022-08-30 22:39:15,827 epoch 1 - iter 12/37 - loss 0.33690953 - samples/sec: 105.59 - lr: 0.400333\n",
      "2022-08-30 22:39:18,180 epoch 1 - iter 15/37 - loss 0.33522119 - samples/sec: 117.70 - lr: 0.400333\n",
      "2022-08-30 22:39:20,614 epoch 1 - iter 18/37 - loss 0.33879601 - samples/sec: 113.64 - lr: 0.400333\n",
      "2022-08-30 22:39:23,244 epoch 1 - iter 21/37 - loss 0.33658582 - samples/sec: 104.95 - lr: 0.400333\n",
      "2022-08-30 22:39:25,708 epoch 1 - iter 24/37 - loss 0.33592808 - samples/sec: 112.08 - lr: 0.400333\n",
      "2022-08-30 22:39:28,059 epoch 1 - iter 27/37 - loss 0.33595380 - samples/sec: 118.85 - lr: 0.400333\n",
      "2022-08-30 22:39:30,182 epoch 1 - iter 30/37 - loss 0.33612345 - samples/sec: 130.88 - lr: 0.400333\n",
      "2022-08-30 22:39:33,120 epoch 1 - iter 33/37 - loss 0.33833008 - samples/sec: 93.88 - lr: 0.400333\n",
      "2022-08-30 22:39:36,117 epoch 1 - iter 36/37 - loss 0.34964907 - samples/sec: 91.99 - lr: 0.400333\n",
      "2022-08-30 22:39:37,240 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:39:37,241 EPOCH 1 done: loss 0.3531 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:39:38,100 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:39:38,131 DEV : loss 0.2676141858100891 - f1-score (micro avg)  0.9102\n",
      "2022-08-30 22:39:38,153 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:39:38,154 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:39:38,866 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:39:41,689 epoch 2 - iter 3/37 - loss 0.37826860 - samples/sec: 95.71 - lr: 0.400333\n",
      "2022-08-30 22:39:44,903 epoch 2 - iter 6/37 - loss 0.36771012 - samples/sec: 85.71 - lr: 0.400333\n",
      "2022-08-30 22:39:47,532 epoch 2 - iter 9/37 - loss 0.36101626 - samples/sec: 105.26 - lr: 0.400333\n",
      "2022-08-30 22:39:50,320 epoch 2 - iter 12/37 - loss 0.36171141 - samples/sec: 99.15 - lr: 0.400333\n",
      "2022-08-30 22:39:52,999 epoch 2 - iter 15/37 - loss 0.36095453 - samples/sec: 104.81 - lr: 0.400333\n",
      "2022-08-30 22:39:55,645 epoch 2 - iter 18/37 - loss 0.36096843 - samples/sec: 104.96 - lr: 0.400333\n",
      "2022-08-30 22:39:58,366 epoch 2 - iter 21/37 - loss 0.35895927 - samples/sec: 101.77 - lr: 0.400333\n",
      "2022-08-30 22:40:00,872 epoch 2 - iter 24/37 - loss 0.35967660 - samples/sec: 113.11 - lr: 0.400333\n",
      "2022-08-30 22:40:03,358 epoch 2 - iter 27/37 - loss 0.35887843 - samples/sec: 111.52 - lr: 0.400333\n",
      "2022-08-30 22:40:06,019 epoch 2 - iter 30/37 - loss 0.35886562 - samples/sec: 105.37 - lr: 0.400333\n",
      "2022-08-30 22:40:08,387 epoch 2 - iter 33/37 - loss 0.35942644 - samples/sec: 117.75 - lr: 0.400333\n",
      "2022-08-30 22:40:11,225 epoch 2 - iter 36/37 - loss 0.35875546 - samples/sec: 97.54 - lr: 0.400333\n",
      "2022-08-30 22:40:12,014 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:40:12,015 EPOCH 2 done: loss 0.3578 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:40:12,776 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:40:12,805 DEV : loss 0.23906433582305908 - f1-score (micro avg)  0.9243\n",
      "2022-08-30 22:40:12,827 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:40:12,828 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:40:13,585 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:40:16,053 epoch 3 - iter 3/37 - loss 0.33829912 - samples/sec: 109.44 - lr: 0.400333\n",
      "2022-08-30 22:40:18,614 epoch 3 - iter 6/37 - loss 0.35713007 - samples/sec: 107.96 - lr: 0.400333\n",
      "2022-08-30 22:40:20,935 epoch 3 - iter 9/37 - loss 0.35826672 - samples/sec: 119.42 - lr: 0.400333\n",
      "2022-08-30 22:40:23,210 epoch 3 - iter 12/37 - loss 0.35898400 - samples/sec: 121.98 - lr: 0.400333\n",
      "2022-08-30 22:40:26,005 epoch 3 - iter 15/37 - loss 0.36012977 - samples/sec: 98.61 - lr: 0.400333\n",
      "2022-08-30 22:40:28,879 epoch 3 - iter 18/37 - loss 0.35921936 - samples/sec: 95.78 - lr: 0.400333\n",
      "2022-08-30 22:40:31,538 epoch 3 - iter 21/37 - loss 0.35728455 - samples/sec: 104.13 - lr: 0.400333\n",
      "2022-08-30 22:40:33,931 epoch 3 - iter 24/37 - loss 0.35776487 - samples/sec: 115.98 - lr: 0.400333\n",
      "2022-08-30 22:40:36,533 epoch 3 - iter 27/37 - loss 0.35849775 - samples/sec: 106.44 - lr: 0.400333\n",
      "2022-08-30 22:40:39,013 epoch 3 - iter 30/37 - loss 0.35853571 - samples/sec: 112.22 - lr: 0.400333\n",
      "2022-08-30 22:40:41,974 epoch 3 - iter 33/37 - loss 0.35652684 - samples/sec: 93.30 - lr: 0.400333\n",
      "2022-08-30 22:40:45,041 epoch 3 - iter 36/37 - loss 0.35637410 - samples/sec: 89.64 - lr: 0.400333\n",
      "2022-08-30 22:40:45,962 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:40:45,963 EPOCH 3 done: loss 0.3562 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:40:46,751 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:40:46,786 DEV : loss 0.2424144744873047 - f1-score (micro avg)  0.9172\n",
      "2022-08-30 22:40:46,807 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:40:46,808 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:40:49,619 epoch 4 - iter 3/37 - loss 0.35002814 - samples/sec: 96.08 - lr: 0.400333\n",
      "2022-08-30 22:40:52,318 epoch 4 - iter 6/37 - loss 0.34576217 - samples/sec: 102.89 - lr: 0.400333\n",
      "2022-08-30 22:40:55,142 epoch 4 - iter 9/37 - loss 0.34881534 - samples/sec: 99.64 - lr: 0.400333\n",
      "2022-08-30 22:40:57,867 epoch 4 - iter 12/37 - loss 0.34874983 - samples/sec: 101.84 - lr: 0.400333\n",
      "2022-08-30 22:41:00,382 epoch 4 - iter 15/37 - loss 0.34988144 - samples/sec: 110.16 - lr: 0.400333\n",
      "2022-08-30 22:41:03,056 epoch 4 - iter 18/37 - loss 0.34942406 - samples/sec: 104.82 - lr: 0.400333\n",
      "2022-08-30 22:41:05,846 epoch 4 - iter 21/37 - loss 0.35138693 - samples/sec: 98.82 - lr: 0.400333\n",
      "2022-08-30 22:41:08,403 epoch 4 - iter 24/37 - loss 0.35330388 - samples/sec: 108.30 - lr: 0.400333\n",
      "2022-08-30 22:41:11,174 epoch 4 - iter 27/37 - loss 0.34915055 - samples/sec: 100.42 - lr: 0.400333\n",
      "2022-08-30 22:41:14,128 epoch 4 - iter 30/37 - loss 0.34738298 - samples/sec: 93.31 - lr: 0.400333\n",
      "2022-08-30 22:41:16,517 epoch 4 - iter 33/37 - loss 0.34858293 - samples/sec: 115.78 - lr: 0.400333\n",
      "2022-08-30 22:41:18,907 epoch 4 - iter 36/37 - loss 0.35074581 - samples/sec: 115.83 - lr: 0.400333\n",
      "2022-08-30 22:41:19,915 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:41:19,916 EPOCH 4 done: loss 0.3506 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:41:20,682 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:41:20,714 DEV : loss 0.23966094851493835 - f1-score (micro avg)  0.9175\n",
      "2022-08-30 22:41:20,730 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:41:20,731 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:41:23,695 epoch 5 - iter 3/37 - loss 0.34490491 - samples/sec: 91.12 - lr: 0.400333\n",
      "2022-08-30 22:41:26,103 epoch 5 - iter 6/37 - loss 0.35353296 - samples/sec: 114.84 - lr: 0.400333\n",
      "2022-08-30 22:41:28,215 epoch 5 - iter 9/37 - loss 0.35166853 - samples/sec: 131.45 - lr: 0.400333\n",
      "2022-08-30 22:41:30,790 epoch 5 - iter 12/37 - loss 0.35711970 - samples/sec: 107.23 - lr: 0.400333\n",
      "2022-08-30 22:41:33,143 epoch 5 - iter 15/37 - loss 0.35600676 - samples/sec: 117.70 - lr: 0.400333\n",
      "2022-08-30 22:41:35,571 epoch 5 - iter 18/37 - loss 0.35408333 - samples/sec: 113.92 - lr: 0.400333\n",
      "2022-08-30 22:41:37,984 epoch 5 - iter 21/37 - loss 0.35590639 - samples/sec: 114.94 - lr: 0.400333\n",
      "2022-08-30 22:41:40,815 epoch 5 - iter 24/37 - loss 0.35463735 - samples/sec: 97.72 - lr: 0.400333\n",
      "2022-08-30 22:41:43,256 epoch 5 - iter 27/37 - loss 0.35377215 - samples/sec: 113.49 - lr: 0.400333\n",
      "2022-08-30 22:41:46,748 epoch 5 - iter 30/37 - loss 0.35316785 - samples/sec: 78.60 - lr: 0.400333\n",
      "2022-08-30 22:41:49,333 epoch 5 - iter 33/37 - loss 0.35387524 - samples/sec: 107.19 - lr: 0.400333\n",
      "2022-08-30 22:41:51,840 epoch 5 - iter 36/37 - loss 0.35286031 - samples/sec: 112.13 - lr: 0.400333\n",
      "2022-08-30 22:41:52,638 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:41:52,639 EPOCH 5 done: loss 0.3530 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:41:53,398 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:41:53,430 DEV : loss 0.24776817858219147 - f1-score (micro avg)  0.9191\n",
      "2022-08-30 22:41:53,447 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 22:41:53,448 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:41:56,121 epoch 6 - iter 3/37 - loss 0.34141209 - samples/sec: 101.05 - lr: 0.400333\n",
      "2022-08-30 22:41:58,675 epoch 6 - iter 6/37 - loss 0.35417214 - samples/sec: 108.17 - lr: 0.400333\n",
      "2022-08-30 22:42:01,650 epoch 6 - iter 9/37 - loss 0.34623842 - samples/sec: 93.49 - lr: 0.400333\n",
      "2022-08-30 22:42:04,310 epoch 6 - iter 12/37 - loss 0.34220263 - samples/sec: 103.85 - lr: 0.400333\n",
      "2022-08-30 22:42:06,670 epoch 6 - iter 15/37 - loss 0.34450787 - samples/sec: 117.85 - lr: 0.400333\n",
      "2022-08-30 22:42:09,066 epoch 6 - iter 18/37 - loss 0.34157669 - samples/sec: 115.53 - lr: 0.400333\n",
      "2022-08-30 22:42:11,912 epoch 6 - iter 21/37 - loss 0.33870449 - samples/sec: 96.91 - lr: 0.400333\n",
      "2022-08-30 22:42:14,717 epoch 6 - iter 24/37 - loss 0.33899181 - samples/sec: 98.32 - lr: 0.400333\n",
      "2022-08-30 22:42:16,924 epoch 6 - iter 27/37 - loss 0.34165034 - samples/sec: 125.70 - lr: 0.400333\n",
      "2022-08-30 22:42:19,157 epoch 6 - iter 30/37 - loss 0.34299154 - samples/sec: 124.08 - lr: 0.400333\n",
      "2022-08-30 22:42:21,584 epoch 6 - iter 33/37 - loss 0.34648070 - samples/sec: 114.02 - lr: 0.400333\n",
      "2022-08-30 22:42:24,168 epoch 6 - iter 36/37 - loss 0.34648501 - samples/sec: 107.31 - lr: 0.400333\n",
      "2022-08-30 22:42:24,990 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:42:24,991 EPOCH 6 done: loss 0.3466 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:42:25,774 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:42:25,802 DEV : loss 0.23689314723014832 - f1-score (micro avg)  0.9202\n",
      "2022-08-30 22:42:25,817 Epoch     6: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 22:42:25,817 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 22:42:25,818 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:42:28,542 epoch 7 - iter 3/37 - loss 0.33102879 - samples/sec: 99.16 - lr: 0.200167\n",
      "2022-08-30 22:42:30,935 epoch 7 - iter 6/37 - loss 0.33046198 - samples/sec: 115.78 - lr: 0.200167\n",
      "2022-08-30 22:42:33,628 epoch 7 - iter 9/37 - loss 0.33572686 - samples/sec: 102.86 - lr: 0.200167\n",
      "2022-08-30 22:42:35,932 epoch 7 - iter 12/37 - loss 0.33207207 - samples/sec: 120.81 - lr: 0.200167\n",
      "2022-08-30 22:42:38,617 epoch 7 - iter 15/37 - loss 0.33450050 - samples/sec: 102.78 - lr: 0.200167\n",
      "2022-08-30 22:42:41,018 epoch 7 - iter 18/37 - loss 0.33624186 - samples/sec: 115.48 - lr: 0.200167\n",
      "2022-08-30 22:42:43,388 epoch 7 - iter 21/37 - loss 0.33634238 - samples/sec: 116.88 - lr: 0.200167\n",
      "2022-08-30 22:42:46,258 epoch 7 - iter 24/37 - loss 0.33618940 - samples/sec: 96.12 - lr: 0.200167\n",
      "2022-08-30 22:42:48,933 epoch 7 - iter 27/37 - loss 0.33414824 - samples/sec: 103.17 - lr: 0.200167\n",
      "2022-08-30 22:42:51,452 epoch 7 - iter 30/37 - loss 0.33397434 - samples/sec: 110.16 - lr: 0.200167\n",
      "2022-08-30 22:42:54,648 epoch 7 - iter 33/37 - loss 0.33274440 - samples/sec: 87.18 - lr: 0.200167\n",
      "2022-08-30 22:42:57,019 epoch 7 - iter 36/37 - loss 0.33447074 - samples/sec: 117.29 - lr: 0.200167\n",
      "2022-08-30 22:42:57,986 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:42:57,987 EPOCH 7 done: loss 0.3351 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:42:58,804 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:42:58,830 DEV : loss 0.22995233535766602 - f1-score (micro avg)  0.9233\n",
      "2022-08-30 22:42:58,844 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:42:58,845 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:43:01,111 epoch 8 - iter 3/37 - loss 0.31460268 - samples/sec: 119.21 - lr: 0.200167\n",
      "2022-08-30 22:43:03,818 epoch 8 - iter 6/37 - loss 0.32963170 - samples/sec: 102.08 - lr: 0.200167\n",
      "2022-08-30 22:43:06,565 epoch 8 - iter 9/37 - loss 0.33117107 - samples/sec: 100.48 - lr: 0.200167\n",
      "2022-08-30 22:43:09,409 epoch 8 - iter 12/37 - loss 0.33013031 - samples/sec: 97.65 - lr: 0.200167\n",
      "2022-08-30 22:43:12,243 epoch 8 - iter 15/37 - loss 0.33017402 - samples/sec: 98.83 - lr: 0.200167\n",
      "2022-08-30 22:43:14,593 epoch 8 - iter 18/37 - loss 0.32824604 - samples/sec: 118.06 - lr: 0.200167\n",
      "2022-08-30 22:43:16,846 epoch 8 - iter 21/37 - loss 0.32749079 - samples/sec: 123.74 - lr: 0.200167\n",
      "2022-08-30 22:43:19,836 epoch 8 - iter 24/37 - loss 0.32739800 - samples/sec: 92.40 - lr: 0.200167\n",
      "2022-08-30 22:43:22,665 epoch 8 - iter 27/37 - loss 0.32603672 - samples/sec: 97.65 - lr: 0.200167\n",
      "2022-08-30 22:43:24,925 epoch 8 - iter 30/37 - loss 0.32514825 - samples/sec: 122.73 - lr: 0.200167\n",
      "2022-08-30 22:43:27,667 epoch 8 - iter 33/37 - loss 0.32510542 - samples/sec: 100.75 - lr: 0.200167\n",
      "2022-08-30 22:43:30,493 epoch 8 - iter 36/37 - loss 0.32528311 - samples/sec: 97.65 - lr: 0.200167\n",
      "2022-08-30 22:43:31,463 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:43:31,464 EPOCH 8 done: loss 0.3260 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:43:32,251 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:43:32,287 DEV : loss 0.23182649910449982 - f1-score (micro avg)  0.9227\n",
      "2022-08-30 22:43:32,302 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:43:32,303 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:43:34,674 epoch 9 - iter 3/37 - loss 0.31458536 - samples/sec: 114.02 - lr: 0.200167\n",
      "2022-08-30 22:43:37,045 epoch 9 - iter 6/37 - loss 0.31069430 - samples/sec: 117.14 - lr: 0.200167\n",
      "2022-08-30 22:43:40,275 epoch 9 - iter 9/37 - loss 0.32266748 - samples/sec: 85.20 - lr: 0.200167\n",
      "2022-08-30 22:43:42,751 epoch 9 - iter 12/37 - loss 0.32641257 - samples/sec: 111.94 - lr: 0.200167\n",
      "2022-08-30 22:43:45,801 epoch 9 - iter 15/37 - loss 0.32505664 - samples/sec: 90.36 - lr: 0.200167\n",
      "2022-08-30 22:43:48,597 epoch 9 - iter 18/37 - loss 0.32670880 - samples/sec: 98.83 - lr: 0.200167\n",
      "2022-08-30 22:43:51,518 epoch 9 - iter 21/37 - loss 0.32797178 - samples/sec: 95.17 - lr: 0.200167\n",
      "2022-08-30 22:43:53,937 epoch 9 - iter 24/37 - loss 0.32610404 - samples/sec: 114.99 - lr: 0.200167\n",
      "2022-08-30 22:43:57,053 epoch 9 - iter 27/37 - loss 0.32734858 - samples/sec: 88.38 - lr: 0.200167\n",
      "2022-08-30 22:43:59,566 epoch 9 - iter 30/37 - loss 0.32794571 - samples/sec: 109.89 - lr: 0.200167\n",
      "2022-08-30 22:44:02,125 epoch 9 - iter 33/37 - loss 0.32719228 - samples/sec: 108.56 - lr: 0.200167\n",
      "2022-08-30 22:44:04,868 epoch 9 - iter 36/37 - loss 0.32616204 - samples/sec: 100.75 - lr: 0.200167\n",
      "2022-08-30 22:44:05,929 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:44:05,930 EPOCH 9 done: loss 0.3273 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:44:06,799 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:44:06,832 DEV : loss 0.2287505865097046 - f1-score (micro avg)  0.9237\n",
      "2022-08-30 22:44:06,849 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 22:44:06,850 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:44:09,474 epoch 10 - iter 3/37 - loss 0.32107940 - samples/sec: 102.97 - lr: 0.200167\n",
      "2022-08-30 22:44:12,237 epoch 10 - iter 6/37 - loss 0.32989802 - samples/sec: 100.33 - lr: 0.200167\n",
      "2022-08-30 22:44:15,282 epoch 10 - iter 9/37 - loss 0.33245970 - samples/sec: 90.70 - lr: 0.200167\n",
      "2022-08-30 22:44:17,736 epoch 10 - iter 12/37 - loss 0.33608172 - samples/sec: 113.02 - lr: 0.200167\n",
      "2022-08-30 22:44:20,706 epoch 10 - iter 15/37 - loss 0.33166182 - samples/sec: 93.10 - lr: 0.200167\n",
      "2022-08-30 22:44:23,497 epoch 10 - iter 18/37 - loss 0.33225500 - samples/sec: 98.90 - lr: 0.200167\n",
      "2022-08-30 22:44:26,411 epoch 10 - iter 21/37 - loss 0.33211207 - samples/sec: 94.87 - lr: 0.200167\n",
      "2022-08-30 22:44:29,088 epoch 10 - iter 24/37 - loss 0.33005441 - samples/sec: 104.90 - lr: 0.200167\n",
      "2022-08-30 22:44:31,688 epoch 10 - iter 27/37 - loss 0.32894452 - samples/sec: 106.55 - lr: 0.200167\n",
      "2022-08-30 22:44:34,263 epoch 10 - iter 30/37 - loss 0.32892816 - samples/sec: 107.70 - lr: 0.200167\n",
      "2022-08-30 22:44:37,383 epoch 10 - iter 33/37 - loss 0.32798039 - samples/sec: 88.52 - lr: 0.200167\n",
      "2022-08-30 22:44:40,083 epoch 10 - iter 36/37 - loss 0.32826937 - samples/sec: 103.73 - lr: 0.200167\n",
      "2022-08-30 22:44:40,905 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:44:40,906 EPOCH 10 done: loss 0.3287 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:44:41,749 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:44:41,780 DEV : loss 0.22463317215442657 - f1-score (micro avg)  0.9243\n",
      "2022-08-30 22:44:41,795 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:44:42,886 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:44:42,887 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 22:44:43,060 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:44:44,498 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:44:44,521 0.9293\t0.9293\t0.9293\t0.9293\n",
      "2022-08-30 22:44:44,522 \n",
      "Results:\n",
      "- F-score (micro) 0.9293\n",
      "- F-score (macro) 0.8092\n",
      "- Accuracy 0.9293\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8807    0.9438    0.9112      1353\n",
      "         ADJ     0.8847    0.9137    0.8990       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9922    0.9864    0.9893       514\n",
      "        VERB     0.9075    0.9176    0.9125       449\n",
      "       PROPN     0.9106    0.7180    0.8029       383\n",
      "         AUX     0.9910    0.9851    0.9880       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.8758    0.8758    0.8758       161\n",
      "         ADV     0.9147    0.7815    0.8429       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9355    0.8169    0.8722        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9293      5264\n",
      "   macro avg     0.8298    0.7926    0.8092      5264\n",
      "weighted avg     0.9306    0.9293    0.9286      5264\n",
      "\n",
      "2022-08-30 22:44:44,523 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:44:44,525 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:44:44,999 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 8 #######################\n",
      "#######################################################\n",
      "2022-08-30 22:47:08,876 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:47:08,876 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 22:47:08,877 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:47:08,878 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 22:47:08,878 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:47:08,879 Parameters:\n",
      "2022-08-30 22:47:08,880  - learning_rate: \"0.400333\"\n",
      "2022-08-30 22:47:08,880  - mini_batch_size: \"90\"\n",
      "2022-08-30 22:47:08,881  - patience: \"3\"\n",
      "2022-08-30 22:47:08,881  - anneal_factor: \"0.5\"\n",
      "2022-08-30 22:47:08,882  - max_epochs: \"11\"\n",
      "2022-08-30 22:47:08,882  - shuffle: \"True\"\n",
      "2022-08-30 22:47:08,883  - train_with_dev: \"False\"\n",
      "2022-08-30 22:47:08,883  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 22:47:08,883 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:47:08,884 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 22:47:08,884 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:47:08,885 Device: cpu\n",
      "2022-08-30 22:47:08,885 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:47:08,886 Embeddings storage mode: cpu\n",
      "2022-08-30 22:47:08,887 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:47:11,223 epoch 1 - iter 3/37 - loss 0.32417900 - samples/sec: 115.68 - lr: 0.400333\n",
      "2022-08-30 22:47:14,083 epoch 1 - iter 6/37 - loss 0.34397333 - samples/sec: 96.74 - lr: 0.400333\n",
      "2022-08-30 22:47:16,544 epoch 1 - iter 9/37 - loss 0.34718012 - samples/sec: 112.88 - lr: 0.400333\n",
      "2022-08-30 22:47:18,967 epoch 1 - iter 12/37 - loss 0.34011762 - samples/sec: 114.60 - lr: 0.400333\n",
      "2022-08-30 22:47:21,549 epoch 1 - iter 15/37 - loss 0.33699152 - samples/sec: 107.02 - lr: 0.400333\n",
      "2022-08-30 22:47:24,053 epoch 1 - iter 18/37 - loss 0.34067938 - samples/sec: 110.88 - lr: 0.400333\n",
      "2022-08-30 22:47:26,905 epoch 1 - iter 21/37 - loss 0.33936298 - samples/sec: 96.88 - lr: 0.400333\n",
      "2022-08-30 22:47:29,354 epoch 1 - iter 24/37 - loss 0.34149892 - samples/sec: 113.11 - lr: 0.400333\n",
      "2022-08-30 22:47:31,880 epoch 1 - iter 27/37 - loss 0.34206860 - samples/sec: 110.84 - lr: 0.400333\n",
      "2022-08-30 22:47:34,037 epoch 1 - iter 30/37 - loss 0.34271715 - samples/sec: 128.69 - lr: 0.400333\n",
      "2022-08-30 22:47:36,834 epoch 1 - iter 33/37 - loss 0.34366492 - samples/sec: 98.54 - lr: 0.400333\n",
      "2022-08-30 22:47:39,776 epoch 1 - iter 36/37 - loss 0.35359363 - samples/sec: 93.82 - lr: 0.400333\n",
      "2022-08-30 22:47:41,002 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:47:41,003 EPOCH 1 done: loss 0.3567 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:47:41,853 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:47:41,888 DEV : loss 0.25757119059562683 - f1-score (micro avg)  0.9157\n",
      "2022-08-30 22:47:41,904 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:47:41,906 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:47:42,778 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:47:45,404 epoch 2 - iter 3/37 - loss 0.35358207 - samples/sec: 102.86 - lr: 0.400333\n",
      "2022-08-30 22:47:48,392 epoch 2 - iter 6/37 - loss 0.34995545 - samples/sec: 92.91 - lr: 0.400333\n",
      "2022-08-30 22:47:51,110 epoch 2 - iter 9/37 - loss 0.34922858 - samples/sec: 102.94 - lr: 0.400333\n",
      "2022-08-30 22:47:53,811 epoch 2 - iter 12/37 - loss 0.34822333 - samples/sec: 102.43 - lr: 0.400333\n",
      "2022-08-30 22:47:56,812 epoch 2 - iter 15/37 - loss 0.35326362 - samples/sec: 91.68 - lr: 0.400333\n",
      "2022-08-30 22:47:59,576 epoch 2 - iter 18/37 - loss 0.35015277 - samples/sec: 100.04 - lr: 0.400333\n",
      "2022-08-30 22:48:02,405 epoch 2 - iter 21/37 - loss 0.34625492 - samples/sec: 97.54 - lr: 0.400333\n",
      "2022-08-30 22:48:04,838 epoch 2 - iter 24/37 - loss 0.35109848 - samples/sec: 115.38 - lr: 0.400333\n",
      "2022-08-30 22:48:07,064 epoch 2 - iter 27/37 - loss 0.35325187 - samples/sec: 124.48 - lr: 0.400333\n",
      "2022-08-30 22:48:09,779 epoch 2 - iter 30/37 - loss 0.35212663 - samples/sec: 101.62 - lr: 0.400333\n",
      "2022-08-30 22:48:12,856 epoch 2 - iter 33/37 - loss 0.35441804 - samples/sec: 89.49 - lr: 0.400333\n",
      "2022-08-30 22:48:15,068 epoch 2 - iter 36/37 - loss 0.35346942 - samples/sec: 125.70 - lr: 0.400333\n",
      "2022-08-30 22:48:15,855 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:48:15,855 EPOCH 2 done: loss 0.3545 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:48:16,650 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:48:16,685 DEV : loss 0.24786819517612457 - f1-score (micro avg)  0.9152\n",
      "2022-08-30 22:48:16,700 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:48:16,701 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:48:19,389 epoch 3 - iter 3/37 - loss 0.36467835 - samples/sec: 100.56 - lr: 0.400333\n",
      "2022-08-30 22:48:22,598 epoch 3 - iter 6/37 - loss 0.36056353 - samples/sec: 87.86 - lr: 0.400333\n",
      "2022-08-30 22:48:25,028 epoch 3 - iter 9/37 - loss 0.35637531 - samples/sec: 114.07 - lr: 0.400333\n",
      "2022-08-30 22:48:27,614 epoch 3 - iter 12/37 - loss 0.35363277 - samples/sec: 106.76 - lr: 0.400333\n",
      "2022-08-30 22:48:30,779 epoch 3 - iter 15/37 - loss 0.35453507 - samples/sec: 87.78 - lr: 0.400333\n",
      "2022-08-30 22:48:33,185 epoch 3 - iter 18/37 - loss 0.35733017 - samples/sec: 115.19 - lr: 0.400333\n",
      "2022-08-30 22:48:35,502 epoch 3 - iter 21/37 - loss 0.35941014 - samples/sec: 119.79 - lr: 0.400333\n",
      "2022-08-30 22:48:37,982 epoch 3 - iter 24/37 - loss 0.35569169 - samples/sec: 112.13 - lr: 0.400333\n",
      "2022-08-30 22:48:40,454 epoch 3 - iter 27/37 - loss 0.35564153 - samples/sec: 112.03 - lr: 0.400333\n",
      "2022-08-30 22:48:42,745 epoch 3 - iter 30/37 - loss 0.35785193 - samples/sec: 121.51 - lr: 0.400333\n",
      "2022-08-30 22:48:45,410 epoch 3 - iter 33/37 - loss 0.35895864 - samples/sec: 104.05 - lr: 0.400333\n",
      "2022-08-30 22:48:48,167 epoch 3 - iter 36/37 - loss 0.35772411 - samples/sec: 101.24 - lr: 0.400333\n",
      "2022-08-30 22:48:48,925 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:48:48,926 EPOCH 3 done: loss 0.3560 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:48:49,788 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:48:49,822 DEV : loss 0.24568310379981995 - f1-score (micro avg)  0.9198\n",
      "2022-08-30 22:48:49,841 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:48:49,842 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:48:50,964 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:48:53,400 epoch 4 - iter 3/37 - loss 0.35227290 - samples/sec: 110.93 - lr: 0.400333\n",
      "2022-08-30 22:48:56,181 epoch 4 - iter 6/37 - loss 0.35669527 - samples/sec: 100.75 - lr: 0.400333\n",
      "2022-08-30 22:48:58,810 epoch 4 - iter 9/37 - loss 0.35526979 - samples/sec: 105.06 - lr: 0.400333\n",
      "2022-08-30 22:49:01,339 epoch 4 - iter 12/37 - loss 0.35180219 - samples/sec: 109.40 - lr: 0.400333\n",
      "2022-08-30 22:49:04,802 epoch 4 - iter 15/37 - loss 0.34798915 - samples/sec: 80.74 - lr: 0.400333\n",
      "2022-08-30 22:49:07,317 epoch 4 - iter 18/37 - loss 0.35076709 - samples/sec: 110.02 - lr: 0.400333\n",
      "2022-08-30 22:49:10,277 epoch 4 - iter 21/37 - loss 0.34876643 - samples/sec: 95.24 - lr: 0.400333\n",
      "2022-08-30 22:49:12,789 epoch 4 - iter 24/37 - loss 0.34949690 - samples/sec: 110.11 - lr: 0.400333\n",
      "2022-08-30 22:49:15,287 epoch 4 - iter 27/37 - loss 0.34817976 - samples/sec: 110.88 - lr: 0.400333\n",
      "2022-08-30 22:49:17,865 epoch 4 - iter 30/37 - loss 0.34906353 - samples/sec: 107.40 - lr: 0.400333\n",
      "2022-08-30 22:49:20,809 epoch 4 - iter 33/37 - loss 0.34911995 - samples/sec: 94.14 - lr: 0.400333\n",
      "2022-08-30 22:49:23,163 epoch 4 - iter 36/37 - loss 0.34988218 - samples/sec: 117.70 - lr: 0.400333\n",
      "2022-08-30 22:49:23,982 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:49:23,983 EPOCH 4 done: loss 0.3504 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:49:24,836 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:49:24,868 DEV : loss 0.24145668745040894 - f1-score (micro avg)  0.9206\n",
      "2022-08-30 22:49:24,885 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:49:24,886 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:49:26,027 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:49:28,808 epoch 5 - iter 3/37 - loss 0.34697193 - samples/sec: 97.16 - lr: 0.400333\n",
      "2022-08-30 22:49:31,336 epoch 5 - iter 6/37 - loss 0.34497297 - samples/sec: 109.62 - lr: 0.400333\n",
      "2022-08-30 22:49:33,864 epoch 5 - iter 9/37 - loss 0.34691822 - samples/sec: 112.31 - lr: 0.400333\n",
      "2022-08-30 22:49:36,805 epoch 5 - iter 12/37 - loss 0.35049316 - samples/sec: 93.75 - lr: 0.400333\n",
      "2022-08-30 22:49:39,770 epoch 5 - iter 15/37 - loss 0.34551479 - samples/sec: 93.01 - lr: 0.400333\n",
      "2022-08-30 22:49:42,206 epoch 5 - iter 18/37 - loss 0.34468355 - samples/sec: 113.49 - lr: 0.400333\n",
      "2022-08-30 22:49:44,979 epoch 5 - iter 21/37 - loss 0.34929892 - samples/sec: 99.52 - lr: 0.400333\n",
      "2022-08-30 22:49:47,419 epoch 5 - iter 24/37 - loss 0.34916557 - samples/sec: 113.83 - lr: 0.400333\n",
      "2022-08-30 22:49:49,755 epoch 5 - iter 27/37 - loss 0.34952990 - samples/sec: 121.40 - lr: 0.400333\n",
      "2022-08-30 22:49:52,843 epoch 5 - iter 30/37 - loss 0.35093447 - samples/sec: 89.23 - lr: 0.400333\n",
      "2022-08-30 22:49:55,616 epoch 5 - iter 33/37 - loss 0.35160183 - samples/sec: 99.63 - lr: 0.400333\n",
      "2022-08-30 22:49:59,351 epoch 5 - iter 36/37 - loss 0.35143472 - samples/sec: 73.51 - lr: 0.400333\n",
      "2022-08-30 22:50:00,160 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:50:00,161 EPOCH 5 done: loss 0.3508 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:50:00,988 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:50:01,019 DEV : loss 0.2471158802509308 - f1-score (micro avg)  0.9191\n",
      "2022-08-30 22:50:01,037 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:50:01,038 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:50:03,442 epoch 6 - iter 3/37 - loss 0.35307761 - samples/sec: 112.36 - lr: 0.400333\n",
      "2022-08-30 22:50:05,804 epoch 6 - iter 6/37 - loss 0.35950471 - samples/sec: 118.73 - lr: 0.400333\n",
      "2022-08-30 22:50:08,162 epoch 6 - iter 9/37 - loss 0.35868505 - samples/sec: 117.65 - lr: 0.400333\n",
      "2022-08-30 22:50:11,161 epoch 6 - iter 12/37 - loss 0.35612527 - samples/sec: 91.81 - lr: 0.400333\n",
      "2022-08-30 22:50:13,625 epoch 6 - iter 15/37 - loss 0.35775983 - samples/sec: 112.31 - lr: 0.400333\n",
      "2022-08-30 22:50:16,110 epoch 6 - iter 18/37 - loss 0.35726339 - samples/sec: 111.43 - lr: 0.400333\n",
      "2022-08-30 22:50:19,035 epoch 6 - iter 21/37 - loss 0.35730287 - samples/sec: 94.50 - lr: 0.400333\n",
      "2022-08-30 22:50:21,330 epoch 6 - iter 24/37 - loss 0.35617815 - samples/sec: 121.24 - lr: 0.400333\n",
      "2022-08-30 22:50:23,725 epoch 6 - iter 27/37 - loss 0.35793195 - samples/sec: 116.88 - lr: 0.400333\n",
      "2022-08-30 22:50:26,332 epoch 6 - iter 30/37 - loss 0.35830634 - samples/sec: 106.22 - lr: 0.400333\n",
      "2022-08-30 22:50:29,179 epoch 6 - iter 33/37 - loss 0.35840239 - samples/sec: 97.37 - lr: 0.400333\n",
      "2022-08-30 22:50:31,470 epoch 6 - iter 36/37 - loss 0.35729485 - samples/sec: 121.68 - lr: 0.400333\n",
      "2022-08-30 22:50:32,380 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:50:32,383 EPOCH 6 done: loss 0.3564 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:50:33,278 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:50:33,307 DEV : loss 0.24781981110572815 - f1-score (micro avg)  0.915\n",
      "2022-08-30 22:50:33,327 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:50:33,328 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:50:35,712 epoch 7 - iter 3/37 - loss 0.35396141 - samples/sec: 113.30 - lr: 0.400333\n",
      "2022-08-30 22:50:38,066 epoch 7 - iter 6/37 - loss 0.34495294 - samples/sec: 117.75 - lr: 0.400333\n",
      "2022-08-30 22:50:40,845 epoch 7 - iter 9/37 - loss 0.34396364 - samples/sec: 99.34 - lr: 0.400333\n",
      "2022-08-30 22:50:43,256 epoch 7 - iter 12/37 - loss 0.34550929 - samples/sec: 114.99 - lr: 0.400333\n",
      "2022-08-30 22:50:45,823 epoch 7 - iter 15/37 - loss 0.34380859 - samples/sec: 107.61 - lr: 0.400333\n",
      "2022-08-30 22:50:48,789 epoch 7 - iter 18/37 - loss 0.34249547 - samples/sec: 92.91 - lr: 0.400333\n",
      "2022-08-30 22:50:51,722 epoch 7 - iter 21/37 - loss 0.34484012 - samples/sec: 93.88 - lr: 0.400333\n",
      "2022-08-30 22:50:54,005 epoch 7 - iter 24/37 - loss 0.34587996 - samples/sec: 121.57 - lr: 0.400333\n",
      "2022-08-30 22:50:56,337 epoch 7 - iter 27/37 - loss 0.34829135 - samples/sec: 118.68 - lr: 0.400333\n",
      "2022-08-30 22:50:58,953 epoch 7 - iter 30/37 - loss 0.34761917 - samples/sec: 107.74 - lr: 0.400333\n",
      "2022-08-30 22:51:01,145 epoch 7 - iter 33/37 - loss 0.34833506 - samples/sec: 126.76 - lr: 0.400333\n",
      "2022-08-30 22:51:03,480 epoch 7 - iter 36/37 - loss 0.34900081 - samples/sec: 118.58 - lr: 0.400333\n",
      "2022-08-30 22:51:04,118 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:51:04,118 EPOCH 7 done: loss 0.3503 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:51:04,921 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:51:04,951 DEV : loss 0.23733021318912506 - f1-score (micro avg)  0.9233\n",
      "2022-08-30 22:51:04,970 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:51:04,971 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:51:05,670 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:51:07,798 epoch 8 - iter 3/37 - loss 0.34365428 - samples/sec: 126.94 - lr: 0.400333\n",
      "2022-08-30 22:51:10,047 epoch 8 - iter 6/37 - loss 0.35878473 - samples/sec: 123.06 - lr: 0.400333\n",
      "2022-08-30 22:51:12,536 epoch 8 - iter 9/37 - loss 0.35672164 - samples/sec: 111.29 - lr: 0.400333\n",
      "2022-08-30 22:51:14,975 epoch 8 - iter 12/37 - loss 0.35441270 - samples/sec: 113.40 - lr: 0.400333\n",
      "2022-08-30 22:51:17,706 epoch 8 - iter 15/37 - loss 0.35506073 - samples/sec: 100.86 - lr: 0.400333\n",
      "2022-08-30 22:51:20,670 epoch 8 - iter 18/37 - loss 0.35126682 - samples/sec: 92.85 - lr: 0.400333\n",
      "2022-08-30 22:51:22,803 epoch 8 - iter 21/37 - loss 0.35078591 - samples/sec: 130.88 - lr: 0.400333\n",
      "2022-08-30 22:51:25,182 epoch 8 - iter 24/37 - loss 0.35001737 - samples/sec: 116.18 - lr: 0.400333\n",
      "2022-08-30 22:51:27,589 epoch 8 - iter 27/37 - loss 0.34764325 - samples/sec: 115.14 - lr: 0.400333\n",
      "2022-08-30 22:51:30,079 epoch 8 - iter 30/37 - loss 0.34968658 - samples/sec: 111.02 - lr: 0.400333\n",
      "2022-08-30 22:51:32,280 epoch 8 - iter 33/37 - loss 0.35058567 - samples/sec: 125.82 - lr: 0.400333\n",
      "2022-08-30 22:51:35,021 epoch 8 - iter 36/37 - loss 0.35081662 - samples/sec: 100.67 - lr: 0.400333\n",
      "2022-08-30 22:51:36,300 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:51:36,301 EPOCH 8 done: loss 0.3515 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:51:37,139 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:51:37,168 DEV : loss 0.24732542037963867 - f1-score (micro avg)  0.9155\n",
      "2022-08-30 22:51:37,188 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:51:37,190 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:51:39,487 epoch 9 - iter 3/37 - loss 0.33534151 - samples/sec: 117.60 - lr: 0.400333\n",
      "2022-08-30 22:51:42,087 epoch 9 - iter 6/37 - loss 0.35194182 - samples/sec: 107.19 - lr: 0.400333\n",
      "2022-08-30 22:51:45,039 epoch 9 - iter 9/37 - loss 0.34996675 - samples/sec: 93.33 - lr: 0.400333\n",
      "2022-08-30 22:51:47,876 epoch 9 - iter 12/37 - loss 0.35309002 - samples/sec: 97.30 - lr: 0.400333\n",
      "2022-08-30 22:51:50,734 epoch 9 - iter 15/37 - loss 0.34986111 - samples/sec: 96.43 - lr: 0.400333\n",
      "2022-08-30 22:51:53,320 epoch 9 - iter 18/37 - loss 0.34987509 - samples/sec: 107.06 - lr: 0.400333\n",
      "2022-08-30 22:51:55,848 epoch 9 - iter 21/37 - loss 0.34753100 - samples/sec: 111.16 - lr: 0.400333\n",
      "2022-08-30 22:51:58,295 epoch 9 - iter 24/37 - loss 0.34835714 - samples/sec: 113.59 - lr: 0.400333\n",
      "2022-08-30 22:52:00,688 epoch 9 - iter 27/37 - loss 0.35080887 - samples/sec: 116.08 - lr: 0.400333\n",
      "2022-08-30 22:52:02,944 epoch 9 - iter 30/37 - loss 0.35040314 - samples/sec: 123.63 - lr: 0.400333\n",
      "2022-08-30 22:52:05,441 epoch 9 - iter 33/37 - loss 0.34987096 - samples/sec: 110.66 - lr: 0.400333\n",
      "2022-08-30 22:52:07,742 epoch 9 - iter 36/37 - loss 0.34907268 - samples/sec: 122.06 - lr: 0.400333\n",
      "2022-08-30 22:52:08,488 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:52:08,488 EPOCH 9 done: loss 0.3487 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:52:09,241 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:52:09,270 DEV : loss 0.24643176794052124 - f1-score (micro avg)  0.9194\n",
      "2022-08-30 22:52:09,285 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:52:09,286 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:52:11,941 epoch 10 - iter 3/37 - loss 0.32936463 - samples/sec: 101.77 - lr: 0.400333\n",
      "2022-08-30 22:52:14,303 epoch 10 - iter 6/37 - loss 0.33770100 - samples/sec: 117.39 - lr: 0.400333\n",
      "2022-08-30 22:52:16,693 epoch 10 - iter 9/37 - loss 0.34527934 - samples/sec: 116.18 - lr: 0.400333\n",
      "2022-08-30 22:52:18,968 epoch 10 - iter 12/37 - loss 0.34979815 - samples/sec: 122.01 - lr: 0.400333\n",
      "2022-08-30 22:52:21,540 epoch 10 - iter 15/37 - loss 0.35075466 - samples/sec: 107.44 - lr: 0.400333\n",
      "2022-08-30 22:52:23,993 epoch 10 - iter 18/37 - loss 0.35088969 - samples/sec: 112.69 - lr: 0.400333\n",
      "2022-08-30 22:52:26,704 epoch 10 - iter 21/37 - loss 0.35086813 - samples/sec: 101.89 - lr: 0.400333\n",
      "2022-08-30 22:52:28,886 epoch 10 - iter 24/37 - loss 0.35132784 - samples/sec: 127.72 - lr: 0.400333\n",
      "2022-08-30 22:52:32,113 epoch 10 - iter 27/37 - loss 0.35283467 - samples/sec: 85.25 - lr: 0.400333\n",
      "2022-08-30 22:52:34,163 epoch 10 - iter 30/37 - loss 0.35406394 - samples/sec: 135.68 - lr: 0.400333\n",
      "2022-08-30 22:52:36,710 epoch 10 - iter 33/37 - loss 0.35153814 - samples/sec: 108.61 - lr: 0.400333\n",
      "2022-08-30 22:52:39,561 epoch 10 - iter 36/37 - loss 0.35326118 - samples/sec: 96.57 - lr: 0.400333\n",
      "2022-08-30 22:52:40,310 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:52:40,310 EPOCH 10 done: loss 0.3532 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:52:41,149 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:52:41,176 DEV : loss 0.2453480213880539 - f1-score (micro avg)  0.9199\n",
      "2022-08-30 22:52:41,196 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 22:52:41,198 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:52:44,557 epoch 11 - iter 3/37 - loss 0.34023751 - samples/sec: 80.40 - lr: 0.400333\n",
      "2022-08-30 22:52:47,024 epoch 11 - iter 6/37 - loss 0.34694722 - samples/sec: 112.59 - lr: 0.400333\n",
      "2022-08-30 22:52:49,685 epoch 11 - iter 9/37 - loss 0.35315428 - samples/sec: 103.65 - lr: 0.400333\n",
      "2022-08-30 22:52:52,171 epoch 11 - iter 12/37 - loss 0.35214612 - samples/sec: 111.34 - lr: 0.400333\n",
      "2022-08-30 22:52:54,585 epoch 11 - iter 15/37 - loss 0.35086795 - samples/sec: 114.70 - lr: 0.400333\n",
      "2022-08-30 22:52:57,451 epoch 11 - iter 18/37 - loss 0.34949792 - samples/sec: 96.26 - lr: 0.400333\n",
      "2022-08-30 22:52:59,953 epoch 11 - iter 21/37 - loss 0.34947753 - samples/sec: 110.75 - lr: 0.400333\n",
      "2022-08-30 22:53:02,242 epoch 11 - iter 24/37 - loss 0.34681370 - samples/sec: 121.73 - lr: 0.400333\n",
      "2022-08-30 22:53:04,916 epoch 11 - iter 27/37 - loss 0.34790544 - samples/sec: 103.41 - lr: 0.400333\n",
      "2022-08-30 22:53:07,277 epoch 11 - iter 30/37 - loss 0.34769000 - samples/sec: 117.19 - lr: 0.400333\n",
      "2022-08-30 22:53:09,820 epoch 11 - iter 33/37 - loss 0.34743206 - samples/sec: 109.00 - lr: 0.400333\n",
      "2022-08-30 22:53:12,233 epoch 11 - iter 36/37 - loss 0.34825803 - samples/sec: 114.80 - lr: 0.400333\n",
      "2022-08-30 22:53:12,946 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:53:12,947 EPOCH 11 done: loss 0.3484 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:53:13,764 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:53:13,795 DEV : loss 0.24087996780872345 - f1-score (micro avg)  0.9206\n",
      "2022-08-30 22:53:13,811 Epoch    11: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 22:53:13,811 BAD EPOCHS (no improvement): 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:53:14,950 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:53:14,951 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 22:53:15,132 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:53:16,537 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:53:16,563 0.924\t0.924\t0.924\t0.924\n",
      "2022-08-30 22:53:16,564 \n",
      "Results:\n",
      "- F-score (micro) 0.924\n",
      "- F-score (macro) 0.8054\n",
      "- Accuracy 0.924\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8970    0.9135    0.9052      1353\n",
      "         ADJ     0.8809    0.9137    0.8970       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9903    0.9922    0.9913       514\n",
      "        VERB     0.8983    0.9243    0.9111       449\n",
      "       PROPN     0.8041    0.7180    0.7586       383\n",
      "         AUX     0.9910    0.9851    0.9880       335\n",
      "       CCONJ     0.9796    1.0000    0.9897       192\n",
      "       SCONJ     0.9945    0.9891    0.9918       184\n",
      "         DET     0.8854    0.8634    0.8742       161\n",
      "         ADV     0.8609    0.8609    0.8609       151\n",
      "        PRON     1.0000    0.9391    0.9686       115\n",
      "         NUM     0.9333    0.7887    0.8550        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9240      5264\n",
      "   macro avg     0.8197    0.7936    0.8054      5264\n",
      "weighted avg     0.9240    0.9240    0.9236      5264\n",
      "\n",
      "2022-08-30 22:53:16,565 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:53:16,566 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:53:17,058 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 9 #######################\n",
      "#######################################################\n",
      "2022-08-30 22:55:39,667 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:55:39,668 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 22:55:39,668 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:55:39,669 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 22:55:39,670 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:55:39,671 Parameters:\n",
      "2022-08-30 22:55:39,671  - learning_rate: \"0.400333\"\n",
      "2022-08-30 22:55:39,672  - mini_batch_size: \"90\"\n",
      "2022-08-30 22:55:39,672  - patience: \"3\"\n",
      "2022-08-30 22:55:39,673  - anneal_factor: \"0.5\"\n",
      "2022-08-30 22:55:39,673  - max_epochs: \"12\"\n",
      "2022-08-30 22:55:39,674  - shuffle: \"True\"\n",
      "2022-08-30 22:55:39,674  - train_with_dev: \"False\"\n",
      "2022-08-30 22:55:39,675  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 22:55:39,676 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:55:39,676 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 22:55:39,677 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:55:39,677 Device: cpu\n",
      "2022-08-30 22:55:39,678 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:55:39,678 Embeddings storage mode: cpu\n",
      "2022-08-30 22:55:39,678 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:55:41,951 epoch 1 - iter 3/37 - loss 0.31615657 - samples/sec: 118.89 - lr: 0.400333\n",
      "2022-08-30 22:55:44,703 epoch 1 - iter 6/37 - loss 0.33427092 - samples/sec: 100.48 - lr: 0.400333\n",
      "2022-08-30 22:55:46,943 epoch 1 - iter 9/37 - loss 0.33372952 - samples/sec: 123.85 - lr: 0.400333\n",
      "2022-08-30 22:55:49,157 epoch 1 - iter 12/37 - loss 0.32821172 - samples/sec: 125.23 - lr: 0.400333\n",
      "2022-08-30 22:55:51,430 epoch 1 - iter 15/37 - loss 0.32685032 - samples/sec: 121.79 - lr: 0.400333\n",
      "2022-08-30 22:55:53,710 epoch 1 - iter 18/37 - loss 0.32874194 - samples/sec: 122.28 - lr: 0.400333\n",
      "2022-08-30 22:55:56,251 epoch 1 - iter 21/37 - loss 0.32807175 - samples/sec: 109.09 - lr: 0.400333\n",
      "2022-08-30 22:55:58,733 epoch 1 - iter 24/37 - loss 0.33106079 - samples/sec: 111.48 - lr: 0.400333\n",
      "2022-08-30 22:56:01,138 epoch 1 - iter 27/37 - loss 0.33061924 - samples/sec: 115.34 - lr: 0.400333\n",
      "2022-08-30 22:56:03,279 epoch 1 - iter 30/37 - loss 0.33016122 - samples/sec: 129.68 - lr: 0.400333\n",
      "2022-08-30 22:56:06,072 epoch 1 - iter 33/37 - loss 0.33268216 - samples/sec: 98.90 - lr: 0.400333\n",
      "2022-08-30 22:56:08,926 epoch 1 - iter 36/37 - loss 0.34170508 - samples/sec: 96.84 - lr: 0.400333\n",
      "2022-08-30 22:56:10,121 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:56:10,121 EPOCH 1 done: loss 0.3452 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:56:10,951 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:56:10,984 DEV : loss 0.255266934633255 - f1-score (micro avg)  0.9147\n",
      "2022-08-30 22:56:10,999 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:56:11,000 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:56:11,683 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:56:14,119 epoch 2 - iter 3/37 - loss 0.36214710 - samples/sec: 110.88 - lr: 0.400333\n",
      "2022-08-30 22:56:16,417 epoch 2 - iter 6/37 - loss 0.34577175 - samples/sec: 120.86 - lr: 0.400333\n",
      "2022-08-30 22:56:19,243 epoch 2 - iter 9/37 - loss 0.34512310 - samples/sec: 98.58 - lr: 0.400333\n",
      "2022-08-30 22:56:22,042 epoch 2 - iter 12/37 - loss 0.34412979 - samples/sec: 98.47 - lr: 0.400333\n",
      "2022-08-30 22:56:24,530 epoch 2 - iter 15/37 - loss 0.34540884 - samples/sec: 111.07 - lr: 0.400333\n",
      "2022-08-30 22:56:27,321 epoch 2 - iter 18/37 - loss 0.34675169 - samples/sec: 99.05 - lr: 0.400333\n",
      "2022-08-30 22:56:29,691 epoch 2 - iter 21/37 - loss 0.34988070 - samples/sec: 119.52 - lr: 0.400333\n",
      "2022-08-30 22:56:32,271 epoch 2 - iter 24/37 - loss 0.34922729 - samples/sec: 107.40 - lr: 0.400333\n",
      "2022-08-30 22:56:34,599 epoch 2 - iter 27/37 - loss 0.34713238 - samples/sec: 119.42 - lr: 0.400333\n",
      "2022-08-30 22:56:37,220 epoch 2 - iter 30/37 - loss 0.34930360 - samples/sec: 105.39 - lr: 0.400333\n",
      "2022-08-30 22:56:39,941 epoch 2 - iter 33/37 - loss 0.34861460 - samples/sec: 101.50 - lr: 0.400333\n",
      "2022-08-30 22:56:42,016 epoch 2 - iter 36/37 - loss 0.35106538 - samples/sec: 134.06 - lr: 0.400333\n",
      "2022-08-30 22:56:42,903 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:56:42,904 EPOCH 2 done: loss 0.3512 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:56:43,700 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:56:43,730 DEV : loss 0.23220577836036682 - f1-score (micro avg)  0.9227\n",
      "2022-08-30 22:56:43,745 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:56:43,746 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:56:44,445 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:56:47,868 epoch 3 - iter 3/37 - loss 0.32761354 - samples/sec: 78.90 - lr: 0.400333\n",
      "2022-08-30 22:56:50,092 epoch 3 - iter 6/37 - loss 0.33753926 - samples/sec: 124.65 - lr: 0.400333\n",
      "2022-08-30 22:56:52,327 epoch 3 - iter 9/37 - loss 0.33832710 - samples/sec: 124.19 - lr: 0.400333\n",
      "2022-08-30 22:56:55,124 epoch 3 - iter 12/37 - loss 0.34688986 - samples/sec: 99.82 - lr: 0.400333\n",
      "2022-08-30 22:56:57,278 epoch 3 - iter 15/37 - loss 0.34704703 - samples/sec: 128.63 - lr: 0.400333\n",
      "2022-08-30 22:56:59,417 epoch 3 - iter 18/37 - loss 0.34570372 - samples/sec: 129.68 - lr: 0.400333\n",
      "2022-08-30 22:57:01,663 epoch 3 - iter 21/37 - loss 0.34508798 - samples/sec: 124.37 - lr: 0.400333\n",
      "2022-08-30 22:57:04,011 epoch 3 - iter 24/37 - loss 0.34422774 - samples/sec: 119.52 - lr: 0.400333\n",
      "2022-08-30 22:57:06,705 epoch 3 - iter 27/37 - loss 0.34388771 - samples/sec: 102.39 - lr: 0.400333\n",
      "2022-08-30 22:57:09,452 epoch 3 - iter 30/37 - loss 0.34592752 - samples/sec: 100.78 - lr: 0.400333\n",
      "2022-08-30 22:57:11,796 epoch 3 - iter 33/37 - loss 0.34680284 - samples/sec: 119.00 - lr: 0.400333\n",
      "2022-08-30 22:57:14,142 epoch 3 - iter 36/37 - loss 0.34723941 - samples/sec: 118.16 - lr: 0.400333\n",
      "2022-08-30 22:57:15,246 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:57:15,247 EPOCH 3 done: loss 0.3477 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:57:16,163 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:57:16,196 DEV : loss 0.2372143417596817 - f1-score (micro avg)  0.9188\n",
      "2022-08-30 22:57:16,214 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 22:57:16,216 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:57:18,633 epoch 4 - iter 3/37 - loss 0.34662792 - samples/sec: 111.75 - lr: 0.400333\n",
      "2022-08-30 22:57:21,193 epoch 4 - iter 6/37 - loss 0.34109167 - samples/sec: 108.09 - lr: 0.400333\n",
      "2022-08-30 22:57:23,767 epoch 4 - iter 9/37 - loss 0.34970213 - samples/sec: 107.40 - lr: 0.400333\n",
      "2022-08-30 22:57:26,501 epoch 4 - iter 12/37 - loss 0.35089132 - samples/sec: 101.12 - lr: 0.400333\n",
      "2022-08-30 22:57:29,308 epoch 4 - iter 15/37 - loss 0.35218146 - samples/sec: 98.61 - lr: 0.400333\n",
      "2022-08-30 22:57:32,073 epoch 4 - iter 18/37 - loss 0.35200438 - samples/sec: 100.00 - lr: 0.400333\n",
      "2022-08-30 22:57:34,760 epoch 4 - iter 21/37 - loss 0.35114256 - samples/sec: 102.78 - lr: 0.400333\n",
      "2022-08-30 22:57:37,669 epoch 4 - iter 24/37 - loss 0.35163985 - samples/sec: 95.68 - lr: 0.400333\n",
      "2022-08-30 22:57:40,592 epoch 4 - iter 27/37 - loss 0.35327397 - samples/sec: 94.46 - lr: 0.400333\n",
      "2022-08-30 22:57:42,907 epoch 4 - iter 30/37 - loss 0.35008208 - samples/sec: 119.63 - lr: 0.400333\n",
      "2022-08-30 22:57:45,391 epoch 4 - iter 33/37 - loss 0.34910022 - samples/sec: 111.57 - lr: 0.400333\n",
      "2022-08-30 22:57:48,050 epoch 4 - iter 36/37 - loss 0.34907355 - samples/sec: 104.65 - lr: 0.400333\n",
      "2022-08-30 22:57:48,939 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:57:48,940 EPOCH 4 done: loss 0.3496 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:57:49,838 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:57:49,875 DEV : loss 0.23805882036685944 - f1-score (micro avg)  0.9196\n",
      "2022-08-30 22:57:49,894 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 22:57:49,896 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:57:52,598 epoch 5 - iter 3/37 - loss 0.34201341 - samples/sec: 99.96 - lr: 0.400333\n",
      "2022-08-30 22:57:55,329 epoch 5 - iter 6/37 - loss 0.34648032 - samples/sec: 101.43 - lr: 0.400333\n",
      "2022-08-30 22:57:57,936 epoch 5 - iter 9/37 - loss 0.34991375 - samples/sec: 108.30 - lr: 0.400333\n",
      "2022-08-30 22:58:00,346 epoch 5 - iter 12/37 - loss 0.34973595 - samples/sec: 114.70 - lr: 0.400333\n",
      "2022-08-30 22:58:03,513 epoch 5 - iter 15/37 - loss 0.34780640 - samples/sec: 88.44 - lr: 0.400333\n",
      "2022-08-30 22:58:05,939 epoch 5 - iter 18/37 - loss 0.34874681 - samples/sec: 115.73 - lr: 0.400333\n",
      "2022-08-30 22:58:08,070 epoch 5 - iter 21/37 - loss 0.34814151 - samples/sec: 130.56 - lr: 0.400333\n",
      "2022-08-30 22:58:10,805 epoch 5 - iter 24/37 - loss 0.34559071 - samples/sec: 100.93 - lr: 0.400333\n",
      "2022-08-30 22:58:13,068 epoch 5 - iter 27/37 - loss 0.34531419 - samples/sec: 122.95 - lr: 0.400333\n",
      "2022-08-30 22:58:15,743 epoch 5 - iter 30/37 - loss 0.34575106 - samples/sec: 103.61 - lr: 0.400333\n",
      "2022-08-30 22:58:18,000 epoch 5 - iter 33/37 - loss 0.34609630 - samples/sec: 122.89 - lr: 0.400333\n",
      "2022-08-30 22:58:20,708 epoch 5 - iter 36/37 - loss 0.34645134 - samples/sec: 102.43 - lr: 0.400333\n",
      "2022-08-30 22:58:21,642 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:58:21,643 EPOCH 5 done: loss 0.3481 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:58:22,420 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:58:22,453 DEV : loss 0.23861418664455414 - f1-score (micro avg)  0.9188\n",
      "2022-08-30 22:58:22,474 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 22:58:22,475 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:58:24,681 epoch 6 - iter 3/37 - loss 0.31218235 - samples/sec: 122.45 - lr: 0.400333\n",
      "2022-08-30 22:58:27,038 epoch 6 - iter 6/37 - loss 0.32513978 - samples/sec: 117.49 - lr: 0.400333\n",
      "2022-08-30 22:58:29,590 epoch 6 - iter 9/37 - loss 0.34078498 - samples/sec: 108.30 - lr: 0.400333\n",
      "2022-08-30 22:58:32,028 epoch 6 - iter 12/37 - loss 0.34024336 - samples/sec: 113.64 - lr: 0.400333\n",
      "2022-08-30 22:58:35,292 epoch 6 - iter 15/37 - loss 0.33966662 - samples/sec: 84.35 - lr: 0.400333\n",
      "2022-08-30 22:58:38,308 epoch 6 - iter 18/37 - loss 0.33909091 - samples/sec: 91.19 - lr: 0.400333\n",
      "2022-08-30 22:58:41,208 epoch 6 - iter 21/37 - loss 0.34002716 - samples/sec: 95.95 - lr: 0.400333\n",
      "2022-08-30 22:58:43,738 epoch 6 - iter 24/37 - loss 0.33800261 - samples/sec: 110.11 - lr: 0.400333\n",
      "2022-08-30 22:58:46,248 epoch 6 - iter 27/37 - loss 0.34117693 - samples/sec: 110.20 - lr: 0.400333\n",
      "2022-08-30 22:58:48,776 epoch 6 - iter 30/37 - loss 0.34394227 - samples/sec: 109.67 - lr: 0.400333\n",
      "2022-08-30 22:58:51,222 epoch 6 - iter 33/37 - loss 0.34439542 - samples/sec: 113.49 - lr: 0.400333\n",
      "2022-08-30 22:58:54,026 epoch 6 - iter 36/37 - loss 0.34463349 - samples/sec: 98.61 - lr: 0.400333\n",
      "2022-08-30 22:58:54,787 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:58:54,788 EPOCH 6 done: loss 0.3451 - lr 0.400333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:58:55,604 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:58:55,635 DEV : loss 0.23984764516353607 - f1-score (micro avg)  0.9198\n",
      "2022-08-30 22:58:55,653 Epoch     6: reducing learning rate of group 0 to 2.0017e-01.\n",
      "2022-08-30 22:58:55,653 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 22:58:55,655 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:58:58,044 epoch 7 - iter 3/37 - loss 0.34600368 - samples/sec: 113.07 - lr: 0.200167\n",
      "2022-08-30 22:59:01,102 epoch 7 - iter 6/37 - loss 0.33798066 - samples/sec: 90.45 - lr: 0.200167\n",
      "2022-08-30 22:59:03,715 epoch 7 - iter 9/37 - loss 0.33409846 - samples/sec: 105.68 - lr: 0.200167\n",
      "2022-08-30 22:59:06,020 epoch 7 - iter 12/37 - loss 0.33493897 - samples/sec: 121.08 - lr: 0.200167\n",
      "2022-08-30 22:59:08,799 epoch 7 - iter 15/37 - loss 0.33876246 - samples/sec: 99.63 - lr: 0.200167\n",
      "2022-08-30 22:59:11,718 epoch 7 - iter 18/37 - loss 0.33430797 - samples/sec: 94.44 - lr: 0.200167\n",
      "2022-08-30 22:59:14,222 epoch 7 - iter 21/37 - loss 0.33134464 - samples/sec: 110.88 - lr: 0.200167\n",
      "2022-08-30 22:59:18,137 epoch 7 - iter 24/37 - loss 0.33031416 - samples/sec: 70.29 - lr: 0.200167\n",
      "2022-08-30 22:59:20,814 epoch 7 - iter 27/37 - loss 0.33128432 - samples/sec: 103.85 - lr: 0.200167\n",
      "2022-08-30 22:59:23,446 epoch 7 - iter 30/37 - loss 0.33175952 - samples/sec: 105.92 - lr: 0.200167\n",
      "2022-08-30 22:59:26,300 epoch 7 - iter 33/37 - loss 0.33140234 - samples/sec: 97.93 - lr: 0.200167\n",
      "2022-08-30 22:59:28,891 epoch 7 - iter 36/37 - loss 0.33244076 - samples/sec: 107.91 - lr: 0.200167\n",
      "2022-08-30 22:59:29,759 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:59:29,760 EPOCH 7 done: loss 0.3315 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:59:30,540 Evaluating as a multi-label problem: False\n",
      "2022-08-30 22:59:30,575 DEV : loss 0.22673356533050537 - f1-score (micro avg)  0.9263\n",
      "2022-08-30 22:59:30,596 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 22:59:30,597 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 22:59:31,286 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 22:59:33,585 epoch 8 - iter 3/37 - loss 0.34316810 - samples/sec: 117.54 - lr: 0.200167\n",
      "2022-08-30 22:59:35,823 epoch 8 - iter 6/37 - loss 0.33792503 - samples/sec: 125.12 - lr: 0.200167\n",
      "2022-08-30 22:59:38,193 epoch 8 - iter 9/37 - loss 0.33095968 - samples/sec: 117.09 - lr: 0.200167\n",
      "2022-08-30 22:59:40,889 epoch 8 - iter 12/37 - loss 0.33216945 - samples/sec: 102.62 - lr: 0.200167\n",
      "2022-08-30 22:59:43,390 epoch 8 - iter 15/37 - loss 0.33450397 - samples/sec: 110.97 - lr: 0.200167\n",
      "2022-08-30 22:59:46,071 epoch 8 - iter 18/37 - loss 0.33209773 - samples/sec: 104.25 - lr: 0.200167\n",
      "2022-08-30 22:59:48,134 epoch 8 - iter 21/37 - loss 0.33155099 - samples/sec: 134.80 - lr: 0.200167\n",
      "2022-08-30 22:59:50,901 epoch 8 - iter 24/37 - loss 0.33114090 - samples/sec: 99.74 - lr: 0.200167\n",
      "2022-08-30 22:59:53,824 epoch 8 - iter 27/37 - loss 0.33014920 - samples/sec: 94.24 - lr: 0.200167\n",
      "2022-08-30 22:59:55,966 epoch 8 - iter 30/37 - loss 0.32980398 - samples/sec: 129.43 - lr: 0.200167\n",
      "2022-08-30 22:59:58,664 epoch 8 - iter 33/37 - loss 0.32845664 - samples/sec: 102.27 - lr: 0.200167\n",
      "2022-08-30 23:00:00,980 epoch 8 - iter 36/37 - loss 0.32765617 - samples/sec: 119.79 - lr: 0.200167\n",
      "2022-08-30 23:00:02,232 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:00:02,233 EPOCH 8 done: loss 0.3273 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:00:04,464 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:00:04,496 DEV : loss 0.23281453549861908 - f1-score (micro avg)  0.9245\n",
      "2022-08-30 23:00:04,515 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:00:04,516 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:00:06,982 epoch 9 - iter 3/37 - loss 0.30531239 - samples/sec: 109.53 - lr: 0.200167\n",
      "2022-08-30 23:00:09,219 epoch 9 - iter 6/37 - loss 0.31652332 - samples/sec: 123.80 - lr: 0.200167\n",
      "2022-08-30 23:00:11,901 epoch 9 - iter 9/37 - loss 0.32070266 - samples/sec: 102.86 - lr: 0.200167\n",
      "2022-08-30 23:00:14,746 epoch 9 - iter 12/37 - loss 0.32468547 - samples/sec: 97.02 - lr: 0.200167\n",
      "2022-08-30 23:00:17,159 epoch 9 - iter 15/37 - loss 0.32407904 - samples/sec: 115.04 - lr: 0.200167\n",
      "2022-08-30 23:00:20,326 epoch 9 - iter 18/37 - loss 0.32639926 - samples/sec: 86.79 - lr: 0.200167\n",
      "2022-08-30 23:00:22,353 epoch 9 - iter 21/37 - loss 0.32502123 - samples/sec: 141.14 - lr: 0.200167\n",
      "2022-08-30 23:00:24,812 epoch 9 - iter 24/37 - loss 0.32584168 - samples/sec: 113.30 - lr: 0.200167\n",
      "2022-08-30 23:00:27,024 epoch 9 - iter 27/37 - loss 0.32692934 - samples/sec: 125.23 - lr: 0.200167\n",
      "2022-08-30 23:00:29,686 epoch 9 - iter 30/37 - loss 0.32698056 - samples/sec: 103.77 - lr: 0.200167\n",
      "2022-08-30 23:00:32,049 epoch 9 - iter 33/37 - loss 0.32394573 - samples/sec: 117.29 - lr: 0.200167\n",
      "2022-08-30 23:00:34,570 epoch 9 - iter 36/37 - loss 0.32274515 - samples/sec: 109.76 - lr: 0.200167\n",
      "2022-08-30 23:00:35,365 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:00:35,366 EPOCH 9 done: loss 0.3227 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:00:36,306 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:00:36,343 DEV : loss 0.2271624356508255 - f1-score (micro avg)  0.9258\n",
      "2022-08-30 23:00:36,362 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 23:00:36,363 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:00:38,890 epoch 10 - iter 3/37 - loss 0.34810869 - samples/sec: 106.89 - lr: 0.200167\n",
      "2022-08-30 23:00:41,078 epoch 10 - iter 6/37 - loss 0.34124515 - samples/sec: 127.06 - lr: 0.200167\n",
      "2022-08-30 23:00:44,079 epoch 10 - iter 9/37 - loss 0.33774198 - samples/sec: 91.87 - lr: 0.200167\n",
      "2022-08-30 23:00:47,028 epoch 10 - iter 12/37 - loss 0.33423442 - samples/sec: 93.39 - lr: 0.200167\n",
      "2022-08-30 23:00:49,631 epoch 10 - iter 15/37 - loss 0.33155721 - samples/sec: 106.30 - lr: 0.200167\n",
      "2022-08-30 23:00:52,249 epoch 10 - iter 18/37 - loss 0.33193279 - samples/sec: 105.76 - lr: 0.200167\n",
      "2022-08-30 23:00:54,818 epoch 10 - iter 21/37 - loss 0.32959882 - samples/sec: 107.48 - lr: 0.200167\n",
      "2022-08-30 23:00:57,057 epoch 10 - iter 24/37 - loss 0.32865208 - samples/sec: 123.68 - lr: 0.200167\n",
      "2022-08-30 23:00:59,460 epoch 10 - iter 27/37 - loss 0.32866990 - samples/sec: 115.04 - lr: 0.200167\n",
      "2022-08-30 23:01:01,699 epoch 10 - iter 30/37 - loss 0.32849062 - samples/sec: 124.25 - lr: 0.200167\n",
      "2022-08-30 23:01:04,234 epoch 10 - iter 33/37 - loss 0.32667927 - samples/sec: 109.09 - lr: 0.200167\n",
      "2022-08-30 23:01:06,648 epoch 10 - iter 36/37 - loss 0.32415448 - samples/sec: 114.84 - lr: 0.200167\n",
      "2022-08-30 23:01:07,785 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:01:07,786 EPOCH 10 done: loss 0.3240 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:01:08,663 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:01:08,700 DEV : loss 0.23129446804523468 - f1-score (micro avg)  0.9222\n",
      "2022-08-30 23:01:08,721 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 23:01:08,722 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:01:10,971 epoch 11 - iter 3/37 - loss 0.30879909 - samples/sec: 120.16 - lr: 0.200167\n",
      "2022-08-30 23:01:13,534 epoch 11 - iter 6/37 - loss 0.30794466 - samples/sec: 108.09 - lr: 0.200167\n",
      "2022-08-30 23:01:15,983 epoch 11 - iter 9/37 - loss 0.31596811 - samples/sec: 114.31 - lr: 0.200167\n",
      "2022-08-30 23:01:18,997 epoch 11 - iter 12/37 - loss 0.30789421 - samples/sec: 91.40 - lr: 0.200167\n",
      "2022-08-30 23:01:21,959 epoch 11 - iter 15/37 - loss 0.30933702 - samples/sec: 93.04 - lr: 0.200167\n",
      "2022-08-30 23:01:24,510 epoch 11 - iter 18/37 - loss 0.31193786 - samples/sec: 108.26 - lr: 0.200167\n",
      "2022-08-30 23:01:26,988 epoch 11 - iter 21/37 - loss 0.31306315 - samples/sec: 111.99 - lr: 0.200167\n",
      "2022-08-30 23:01:29,507 epoch 11 - iter 24/37 - loss 0.31323944 - samples/sec: 109.93 - lr: 0.200167\n",
      "2022-08-30 23:01:32,287 epoch 11 - iter 27/37 - loss 0.31613096 - samples/sec: 99.37 - lr: 0.200167\n",
      "2022-08-30 23:01:34,926 epoch 11 - iter 30/37 - loss 0.31831988 - samples/sec: 105.47 - lr: 0.200167\n",
      "2022-08-30 23:01:37,243 epoch 11 - iter 33/37 - loss 0.31831797 - samples/sec: 119.73 - lr: 0.200167\n",
      "2022-08-30 23:01:39,650 epoch 11 - iter 36/37 - loss 0.31812578 - samples/sec: 114.99 - lr: 0.200167\n",
      "2022-08-30 23:01:40,555 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:01:40,556 EPOCH 11 done: loss 0.3181 - lr 0.200167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:01:41,349 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:01:41,383 DEV : loss 0.2269372045993805 - f1-score (micro avg)  0.924\n",
      "2022-08-30 23:01:41,398 Epoch    11: reducing learning rate of group 0 to 1.0008e-01.\n",
      "2022-08-30 23:01:41,398 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 23:01:41,400 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:01:43,949 epoch 12 - iter 3/37 - loss 0.32220454 - samples/sec: 105.97 - lr: 0.100083\n",
      "2022-08-30 23:01:46,389 epoch 12 - iter 6/37 - loss 0.32504465 - samples/sec: 113.78 - lr: 0.100083\n",
      "2022-08-30 23:01:49,196 epoch 12 - iter 9/37 - loss 0.32167437 - samples/sec: 99.03 - lr: 0.100083\n",
      "2022-08-30 23:01:51,560 epoch 12 - iter 12/37 - loss 0.31780409 - samples/sec: 117.49 - lr: 0.100083\n",
      "2022-08-30 23:01:53,964 epoch 12 - iter 15/37 - loss 0.31565941 - samples/sec: 115.58 - lr: 0.100083\n",
      "2022-08-30 23:01:56,955 epoch 12 - iter 18/37 - loss 0.31320355 - samples/sec: 92.15 - lr: 0.100083\n",
      "2022-08-30 23:01:59,436 epoch 12 - iter 21/37 - loss 0.31573294 - samples/sec: 111.66 - lr: 0.100083\n",
      "2022-08-30 23:02:01,911 epoch 12 - iter 24/37 - loss 0.31586079 - samples/sec: 113.16 - lr: 0.100083\n",
      "2022-08-30 23:02:04,308 epoch 12 - iter 27/37 - loss 0.31772634 - samples/sec: 115.38 - lr: 0.100083\n",
      "2022-08-30 23:02:06,860 epoch 12 - iter 30/37 - loss 0.31597150 - samples/sec: 109.18 - lr: 0.100083\n",
      "2022-08-30 23:02:10,035 epoch 12 - iter 33/37 - loss 0.31602497 - samples/sec: 86.84 - lr: 0.100083\n",
      "2022-08-30 23:02:12,332 epoch 12 - iter 36/37 - loss 0.31413604 - samples/sec: 120.70 - lr: 0.100083\n",
      "2022-08-30 23:02:13,116 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:02:13,117 EPOCH 12 done: loss 0.3137 - lr 0.100083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:02:13,952 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:02:13,987 DEV : loss 0.22802519798278809 - f1-score (micro avg)  0.9225\n",
      "2022-08-30 23:02:14,002 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:02:14,752 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:02:14,753 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 23:02:14,934 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:02:16,380 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:02:16,403 0.9301\t0.9301\t0.9301\t0.9301\n",
      "2022-08-30 23:02:16,404 \n",
      "Results:\n",
      "- F-score (micro) 0.9301\n",
      "- F-score (macro) 0.8708\n",
      "- Accuracy 0.9301\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.9143    0.9150    0.9147      1353\n",
      "         ADJ     0.8771    0.9241    0.9000       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9903    0.9903    0.9903       514\n",
      "        VERB     0.9087    0.9310    0.9197       449\n",
      "       PROPN     0.8377    0.7546    0.7940       383\n",
      "         AUX     0.9910    0.9910    0.9910       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9945    0.9891    0.9918       184\n",
      "         DET     0.8424    0.8634    0.8528       161\n",
      "         ADV     0.8627    0.8742    0.8684       151\n",
      "        PRON     1.0000    0.9478    0.9732       115\n",
      "         NUM     0.9500    0.8028    0.8702        71\n",
      "        PART     0.9444    0.8095    0.8718        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9301      5264\n",
      "   macro avg     0.8814    0.8620    0.8708      5264\n",
      "weighted avg     0.9306    0.9301    0.9300      5264\n",
      "\n",
      "2022-08-30 23:02:16,404 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:02:16,406 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:02:16,901 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 4 #######################\n",
      "#######################################################\n",
      "2022-08-30 23:04:43,845 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:04:43,846 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 23:04:43,847 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:04:43,847 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 23:04:43,848 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:04:43,848 Parameters:\n",
      "2022-08-30 23:04:43,849  - learning_rate: \"0.600000\"\n",
      "2022-08-30 23:04:43,849  - mini_batch_size: \"10\"\n",
      "2022-08-30 23:04:43,850  - patience: \"3\"\n",
      "2022-08-30 23:04:43,850  - anneal_factor: \"0.5\"\n",
      "2022-08-30 23:04:43,850  - max_epochs: \"10\"\n",
      "2022-08-30 23:04:43,851  - shuffle: \"True\"\n",
      "2022-08-30 23:04:43,852  - train_with_dev: \"False\"\n",
      "2022-08-30 23:04:43,852  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 23:04:43,853 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:04:43,853 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 23:04:43,854 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:04:43,854 Device: cpu\n",
      "2022-08-30 23:04:43,855 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:04:43,855 Embeddings storage mode: cpu\n",
      "2022-08-30 23:04:43,856 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:04:48,043 epoch 1 - iter 33/333 - loss 0.40092523 - samples/sec: 78.83 - lr: 0.600000\n",
      "2022-08-30 23:04:52,449 epoch 1 - iter 66/333 - loss 0.43131634 - samples/sec: 76.02 - lr: 0.600000\n",
      "2022-08-30 23:04:56,120 epoch 1 - iter 99/333 - loss 0.44495115 - samples/sec: 91.69 - lr: 0.600000\n",
      "2022-08-30 23:05:00,092 epoch 1 - iter 132/333 - loss 0.45833935 - samples/sec: 84.33 - lr: 0.600000\n",
      "2022-08-30 23:05:04,895 epoch 1 - iter 165/333 - loss 0.47291115 - samples/sec: 69.62 - lr: 0.600000\n",
      "2022-08-30 23:05:08,646 epoch 1 - iter 198/333 - loss 0.48058159 - samples/sec: 89.43 - lr: 0.600000\n",
      "2022-08-30 23:05:12,874 epoch 1 - iter 231/333 - loss 0.48645270 - samples/sec: 79.35 - lr: 0.600000\n",
      "2022-08-30 23:05:16,561 epoch 1 - iter 264/333 - loss 0.49120014 - samples/sec: 91.06 - lr: 0.600000\n",
      "2022-08-30 23:05:20,739 epoch 1 - iter 297/333 - loss 0.49837033 - samples/sec: 80.21 - lr: 0.600000\n",
      "2022-08-30 23:05:25,071 epoch 1 - iter 330/333 - loss 0.51843270 - samples/sec: 77.18 - lr: 0.600000\n",
      "2022-08-30 23:05:25,530 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:05:25,531 EPOCH 1 done: loss 0.5194 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:05:26,512 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:05:26,543 DEV : loss 0.39866459369659424 - f1-score (micro avg)  0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:05:26,563 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:05:26,564 saving best model\n",
      "2022-08-30 23:05:27,565 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:05:31,386 epoch 2 - iter 33/333 - loss 0.57800715 - samples/sec: 86.52 - lr: 0.600000\n",
      "2022-08-30 23:05:35,652 epoch 2 - iter 66/333 - loss 0.56205501 - samples/sec: 78.65 - lr: 0.600000\n",
      "2022-08-30 23:05:39,284 epoch 2 - iter 99/333 - loss 0.56377726 - samples/sec: 92.44 - lr: 0.600000\n",
      "2022-08-30 23:05:43,228 epoch 2 - iter 132/333 - loss 0.57083794 - samples/sec: 84.92 - lr: 0.600000\n",
      "2022-08-30 23:05:47,587 epoch 2 - iter 165/333 - loss 0.56283638 - samples/sec: 76.67 - lr: 0.600000\n",
      "2022-08-30 23:05:51,689 epoch 2 - iter 198/333 - loss 0.56033690 - samples/sec: 81.68 - lr: 0.600000\n",
      "2022-08-30 23:05:55,650 epoch 2 - iter 231/333 - loss 0.56642630 - samples/sec: 84.44 - lr: 0.600000\n",
      "2022-08-30 23:05:59,999 epoch 2 - iter 264/333 - loss 0.56531099 - samples/sec: 76.94 - lr: 0.600000\n",
      "2022-08-30 23:06:04,095 epoch 2 - iter 297/333 - loss 0.57021019 - samples/sec: 81.72 - lr: 0.600000\n",
      "2022-08-30 23:06:07,632 epoch 2 - iter 330/333 - loss 0.57306843 - samples/sec: 95.10 - lr: 0.600000\n",
      "2022-08-30 23:06:07,995 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:06:07,996 EPOCH 2 done: loss 0.5731 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:06:09,011 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:06:09,048 DEV : loss 0.34263432025909424 - f1-score (micro avg)  0.8814\n",
      "2022-08-30 23:06:09,067 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:06:09,069 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:06:10,073 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:06:13,737 epoch 3 - iter 33/333 - loss 0.54733110 - samples/sec: 90.16 - lr: 0.600000\n",
      "2022-08-30 23:06:17,838 epoch 3 - iter 66/333 - loss 0.56476919 - samples/sec: 81.66 - lr: 0.600000\n",
      "2022-08-30 23:06:22,001 epoch 3 - iter 99/333 - loss 0.56322861 - samples/sec: 80.49 - lr: 0.600000\n",
      "2022-08-30 23:06:25,854 epoch 3 - iter 132/333 - loss 0.57161083 - samples/sec: 87.05 - lr: 0.600000\n",
      "2022-08-30 23:06:30,011 epoch 3 - iter 165/333 - loss 0.57624360 - samples/sec: 80.45 - lr: 0.600000\n",
      "2022-08-30 23:06:33,880 epoch 3 - iter 198/333 - loss 0.58116861 - samples/sec: 86.59 - lr: 0.600000\n",
      "2022-08-30 23:06:37,621 epoch 3 - iter 231/333 - loss 0.58266388 - samples/sec: 89.75 - lr: 0.600000\n",
      "2022-08-30 23:06:41,779 epoch 3 - iter 264/333 - loss 0.58492416 - samples/sec: 80.59 - lr: 0.600000\n",
      "2022-08-30 23:06:45,763 epoch 3 - iter 297/333 - loss 0.58848892 - samples/sec: 83.97 - lr: 0.600000\n",
      "2022-08-30 23:06:49,846 epoch 3 - iter 330/333 - loss 0.58993917 - samples/sec: 81.95 - lr: 0.600000\n",
      "2022-08-30 23:06:50,258 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:06:50,258 EPOCH 3 done: loss 0.5898 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:06:51,232 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:06:51,262 DEV : loss 0.3639705181121826 - f1-score (micro avg)  0.8778\n",
      "2022-08-30 23:06:51,279 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:06:51,280 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:06:55,246 epoch 4 - iter 33/333 - loss 0.59727261 - samples/sec: 83.23 - lr: 0.600000\n",
      "2022-08-30 23:06:59,450 epoch 4 - iter 66/333 - loss 0.60288406 - samples/sec: 79.61 - lr: 0.600000\n",
      "2022-08-30 23:07:03,571 epoch 4 - iter 99/333 - loss 0.60828261 - samples/sec: 81.58 - lr: 0.600000\n",
      "2022-08-30 23:07:07,697 epoch 4 - iter 132/333 - loss 0.61078591 - samples/sec: 81.32 - lr: 0.600000\n",
      "2022-08-30 23:07:11,614 epoch 4 - iter 165/333 - loss 0.61568179 - samples/sec: 85.45 - lr: 0.600000\n",
      "2022-08-30 23:07:15,592 epoch 4 - iter 198/333 - loss 0.61635595 - samples/sec: 84.38 - lr: 0.600000\n",
      "2022-08-30 23:07:19,817 epoch 4 - iter 231/333 - loss 0.61422360 - samples/sec: 79.27 - lr: 0.600000\n",
      "2022-08-30 23:07:23,650 epoch 4 - iter 264/333 - loss 0.61367033 - samples/sec: 87.67 - lr: 0.600000\n",
      "2022-08-30 23:07:27,793 epoch 4 - iter 297/333 - loss 0.61464138 - samples/sec: 80.76 - lr: 0.600000\n",
      "2022-08-30 23:07:31,523 epoch 4 - iter 330/333 - loss 0.61434474 - samples/sec: 89.97 - lr: 0.600000\n",
      "2022-08-30 23:07:31,929 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:07:31,930 EPOCH 4 done: loss 0.6137 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:07:32,897 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:07:32,925 DEV : loss 0.3435022830963135 - f1-score (micro avg)  0.8837\n",
      "2022-08-30 23:07:32,940 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:07:32,941 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:07:33,684 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:07:37,870 epoch 5 - iter 33/333 - loss 0.60343046 - samples/sec: 78.91 - lr: 0.600000\n",
      "2022-08-30 23:07:42,264 epoch 5 - iter 66/333 - loss 0.61319489 - samples/sec: 76.11 - lr: 0.600000\n",
      "2022-08-30 23:07:46,374 epoch 5 - iter 99/333 - loss 0.61126850 - samples/sec: 81.48 - lr: 0.600000\n",
      "2022-08-30 23:07:50,747 epoch 5 - iter 132/333 - loss 0.61437968 - samples/sec: 76.71 - lr: 0.600000\n",
      "2022-08-30 23:07:54,443 epoch 5 - iter 165/333 - loss 0.61850061 - samples/sec: 90.81 - lr: 0.600000\n",
      "2022-08-30 23:07:58,411 epoch 5 - iter 198/333 - loss 0.61798242 - samples/sec: 84.38 - lr: 0.600000\n",
      "2022-08-30 23:08:02,344 epoch 5 - iter 231/333 - loss 0.61727495 - samples/sec: 85.25 - lr: 0.600000\n",
      "2022-08-30 23:08:06,394 epoch 5 - iter 264/333 - loss 0.61841862 - samples/sec: 82.89 - lr: 0.600000\n",
      "2022-08-30 23:08:10,095 epoch 5 - iter 297/333 - loss 0.62088486 - samples/sec: 90.88 - lr: 0.600000\n",
      "2022-08-30 23:08:13,642 epoch 5 - iter 330/333 - loss 0.62467137 - samples/sec: 94.53 - lr: 0.600000\n",
      "2022-08-30 23:08:14,120 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:08:14,121 EPOCH 5 done: loss 0.6247 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:08:15,132 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:08:15,168 DEV : loss 0.35086333751678467 - f1-score (micro avg)  0.8726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:08:15,192 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:08:15,193 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:08:19,219 epoch 6 - iter 33/333 - loss 0.62362424 - samples/sec: 82.03 - lr: 0.600000\n",
      "2022-08-30 23:08:23,605 epoch 6 - iter 66/333 - loss 0.62273422 - samples/sec: 76.28 - lr: 0.600000\n",
      "2022-08-30 23:08:27,553 epoch 6 - iter 99/333 - loss 0.63932653 - samples/sec: 85.07 - lr: 0.600000\n",
      "2022-08-30 23:08:31,166 epoch 6 - iter 132/333 - loss 0.64119747 - samples/sec: 93.14 - lr: 0.600000\n",
      "2022-08-30 23:08:35,702 epoch 6 - iter 165/333 - loss 0.63635881 - samples/sec: 73.81 - lr: 0.600000\n",
      "2022-08-30 23:08:39,598 epoch 6 - iter 198/333 - loss 0.64160165 - samples/sec: 86.23 - lr: 0.600000\n",
      "2022-08-30 23:08:44,271 epoch 6 - iter 231/333 - loss 0.64124829 - samples/sec: 71.68 - lr: 0.600000\n",
      "2022-08-30 23:08:48,487 epoch 6 - iter 264/333 - loss 0.64127592 - samples/sec: 79.37 - lr: 0.600000\n",
      "2022-08-30 23:08:51,987 epoch 6 - iter 297/333 - loss 0.64483368 - samples/sec: 95.87 - lr: 0.600000\n",
      "2022-08-30 23:08:55,870 epoch 6 - iter 330/333 - loss 0.64411585 - samples/sec: 86.32 - lr: 0.600000\n",
      "2022-08-30 23:08:56,262 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:08:56,262 EPOCH 6 done: loss 0.6446 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:08:57,303 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:08:57,334 DEV : loss 0.3898892104625702 - f1-score (micro avg)  0.865\n",
      "2022-08-30 23:08:57,352 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 23:08:57,354 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:09:01,149 epoch 7 - iter 33/333 - loss 0.67034067 - samples/sec: 87.05 - lr: 0.600000\n",
      "2022-08-30 23:09:04,954 epoch 7 - iter 66/333 - loss 0.66693407 - samples/sec: 88.21 - lr: 0.600000\n",
      "2022-08-30 23:09:09,216 epoch 7 - iter 99/333 - loss 0.65105015 - samples/sec: 78.59 - lr: 0.600000\n",
      "2022-08-30 23:09:13,308 epoch 7 - iter 132/333 - loss 0.65613447 - samples/sec: 81.95 - lr: 0.600000\n",
      "2022-08-30 23:09:17,640 epoch 7 - iter 165/333 - loss 0.65516914 - samples/sec: 77.23 - lr: 0.600000\n",
      "2022-08-30 23:09:21,617 epoch 7 - iter 198/333 - loss 0.65395929 - samples/sec: 84.25 - lr: 0.600000\n",
      "2022-08-30 23:09:25,643 epoch 7 - iter 231/333 - loss 0.65091770 - samples/sec: 83.17 - lr: 0.600000\n",
      "2022-08-30 23:09:29,612 epoch 7 - iter 264/333 - loss 0.64902528 - samples/sec: 84.46 - lr: 0.600000\n",
      "2022-08-30 23:09:33,570 epoch 7 - iter 297/333 - loss 0.64966034 - samples/sec: 84.75 - lr: 0.600000\n",
      "2022-08-30 23:09:38,083 epoch 7 - iter 330/333 - loss 0.65176590 - samples/sec: 74.24 - lr: 0.600000\n",
      "2022-08-30 23:09:38,527 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:09:38,528 EPOCH 7 done: loss 0.6521 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:09:39,514 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:09:39,543 DEV : loss 0.41394662857055664 - f1-score (micro avg)  0.8533\n",
      "2022-08-30 23:09:39,558 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 23:09:39,559 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:09:43,360 epoch 8 - iter 33/333 - loss 0.65638440 - samples/sec: 86.84 - lr: 0.600000\n",
      "2022-08-30 23:09:46,999 epoch 8 - iter 66/333 - loss 0.64858154 - samples/sec: 92.51 - lr: 0.600000\n",
      "2022-08-30 23:09:51,804 epoch 8 - iter 99/333 - loss 0.64957469 - samples/sec: 69.58 - lr: 0.600000\n",
      "2022-08-30 23:09:55,679 epoch 8 - iter 132/333 - loss 0.65542344 - samples/sec: 86.39 - lr: 0.600000\n",
      "2022-08-30 23:09:59,655 epoch 8 - iter 165/333 - loss 0.65408115 - samples/sec: 84.21 - lr: 0.600000\n",
      "2022-08-30 23:10:03,750 epoch 8 - iter 198/333 - loss 0.65385906 - samples/sec: 81.85 - lr: 0.600000\n",
      "2022-08-30 23:10:07,544 epoch 8 - iter 231/333 - loss 0.65799721 - samples/sec: 88.42 - lr: 0.600000\n",
      "2022-08-30 23:10:11,573 epoch 8 - iter 264/333 - loss 0.65847806 - samples/sec: 83.17 - lr: 0.600000\n",
      "2022-08-30 23:10:15,504 epoch 8 - iter 297/333 - loss 0.66117427 - samples/sec: 85.38 - lr: 0.600000\n",
      "2022-08-30 23:10:19,696 epoch 8 - iter 330/333 - loss 0.66243954 - samples/sec: 79.85 - lr: 0.600000\n",
      "2022-08-30 23:10:20,089 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:10:20,089 EPOCH 8 done: loss 0.6628 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:10:21,159 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:10:21,193 DEV : loss 0.3879641890525818 - f1-score (micro avg)  0.8673\n",
      "2022-08-30 23:10:21,210 Epoch     8: reducing learning rate of group 0 to 3.0000e-01.\n",
      "2022-08-30 23:10:21,211 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 23:10:21,212 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:10:24,968 epoch 9 - iter 33/333 - loss 0.59834170 - samples/sec: 87.91 - lr: 0.300000\n",
      "2022-08-30 23:10:28,810 epoch 9 - iter 66/333 - loss 0.60564255 - samples/sec: 87.19 - lr: 0.300000\n",
      "2022-08-30 23:10:33,079 epoch 9 - iter 99/333 - loss 0.60503410 - samples/sec: 78.52 - lr: 0.300000\n",
      "2022-08-30 23:10:37,625 epoch 9 - iter 132/333 - loss 0.60731254 - samples/sec: 73.69 - lr: 0.300000\n",
      "2022-08-30 23:10:42,054 epoch 9 - iter 165/333 - loss 0.59901605 - samples/sec: 75.74 - lr: 0.300000\n",
      "2022-08-30 23:10:45,796 epoch 9 - iter 198/333 - loss 0.60080654 - samples/sec: 89.55 - lr: 0.300000\n",
      "2022-08-30 23:10:49,962 epoch 9 - iter 231/333 - loss 0.59582518 - samples/sec: 80.45 - lr: 0.300000\n",
      "2022-08-30 23:10:53,458 epoch 9 - iter 264/333 - loss 0.59356510 - samples/sec: 95.93 - lr: 0.300000\n",
      "2022-08-30 23:10:57,653 epoch 9 - iter 297/333 - loss 0.59078678 - samples/sec: 79.90 - lr: 0.300000\n",
      "2022-08-30 23:11:01,471 epoch 9 - iter 330/333 - loss 0.58863713 - samples/sec: 87.81 - lr: 0.300000\n",
      "2022-08-30 23:11:01,801 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:11:01,802 EPOCH 9 done: loss 0.5889 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:11:02,861 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:11:02,890 DEV : loss 0.3300388753414154 - f1-score (micro avg)  0.8845\n",
      "2022-08-30 23:11:02,905 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:11:02,906 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:11:03,622 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:11:07,324 epoch 10 - iter 33/333 - loss 0.52982750 - samples/sec: 89.21 - lr: 0.300000\n",
      "2022-08-30 23:11:11,186 epoch 10 - iter 66/333 - loss 0.54099945 - samples/sec: 87.05 - lr: 0.300000\n",
      "2022-08-30 23:11:15,327 epoch 10 - iter 99/333 - loss 0.54090781 - samples/sec: 80.86 - lr: 0.300000\n",
      "2022-08-30 23:11:19,597 epoch 10 - iter 132/333 - loss 0.54927204 - samples/sec: 78.61 - lr: 0.300000\n",
      "2022-08-30 23:11:23,541 epoch 10 - iter 165/333 - loss 0.55844260 - samples/sec: 85.16 - lr: 0.300000\n",
      "2022-08-30 23:11:27,417 epoch 10 - iter 198/333 - loss 0.55663180 - samples/sec: 86.48 - lr: 0.300000\n",
      "2022-08-30 23:11:31,466 epoch 10 - iter 231/333 - loss 0.55717607 - samples/sec: 82.91 - lr: 0.300000\n",
      "2022-08-30 23:11:35,123 epoch 10 - iter 264/333 - loss 0.55779492 - samples/sec: 91.92 - lr: 0.300000\n",
      "2022-08-30 23:11:39,113 epoch 10 - iter 297/333 - loss 0.55928178 - samples/sec: 84.08 - lr: 0.300000\n",
      "2022-08-30 23:11:43,040 epoch 10 - iter 330/333 - loss 0.56064522 - samples/sec: 85.29 - lr: 0.300000\n",
      "2022-08-30 23:11:43,496 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:11:43,497 EPOCH 10 done: loss 0.5619 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:11:44,492 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:11:44,523 DEV : loss 0.3266279101371765 - f1-score (micro avg)  0.8894\n",
      "2022-08-30 23:11:44,544 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:11:44,545 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:11:45,944 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:11:45,945 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 23:11:46,122 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:11:47,648 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:11:47,676 0.8955\t0.8955\t0.8955\t0.8955\n",
      "2022-08-30 23:11:47,676 \n",
      "Results:\n",
      "- F-score (micro) 0.8955\n",
      "- F-score (macro) 0.7747\n",
      "- Accuracy 0.8955\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8343    0.9194    0.8748      1353\n",
      "         ADJ     0.8140    0.8988    0.8543       672\n",
      "       PUNCT     0.9985    1.0000    0.9992       660\n",
      "         ADP     0.9921    0.9747    0.9833       514\n",
      "        VERB     0.8756    0.8307    0.8526       449\n",
      "       PROPN     0.8153    0.6110    0.6985       383\n",
      "         AUX     0.9909    0.9701    0.9804       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         DET     0.9091    0.7453    0.8191       161\n",
      "         ADV     0.8120    0.7152    0.7606       151\n",
      "        PRON     0.9904    0.8957    0.9406       115\n",
      "         NUM     0.9615    0.7042    0.8130        71\n",
      "        PART     0.8500    0.8095    0.8293        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8955      5264\n",
      "   macro avg     0.8017    0.7543    0.7747      5264\n",
      "weighted avg     0.8974    0.8955    0.8939      5264\n",
      "\n",
      "2022-08-30 23:11:47,677 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:11:47,679 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 23:11:48,186 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 23:14:10,471 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:14:10,471 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 23:14:10,472 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:14:10,473 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 23:14:10,474 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:14:10,474 Parameters:\n",
      "2022-08-30 23:14:10,474  - learning_rate: \"0.600000\"\n",
      "2022-08-30 23:14:10,475  - mini_batch_size: \"10\"\n",
      "2022-08-30 23:14:10,475  - patience: \"3\"\n",
      "2022-08-30 23:14:10,476  - anneal_factor: \"0.5\"\n",
      "2022-08-30 23:14:10,476  - max_epochs: \"11\"\n",
      "2022-08-30 23:14:10,477  - shuffle: \"True\"\n",
      "2022-08-30 23:14:10,478  - train_with_dev: \"False\"\n",
      "2022-08-30 23:14:10,478  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 23:14:10,478 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:14:10,479 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 23:14:10,479 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:14:10,480 Device: cpu\n",
      "2022-08-30 23:14:10,480 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:14:10,481 Embeddings storage mode: cpu\n",
      "2022-08-30 23:14:10,481 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:14:14,586 epoch 1 - iter 33/333 - loss 0.55518506 - samples/sec: 80.49 - lr: 0.600000\n",
      "2022-08-30 23:14:18,797 epoch 1 - iter 66/333 - loss 0.58229055 - samples/sec: 79.65 - lr: 0.600000\n",
      "2022-08-30 23:14:22,379 epoch 1 - iter 99/333 - loss 0.58967665 - samples/sec: 93.62 - lr: 0.600000\n",
      "2022-08-30 23:14:26,321 epoch 1 - iter 132/333 - loss 0.59365789 - samples/sec: 85.25 - lr: 0.600000\n",
      "2022-08-30 23:14:30,934 epoch 1 - iter 165/333 - loss 0.60386599 - samples/sec: 72.53 - lr: 0.600000\n",
      "2022-08-30 23:14:34,509 epoch 1 - iter 198/333 - loss 0.60338186 - samples/sec: 93.86 - lr: 0.600000\n",
      "2022-08-30 23:14:38,643 epoch 1 - iter 231/333 - loss 0.60948149 - samples/sec: 81.02 - lr: 0.600000\n",
      "2022-08-30 23:14:42,378 epoch 1 - iter 264/333 - loss 0.61177264 - samples/sec: 89.87 - lr: 0.600000\n",
      "2022-08-30 23:14:46,611 epoch 1 - iter 297/333 - loss 0.61588098 - samples/sec: 79.23 - lr: 0.600000\n",
      "2022-08-30 23:14:50,901 epoch 1 - iter 330/333 - loss 0.63688974 - samples/sec: 78.03 - lr: 0.600000\n",
      "2022-08-30 23:14:51,348 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:14:51,348 EPOCH 1 done: loss 0.6377 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:14:52,327 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:14:52,357 DEV : loss 0.4495868980884552 - f1-score (micro avg)  0.8486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:14:52,375 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:14:52,376 saving best model\n",
      "2022-08-30 23:14:53,103 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:14:57,134 epoch 2 - iter 33/333 - loss 0.67109789 - samples/sec: 81.97 - lr: 0.600000\n",
      "2022-08-30 23:15:01,527 epoch 2 - iter 66/333 - loss 0.67541558 - samples/sec: 76.19 - lr: 0.600000\n",
      "2022-08-30 23:15:05,905 epoch 2 - iter 99/333 - loss 0.66934559 - samples/sec: 76.50 - lr: 0.600000\n",
      "2022-08-30 23:15:09,798 epoch 2 - iter 132/333 - loss 0.66909207 - samples/sec: 86.12 - lr: 0.600000\n",
      "2022-08-30 23:15:14,391 epoch 2 - iter 165/333 - loss 0.66973301 - samples/sec: 72.77 - lr: 0.600000\n",
      "2022-08-30 23:15:18,958 epoch 2 - iter 198/333 - loss 0.66908992 - samples/sec: 73.46 - lr: 0.600000\n",
      "2022-08-30 23:15:22,610 epoch 2 - iter 231/333 - loss 0.66566465 - samples/sec: 91.79 - lr: 0.600000\n",
      "2022-08-30 23:15:26,699 epoch 2 - iter 264/333 - loss 0.66643194 - samples/sec: 81.95 - lr: 0.600000\n",
      "2022-08-30 23:15:30,594 epoch 2 - iter 297/333 - loss 0.66585624 - samples/sec: 86.09 - lr: 0.600000\n",
      "2022-08-30 23:15:35,405 epoch 2 - iter 330/333 - loss 0.66651409 - samples/sec: 69.61 - lr: 0.600000\n",
      "2022-08-30 23:15:35,873 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:15:35,873 EPOCH 2 done: loss 0.6664 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:15:36,933 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:15:36,968 DEV : loss 0.38882964849472046 - f1-score (micro avg)  0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:15:36,990 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:15:36,992 saving best model\n",
      "2022-08-30 23:15:37,729 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:15:42,400 epoch 3 - iter 33/333 - loss 0.67270876 - samples/sec: 70.71 - lr: 0.600000\n",
      "2022-08-30 23:15:47,072 epoch 3 - iter 66/333 - loss 0.66825458 - samples/sec: 71.75 - lr: 0.600000\n",
      "2022-08-30 23:15:51,678 epoch 3 - iter 99/333 - loss 0.67088409 - samples/sec: 72.77 - lr: 0.600000\n",
      "2022-08-30 23:15:56,100 epoch 3 - iter 132/333 - loss 0.67666336 - samples/sec: 75.64 - lr: 0.600000\n",
      "2022-08-30 23:16:00,415 epoch 3 - iter 165/333 - loss 0.67763029 - samples/sec: 77.56 - lr: 0.600000\n",
      "2022-08-30 23:16:04,091 epoch 3 - iter 198/333 - loss 0.68011355 - samples/sec: 91.49 - lr: 0.600000\n",
      "2022-08-30 23:16:08,174 epoch 3 - iter 231/333 - loss 0.67839405 - samples/sec: 82.13 - lr: 0.600000\n",
      "2022-08-30 23:16:12,255 epoch 3 - iter 264/333 - loss 0.67774631 - samples/sec: 82.05 - lr: 0.600000\n",
      "2022-08-30 23:16:16,230 epoch 3 - iter 297/333 - loss 0.67780394 - samples/sec: 84.33 - lr: 0.600000\n",
      "2022-08-30 23:16:20,725 epoch 3 - iter 330/333 - loss 0.67986911 - samples/sec: 74.37 - lr: 0.600000\n",
      "2022-08-30 23:16:21,080 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:16:21,080 EPOCH 3 done: loss 0.6795 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:16:22,156 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:16:22,189 DEV : loss 0.401199072599411 - f1-score (micro avg)  0.8629\n",
      "2022-08-30 23:16:22,208 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:16:22,210 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:16:26,308 epoch 4 - iter 33/333 - loss 0.70409953 - samples/sec: 80.59 - lr: 0.600000\n",
      "2022-08-30 23:16:30,727 epoch 4 - iter 66/333 - loss 0.69341097 - samples/sec: 75.83 - lr: 0.600000\n",
      "2022-08-30 23:16:35,179 epoch 4 - iter 99/333 - loss 0.69333126 - samples/sec: 75.12 - lr: 0.600000\n",
      "2022-08-30 23:16:39,023 epoch 4 - iter 132/333 - loss 0.69320828 - samples/sec: 87.39 - lr: 0.600000\n",
      "2022-08-30 23:16:42,947 epoch 4 - iter 165/333 - loss 0.69668135 - samples/sec: 85.56 - lr: 0.600000\n",
      "2022-08-30 23:16:46,993 epoch 4 - iter 198/333 - loss 0.69241002 - samples/sec: 82.85 - lr: 0.600000\n",
      "2022-08-30 23:16:51,004 epoch 4 - iter 231/333 - loss 0.69317392 - samples/sec: 83.63 - lr: 0.600000\n",
      "2022-08-30 23:16:54,812 epoch 4 - iter 264/333 - loss 0.69459772 - samples/sec: 88.12 - lr: 0.600000\n",
      "2022-08-30 23:16:58,782 epoch 4 - iter 297/333 - loss 0.69724375 - samples/sec: 84.51 - lr: 0.600000\n",
      "2022-08-30 23:17:03,323 epoch 4 - iter 330/333 - loss 0.69572459 - samples/sec: 73.78 - lr: 0.600000\n",
      "2022-08-30 23:17:03,659 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:17:03,660 EPOCH 4 done: loss 0.6956 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:17:06,005 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:17:06,036 DEV : loss 0.424325555562973 - f1-score (micro avg)  0.8496\n",
      "2022-08-30 23:17:06,057 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 23:17:06,058 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:17:09,827 epoch 5 - iter 33/333 - loss 0.65749346 - samples/sec: 87.60 - lr: 0.600000\n",
      "2022-08-30 23:17:13,858 epoch 5 - iter 66/333 - loss 0.65510434 - samples/sec: 83.14 - lr: 0.600000\n",
      "2022-08-30 23:17:17,852 epoch 5 - iter 99/333 - loss 0.67026821 - samples/sec: 83.93 - lr: 0.600000\n",
      "2022-08-30 23:17:22,084 epoch 5 - iter 132/333 - loss 0.68469789 - samples/sec: 79.02 - lr: 0.600000\n",
      "2022-08-30 23:17:26,204 epoch 5 - iter 165/333 - loss 0.68794243 - samples/sec: 81.32 - lr: 0.600000\n",
      "2022-08-30 23:17:30,059 epoch 5 - iter 198/333 - loss 0.69342171 - samples/sec: 86.91 - lr: 0.600000\n",
      "2022-08-30 23:17:34,954 epoch 5 - iter 231/333 - loss 0.69338767 - samples/sec: 68.21 - lr: 0.600000\n",
      "2022-08-30 23:17:39,483 epoch 5 - iter 264/333 - loss 0.69269961 - samples/sec: 73.89 - lr: 0.600000\n",
      "2022-08-30 23:17:43,340 epoch 5 - iter 297/333 - loss 0.69335836 - samples/sec: 87.00 - lr: 0.600000\n",
      "2022-08-30 23:17:47,848 epoch 5 - iter 330/333 - loss 0.69227590 - samples/sec: 74.32 - lr: 0.600000\n",
      "2022-08-30 23:17:48,232 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:17:48,233 EPOCH 5 done: loss 0.6935 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 25.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:17:49,365 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:17:49,395 DEV : loss 0.45175644755363464 - f1-score (micro avg)  0.8398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:17:49,413 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 23:17:49,414 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:17:53,338 epoch 6 - iter 33/333 - loss 0.70088300 - samples/sec: 84.14 - lr: 0.600000\n",
      "2022-08-30 23:17:57,377 epoch 6 - iter 66/333 - loss 0.69968657 - samples/sec: 83.10 - lr: 0.600000\n",
      "2022-08-30 23:18:02,021 epoch 6 - iter 99/333 - loss 0.70378432 - samples/sec: 72.21 - lr: 0.600000\n",
      "2022-08-30 23:18:06,190 epoch 6 - iter 132/333 - loss 0.69535295 - samples/sec: 80.57 - lr: 0.600000\n",
      "2022-08-30 23:18:09,963 epoch 6 - iter 165/333 - loss 0.69157185 - samples/sec: 88.88 - lr: 0.600000\n",
      "2022-08-30 23:18:14,479 epoch 6 - iter 198/333 - loss 0.69442369 - samples/sec: 74.12 - lr: 0.600000\n",
      "2022-08-30 23:18:18,699 epoch 6 - iter 231/333 - loss 0.69397082 - samples/sec: 79.63 - lr: 0.600000\n",
      "2022-08-30 23:18:23,418 epoch 6 - iter 264/333 - loss 0.69266481 - samples/sec: 70.83 - lr: 0.600000\n",
      "2022-08-30 23:18:27,124 epoch 6 - iter 297/333 - loss 0.69394547 - samples/sec: 90.98 - lr: 0.600000\n",
      "2022-08-30 23:18:32,150 epoch 6 - iter 330/333 - loss 0.69374337 - samples/sec: 66.45 - lr: 0.600000\n",
      "2022-08-30 23:18:32,654 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:18:32,655 EPOCH 6 done: loss 0.6938 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:18:33,713 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:18:33,743 DEV : loss 0.41800907254219055 - f1-score (micro avg)  0.8551\n",
      "2022-08-30 23:18:33,762 Epoch     6: reducing learning rate of group 0 to 3.0000e-01.\n",
      "2022-08-30 23:18:33,763 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 23:18:33,764 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:18:37,677 epoch 7 - iter 33/333 - loss 0.66648917 - samples/sec: 84.38 - lr: 0.300000\n",
      "2022-08-30 23:18:41,555 epoch 7 - iter 66/333 - loss 0.66817523 - samples/sec: 86.64 - lr: 0.300000\n",
      "2022-08-30 23:18:46,022 epoch 7 - iter 99/333 - loss 0.66397031 - samples/sec: 74.90 - lr: 0.300000\n",
      "2022-08-30 23:18:50,063 epoch 7 - iter 132/333 - loss 0.65818254 - samples/sec: 83.02 - lr: 0.300000\n",
      "2022-08-30 23:18:54,407 epoch 7 - iter 165/333 - loss 0.65497972 - samples/sec: 77.10 - lr: 0.300000\n",
      "2022-08-30 23:18:59,004 epoch 7 - iter 198/333 - loss 0.65096912 - samples/sec: 72.94 - lr: 0.300000\n",
      "2022-08-30 23:19:02,921 epoch 7 - iter 231/333 - loss 0.64798880 - samples/sec: 85.67 - lr: 0.300000\n",
      "2022-08-30 23:19:06,751 epoch 7 - iter 264/333 - loss 0.64384557 - samples/sec: 87.46 - lr: 0.300000\n",
      "2022-08-30 23:19:10,829 epoch 7 - iter 297/333 - loss 0.63848977 - samples/sec: 82.15 - lr: 0.300000\n",
      "2022-08-30 23:19:15,110 epoch 7 - iter 330/333 - loss 0.63691794 - samples/sec: 78.25 - lr: 0.300000\n",
      "2022-08-30 23:19:15,576 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:19:15,577 EPOCH 7 done: loss 0.6358 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:19:16,582 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:19:16,611 DEV : loss 0.36987900733947754 - f1-score (micro avg)  0.8733\n",
      "2022-08-30 23:19:16,629 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:19:16,630 saving best model\n",
      "2022-08-30 23:19:17,491 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:19:22,005 epoch 8 - iter 33/333 - loss 0.60840294 - samples/sec: 73.12 - lr: 0.300000\n",
      "2022-08-30 23:19:26,298 epoch 8 - iter 66/333 - loss 0.61437656 - samples/sec: 77.98 - lr: 0.300000\n",
      "2022-08-30 23:19:30,760 epoch 8 - iter 99/333 - loss 0.60667024 - samples/sec: 74.93 - lr: 0.300000\n",
      "2022-08-30 23:19:34,768 epoch 8 - iter 132/333 - loss 0.60752795 - samples/sec: 83.65 - lr: 0.300000\n",
      "2022-08-30 23:19:38,741 epoch 8 - iter 165/333 - loss 0.60469257 - samples/sec: 84.33 - lr: 0.300000\n",
      "2022-08-30 23:19:42,738 epoch 8 - iter 198/333 - loss 0.60612455 - samples/sec: 83.95 - lr: 0.300000\n",
      "2022-08-30 23:19:46,929 epoch 8 - iter 231/333 - loss 0.60352267 - samples/sec: 79.96 - lr: 0.300000\n",
      "2022-08-30 23:19:51,569 epoch 8 - iter 264/333 - loss 0.60663307 - samples/sec: 72.16 - lr: 0.300000\n",
      "2022-08-30 23:19:55,614 epoch 8 - iter 297/333 - loss 0.60720158 - samples/sec: 82.87 - lr: 0.300000\n",
      "2022-08-30 23:19:59,259 epoch 8 - iter 330/333 - loss 0.60838825 - samples/sec: 92.15 - lr: 0.300000\n",
      "2022-08-30 23:19:59,681 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:19:59,682 EPOCH 8 done: loss 0.6076 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:20:00,713 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:20:00,743 DEV : loss 0.36481112241744995 - f1-score (micro avg)  0.8725\n",
      "2022-08-30 23:20:00,758 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:20:00,760 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:20:04,677 epoch 9 - iter 33/333 - loss 0.60083646 - samples/sec: 84.33 - lr: 0.300000\n",
      "2022-08-30 23:20:08,769 epoch 9 - iter 66/333 - loss 0.59498615 - samples/sec: 81.87 - lr: 0.300000\n",
      "2022-08-30 23:20:12,997 epoch 9 - iter 99/333 - loss 0.59336494 - samples/sec: 79.17 - lr: 0.300000\n",
      "2022-08-30 23:20:17,310 epoch 9 - iter 132/333 - loss 0.59170072 - samples/sec: 77.63 - lr: 0.300000\n",
      "2022-08-30 23:20:21,416 epoch 9 - iter 165/333 - loss 0.59573189 - samples/sec: 81.70 - lr: 0.300000\n",
      "2022-08-30 23:20:25,203 epoch 9 - iter 198/333 - loss 0.59642498 - samples/sec: 88.81 - lr: 0.300000\n",
      "2022-08-30 23:20:29,443 epoch 9 - iter 231/333 - loss 0.59625365 - samples/sec: 79.00 - lr: 0.300000\n",
      "2022-08-30 23:20:33,761 epoch 9 - iter 264/333 - loss 0.59736160 - samples/sec: 77.61 - lr: 0.300000\n",
      "2022-08-30 23:20:37,575 epoch 9 - iter 297/333 - loss 0.59828957 - samples/sec: 87.91 - lr: 0.300000\n",
      "2022-08-30 23:20:41,741 epoch 9 - iter 330/333 - loss 0.59637393 - samples/sec: 80.33 - lr: 0.300000\n",
      "2022-08-30 23:20:42,177 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:20:42,178 EPOCH 9 done: loss 0.5966 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:20:43,235 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:20:43,273 DEV : loss 0.3575900197029114 - f1-score (micro avg)  0.8761\n",
      "2022-08-30 23:20:43,289 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:20:43,290 saving best model\n",
      "2022-08-30 23:20:44,152 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:20:48,482 epoch 10 - iter 33/333 - loss 0.59551039 - samples/sec: 76.25 - lr: 0.300000\n",
      "2022-08-30 23:20:52,390 epoch 10 - iter 66/333 - loss 0.59498572 - samples/sec: 85.89 - lr: 0.300000\n",
      "2022-08-30 23:20:56,173 epoch 10 - iter 99/333 - loss 0.59084306 - samples/sec: 88.83 - lr: 0.300000\n",
      "2022-08-30 23:21:00,048 epoch 10 - iter 132/333 - loss 0.58714526 - samples/sec: 86.61 - lr: 0.300000\n",
      "2022-08-30 23:21:04,078 epoch 10 - iter 165/333 - loss 0.58689823 - samples/sec: 83.17 - lr: 0.300000\n",
      "2022-08-30 23:21:08,606 epoch 10 - iter 198/333 - loss 0.58416261 - samples/sec: 73.92 - lr: 0.300000\n",
      "2022-08-30 23:21:13,129 epoch 10 - iter 231/333 - loss 0.58721482 - samples/sec: 73.94 - lr: 0.300000\n",
      "2022-08-30 23:21:18,809 epoch 10 - iter 264/333 - loss 0.58677357 - samples/sec: 58.82 - lr: 0.300000\n",
      "2022-08-30 23:21:23,353 epoch 10 - iter 297/333 - loss 0.58585723 - samples/sec: 73.94 - lr: 0.300000\n",
      "2022-08-30 23:21:28,015 epoch 10 - iter 330/333 - loss 0.58559775 - samples/sec: 71.96 - lr: 0.300000\n",
      "2022-08-30 23:21:28,417 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:21:28,418 EPOCH 10 done: loss 0.5856 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 24.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:21:29,573 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:21:29,605 DEV : loss 0.3578486740589142 - f1-score (micro avg)  0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:21:29,622 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:21:29,623 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:21:34,099 epoch 11 - iter 33/333 - loss 0.59816344 - samples/sec: 73.76 - lr: 0.300000\n",
      "2022-08-30 23:21:38,573 epoch 11 - iter 66/333 - loss 0.59596421 - samples/sec: 74.85 - lr: 0.300000\n",
      "2022-08-30 23:21:42,885 epoch 11 - iter 99/333 - loss 0.60193794 - samples/sec: 77.74 - lr: 0.300000\n",
      "2022-08-30 23:21:47,030 epoch 11 - iter 132/333 - loss 0.59702657 - samples/sec: 80.74 - lr: 0.300000\n",
      "2022-08-30 23:21:51,115 epoch 11 - iter 165/333 - loss 0.59163106 - samples/sec: 82.19 - lr: 0.300000\n",
      "2022-08-30 23:21:55,913 epoch 11 - iter 198/333 - loss 0.59026321 - samples/sec: 69.69 - lr: 0.300000\n",
      "2022-08-30 23:22:00,171 epoch 11 - iter 231/333 - loss 0.58753550 - samples/sec: 78.63 - lr: 0.300000\n",
      "2022-08-30 23:22:04,332 epoch 11 - iter 264/333 - loss 0.58672527 - samples/sec: 80.49 - lr: 0.300000\n",
      "2022-08-30 23:22:07,995 epoch 11 - iter 297/333 - loss 0.58602004 - samples/sec: 91.85 - lr: 0.300000\n",
      "2022-08-30 23:22:12,319 epoch 11 - iter 330/333 - loss 0.58517552 - samples/sec: 77.37 - lr: 0.300000\n",
      "2022-08-30 23:22:12,686 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:22:12,687 EPOCH 11 done: loss 0.5853 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:22:13,838 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:22:13,874 DEV : loss 0.3542874753475189 - f1-score (micro avg)  0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:22:13,890 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 23:22:14,790 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:22:14,791 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 23:22:14,981 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:22:16,616 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:22:16,642 0.8892\t0.8892\t0.8892\t0.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:22:16,643 \n",
      "Results:\n",
      "- F-score (micro) 0.8892\n",
      "- F-score (macro) 0.7721\n",
      "- Accuracy 0.8892\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8273    0.9172    0.8700      1353\n",
      "         ADJ     0.8145    0.8690    0.8409       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9901    0.9708    0.9804       514\n",
      "        VERB     0.8165    0.8619    0.8386       449\n",
      "         AUX     0.9909    0.9791    0.9850       335\n",
      "       PROPN     0.8992    0.5587    0.6892       383\n",
      "       CCONJ     0.9746    1.0000    0.9871       192\n",
      "       SCONJ     0.9891    0.9891    0.9891       184\n",
      "         ADV     0.7124    0.7219    0.7171       151\n",
      "         DET     0.8889    0.6957    0.7805       161\n",
      "        PRON     1.0000    0.9043    0.9498       115\n",
      "         NUM     0.9630    0.7324    0.8320        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8892      5264\n",
      "   macro avg     0.8042    0.7506    0.7721      5264\n",
      "weighted avg     0.8934    0.8892    0.8870      5264\n",
      "\n",
      "2022-08-30 23:22:16,644 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:22:16,645 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 23:22:17,133 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 23:24:49,061 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:24:49,062 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 23:24:49,062 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:24:49,063 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 23:24:49,064 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:24:49,064 Parameters:\n",
      "2022-08-30 23:24:49,065  - learning_rate: \"0.600000\"\n",
      "2022-08-30 23:24:49,065  - mini_batch_size: \"10\"\n",
      "2022-08-30 23:24:49,066  - patience: \"3\"\n",
      "2022-08-30 23:24:49,066  - anneal_factor: \"0.5\"\n",
      "2022-08-30 23:24:49,067  - max_epochs: \"12\"\n",
      "2022-08-30 23:24:49,068  - shuffle: \"True\"\n",
      "2022-08-30 23:24:49,068  - train_with_dev: \"False\"\n",
      "2022-08-30 23:24:49,068  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 23:24:49,069 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:24:49,070 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 23:24:49,070 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:24:49,071 Device: cpu\n",
      "2022-08-30 23:24:49,072 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:24:49,072 Embeddings storage mode: cpu\n",
      "2022-08-30 23:24:49,073 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:24:53,298 epoch 1 - iter 33/333 - loss 0.58713057 - samples/sec: 78.12 - lr: 0.600000\n",
      "2022-08-30 23:24:57,832 epoch 1 - iter 66/333 - loss 0.61657415 - samples/sec: 73.89 - lr: 0.600000\n",
      "2022-08-30 23:25:01,448 epoch 1 - iter 99/333 - loss 0.62263267 - samples/sec: 92.75 - lr: 0.600000\n",
      "2022-08-30 23:25:05,375 epoch 1 - iter 132/333 - loss 0.62145723 - samples/sec: 85.56 - lr: 0.600000\n",
      "2022-08-30 23:25:10,170 epoch 1 - iter 165/333 - loss 0.63010547 - samples/sec: 69.78 - lr: 0.600000\n",
      "2022-08-30 23:25:14,127 epoch 1 - iter 198/333 - loss 0.63527867 - samples/sec: 84.62 - lr: 0.600000\n",
      "2022-08-30 23:25:18,447 epoch 1 - iter 231/333 - loss 0.63954574 - samples/sec: 77.43 - lr: 0.600000\n",
      "2022-08-30 23:25:22,442 epoch 1 - iter 264/333 - loss 0.64231177 - samples/sec: 84.12 - lr: 0.600000\n",
      "2022-08-30 23:25:27,064 epoch 1 - iter 297/333 - loss 0.64517952 - samples/sec: 72.51 - lr: 0.600000\n",
      "2022-08-30 23:25:31,567 epoch 1 - iter 330/333 - loss 0.66604950 - samples/sec: 74.19 - lr: 0.600000\n",
      "2022-08-30 23:25:32,018 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:25:32,019 EPOCH 1 done: loss 0.6671 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:25:33,028 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:25:33,058 DEV : loss 0.4623904526233673 - f1-score (micro avg)  0.8434\n",
      "2022-08-30 23:25:33,076 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:25:33,077 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:25:34,143 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:25:38,606 epoch 2 - iter 33/333 - loss 0.67365051 - samples/sec: 73.97 - lr: 0.600000\n",
      "2022-08-30 23:25:42,653 epoch 2 - iter 66/333 - loss 0.67342903 - samples/sec: 82.89 - lr: 0.600000\n",
      "2022-08-30 23:25:47,463 epoch 2 - iter 99/333 - loss 0.67961846 - samples/sec: 69.47 - lr: 0.600000\n",
      "2022-08-30 23:25:51,553 epoch 2 - iter 132/333 - loss 0.68359140 - samples/sec: 82.17 - lr: 0.600000\n",
      "2022-08-30 23:25:55,387 epoch 2 - iter 165/333 - loss 0.68454482 - samples/sec: 87.49 - lr: 0.600000\n",
      "2022-08-30 23:25:59,394 epoch 2 - iter 198/333 - loss 0.68792724 - samples/sec: 83.86 - lr: 0.600000\n",
      "2022-08-30 23:26:04,213 epoch 2 - iter 231/333 - loss 0.68830264 - samples/sec: 69.50 - lr: 0.600000\n",
      "2022-08-30 23:26:08,569 epoch 2 - iter 264/333 - loss 0.68745138 - samples/sec: 77.01 - lr: 0.600000\n",
      "2022-08-30 23:26:12,537 epoch 2 - iter 297/333 - loss 0.68814523 - samples/sec: 84.46 - lr: 0.600000\n",
      "2022-08-30 23:26:16,610 epoch 2 - iter 330/333 - loss 0.68780528 - samples/sec: 82.13 - lr: 0.600000\n",
      "2022-08-30 23:26:17,012 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:26:17,012 EPOCH 2 done: loss 0.6876 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:26:18,011 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:26:18,041 DEV : loss 0.4432508647441864 - f1-score (micro avg)  0.845\n",
      "2022-08-30 23:26:18,057 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:26:18,058 saving best model\n",
      "2022-08-30 23:26:19,181 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:26:23,689 epoch 3 - iter 33/333 - loss 0.69337481 - samples/sec: 73.24 - lr: 0.600000\n",
      "2022-08-30 23:26:28,148 epoch 3 - iter 66/333 - loss 0.69793104 - samples/sec: 74.98 - lr: 0.600000\n",
      "2022-08-30 23:26:32,163 epoch 3 - iter 99/333 - loss 0.69335934 - samples/sec: 83.40 - lr: 0.600000\n",
      "2022-08-30 23:26:36,602 epoch 3 - iter 132/333 - loss 0.69043082 - samples/sec: 75.29 - lr: 0.600000\n",
      "2022-08-30 23:26:41,238 epoch 3 - iter 165/333 - loss 0.68775112 - samples/sec: 72.10 - lr: 0.600000\n",
      "2022-08-30 23:26:45,817 epoch 3 - iter 198/333 - loss 0.68941757 - samples/sec: 73.07 - lr: 0.600000\n",
      "2022-08-30 23:26:49,905 epoch 3 - iter 231/333 - loss 0.69545475 - samples/sec: 81.99 - lr: 0.600000\n",
      "2022-08-30 23:26:54,142 epoch 3 - iter 264/333 - loss 0.69427458 - samples/sec: 78.97 - lr: 0.600000\n",
      "2022-08-30 23:26:58,314 epoch 3 - iter 297/333 - loss 0.69707024 - samples/sec: 80.21 - lr: 0.600000\n",
      "2022-08-30 23:27:02,294 epoch 3 - iter 330/333 - loss 0.69890371 - samples/sec: 84.38 - lr: 0.600000\n",
      "2022-08-30 23:27:02,640 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:27:02,641 EPOCH 3 done: loss 0.6989 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:27:03,640 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:27:03,672 DEV : loss 0.45966318249702454 - f1-score (micro avg)  0.8346\n",
      "2022-08-30 23:27:03,689 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:27:03,690 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:27:08,137 epoch 4 - iter 33/333 - loss 0.70668523 - samples/sec: 74.26 - lr: 0.600000\n",
      "2022-08-30 23:27:12,416 epoch 4 - iter 66/333 - loss 0.69570712 - samples/sec: 78.20 - lr: 0.600000\n",
      "2022-08-30 23:27:16,881 epoch 4 - iter 99/333 - loss 0.70258816 - samples/sec: 75.03 - lr: 0.600000\n",
      "2022-08-30 23:27:21,168 epoch 4 - iter 132/333 - loss 0.70163669 - samples/sec: 78.05 - lr: 0.600000\n",
      "2022-08-30 23:27:25,248 epoch 4 - iter 165/333 - loss 0.70172594 - samples/sec: 82.03 - lr: 0.600000\n",
      "2022-08-30 23:27:29,197 epoch 4 - iter 198/333 - loss 0.70065551 - samples/sec: 85.03 - lr: 0.600000\n",
      "2022-08-30 23:27:34,025 epoch 4 - iter 231/333 - loss 0.70008172 - samples/sec: 69.20 - lr: 0.600000\n",
      "2022-08-30 23:27:38,201 epoch 4 - iter 264/333 - loss 0.69802193 - samples/sec: 80.16 - lr: 0.600000\n",
      "2022-08-30 23:27:43,172 epoch 4 - iter 297/333 - loss 0.70202038 - samples/sec: 67.37 - lr: 0.600000\n",
      "2022-08-30 23:27:47,043 epoch 4 - iter 330/333 - loss 0.70384034 - samples/sec: 86.55 - lr: 0.600000\n",
      "2022-08-30 23:27:47,519 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:27:47,520 EPOCH 4 done: loss 0.7048 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:27:48,518 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:27:48,550 DEV : loss 0.4617578089237213 - f1-score (micro avg)  0.8377\n",
      "2022-08-30 23:27:48,569 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 23:27:48,571 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:27:52,981 epoch 5 - iter 33/333 - loss 0.74793628 - samples/sec: 74.90 - lr: 0.600000\n",
      "2022-08-30 23:27:57,515 epoch 5 - iter 66/333 - loss 0.71786258 - samples/sec: 73.76 - lr: 0.600000\n",
      "2022-08-30 23:28:02,199 epoch 5 - iter 99/333 - loss 0.72337165 - samples/sec: 71.49 - lr: 0.600000\n",
      "2022-08-30 23:28:06,610 epoch 5 - iter 132/333 - loss 0.71927711 - samples/sec: 75.79 - lr: 0.600000\n",
      "2022-08-30 23:28:10,950 epoch 5 - iter 165/333 - loss 0.71439532 - samples/sec: 77.10 - lr: 0.600000\n",
      "2022-08-30 23:28:14,993 epoch 5 - iter 198/333 - loss 0.71451122 - samples/sec: 82.89 - lr: 0.600000\n",
      "2022-08-30 23:28:19,103 epoch 5 - iter 231/333 - loss 0.70789720 - samples/sec: 81.38 - lr: 0.600000\n",
      "2022-08-30 23:28:23,713 epoch 5 - iter 264/333 - loss 0.70762914 - samples/sec: 72.53 - lr: 0.600000\n",
      "2022-08-30 23:28:28,191 epoch 5 - iter 297/333 - loss 0.70716859 - samples/sec: 74.68 - lr: 0.600000\n",
      "2022-08-30 23:28:31,948 epoch 5 - iter 330/333 - loss 0.70659135 - samples/sec: 89.36 - lr: 0.600000\n",
      "2022-08-30 23:28:32,332 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:28:32,332 EPOCH 5 done: loss 0.7066 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:28:33,345 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:28:33,377 DEV : loss 0.4316825568675995 - f1-score (micro avg)  0.848\n",
      "2022-08-30 23:28:33,396 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:28:33,398 saving best model\n",
      "2022-08-30 23:28:34,171 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:28:38,458 epoch 6 - iter 33/333 - loss 0.74555146 - samples/sec: 77.05 - lr: 0.600000\n",
      "2022-08-30 23:28:42,623 epoch 6 - iter 66/333 - loss 0.71603791 - samples/sec: 80.57 - lr: 0.600000\n",
      "2022-08-30 23:28:46,599 epoch 6 - iter 99/333 - loss 0.70671677 - samples/sec: 84.27 - lr: 0.600000\n",
      "2022-08-30 23:28:51,098 epoch 6 - iter 132/333 - loss 0.70728102 - samples/sec: 74.37 - lr: 0.600000\n",
      "2022-08-30 23:28:55,630 epoch 6 - iter 165/333 - loss 0.70826839 - samples/sec: 73.91 - lr: 0.600000\n",
      "2022-08-30 23:29:00,608 epoch 6 - iter 198/333 - loss 0.70578570 - samples/sec: 67.09 - lr: 0.600000\n",
      "2022-08-30 23:29:05,043 epoch 6 - iter 231/333 - loss 0.70544152 - samples/sec: 75.38 - lr: 0.600000\n",
      "2022-08-30 23:29:08,927 epoch 6 - iter 264/333 - loss 0.70630471 - samples/sec: 86.30 - lr: 0.600000\n",
      "2022-08-30 23:29:13,427 epoch 6 - iter 297/333 - loss 0.70556898 - samples/sec: 74.41 - lr: 0.600000\n",
      "2022-08-30 23:29:17,520 epoch 6 - iter 330/333 - loss 0.70814141 - samples/sec: 82.07 - lr: 0.600000\n",
      "2022-08-30 23:29:18,024 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:29:18,024 EPOCH 6 done: loss 0.7076 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:29:19,045 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:29:19,087 DEV : loss 0.45311224460601807 - f1-score (micro avg)  0.8398\n",
      "2022-08-30 23:29:19,107 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:29:19,108 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:29:23,580 epoch 7 - iter 33/333 - loss 0.71380542 - samples/sec: 73.88 - lr: 0.600000\n",
      "2022-08-30 23:29:28,080 epoch 7 - iter 66/333 - loss 0.71000726 - samples/sec: 74.39 - lr: 0.600000\n",
      "2022-08-30 23:29:32,000 epoch 7 - iter 99/333 - loss 0.72038736 - samples/sec: 85.56 - lr: 0.600000\n",
      "2022-08-30 23:29:35,752 epoch 7 - iter 132/333 - loss 0.71880492 - samples/sec: 89.24 - lr: 0.600000\n",
      "2022-08-30 23:29:39,447 epoch 7 - iter 165/333 - loss 0.71805900 - samples/sec: 90.96 - lr: 0.600000\n",
      "2022-08-30 23:29:43,495 epoch 7 - iter 198/333 - loss 0.71990161 - samples/sec: 82.89 - lr: 0.600000\n",
      "2022-08-30 23:29:47,475 epoch 7 - iter 231/333 - loss 0.72102501 - samples/sec: 84.25 - lr: 0.600000\n",
      "2022-08-30 23:29:51,762 epoch 7 - iter 264/333 - loss 0.71705132 - samples/sec: 78.24 - lr: 0.600000\n",
      "2022-08-30 23:29:55,898 epoch 7 - iter 297/333 - loss 0.71619540 - samples/sec: 81.00 - lr: 0.600000\n",
      "2022-08-30 23:30:00,160 epoch 7 - iter 330/333 - loss 0.71473193 - samples/sec: 78.44 - lr: 0.600000\n",
      "2022-08-30 23:30:00,553 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:30:00,554 EPOCH 7 done: loss 0.7157 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:30:01,559 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:30:01,591 DEV : loss 0.47479844093322754 - f1-score (micro avg)  0.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:30:01,609 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 23:30:01,610 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:30:05,558 epoch 8 - iter 33/333 - loss 0.72478188 - samples/sec: 83.63 - lr: 0.600000\n",
      "2022-08-30 23:30:10,079 epoch 8 - iter 66/333 - loss 0.72692210 - samples/sec: 74.06 - lr: 0.600000\n",
      "2022-08-30 23:30:14,067 epoch 8 - iter 99/333 - loss 0.72261026 - samples/sec: 84.08 - lr: 0.600000\n",
      "2022-08-30 23:30:18,362 epoch 8 - iter 132/333 - loss 0.72141536 - samples/sec: 77.87 - lr: 0.600000\n",
      "2022-08-30 23:30:22,605 epoch 8 - iter 165/333 - loss 0.72265946 - samples/sec: 79.06 - lr: 0.600000\n",
      "2022-08-30 23:30:27,360 epoch 8 - iter 198/333 - loss 0.71894788 - samples/sec: 70.30 - lr: 0.600000\n",
      "2022-08-30 23:30:31,796 epoch 8 - iter 231/333 - loss 0.71912069 - samples/sec: 75.53 - lr: 0.600000\n",
      "2022-08-30 23:30:35,938 epoch 8 - iter 264/333 - loss 0.71909774 - samples/sec: 80.78 - lr: 0.600000\n",
      "2022-08-30 23:30:39,944 epoch 8 - iter 297/333 - loss 0.71864479 - samples/sec: 83.50 - lr: 0.600000\n",
      "2022-08-30 23:30:44,136 epoch 8 - iter 330/333 - loss 0.71976278 - samples/sec: 80.00 - lr: 0.600000\n",
      "2022-08-30 23:30:44,554 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:30:44,554 EPOCH 8 done: loss 0.7200 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:30:45,588 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:30:45,616 DEV : loss 0.47272607684135437 - f1-score (micro avg)  0.8363\n",
      "2022-08-30 23:30:45,634 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 23:30:45,636 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:30:50,688 epoch 9 - iter 33/333 - loss 0.73563921 - samples/sec: 65.36 - lr: 0.600000\n",
      "2022-08-30 23:30:54,499 epoch 9 - iter 66/333 - loss 0.73708980 - samples/sec: 88.14 - lr: 0.600000\n",
      "2022-08-30 23:30:58,529 epoch 9 - iter 99/333 - loss 0.73261095 - samples/sec: 83.27 - lr: 0.600000\n",
      "2022-08-30 23:31:03,073 epoch 9 - iter 132/333 - loss 0.73052779 - samples/sec: 73.79 - lr: 0.600000\n",
      "2022-08-30 23:31:07,897 epoch 9 - iter 165/333 - loss 0.72760191 - samples/sec: 69.37 - lr: 0.600000\n",
      "2022-08-30 23:31:11,975 epoch 9 - iter 198/333 - loss 0.72661527 - samples/sec: 82.15 - lr: 0.600000\n",
      "2022-08-30 23:31:16,359 epoch 9 - iter 231/333 - loss 0.73025039 - samples/sec: 76.34 - lr: 0.600000\n",
      "2022-08-30 23:31:20,394 epoch 9 - iter 264/333 - loss 0.73098789 - samples/sec: 83.38 - lr: 0.600000\n",
      "2022-08-30 23:31:24,351 epoch 9 - iter 297/333 - loss 0.73079202 - samples/sec: 84.94 - lr: 0.600000\n",
      "2022-08-30 23:31:28,917 epoch 9 - iter 330/333 - loss 0.72935836 - samples/sec: 73.40 - lr: 0.600000\n",
      "2022-08-30 23:31:29,255 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:31:29,256 EPOCH 9 done: loss 0.7290 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:31:30,304 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:31:30,339 DEV : loss 0.46314388513565063 - f1-score (micro avg)  0.8353\n",
      "2022-08-30 23:31:30,358 Epoch     9: reducing learning rate of group 0 to 3.0000e-01.\n",
      "2022-08-30 23:31:30,358 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 23:31:30,359 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:31:34,440 epoch 10 - iter 33/333 - loss 0.70177825 - samples/sec: 80.92 - lr: 0.300000\n",
      "2022-08-30 23:31:39,209 epoch 10 - iter 66/333 - loss 0.68405465 - samples/sec: 70.24 - lr: 0.300000\n",
      "2022-08-30 23:31:43,266 epoch 10 - iter 99/333 - loss 0.68568853 - samples/sec: 82.50 - lr: 0.300000\n",
      "2022-08-30 23:31:47,264 epoch 10 - iter 132/333 - loss 0.68531672 - samples/sec: 83.69 - lr: 0.300000\n",
      "2022-08-30 23:31:51,422 epoch 10 - iter 165/333 - loss 0.68398868 - samples/sec: 80.78 - lr: 0.300000\n",
      "2022-08-30 23:31:55,999 epoch 10 - iter 198/333 - loss 0.67673749 - samples/sec: 73.22 - lr: 0.300000\n",
      "2022-08-30 23:32:00,175 epoch 10 - iter 231/333 - loss 0.67423485 - samples/sec: 80.23 - lr: 0.300000\n",
      "2022-08-30 23:32:05,059 epoch 10 - iter 264/333 - loss 0.67417049 - samples/sec: 68.42 - lr: 0.300000\n",
      "2022-08-30 23:32:09,215 epoch 10 - iter 297/333 - loss 0.67245190 - samples/sec: 80.70 - lr: 0.300000\n",
      "2022-08-30 23:32:13,781 epoch 10 - iter 330/333 - loss 0.66972199 - samples/sec: 73.30 - lr: 0.300000\n",
      "2022-08-30 23:32:14,247 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:32:14,248 EPOCH 10 done: loss 0.6699 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 26.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:32:15,329 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:32:15,361 DEV : loss 0.41324174404144287 - f1-score (micro avg)  0.8533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:32:15,377 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:32:15,378 saving best model\n",
      "2022-08-30 23:32:16,326 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:32:20,677 epoch 11 - iter 33/333 - loss 0.64261394 - samples/sec: 75.90 - lr: 0.300000\n",
      "2022-08-30 23:32:25,038 epoch 11 - iter 66/333 - loss 0.64552652 - samples/sec: 76.87 - lr: 0.300000\n",
      "2022-08-30 23:32:29,546 epoch 11 - iter 99/333 - loss 0.64945888 - samples/sec: 74.27 - lr: 0.300000\n",
      "2022-08-30 23:32:33,964 epoch 11 - iter 132/333 - loss 0.64447690 - samples/sec: 75.76 - lr: 0.300000\n",
      "2022-08-30 23:32:38,663 epoch 11 - iter 165/333 - loss 0.64839369 - samples/sec: 71.12 - lr: 0.300000\n",
      "2022-08-30 23:32:43,370 epoch 11 - iter 198/333 - loss 0.64851563 - samples/sec: 71.27 - lr: 0.300000\n",
      "2022-08-30 23:32:47,294 epoch 11 - iter 231/333 - loss 0.64872401 - samples/sec: 85.65 - lr: 0.300000\n",
      "2022-08-30 23:32:51,581 epoch 11 - iter 264/333 - loss 0.64617049 - samples/sec: 78.13 - lr: 0.300000\n",
      "2022-08-30 23:32:55,732 epoch 11 - iter 297/333 - loss 0.64706064 - samples/sec: 80.70 - lr: 0.300000\n",
      "2022-08-30 23:33:00,686 epoch 11 - iter 330/333 - loss 0.64650763 - samples/sec: 67.46 - lr: 0.300000\n",
      "2022-08-30 23:33:01,227 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:33:01,228 EPOCH 11 done: loss 0.6459 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 25.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:33:02,324 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:33:02,358 DEV : loss 0.40607431530952454 - f1-score (micro avg)  0.8567\n",
      "2022-08-30 23:33:02,380 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:33:02,381 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:33:03,371 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:33:07,896 epoch 12 - iter 33/333 - loss 0.63931757 - samples/sec: 72.94 - lr: 0.300000\n",
      "2022-08-30 23:33:12,140 epoch 12 - iter 66/333 - loss 0.63462847 - samples/sec: 78.87 - lr: 0.300000\n",
      "2022-08-30 23:33:16,291 epoch 12 - iter 99/333 - loss 0.63256441 - samples/sec: 80.80 - lr: 0.300000\n",
      "2022-08-30 23:33:20,485 epoch 12 - iter 132/333 - loss 0.63473981 - samples/sec: 79.81 - lr: 0.300000\n",
      "2022-08-30 23:33:24,590 epoch 12 - iter 165/333 - loss 0.64021410 - samples/sec: 81.66 - lr: 0.300000\n",
      "2022-08-30 23:33:28,549 epoch 12 - iter 198/333 - loss 0.64106747 - samples/sec: 84.62 - lr: 0.300000\n",
      "2022-08-30 23:33:32,909 epoch 12 - iter 231/333 - loss 0.63777065 - samples/sec: 76.87 - lr: 0.300000\n",
      "2022-08-30 23:33:37,168 epoch 12 - iter 264/333 - loss 0.63521487 - samples/sec: 78.76 - lr: 0.300000\n",
      "2022-08-30 23:33:41,683 epoch 12 - iter 297/333 - loss 0.63649506 - samples/sec: 74.06 - lr: 0.300000\n",
      "2022-08-30 23:33:45,986 epoch 12 - iter 330/333 - loss 0.63397791 - samples/sec: 78.14 - lr: 0.300000\n",
      "2022-08-30 23:33:46,415 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:33:46,416 EPOCH 12 done: loss 0.6340 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:33:47,415 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:33:47,447 DEV : loss 0.39132705330848694 - f1-score (micro avg)  0.8608\n",
      "2022-08-30 23:33:47,464 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:33:47,465 saving best model\n",
      "2022-08-30 23:33:48,890 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:33:48,892 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 23:33:49,076 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 15.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:33:50,764 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:33:50,794 0.8754\t0.8754\t0.8754\t0.8754\n",
      "2022-08-30 23:33:50,795 \n",
      "Results:\n",
      "- F-score (micro) 0.8754\n",
      "- F-score (macro) 0.7574\n",
      "- Accuracy 0.8754\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8044    0.8877    0.8440      1353\n",
      "         ADJ     0.8121    0.8423    0.8269       672\n",
      "       PUNCT     0.9985    1.0000    0.9992       660\n",
      "         ADP     0.9786    0.9767    0.9776       514\n",
      "        VERB     0.8285    0.8285    0.8285       449\n",
      "       PROPN     0.7483    0.5822    0.6549       383\n",
      "         AUX     0.9938    0.9612    0.9772       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         ADV     0.7372    0.6689    0.7014       151\n",
      "         DET     0.9174    0.6894    0.7872       161\n",
      "        PRON     0.9817    0.9304    0.9554       115\n",
      "         NUM     0.9107    0.7183    0.8031        71\n",
      "        PART     0.7391    0.8095    0.7727        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8754      5264\n",
      "   macro avg     0.7772    0.7431    0.7574      5264\n",
      "weighted avg     0.8763    0.8754    0.8738      5264\n",
      "\n",
      "2022-08-30 23:33:50,795 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:33:50,797 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:33:51,294 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 5 #######################\n",
      "#######################################################\n",
      "2022-08-30 23:36:18,633 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:36:18,634 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 23:36:18,635 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:36:18,635 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 23:36:18,636 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:36:18,636 Parameters:\n",
      "2022-08-30 23:36:18,637  - learning_rate: \"0.600000\"\n",
      "2022-08-30 23:36:18,638  - mini_batch_size: \"30\"\n",
      "2022-08-30 23:36:18,639  - patience: \"3\"\n",
      "2022-08-30 23:36:18,639  - anneal_factor: \"0.5\"\n",
      "2022-08-30 23:36:18,640  - max_epochs: \"10\"\n",
      "2022-08-30 23:36:18,640  - shuffle: \"True\"\n",
      "2022-08-30 23:36:18,640  - train_with_dev: \"False\"\n",
      "2022-08-30 23:36:18,641  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 23:36:18,641 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:36:18,642 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 23:36:18,643 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:36:18,643 Device: cpu\n",
      "2022-08-30 23:36:18,644 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:36:18,644 Embeddings storage mode: cpu\n",
      "2022-08-30 23:36:18,645 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:36:22,720 epoch 1 - iter 11/111 - loss 0.61589387 - samples/sec: 81.00 - lr: 0.600000\n",
      "2022-08-30 23:36:26,902 epoch 1 - iter 22/111 - loss 0.62567015 - samples/sec: 80.16 - lr: 0.600000\n",
      "2022-08-30 23:36:30,591 epoch 1 - iter 33/111 - loss 0.62659784 - samples/sec: 90.91 - lr: 0.600000\n",
      "2022-08-30 23:36:34,410 epoch 1 - iter 44/111 - loss 0.62598000 - samples/sec: 87.98 - lr: 0.600000\n",
      "2022-08-30 23:36:38,779 epoch 1 - iter 55/111 - loss 0.62542955 - samples/sec: 76.55 - lr: 0.600000\n",
      "2022-08-30 23:36:42,597 epoch 1 - iter 66/111 - loss 0.62438577 - samples/sec: 87.84 - lr: 0.600000\n",
      "2022-08-30 23:36:46,919 epoch 1 - iter 77/111 - loss 0.62757858 - samples/sec: 77.46 - lr: 0.600000\n",
      "2022-08-30 23:36:50,729 epoch 1 - iter 88/111 - loss 0.62753998 - samples/sec: 87.95 - lr: 0.600000\n",
      "2022-08-30 23:36:54,784 epoch 1 - iter 99/111 - loss 0.62807790 - samples/sec: 82.58 - lr: 0.600000\n",
      "2022-08-30 23:36:59,347 epoch 1 - iter 110/111 - loss 0.64566559 - samples/sec: 73.25 - lr: 0.600000\n",
      "2022-08-30 23:36:59,827 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:36:59,828 EPOCH 1 done: loss 0.6464 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:37:02,156 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:37:02,190 DEV : loss 0.4564782381057739 - f1-score (micro avg)  0.841\n",
      "2022-08-30 23:37:02,209 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:37:02,211 saving best model\n",
      "2022-08-30 23:37:02,951 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:37:07,467 epoch 2 - iter 11/111 - loss 0.65855568 - samples/sec: 73.11 - lr: 0.600000\n",
      "2022-08-30 23:37:11,547 epoch 2 - iter 22/111 - loss 0.64978716 - samples/sec: 82.50 - lr: 0.600000\n",
      "2022-08-30 23:37:15,556 epoch 2 - iter 33/111 - loss 0.65256874 - samples/sec: 83.65 - lr: 0.600000\n",
      "2022-08-30 23:37:19,714 epoch 2 - iter 44/111 - loss 0.64957827 - samples/sec: 80.47 - lr: 0.600000\n",
      "2022-08-30 23:37:23,785 epoch 2 - iter 55/111 - loss 0.64838408 - samples/sec: 82.31 - lr: 0.600000\n",
      "2022-08-30 23:37:27,651 epoch 2 - iter 66/111 - loss 0.64840039 - samples/sec: 86.68 - lr: 0.600000\n",
      "2022-08-30 23:37:31,837 epoch 2 - iter 77/111 - loss 0.64358786 - samples/sec: 80.02 - lr: 0.600000\n",
      "2022-08-30 23:37:36,304 epoch 2 - iter 88/111 - loss 0.64127450 - samples/sec: 74.86 - lr: 0.600000\n",
      "2022-08-30 23:37:40,416 epoch 2 - iter 99/111 - loss 0.64189825 - samples/sec: 81.68 - lr: 0.600000\n",
      "2022-08-30 23:37:44,932 epoch 2 - iter 110/111 - loss 0.64055070 - samples/sec: 74.48 - lr: 0.600000\n",
      "2022-08-30 23:37:45,394 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:37:45,395 EPOCH 2 done: loss 0.6411 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:37:46,337 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:37:46,372 DEV : loss 0.4083750545978546 - f1-score (micro avg)  0.8506\n",
      "2022-08-30 23:37:46,393 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:37:46,394 saving best model\n",
      "2022-08-30 23:37:47,395 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:37:51,332 epoch 3 - iter 11/111 - loss 0.61328691 - samples/sec: 83.91 - lr: 0.600000\n",
      "2022-08-30 23:37:55,748 epoch 3 - iter 22/111 - loss 0.62389425 - samples/sec: 76.00 - lr: 0.600000\n",
      "2022-08-30 23:37:59,912 epoch 3 - iter 33/111 - loss 0.62272234 - samples/sec: 80.41 - lr: 0.600000\n",
      "2022-08-30 23:38:04,053 epoch 3 - iter 44/111 - loss 0.62630075 - samples/sec: 80.82 - lr: 0.600000\n",
      "2022-08-30 23:38:07,936 epoch 3 - iter 55/111 - loss 0.62590547 - samples/sec: 86.50 - lr: 0.600000\n",
      "2022-08-30 23:38:12,486 epoch 3 - iter 66/111 - loss 0.63000236 - samples/sec: 73.55 - lr: 0.600000\n",
      "2022-08-30 23:38:16,516 epoch 3 - iter 77/111 - loss 0.63255203 - samples/sec: 83.31 - lr: 0.600000\n",
      "2022-08-30 23:38:20,802 epoch 3 - iter 88/111 - loss 0.63670991 - samples/sec: 78.24 - lr: 0.600000\n",
      "2022-08-30 23:38:24,897 epoch 3 - iter 99/111 - loss 0.63512932 - samples/sec: 81.76 - lr: 0.600000\n",
      "2022-08-30 23:38:28,774 epoch 3 - iter 110/111 - loss 0.63619903 - samples/sec: 86.57 - lr: 0.600000\n",
      "2022-08-30 23:38:29,175 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:38:29,176 EPOCH 3 done: loss 0.6365 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:38:30,156 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:38:30,188 DEV : loss 0.3910721242427826 - f1-score (micro avg)  0.8671\n",
      "2022-08-30 23:38:30,209 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:38:30,210 saving best model\n",
      "2022-08-30 23:38:31,037 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:38:35,033 epoch 4 - iter 11/111 - loss 0.62246148 - samples/sec: 82.60 - lr: 0.600000\n",
      "2022-08-30 23:38:39,343 epoch 4 - iter 22/111 - loss 0.64595985 - samples/sec: 77.72 - lr: 0.600000\n",
      "2022-08-30 23:38:43,525 epoch 4 - iter 33/111 - loss 0.63560222 - samples/sec: 80.43 - lr: 0.600000\n",
      "2022-08-30 23:38:47,660 epoch 4 - iter 44/111 - loss 0.63277524 - samples/sec: 81.04 - lr: 0.600000\n",
      "2022-08-30 23:38:52,076 epoch 4 - iter 55/111 - loss 0.63372817 - samples/sec: 75.77 - lr: 0.600000\n",
      "2022-08-30 23:38:56,327 epoch 4 - iter 66/111 - loss 0.63676036 - samples/sec: 78.68 - lr: 0.600000\n",
      "2022-08-30 23:39:00,561 epoch 4 - iter 77/111 - loss 0.63497811 - samples/sec: 79.35 - lr: 0.600000\n",
      "2022-08-30 23:39:04,536 epoch 4 - iter 88/111 - loss 0.63399868 - samples/sec: 84.62 - lr: 0.600000\n",
      "2022-08-30 23:39:08,851 epoch 4 - iter 99/111 - loss 0.63317971 - samples/sec: 77.54 - lr: 0.600000\n",
      "2022-08-30 23:39:12,942 epoch 4 - iter 110/111 - loss 0.63312855 - samples/sec: 81.95 - lr: 0.600000\n",
      "2022-08-30 23:39:13,348 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:39:13,348 EPOCH 4 done: loss 0.6340 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:39:14,281 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:39:14,310 DEV : loss 0.39871716499328613 - f1-score (micro avg)  0.8533\n",
      "2022-08-30 23:39:14,326 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:39:14,327 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:39:18,670 epoch 5 - iter 11/111 - loss 0.61177240 - samples/sec: 76.00 - lr: 0.600000\n",
      "2022-08-30 23:39:23,174 epoch 5 - iter 22/111 - loss 0.62864007 - samples/sec: 74.27 - lr: 0.600000\n",
      "2022-08-30 23:39:27,882 epoch 5 - iter 33/111 - loss 0.62152324 - samples/sec: 70.94 - lr: 0.600000\n",
      "2022-08-30 23:39:32,385 epoch 5 - iter 44/111 - loss 0.62670490 - samples/sec: 74.26 - lr: 0.600000\n",
      "2022-08-30 23:39:36,753 epoch 5 - iter 55/111 - loss 0.62512346 - samples/sec: 76.71 - lr: 0.600000\n",
      "2022-08-30 23:39:41,114 epoch 5 - iter 66/111 - loss 0.62733288 - samples/sec: 76.71 - lr: 0.600000\n",
      "2022-08-30 23:39:45,376 epoch 5 - iter 77/111 - loss 0.62914236 - samples/sec: 78.53 - lr: 0.600000\n",
      "2022-08-30 23:39:49,478 epoch 5 - iter 88/111 - loss 0.62917849 - samples/sec: 81.60 - lr: 0.600000\n",
      "2022-08-30 23:39:53,505 epoch 5 - iter 99/111 - loss 0.62755588 - samples/sec: 83.33 - lr: 0.600000\n",
      "2022-08-30 23:39:58,025 epoch 5 - iter 110/111 - loss 0.62933502 - samples/sec: 73.99 - lr: 0.600000\n",
      "2022-08-30 23:39:58,448 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:39:58,448 EPOCH 5 done: loss 0.6295 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:39:59,372 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:39:59,402 DEV : loss 0.4362289309501648 - f1-score (micro avg)  0.8442\n",
      "2022-08-30 23:39:59,420 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:39:59,421 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:40:03,826 epoch 6 - iter 11/111 - loss 0.66570122 - samples/sec: 74.95 - lr: 0.600000\n",
      "2022-08-30 23:40:07,928 epoch 6 - iter 22/111 - loss 0.65099490 - samples/sec: 81.62 - lr: 0.600000\n",
      "2022-08-30 23:40:11,957 epoch 6 - iter 33/111 - loss 0.63623548 - samples/sec: 83.06 - lr: 0.600000\n",
      "2022-08-30 23:40:15,947 epoch 6 - iter 44/111 - loss 0.63854508 - samples/sec: 83.88 - lr: 0.600000\n",
      "2022-08-30 23:40:20,557 epoch 6 - iter 55/111 - loss 0.63507983 - samples/sec: 72.64 - lr: 0.600000\n",
      "2022-08-30 23:40:24,288 epoch 6 - iter 66/111 - loss 0.63343065 - samples/sec: 90.21 - lr: 0.600000\n",
      "2022-08-30 23:40:28,399 epoch 6 - iter 77/111 - loss 0.63100403 - samples/sec: 81.46 - lr: 0.600000\n",
      "2022-08-30 23:40:32,163 epoch 6 - iter 88/111 - loss 0.62961135 - samples/sec: 89.46 - lr: 0.600000\n",
      "2022-08-30 23:40:36,456 epoch 6 - iter 99/111 - loss 0.62959248 - samples/sec: 77.94 - lr: 0.600000\n",
      "2022-08-30 23:40:40,871 epoch 6 - iter 110/111 - loss 0.63040931 - samples/sec: 75.86 - lr: 0.600000\n",
      "2022-08-30 23:40:41,285 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:40:41,286 EPOCH 6 done: loss 0.6300 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:40:42,228 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:40:42,259 DEV : loss 0.41439956426620483 - f1-score (micro avg)  0.8509\n",
      "2022-08-30 23:40:42,276 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 23:40:42,278 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:40:46,715 epoch 7 - iter 11/111 - loss 0.64809443 - samples/sec: 74.39 - lr: 0.600000\n",
      "2022-08-30 23:40:50,810 epoch 7 - iter 22/111 - loss 0.62828289 - samples/sec: 81.95 - lr: 0.600000\n",
      "2022-08-30 23:40:54,869 epoch 7 - iter 33/111 - loss 0.63341848 - samples/sec: 82.48 - lr: 0.600000\n",
      "2022-08-30 23:40:59,100 epoch 7 - iter 44/111 - loss 0.62860128 - samples/sec: 79.04 - lr: 0.600000\n",
      "2022-08-30 23:41:03,377 epoch 7 - iter 55/111 - loss 0.62426339 - samples/sec: 78.18 - lr: 0.600000\n",
      "2022-08-30 23:41:07,337 epoch 7 - iter 66/111 - loss 0.62949693 - samples/sec: 84.79 - lr: 0.600000\n",
      "2022-08-30 23:41:11,636 epoch 7 - iter 77/111 - loss 0.62912603 - samples/sec: 78.25 - lr: 0.600000\n",
      "2022-08-30 23:41:15,829 epoch 7 - iter 88/111 - loss 0.62881511 - samples/sec: 79.75 - lr: 0.600000\n",
      "2022-08-30 23:41:19,725 epoch 7 - iter 99/111 - loss 0.62755897 - samples/sec: 86.00 - lr: 0.600000\n",
      "2022-08-30 23:41:24,330 epoch 7 - iter 110/111 - loss 0.63037979 - samples/sec: 72.62 - lr: 0.600000\n",
      "2022-08-30 23:41:24,761 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:41:24,762 EPOCH 7 done: loss 0.6298 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:41:25,727 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:41:25,758 DEV : loss 0.3930167555809021 - f1-score (micro avg)  0.8626\n",
      "2022-08-30 23:41:25,776 Epoch     7: reducing learning rate of group 0 to 3.0000e-01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:41:25,777 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 23:41:25,778 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:41:29,951 epoch 8 - iter 11/111 - loss 0.61568242 - samples/sec: 79.12 - lr: 0.300000\n",
      "2022-08-30 23:41:34,408 epoch 8 - iter 22/111 - loss 0.59962813 - samples/sec: 75.09 - lr: 0.300000\n",
      "2022-08-30 23:41:38,547 epoch 8 - iter 33/111 - loss 0.60176426 - samples/sec: 81.22 - lr: 0.300000\n",
      "2022-08-30 23:41:42,543 epoch 8 - iter 44/111 - loss 0.60347781 - samples/sec: 83.88 - lr: 0.300000\n",
      "2022-08-30 23:41:46,718 epoch 8 - iter 55/111 - loss 0.60647424 - samples/sec: 80.23 - lr: 0.300000\n",
      "2022-08-30 23:41:51,447 epoch 8 - iter 66/111 - loss 0.60226661 - samples/sec: 70.74 - lr: 0.300000\n",
      "2022-08-30 23:41:56,189 epoch 8 - iter 77/111 - loss 0.60036208 - samples/sec: 70.80 - lr: 0.300000\n",
      "2022-08-30 23:42:00,242 epoch 8 - iter 88/111 - loss 0.59729120 - samples/sec: 82.77 - lr: 0.300000\n",
      "2022-08-30 23:42:04,530 epoch 8 - iter 99/111 - loss 0.59462041 - samples/sec: 78.07 - lr: 0.300000\n",
      "2022-08-30 23:42:08,666 epoch 8 - iter 110/111 - loss 0.59553113 - samples/sec: 81.16 - lr: 0.300000\n",
      "2022-08-30 23:42:09,084 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:42:09,085 EPOCH 8 done: loss 0.5957 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:42:10,030 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:42:10,060 DEV : loss 0.367838591337204 - f1-score (micro avg)  0.8683\n",
      "2022-08-30 23:42:10,078 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:42:10,079 saving best model\n",
      "2022-08-30 23:42:11,222 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:42:15,243 epoch 9 - iter 11/111 - loss 0.59273132 - samples/sec: 82.11 - lr: 0.300000\n",
      "2022-08-30 23:42:19,301 epoch 9 - iter 22/111 - loss 0.58373129 - samples/sec: 82.50 - lr: 0.300000\n",
      "2022-08-30 23:42:23,053 epoch 9 - iter 33/111 - loss 0.58108874 - samples/sec: 89.50 - lr: 0.300000\n",
      "2022-08-30 23:42:27,269 epoch 9 - iter 44/111 - loss 0.58052437 - samples/sec: 79.40 - lr: 0.300000\n",
      "2022-08-30 23:42:31,494 epoch 9 - iter 55/111 - loss 0.57536230 - samples/sec: 79.21 - lr: 0.300000\n",
      "2022-08-30 23:42:35,716 epoch 9 - iter 66/111 - loss 0.57977873 - samples/sec: 79.27 - lr: 0.300000\n",
      "2022-08-30 23:42:39,954 epoch 9 - iter 77/111 - loss 0.58167912 - samples/sec: 79.12 - lr: 0.300000\n",
      "2022-08-30 23:42:44,104 epoch 9 - iter 88/111 - loss 0.58296341 - samples/sec: 80.80 - lr: 0.300000\n",
      "2022-08-30 23:42:48,200 epoch 9 - iter 99/111 - loss 0.58443454 - samples/sec: 81.78 - lr: 0.300000\n",
      "2022-08-30 23:42:52,469 epoch 9 - iter 110/111 - loss 0.58181715 - samples/sec: 78.33 - lr: 0.300000\n",
      "2022-08-30 23:42:52,952 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:42:52,953 EPOCH 9 done: loss 0.5821 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:42:53,916 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:42:53,945 DEV : loss 0.3682323098182678 - f1-score (micro avg)  0.8691\n",
      "2022-08-30 23:42:53,960 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:42:53,962 saving best model\n",
      "2022-08-30 23:42:54,664 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:42:58,877 epoch 10 - iter 11/111 - loss 0.59145189 - samples/sec: 78.37 - lr: 0.300000\n",
      "2022-08-30 23:43:03,164 epoch 10 - iter 22/111 - loss 0.57720100 - samples/sec: 78.09 - lr: 0.300000\n",
      "2022-08-30 23:43:07,135 epoch 10 - iter 33/111 - loss 0.57661914 - samples/sec: 84.44 - lr: 0.300000\n",
      "2022-08-30 23:43:11,812 epoch 10 - iter 44/111 - loss 0.58103086 - samples/sec: 71.52 - lr: 0.300000\n",
      "2022-08-30 23:43:15,954 epoch 10 - iter 55/111 - loss 0.57551321 - samples/sec: 80.96 - lr: 0.300000\n",
      "2022-08-30 23:43:19,951 epoch 10 - iter 66/111 - loss 0.57400471 - samples/sec: 83.86 - lr: 0.300000\n",
      "2022-08-30 23:43:23,885 epoch 10 - iter 77/111 - loss 0.57386633 - samples/sec: 85.21 - lr: 0.300000\n",
      "2022-08-30 23:43:28,092 epoch 10 - iter 88/111 - loss 0.57719821 - samples/sec: 79.61 - lr: 0.300000\n",
      "2022-08-30 23:43:31,933 epoch 10 - iter 99/111 - loss 0.57755867 - samples/sec: 87.26 - lr: 0.300000\n",
      "2022-08-30 23:43:35,869 epoch 10 - iter 110/111 - loss 0.58001916 - samples/sec: 85.23 - lr: 0.300000\n",
      "2022-08-30 23:43:36,303 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:43:36,304 EPOCH 10 done: loss 0.5799 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:43:37,204 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:43:37,240 DEV : loss 0.3564433157444 - f1-score (micro avg)  0.8707\n",
      "2022-08-30 23:43:37,263 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:43:37,264 saving best model\n",
      "2022-08-30 23:43:38,937 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:43:38,938 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 23:43:39,122 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:43:40,588 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:43:40,615 0.8822\t0.8822\t0.8822\t0.8822\n",
      "2022-08-30 23:43:40,615 \n",
      "Results:\n",
      "- F-score (micro) 0.8822\n",
      "- F-score (macro) 0.7645\n",
      "- Accuracy 0.8822\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8197    0.9039    0.8598      1353\n",
      "         ADJ     0.7733    0.8884    0.8269       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9921    0.9747    0.9833       514\n",
      "        VERB     0.8458    0.8062    0.8255       449\n",
      "         AUX     0.9939    0.9672    0.9803       335\n",
      "       PROPN     0.8429    0.5744    0.6832       383\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9945    0.9891    0.9918       184\n",
      "         ADV     0.7241    0.6954    0.7095       151\n",
      "         DET     0.9292    0.6522    0.7664       161\n",
      "        PRON     1.0000    0.9043    0.9498       115\n",
      "         NUM     0.9630    0.7324    0.8320        71\n",
      "        PART     0.8500    0.8095    0.8293        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8822      5264\n",
      "   macro avg     0.7949    0.7436    0.7645      5264\n",
      "weighted avg     0.8867    0.8822    0.8805      5264\n",
      "\n",
      "2022-08-30 23:43:40,616 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:43:40,618 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 23:43:41,120 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-30 23:46:01,160 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:46:01,161 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 23:46:01,161 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:46:01,162 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 23:46:01,162 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:46:01,163 Parameters:\n",
      "2022-08-30 23:46:01,163  - learning_rate: \"0.600000\"\n",
      "2022-08-30 23:46:01,164  - mini_batch_size: \"30\"\n",
      "2022-08-30 23:46:01,164  - patience: \"3\"\n",
      "2022-08-30 23:46:01,165  - anneal_factor: \"0.5\"\n",
      "2022-08-30 23:46:01,165  - max_epochs: \"11\"\n",
      "2022-08-30 23:46:01,166  - shuffle: \"True\"\n",
      "2022-08-30 23:46:01,166  - train_with_dev: \"False\"\n",
      "2022-08-30 23:46:01,167  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 23:46:01,167 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:46:01,168 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 23:46:01,168 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:46:01,169 Device: cpu\n",
      "2022-08-30 23:46:01,169 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:46:01,170 Embeddings storage mode: cpu\n",
      "2022-08-30 23:46:01,170 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:46:05,262 epoch 1 - iter 11/111 - loss 0.57217733 - samples/sec: 80.68 - lr: 0.600000\n",
      "2022-08-30 23:46:09,466 epoch 1 - iter 22/111 - loss 0.58654028 - samples/sec: 79.61 - lr: 0.600000\n",
      "2022-08-30 23:46:13,132 epoch 1 - iter 33/111 - loss 0.58961667 - samples/sec: 91.49 - lr: 0.600000\n",
      "2022-08-30 23:46:17,169 epoch 1 - iter 44/111 - loss 0.59070736 - samples/sec: 82.96 - lr: 0.600000\n",
      "2022-08-30 23:46:21,936 epoch 1 - iter 55/111 - loss 0.59395146 - samples/sec: 70.06 - lr: 0.600000\n",
      "2022-08-30 23:46:25,967 epoch 1 - iter 66/111 - loss 0.59601091 - samples/sec: 83.10 - lr: 0.600000\n",
      "2022-08-30 23:46:30,317 epoch 1 - iter 77/111 - loss 0.59771189 - samples/sec: 76.89 - lr: 0.600000\n",
      "2022-08-30 23:46:34,163 epoch 1 - iter 88/111 - loss 0.59721678 - samples/sec: 87.28 - lr: 0.600000\n",
      "2022-08-30 23:46:38,328 epoch 1 - iter 99/111 - loss 0.59682089 - samples/sec: 80.43 - lr: 0.600000\n",
      "2022-08-30 23:46:42,919 epoch 1 - iter 110/111 - loss 0.61343111 - samples/sec: 72.88 - lr: 0.600000\n",
      "2022-08-30 23:46:43,395 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:46:43,396 EPOCH 1 done: loss 0.6136 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:46:44,330 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:46:44,363 DEV : loss 0.4282582700252533 - f1-score (micro avg)  0.8543\n",
      "2022-08-30 23:46:44,384 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:46:44,385 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:46:45,105 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:46:48,990 epoch 2 - iter 11/111 - loss 0.60253662 - samples/sec: 84.99 - lr: 0.600000\n",
      "2022-08-30 23:46:53,415 epoch 2 - iter 22/111 - loss 0.60762278 - samples/sec: 75.67 - lr: 0.600000\n",
      "2022-08-30 23:46:57,937 epoch 2 - iter 33/111 - loss 0.60728556 - samples/sec: 74.11 - lr: 0.600000\n",
      "2022-08-30 23:47:01,926 epoch 2 - iter 44/111 - loss 0.61035506 - samples/sec: 83.93 - lr: 0.600000\n",
      "2022-08-30 23:47:06,069 epoch 2 - iter 55/111 - loss 0.61065441 - samples/sec: 80.86 - lr: 0.600000\n",
      "2022-08-30 23:47:10,178 epoch 2 - iter 66/111 - loss 0.60707400 - samples/sec: 81.57 - lr: 0.600000\n",
      "2022-08-30 23:47:14,454 epoch 2 - iter 77/111 - loss 0.60961030 - samples/sec: 78.29 - lr: 0.600000\n",
      "2022-08-30 23:47:18,620 epoch 2 - iter 88/111 - loss 0.61073299 - samples/sec: 80.31 - lr: 0.600000\n",
      "2022-08-30 23:47:22,811 epoch 2 - iter 99/111 - loss 0.61279673 - samples/sec: 80.02 - lr: 0.600000\n",
      "2022-08-30 23:47:26,936 epoch 2 - iter 110/111 - loss 0.61522539 - samples/sec: 81.16 - lr: 0.600000\n",
      "2022-08-30 23:47:27,303 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:47:27,304 EPOCH 2 done: loss 0.6147 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:47:28,229 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:47:28,257 DEV : loss 0.37754857540130615 - f1-score (micro avg)  0.872\n",
      "2022-08-30 23:47:28,275 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:47:28,276 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:47:29,213 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:47:33,111 epoch 3 - iter 11/111 - loss 0.64391261 - samples/sec: 84.70 - lr: 0.600000\n",
      "2022-08-30 23:47:37,131 epoch 3 - iter 22/111 - loss 0.63671031 - samples/sec: 83.23 - lr: 0.600000\n",
      "2022-08-30 23:47:41,372 epoch 3 - iter 33/111 - loss 0.62719430 - samples/sec: 78.87 - lr: 0.600000\n",
      "2022-08-30 23:47:45,785 epoch 3 - iter 44/111 - loss 0.62537350 - samples/sec: 76.30 - lr: 0.600000\n",
      "2022-08-30 23:47:50,347 epoch 3 - iter 55/111 - loss 0.62144541 - samples/sec: 73.48 - lr: 0.600000\n",
      "2022-08-30 23:47:54,508 epoch 3 - iter 66/111 - loss 0.62145605 - samples/sec: 80.82 - lr: 0.600000\n",
      "2022-08-30 23:47:58,666 epoch 3 - iter 77/111 - loss 0.61922522 - samples/sec: 80.74 - lr: 0.600000\n",
      "2022-08-30 23:48:03,251 epoch 3 - iter 88/111 - loss 0.61660720 - samples/sec: 72.91 - lr: 0.600000\n",
      "2022-08-30 23:48:07,083 epoch 3 - iter 99/111 - loss 0.61613521 - samples/sec: 87.58 - lr: 0.600000\n",
      "2022-08-30 23:48:11,082 epoch 3 - iter 110/111 - loss 0.61255567 - samples/sec: 83.84 - lr: 0.600000\n",
      "2022-08-30 23:48:11,448 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:48:11,449 EPOCH 3 done: loss 0.6131 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:48:12,450 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:48:12,485 DEV : loss 0.39449095726013184 - f1-score (micro avg)  0.8616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:48:12,504 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:48:12,505 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:48:16,402 epoch 4 - iter 11/111 - loss 0.60760295 - samples/sec: 84.70 - lr: 0.600000\n",
      "2022-08-30 23:48:21,048 epoch 4 - iter 22/111 - loss 0.61399771 - samples/sec: 72.16 - lr: 0.600000\n",
      "2022-08-30 23:48:25,500 epoch 4 - iter 33/111 - loss 0.61513667 - samples/sec: 75.17 - lr: 0.600000\n",
      "2022-08-30 23:48:30,071 epoch 4 - iter 44/111 - loss 0.61681453 - samples/sec: 73.55 - lr: 0.600000\n",
      "2022-08-30 23:48:34,549 epoch 4 - iter 55/111 - loss 0.61197596 - samples/sec: 74.74 - lr: 0.600000\n",
      "2022-08-30 23:48:38,576 epoch 4 - iter 66/111 - loss 0.61237960 - samples/sec: 83.46 - lr: 0.600000\n",
      "2022-08-30 23:48:42,686 epoch 4 - iter 77/111 - loss 0.60962665 - samples/sec: 81.50 - lr: 0.600000\n",
      "2022-08-30 23:48:47,191 epoch 4 - iter 88/111 - loss 0.61177353 - samples/sec: 74.26 - lr: 0.600000\n",
      "2022-08-30 23:48:51,829 epoch 4 - iter 99/111 - loss 0.61203235 - samples/sec: 72.16 - lr: 0.600000\n",
      "2022-08-30 23:48:55,772 epoch 4 - iter 110/111 - loss 0.61108422 - samples/sec: 85.05 - lr: 0.600000\n",
      "2022-08-30 23:48:56,189 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:48:56,189 EPOCH 4 done: loss 0.6117 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:48:57,117 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:48:57,148 DEV : loss 0.39669862389564514 - f1-score (micro avg)  0.8603\n",
      "2022-08-30 23:48:57,166 BAD EPOCHS (no improvement): 2\n",
      "2022-08-30 23:48:57,167 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:49:01,517 epoch 5 - iter 11/111 - loss 0.65038415 - samples/sec: 75.88 - lr: 0.600000\n",
      "2022-08-30 23:49:05,594 epoch 5 - iter 22/111 - loss 0.62121617 - samples/sec: 82.50 - lr: 0.600000\n",
      "2022-08-30 23:49:10,031 epoch 5 - iter 33/111 - loss 0.62290458 - samples/sec: 75.51 - lr: 0.600000\n",
      "2022-08-30 23:49:14,152 epoch 5 - iter 44/111 - loss 0.61534691 - samples/sec: 81.24 - lr: 0.600000\n",
      "2022-08-30 23:49:18,201 epoch 5 - iter 55/111 - loss 0.61126303 - samples/sec: 82.69 - lr: 0.600000\n",
      "2022-08-30 23:49:22,628 epoch 5 - iter 66/111 - loss 0.61054516 - samples/sec: 75.60 - lr: 0.600000\n",
      "2022-08-30 23:49:26,942 epoch 5 - iter 77/111 - loss 0.61338995 - samples/sec: 77.52 - lr: 0.600000\n",
      "2022-08-30 23:49:31,153 epoch 5 - iter 88/111 - loss 0.61282289 - samples/sec: 79.48 - lr: 0.600000\n",
      "2022-08-30 23:49:35,319 epoch 5 - iter 99/111 - loss 0.61323618 - samples/sec: 80.35 - lr: 0.600000\n",
      "2022-08-30 23:49:39,915 epoch 5 - iter 110/111 - loss 0.61185693 - samples/sec: 72.75 - lr: 0.600000\n",
      "2022-08-30 23:49:40,272 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:49:40,273 EPOCH 5 done: loss 0.6125 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:49:41,212 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:49:41,240 DEV : loss 0.40108829736709595 - f1-score (micro avg)  0.8613\n",
      "2022-08-30 23:49:41,255 BAD EPOCHS (no improvement): 3\n",
      "2022-08-30 23:49:41,256 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:49:45,338 epoch 6 - iter 11/111 - loss 0.64126841 - samples/sec: 80.86 - lr: 0.600000\n",
      "2022-08-30 23:49:49,650 epoch 6 - iter 22/111 - loss 0.61486995 - samples/sec: 78.14 - lr: 0.600000\n",
      "2022-08-30 23:49:53,678 epoch 6 - iter 33/111 - loss 0.61982195 - samples/sec: 83.10 - lr: 0.600000\n",
      "2022-08-30 23:49:57,837 epoch 6 - iter 44/111 - loss 0.61939004 - samples/sec: 80.53 - lr: 0.600000\n",
      "2022-08-30 23:50:01,886 epoch 6 - iter 55/111 - loss 0.61884348 - samples/sec: 82.73 - lr: 0.600000\n",
      "2022-08-30 23:50:06,322 epoch 6 - iter 66/111 - loss 0.61712700 - samples/sec: 75.55 - lr: 0.600000\n",
      "2022-08-30 23:50:10,533 epoch 6 - iter 77/111 - loss 0.61856624 - samples/sec: 79.61 - lr: 0.600000\n",
      "2022-08-30 23:50:14,808 epoch 6 - iter 88/111 - loss 0.61804551 - samples/sec: 78.39 - lr: 0.600000\n",
      "2022-08-30 23:50:19,166 epoch 6 - iter 99/111 - loss 0.61633395 - samples/sec: 76.87 - lr: 0.600000\n",
      "2022-08-30 23:50:23,481 epoch 6 - iter 110/111 - loss 0.61654597 - samples/sec: 77.61 - lr: 0.600000\n",
      "2022-08-30 23:50:24,024 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:50:24,024 EPOCH 6 done: loss 0.6170 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:50:24,963 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:50:24,995 DEV : loss 0.383425235748291 - f1-score (micro avg)  0.8702\n",
      "2022-08-30 23:50:25,011 Epoch     6: reducing learning rate of group 0 to 3.0000e-01.\n",
      "2022-08-30 23:50:25,012 BAD EPOCHS (no improvement): 4\n",
      "2022-08-30 23:50:25,013 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:50:29,262 epoch 7 - iter 11/111 - loss 0.59167444 - samples/sec: 77.68 - lr: 0.300000\n",
      "2022-08-30 23:50:33,506 epoch 7 - iter 22/111 - loss 0.59424103 - samples/sec: 78.83 - lr: 0.300000\n",
      "2022-08-30 23:50:37,384 epoch 7 - iter 33/111 - loss 0.59291923 - samples/sec: 86.54 - lr: 0.300000\n",
      "2022-08-30 23:50:41,400 epoch 7 - iter 44/111 - loss 0.59276174 - samples/sec: 83.67 - lr: 0.300000\n",
      "2022-08-30 23:50:45,708 epoch 7 - iter 55/111 - loss 0.59130408 - samples/sec: 77.79 - lr: 0.300000\n",
      "2022-08-30 23:50:50,132 epoch 7 - iter 66/111 - loss 0.58690678 - samples/sec: 75.86 - lr: 0.300000\n",
      "2022-08-30 23:50:54,684 epoch 7 - iter 77/111 - loss 0.58385946 - samples/sec: 73.53 - lr: 0.300000\n",
      "2022-08-30 23:50:59,187 epoch 7 - iter 88/111 - loss 0.58358168 - samples/sec: 74.22 - lr: 0.300000\n",
      "2022-08-30 23:51:03,379 epoch 7 - iter 99/111 - loss 0.58417479 - samples/sec: 79.96 - lr: 0.300000\n",
      "2022-08-30 23:51:07,700 epoch 7 - iter 110/111 - loss 0.58175665 - samples/sec: 77.90 - lr: 0.300000\n",
      "2022-08-30 23:51:08,082 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:51:08,083 EPOCH 7 done: loss 0.5813 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:51:09,005 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:51:09,034 DEV : loss 0.3623078465461731 - f1-score (micro avg)  0.8744\n",
      "2022-08-30 23:51:09,050 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:51:09,051 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:51:09,855 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:51:14,083 epoch 8 - iter 11/111 - loss 0.59219416 - samples/sec: 78.11 - lr: 0.300000\n",
      "2022-08-30 23:51:18,574 epoch 8 - iter 22/111 - loss 0.58760061 - samples/sec: 74.54 - lr: 0.300000\n",
      "2022-08-30 23:51:22,931 epoch 8 - iter 33/111 - loss 0.58585580 - samples/sec: 77.05 - lr: 0.300000\n",
      "2022-08-30 23:51:26,834 epoch 8 - iter 44/111 - loss 0.58634503 - samples/sec: 85.96 - lr: 0.300000\n",
      "2022-08-30 23:51:30,901 epoch 8 - iter 55/111 - loss 0.58240516 - samples/sec: 82.42 - lr: 0.300000\n",
      "2022-08-30 23:51:35,430 epoch 8 - iter 66/111 - loss 0.58097573 - samples/sec: 73.87 - lr: 0.300000\n",
      "2022-08-30 23:51:39,612 epoch 8 - iter 77/111 - loss 0.57569557 - samples/sec: 80.35 - lr: 0.300000\n",
      "2022-08-30 23:51:43,512 epoch 8 - iter 88/111 - loss 0.57423005 - samples/sec: 85.85 - lr: 0.300000\n",
      "2022-08-30 23:51:47,782 epoch 8 - iter 99/111 - loss 0.57422994 - samples/sec: 78.46 - lr: 0.300000\n",
      "2022-08-30 23:51:52,172 epoch 8 - iter 110/111 - loss 0.57458114 - samples/sec: 76.27 - lr: 0.300000\n",
      "2022-08-30 23:51:52,699 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:51:52,700 EPOCH 8 done: loss 0.5751 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:51:54,972 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:51:55,000 DEV : loss 0.363484650850296 - f1-score (micro avg)  0.8741\n",
      "2022-08-30 23:51:55,019 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:51:55,020 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:51:59,509 epoch 9 - iter 11/111 - loss 0.57038638 - samples/sec: 73.58 - lr: 0.300000\n",
      "2022-08-30 23:52:04,048 epoch 9 - iter 22/111 - loss 0.56573658 - samples/sec: 73.83 - lr: 0.300000\n",
      "2022-08-30 23:52:08,299 epoch 9 - iter 33/111 - loss 0.56646664 - samples/sec: 78.82 - lr: 0.300000\n",
      "2022-08-30 23:52:12,626 epoch 9 - iter 44/111 - loss 0.56247916 - samples/sec: 77.46 - lr: 0.300000\n",
      "2022-08-30 23:52:16,735 epoch 9 - iter 55/111 - loss 0.56213224 - samples/sec: 81.61 - lr: 0.300000\n",
      "2022-08-30 23:52:21,045 epoch 9 - iter 66/111 - loss 0.56450209 - samples/sec: 77.61 - lr: 0.300000\n",
      "2022-08-30 23:52:25,182 epoch 9 - iter 77/111 - loss 0.56663042 - samples/sec: 80.93 - lr: 0.300000\n",
      "2022-08-30 23:52:29,501 epoch 9 - iter 88/111 - loss 0.56685946 - samples/sec: 77.45 - lr: 0.300000\n",
      "2022-08-30 23:52:33,888 epoch 9 - iter 99/111 - loss 0.56485473 - samples/sec: 76.22 - lr: 0.300000\n",
      "2022-08-30 23:52:38,250 epoch 9 - iter 110/111 - loss 0.56476555 - samples/sec: 76.71 - lr: 0.300000\n",
      "2022-08-30 23:52:38,682 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:52:38,683 EPOCH 9 done: loss 0.5651 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:52:39,603 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:52:39,636 DEV : loss 0.3490714132785797 - f1-score (micro avg)  0.879\n",
      "2022-08-30 23:52:39,655 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:52:39,656 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:52:40,374 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:52:44,901 epoch 10 - iter 11/111 - loss 0.53752912 - samples/sec: 72.94 - lr: 0.300000\n",
      "2022-08-30 23:52:49,211 epoch 10 - iter 22/111 - loss 0.54882510 - samples/sec: 77.67 - lr: 0.300000\n",
      "2022-08-30 23:52:53,422 epoch 10 - iter 33/111 - loss 0.55111060 - samples/sec: 79.58 - lr: 0.300000\n",
      "2022-08-30 23:52:57,612 epoch 10 - iter 44/111 - loss 0.55901008 - samples/sec: 80.17 - lr: 0.300000\n",
      "2022-08-30 23:53:02,314 epoch 10 - iter 55/111 - loss 0.55732783 - samples/sec: 71.07 - lr: 0.300000\n",
      "2022-08-30 23:53:06,607 epoch 10 - iter 66/111 - loss 0.55829408 - samples/sec: 78.22 - lr: 0.300000\n",
      "2022-08-30 23:53:10,739 epoch 10 - iter 77/111 - loss 0.55926704 - samples/sec: 81.12 - lr: 0.300000\n",
      "2022-08-30 23:53:14,654 epoch 10 - iter 88/111 - loss 0.56166791 - samples/sec: 85.85 - lr: 0.300000\n",
      "2022-08-30 23:53:19,225 epoch 10 - iter 99/111 - loss 0.56295513 - samples/sec: 73.28 - lr: 0.300000\n",
      "2022-08-30 23:53:23,032 epoch 10 - iter 110/111 - loss 0.56356668 - samples/sec: 88.14 - lr: 0.300000\n",
      "2022-08-30 23:53:23,421 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:53:23,422 EPOCH 10 done: loss 0.5632 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:53:24,407 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:53:24,440 DEV : loss 0.36336472630500793 - f1-score (micro avg)  0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:53:24,456 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:53:24,458 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:53:28,634 epoch 11 - iter 11/111 - loss 0.54731819 - samples/sec: 79.04 - lr: 0.300000\n",
      "2022-08-30 23:53:33,229 epoch 11 - iter 22/111 - loss 0.55107139 - samples/sec: 72.88 - lr: 0.300000\n",
      "2022-08-30 23:53:37,977 epoch 11 - iter 33/111 - loss 0.55813439 - samples/sec: 70.60 - lr: 0.300000\n",
      "2022-08-30 23:53:42,564 epoch 11 - iter 44/111 - loss 0.55613204 - samples/sec: 72.99 - lr: 0.300000\n",
      "2022-08-30 23:53:47,339 epoch 11 - iter 55/111 - loss 0.55538106 - samples/sec: 70.03 - lr: 0.300000\n",
      "2022-08-30 23:53:51,571 epoch 11 - iter 66/111 - loss 0.55978801 - samples/sec: 79.38 - lr: 0.300000\n",
      "2022-08-30 23:53:55,891 epoch 11 - iter 77/111 - loss 0.55845627 - samples/sec: 77.67 - lr: 0.300000\n",
      "2022-08-30 23:54:00,284 epoch 11 - iter 88/111 - loss 0.55982709 - samples/sec: 76.25 - lr: 0.300000\n",
      "2022-08-30 23:54:04,583 epoch 11 - iter 99/111 - loss 0.55817270 - samples/sec: 78.03 - lr: 0.300000\n",
      "2022-08-30 23:54:08,815 epoch 11 - iter 110/111 - loss 0.55915307 - samples/sec: 79.37 - lr: 0.300000\n",
      "2022-08-30 23:54:09,190 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:54:09,191 EPOCH 11 done: loss 0.5591 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:54:10,151 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:54:10,187 DEV : loss 0.3481597602367401 - f1-score (micro avg)  0.8785\n",
      "2022-08-30 23:54:10,202 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:54:11,100 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:54:11,101 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-30 23:54:11,286 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:54:12,774 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:54:12,798 0.8822\t0.8822\t0.8822\t0.8822\n",
      "2022-08-30 23:54:12,799 \n",
      "Results:\n",
      "- F-score (micro) 0.8822\n",
      "- F-score (macro) 0.8291\n",
      "- Accuracy 0.8822\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8395    0.8817    0.8601      1353\n",
      "         ADJ     0.7846    0.8780    0.8287       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9881    0.9708    0.9794       514\n",
      "        VERB     0.8188    0.8352    0.8269       449\n",
      "       PROPN     0.7781    0.6136    0.6861       383\n",
      "         AUX     0.9939    0.9701    0.9819       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         ADV     0.7208    0.7351    0.7279       151\n",
      "         DET     0.8843    0.6646    0.7589       161\n",
      "        PRON     1.0000    0.8957    0.9450       115\n",
      "         NUM     0.9464    0.7465    0.8346        71\n",
      "        PART     0.8947    0.8095    0.8500        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.8822      5264\n",
      "   macro avg     0.8518    0.8122    0.8291      5264\n",
      "weighted avg     0.8843    0.8822    0.8813      5264\n",
      "\n",
      "2022-08-30 23:54:12,800 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:54:12,802 loading file resources/taggers/optimized-upos/final-model.pt\n",
      "2022-08-30 23:54:13,285 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 7 #######################\n",
      "#######################################################\n",
      "2022-08-30 23:56:46,205 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:56:46,206 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-30 23:56:46,207 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:56:46,207 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-30 23:56:46,208 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:56:46,209 Parameters:\n",
      "2022-08-30 23:56:46,209  - learning_rate: \"0.600000\"\n",
      "2022-08-30 23:56:46,210  - mini_batch_size: \"30\"\n",
      "2022-08-30 23:56:46,211  - patience: \"3\"\n",
      "2022-08-30 23:56:46,211  - anneal_factor: \"0.5\"\n",
      "2022-08-30 23:56:46,212  - max_epochs: \"12\"\n",
      "2022-08-30 23:56:46,212  - shuffle: \"True\"\n",
      "2022-08-30 23:56:46,213  - train_with_dev: \"False\"\n",
      "2022-08-30 23:56:46,213  - batch_growth_annealing: \"False\"\n",
      "2022-08-30 23:56:46,214 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:56:46,215 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-30 23:56:46,215 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:56:46,216 Device: cpu\n",
      "2022-08-30 23:56:46,216 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:56:46,217 Embeddings storage mode: cpu\n",
      "2022-08-30 23:56:46,217 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:56:50,477 epoch 1 - iter 11/111 - loss 0.56132280 - samples/sec: 77.52 - lr: 0.600000\n",
      "2022-08-30 23:56:54,878 epoch 1 - iter 22/111 - loss 0.57278600 - samples/sec: 76.42 - lr: 0.600000\n",
      "2022-08-30 23:56:58,692 epoch 1 - iter 33/111 - loss 0.57279131 - samples/sec: 87.88 - lr: 0.600000\n",
      "2022-08-30 23:57:02,767 epoch 1 - iter 44/111 - loss 0.57984480 - samples/sec: 82.40 - lr: 0.600000\n",
      "2022-08-30 23:57:07,291 epoch 1 - iter 55/111 - loss 0.58210909 - samples/sec: 73.99 - lr: 0.600000\n",
      "2022-08-30 23:57:11,283 epoch 1 - iter 66/111 - loss 0.58078883 - samples/sec: 84.10 - lr: 0.600000\n",
      "2022-08-30 23:57:15,783 epoch 1 - iter 77/111 - loss 0.58278511 - samples/sec: 74.32 - lr: 0.600000\n",
      "2022-08-30 23:57:19,657 epoch 1 - iter 88/111 - loss 0.58317503 - samples/sec: 86.66 - lr: 0.600000\n",
      "2022-08-30 23:57:23,826 epoch 1 - iter 99/111 - loss 0.58389769 - samples/sec: 80.39 - lr: 0.600000\n",
      "2022-08-30 23:57:28,451 epoch 1 - iter 110/111 - loss 0.59962923 - samples/sec: 72.24 - lr: 0.600000\n",
      "2022-08-30 23:57:28,935 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:57:28,936 EPOCH 1 done: loss 0.6006 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:57:29,914 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:57:29,945 DEV : loss 0.4147459864616394 - f1-score (micro avg)  0.8566\n",
      "2022-08-30 23:57:29,961 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:57:29,962 saving best model\n",
      "2022-08-30 23:57:30,689 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:57:34,681 epoch 2 - iter 11/111 - loss 0.60147520 - samples/sec: 82.71 - lr: 0.600000\n",
      "2022-08-30 23:57:39,773 epoch 2 - iter 22/111 - loss 0.60325489 - samples/sec: 65.62 - lr: 0.600000\n",
      "2022-08-30 23:57:43,734 epoch 2 - iter 33/111 - loss 0.60434627 - samples/sec: 84.59 - lr: 0.600000\n",
      "2022-08-30 23:57:48,003 epoch 2 - iter 44/111 - loss 0.60090532 - samples/sec: 78.50 - lr: 0.600000\n",
      "2022-08-30 23:57:52,623 epoch 2 - iter 55/111 - loss 0.59685302 - samples/sec: 72.48 - lr: 0.600000\n",
      "2022-08-30 23:57:56,905 epoch 2 - iter 66/111 - loss 0.59751627 - samples/sec: 78.50 - lr: 0.600000\n",
      "2022-08-30 23:58:01,207 epoch 2 - iter 77/111 - loss 0.60124381 - samples/sec: 77.94 - lr: 0.600000\n",
      "2022-08-30 23:58:05,305 epoch 2 - iter 88/111 - loss 0.60110830 - samples/sec: 81.72 - lr: 0.600000\n",
      "2022-08-30 23:58:09,558 epoch 2 - iter 99/111 - loss 0.60039762 - samples/sec: 78.91 - lr: 0.600000\n",
      "2022-08-30 23:58:13,814 epoch 2 - iter 110/111 - loss 0.60261682 - samples/sec: 78.67 - lr: 0.600000\n",
      "2022-08-30 23:58:14,217 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:58:14,218 EPOCH 2 done: loss 0.6030 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:58:15,201 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:58:15,234 DEV : loss 0.38498640060424805 - f1-score (micro avg)  0.8642\n",
      "2022-08-30 23:58:15,257 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:58:15,258 saving best model\n",
      "2022-08-30 23:58:15,955 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:58:20,215 epoch 3 - iter 11/111 - loss 0.60582510 - samples/sec: 77.50 - lr: 0.600000\n",
      "2022-08-30 23:58:24,551 epoch 3 - iter 22/111 - loss 0.61245197 - samples/sec: 77.27 - lr: 0.600000\n",
      "2022-08-30 23:58:28,505 epoch 3 - iter 33/111 - loss 0.60358123 - samples/sec: 84.75 - lr: 0.600000\n",
      "2022-08-30 23:58:33,378 epoch 3 - iter 44/111 - loss 0.60901352 - samples/sec: 68.61 - lr: 0.600000\n",
      "2022-08-30 23:58:37,692 epoch 3 - iter 55/111 - loss 0.61165770 - samples/sec: 78.11 - lr: 0.600000\n",
      "2022-08-30 23:58:41,765 epoch 3 - iter 66/111 - loss 0.60862555 - samples/sec: 82.38 - lr: 0.600000\n",
      "2022-08-30 23:58:46,101 epoch 3 - iter 77/111 - loss 0.60947752 - samples/sec: 77.37 - lr: 0.600000\n",
      "2022-08-30 23:58:50,167 epoch 3 - iter 88/111 - loss 0.60696763 - samples/sec: 82.36 - lr: 0.600000\n",
      "2022-08-30 23:58:54,394 epoch 3 - iter 99/111 - loss 0.60853358 - samples/sec: 79.17 - lr: 0.600000\n",
      "2022-08-30 23:58:58,819 epoch 3 - iter 110/111 - loss 0.60995950 - samples/sec: 75.95 - lr: 0.600000\n",
      "2022-08-30 23:58:59,237 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:58:59,238 EPOCH 3 done: loss 0.6095 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:59:00,215 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:59:00,246 DEV : loss 0.3696824312210083 - f1-score (micro avg)  0.872\n",
      "2022-08-30 23:59:00,265 BAD EPOCHS (no improvement): 0\n",
      "2022-08-30 23:59:00,266 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:59:01,066 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:59:05,175 epoch 4 - iter 11/111 - loss 0.57692631 - samples/sec: 80.37 - lr: 0.600000\n",
      "2022-08-30 23:59:09,268 epoch 4 - iter 22/111 - loss 0.60774377 - samples/sec: 81.85 - lr: 0.600000\n",
      "2022-08-30 23:59:14,110 epoch 4 - iter 33/111 - loss 0.59952195 - samples/sec: 69.14 - lr: 0.600000\n",
      "2022-08-30 23:59:17,847 epoch 4 - iter 44/111 - loss 0.59977170 - samples/sec: 89.65 - lr: 0.600000\n",
      "2022-08-30 23:59:22,123 epoch 4 - iter 55/111 - loss 0.60188336 - samples/sec: 78.31 - lr: 0.600000\n",
      "2022-08-30 23:59:26,565 epoch 4 - iter 66/111 - loss 0.60398413 - samples/sec: 75.39 - lr: 0.600000\n",
      "2022-08-30 23:59:30,880 epoch 4 - iter 77/111 - loss 0.60432287 - samples/sec: 77.72 - lr: 0.600000\n",
      "2022-08-30 23:59:35,301 epoch 4 - iter 88/111 - loss 0.60321816 - samples/sec: 75.76 - lr: 0.600000\n",
      "2022-08-30 23:59:39,714 epoch 4 - iter 99/111 - loss 0.60625384 - samples/sec: 76.12 - lr: 0.600000\n",
      "2022-08-30 23:59:43,885 epoch 4 - iter 110/111 - loss 0.60543218 - samples/sec: 80.25 - lr: 0.600000\n",
      "2022-08-30 23:59:44,284 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-30 23:59:44,285 EPOCH 4 done: loss 0.6060 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:59:45,268 Evaluating as a multi-label problem: False\n",
      "2022-08-30 23:59:45,297 DEV : loss 0.3683909475803375 - f1-score (micro avg)  0.8679\n",
      "2022-08-30 23:59:45,314 BAD EPOCHS (no improvement): 1\n",
      "2022-08-30 23:59:45,315 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 23:59:49,621 epoch 5 - iter 11/111 - loss 0.60889124 - samples/sec: 76.67 - lr: 0.600000\n",
      "2022-08-30 23:59:53,974 epoch 5 - iter 22/111 - loss 0.59793154 - samples/sec: 76.96 - lr: 0.600000\n",
      "2022-08-30 23:59:58,584 epoch 5 - iter 33/111 - loss 0.60365910 - samples/sec: 72.61 - lr: 0.600000\n",
      "2022-08-31 00:00:02,994 epoch 5 - iter 44/111 - loss 0.59748135 - samples/sec: 75.88 - lr: 0.600000\n",
      "2022-08-31 00:00:07,316 epoch 5 - iter 55/111 - loss 0.59770167 - samples/sec: 77.52 - lr: 0.600000\n",
      "2022-08-31 00:00:11,352 epoch 5 - iter 66/111 - loss 0.59995262 - samples/sec: 83.52 - lr: 0.600000\n",
      "2022-08-31 00:00:15,695 epoch 5 - iter 77/111 - loss 0.60140553 - samples/sec: 77.28 - lr: 0.600000\n",
      "2022-08-31 00:00:20,124 epoch 5 - iter 88/111 - loss 0.60467033 - samples/sec: 75.74 - lr: 0.600000\n",
      "2022-08-31 00:00:24,220 epoch 5 - iter 99/111 - loss 0.60670290 - samples/sec: 81.74 - lr: 0.600000\n",
      "2022-08-31 00:00:28,438 epoch 5 - iter 110/111 - loss 0.60535421 - samples/sec: 79.38 - lr: 0.600000\n",
      "2022-08-31 00:00:28,864 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:00:28,865 EPOCH 5 done: loss 0.6051 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:00:29,818 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:00:29,853 DEV : loss 0.4052925407886505 - f1-score (micro avg)  0.8566\n",
      "2022-08-31 00:00:29,873 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:00:29,874 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:00:34,146 epoch 6 - iter 11/111 - loss 0.60123713 - samples/sec: 77.27 - lr: 0.600000\n",
      "2022-08-31 00:00:38,502 epoch 6 - iter 22/111 - loss 0.60349508 - samples/sec: 76.83 - lr: 0.600000\n",
      "2022-08-31 00:00:42,732 epoch 6 - iter 33/111 - loss 0.60439259 - samples/sec: 79.19 - lr: 0.600000\n",
      "2022-08-31 00:00:46,834 epoch 6 - iter 44/111 - loss 0.59659131 - samples/sec: 81.82 - lr: 0.600000\n",
      "2022-08-31 00:00:51,230 epoch 6 - iter 55/111 - loss 0.60329838 - samples/sec: 76.23 - lr: 0.600000\n",
      "2022-08-31 00:00:55,547 epoch 6 - iter 66/111 - loss 0.60514015 - samples/sec: 77.57 - lr: 0.600000\n",
      "2022-08-31 00:00:59,597 epoch 6 - iter 77/111 - loss 0.60427754 - samples/sec: 82.83 - lr: 0.600000\n",
      "2022-08-31 00:01:03,979 epoch 6 - iter 88/111 - loss 0.60541666 - samples/sec: 76.51 - lr: 0.600000\n",
      "2022-08-31 00:01:08,171 epoch 6 - iter 99/111 - loss 0.60400020 - samples/sec: 79.86 - lr: 0.600000\n",
      "2022-08-31 00:01:12,675 epoch 6 - iter 110/111 - loss 0.60313510 - samples/sec: 74.31 - lr: 0.600000\n",
      "2022-08-31 00:01:13,202 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:01:13,203 EPOCH 6 done: loss 0.6029 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:01:14,211 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:01:14,240 DEV : loss 0.3830934464931488 - f1-score (micro avg)  0.8559\n",
      "2022-08-31 00:01:14,259 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:01:14,260 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:01:18,280 epoch 7 - iter 11/111 - loss 0.59553189 - samples/sec: 82.13 - lr: 0.600000\n",
      "2022-08-31 00:01:22,686 epoch 7 - iter 22/111 - loss 0.60782997 - samples/sec: 75.97 - lr: 0.600000\n",
      "2022-08-31 00:01:27,114 epoch 7 - iter 33/111 - loss 0.60941897 - samples/sec: 75.65 - lr: 0.600000\n",
      "2022-08-31 00:01:31,948 epoch 7 - iter 44/111 - loss 0.60201900 - samples/sec: 69.18 - lr: 0.600000\n",
      "2022-08-31 00:01:35,976 epoch 7 - iter 55/111 - loss 0.60313185 - samples/sec: 83.31 - lr: 0.600000\n",
      "2022-08-31 00:01:40,101 epoch 7 - iter 66/111 - loss 0.60672566 - samples/sec: 81.26 - lr: 0.600000\n",
      "2022-08-31 00:01:44,134 epoch 7 - iter 77/111 - loss 0.60527262 - samples/sec: 83.06 - lr: 0.600000\n",
      "2022-08-31 00:01:48,572 epoch 7 - iter 88/111 - loss 0.60450426 - samples/sec: 75.38 - lr: 0.600000\n",
      "2022-08-31 00:01:52,846 epoch 7 - iter 99/111 - loss 0.60347368 - samples/sec: 78.50 - lr: 0.600000\n",
      "2022-08-31 00:01:57,399 epoch 7 - iter 110/111 - loss 0.60081280 - samples/sec: 73.40 - lr: 0.600000\n",
      "2022-08-31 00:01:57,893 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:01:57,893 EPOCH 7 done: loss 0.6012 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:01:58,888 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:01:58,929 DEV : loss 0.36947551369667053 - f1-score (micro avg)  0.8741\n",
      "2022-08-31 00:01:58,954 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:01:58,955 saving best model\n",
      "2022-08-31 00:01:59,998 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:02:04,639 epoch 8 - iter 11/111 - loss 0.60086275 - samples/sec: 71.15 - lr: 0.600000\n",
      "2022-08-31 00:02:08,835 epoch 8 - iter 22/111 - loss 0.60674156 - samples/sec: 79.83 - lr: 0.600000\n",
      "2022-08-31 00:02:13,461 epoch 8 - iter 33/111 - loss 0.60527618 - samples/sec: 72.35 - lr: 0.600000\n",
      "2022-08-31 00:02:17,788 epoch 8 - iter 44/111 - loss 0.60239187 - samples/sec: 77.65 - lr: 0.600000\n",
      "2022-08-31 00:02:22,255 epoch 8 - iter 55/111 - loss 0.59968854 - samples/sec: 75.05 - lr: 0.600000\n",
      "2022-08-31 00:02:26,956 epoch 8 - iter 66/111 - loss 0.60592719 - samples/sec: 71.29 - lr: 0.600000\n",
      "2022-08-31 00:02:30,933 epoch 8 - iter 77/111 - loss 0.60239597 - samples/sec: 84.36 - lr: 0.600000\n",
      "2022-08-31 00:02:35,082 epoch 8 - iter 88/111 - loss 0.60453619 - samples/sec: 80.74 - lr: 0.600000\n",
      "2022-08-31 00:02:39,365 epoch 8 - iter 99/111 - loss 0.60280686 - samples/sec: 78.13 - lr: 0.600000\n",
      "2022-08-31 00:02:43,659 epoch 8 - iter 110/111 - loss 0.60157944 - samples/sec: 78.40 - lr: 0.600000\n",
      "2022-08-31 00:02:44,068 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:02:44,069 EPOCH 8 done: loss 0.6018 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:02:45,020 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:02:45,050 DEV : loss 0.377639502286911 - f1-score (micro avg)  0.8687\n",
      "2022-08-31 00:02:45,067 BAD EPOCHS (no improvement): 1\n",
      "2022-08-31 00:02:45,068 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:02:49,270 epoch 9 - iter 11/111 - loss 0.59980014 - samples/sec: 78.57 - lr: 0.600000\n",
      "2022-08-31 00:02:53,679 epoch 9 - iter 22/111 - loss 0.59493767 - samples/sec: 75.90 - lr: 0.600000\n",
      "2022-08-31 00:02:58,347 epoch 9 - iter 33/111 - loss 0.60004715 - samples/sec: 71.65 - lr: 0.600000\n",
      "2022-08-31 00:03:02,667 epoch 9 - iter 44/111 - loss 0.60077286 - samples/sec: 77.92 - lr: 0.600000\n",
      "2022-08-31 00:03:07,185 epoch 9 - iter 55/111 - loss 0.59816058 - samples/sec: 74.02 - lr: 0.600000\n",
      "2022-08-31 00:03:11,611 epoch 9 - iter 66/111 - loss 0.60088224 - samples/sec: 75.53 - lr: 0.600000\n",
      "2022-08-31 00:03:15,799 epoch 9 - iter 77/111 - loss 0.60128631 - samples/sec: 79.88 - lr: 0.600000\n",
      "2022-08-31 00:03:19,889 epoch 9 - iter 88/111 - loss 0.60160971 - samples/sec: 81.80 - lr: 0.600000\n",
      "2022-08-31 00:03:23,975 epoch 9 - iter 99/111 - loss 0.60038533 - samples/sec: 81.91 - lr: 0.600000\n",
      "2022-08-31 00:03:28,061 epoch 9 - iter 110/111 - loss 0.60100577 - samples/sec: 82.19 - lr: 0.600000\n",
      "2022-08-31 00:03:28,513 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:03:28,514 EPOCH 9 done: loss 0.6017 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:03:29,447 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:03:29,477 DEV : loss 0.362682968378067 - f1-score (micro avg)  0.8722\n",
      "2022-08-31 00:03:29,493 BAD EPOCHS (no improvement): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:03:29,495 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:03:33,478 epoch 10 - iter 11/111 - loss 0.57500928 - samples/sec: 82.87 - lr: 0.600000\n",
      "2022-08-31 00:03:37,770 epoch 10 - iter 22/111 - loss 0.59611813 - samples/sec: 78.09 - lr: 0.600000\n",
      "2022-08-31 00:03:42,189 epoch 10 - iter 33/111 - loss 0.60272213 - samples/sec: 75.72 - lr: 0.600000\n",
      "2022-08-31 00:03:46,937 epoch 10 - iter 44/111 - loss 0.60010658 - samples/sec: 70.54 - lr: 0.600000\n",
      "2022-08-31 00:03:50,945 epoch 10 - iter 55/111 - loss 0.60033371 - samples/sec: 83.52 - lr: 0.600000\n",
      "2022-08-31 00:03:55,203 epoch 10 - iter 66/111 - loss 0.60052729 - samples/sec: 78.63 - lr: 0.600000\n",
      "2022-08-31 00:03:59,256 epoch 10 - iter 77/111 - loss 0.60100609 - samples/sec: 82.67 - lr: 0.600000\n",
      "2022-08-31 00:04:03,730 epoch 10 - iter 88/111 - loss 0.59912985 - samples/sec: 74.85 - lr: 0.600000\n",
      "2022-08-31 00:04:07,987 epoch 10 - iter 99/111 - loss 0.60126071 - samples/sec: 78.63 - lr: 0.600000\n",
      "2022-08-31 00:04:12,589 epoch 10 - iter 110/111 - loss 0.59993299 - samples/sec: 72.72 - lr: 0.600000\n",
      "2022-08-31 00:04:13,034 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:04:13,034 EPOCH 10 done: loss 0.6000 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:04:14,022 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:04:14,054 DEV : loss 0.37902000546455383 - f1-score (micro avg)  0.8668\n",
      "2022-08-31 00:04:14,074 BAD EPOCHS (no improvement): 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:04:14,075 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:04:18,523 epoch 11 - iter 11/111 - loss 0.59180775 - samples/sec: 74.21 - lr: 0.600000\n",
      "2022-08-31 00:04:22,980 epoch 11 - iter 22/111 - loss 0.58813817 - samples/sec: 75.31 - lr: 0.600000\n",
      "2022-08-31 00:04:27,108 epoch 11 - iter 33/111 - loss 0.59805403 - samples/sec: 81.24 - lr: 0.600000\n",
      "2022-08-31 00:04:31,577 epoch 11 - iter 44/111 - loss 0.59591003 - samples/sec: 74.80 - lr: 0.600000\n",
      "2022-08-31 00:04:35,665 epoch 11 - iter 55/111 - loss 0.59914992 - samples/sec: 82.21 - lr: 0.600000\n",
      "2022-08-31 00:04:39,931 epoch 11 - iter 66/111 - loss 0.60378665 - samples/sec: 78.44 - lr: 0.600000\n",
      "2022-08-31 00:04:43,896 epoch 11 - iter 77/111 - loss 0.60551271 - samples/sec: 84.62 - lr: 0.600000\n",
      "2022-08-31 00:04:47,978 epoch 11 - iter 88/111 - loss 0.60420958 - samples/sec: 82.11 - lr: 0.600000\n",
      "2022-08-31 00:04:52,172 epoch 11 - iter 99/111 - loss 0.60379698 - samples/sec: 79.83 - lr: 0.600000\n",
      "2022-08-31 00:04:56,656 epoch 11 - iter 110/111 - loss 0.60431876 - samples/sec: 74.58 - lr: 0.600000\n",
      "2022-08-31 00:04:56,901 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:04:56,901 EPOCH 11 done: loss 0.6048 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:04:57,860 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:04:57,897 DEV : loss 0.37524157762527466 - f1-score (micro avg)  0.8626\n",
      "2022-08-31 00:04:57,912 Epoch    11: reducing learning rate of group 0 to 3.0000e-01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:04:57,913 BAD EPOCHS (no improvement): 4\n",
      "2022-08-31 00:04:57,914 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:05:02,167 epoch 12 - iter 11/111 - loss 0.58980053 - samples/sec: 77.65 - lr: 0.300000\n",
      "2022-08-31 00:05:06,384 epoch 12 - iter 22/111 - loss 0.58003681 - samples/sec: 79.46 - lr: 0.300000\n",
      "2022-08-31 00:05:10,805 epoch 12 - iter 33/111 - loss 0.56902307 - samples/sec: 76.04 - lr: 0.300000\n",
      "2022-08-31 00:05:15,035 epoch 12 - iter 44/111 - loss 0.57067366 - samples/sec: 79.08 - lr: 0.300000\n",
      "2022-08-31 00:05:19,184 epoch 12 - iter 55/111 - loss 0.57187778 - samples/sec: 80.80 - lr: 0.300000\n",
      "2022-08-31 00:05:23,776 epoch 12 - iter 66/111 - loss 0.57034636 - samples/sec: 73.01 - lr: 0.300000\n",
      "2022-08-31 00:05:28,094 epoch 12 - iter 77/111 - loss 0.57100019 - samples/sec: 77.59 - lr: 0.300000\n",
      "2022-08-31 00:05:32,421 epoch 12 - iter 88/111 - loss 0.57082219 - samples/sec: 77.45 - lr: 0.300000\n",
      "2022-08-31 00:05:36,609 epoch 12 - iter 99/111 - loss 0.57137646 - samples/sec: 80.16 - lr: 0.300000\n",
      "2022-08-31 00:05:41,005 epoch 12 - iter 110/111 - loss 0.56997397 - samples/sec: 76.27 - lr: 0.300000\n",
      "2022-08-31 00:05:41,437 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:05:41,437 EPOCH 12 done: loss 0.5698 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:05:42,351 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:05:42,385 DEV : loss 0.35166528820991516 - f1-score (micro avg)  0.8769\n",
      "2022-08-31 00:05:42,401 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:05:42,402 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:05:44,760 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:05:44,761 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-31 00:05:44,938 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:05:46,466 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:05:46,495 0.8837\t0.8837\t0.8837\t0.8837\n",
      "2022-08-31 00:05:46,495 \n",
      "Results:\n",
      "- F-score (micro) 0.8837\n",
      "- F-score (macro) 0.7714\n",
      "- Accuracy 0.8837\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8536    0.8707    0.8621      1353\n",
      "         ADJ     0.7941    0.8780    0.8339       672\n",
      "       PUNCT     0.9985    1.0000    0.9992       660\n",
      "         ADP     0.9862    0.9767    0.9814       514\n",
      "        VERB     0.7630    0.8820    0.8182       449\n",
      "       PROPN     0.7715    0.6084    0.6803       383\n",
      "         AUX     0.9850    0.9791    0.9820       335\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9946    0.9946    0.9946       184\n",
      "         ADV     0.7737    0.7020    0.7361       151\n",
      "         DET     0.9244    0.6832    0.7857       161\n",
      "        PRON     0.9815    0.9217    0.9507       115\n",
      "         NUM     0.9808    0.7183    0.8293        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8837      5264\n",
      "   macro avg     0.7998    0.7515    0.7714      5264\n",
      "weighted avg     0.8862    0.8837    0.8826      5264\n",
      "\n",
      "2022-08-31 00:05:46,496 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:05:46,498 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:05:46,995 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 6 #######################\n",
      "#######################################################\n",
      "2022-08-31 00:08:14,957 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:08:14,958 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-31 00:08:14,959 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:08:14,960 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-31 00:08:14,960 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:08:14,961 Parameters:\n",
      "2022-08-31 00:08:14,961  - learning_rate: \"0.600000\"\n",
      "2022-08-31 00:08:14,962  - mini_batch_size: \"50\"\n",
      "2022-08-31 00:08:14,962  - patience: \"3\"\n",
      "2022-08-31 00:08:14,963  - anneal_factor: \"0.5\"\n",
      "2022-08-31 00:08:14,963  - max_epochs: \"10\"\n",
      "2022-08-31 00:08:14,964  - shuffle: \"True\"\n",
      "2022-08-31 00:08:14,964  - train_with_dev: \"False\"\n",
      "2022-08-31 00:08:14,965  - batch_growth_annealing: \"False\"\n",
      "2022-08-31 00:08:14,965 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:08:14,966 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-31 00:08:14,967 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:08:14,967 Device: cpu\n",
      "2022-08-31 00:08:14,968 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:08:14,968 Embeddings storage mode: cpu\n",
      "2022-08-31 00:08:14,969 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:08:17,948 epoch 1 - iter 6/67 - loss 0.54291583 - samples/sec: 100.77 - lr: 0.600000\n",
      "2022-08-31 00:08:21,395 epoch 1 - iter 12/67 - loss 0.55314924 - samples/sec: 88.57 - lr: 0.600000\n",
      "2022-08-31 00:08:24,369 epoch 1 - iter 18/67 - loss 0.55972056 - samples/sec: 103.48 - lr: 0.600000\n",
      "2022-08-31 00:08:27,289 epoch 1 - iter 24/67 - loss 0.57084441 - samples/sec: 105.15 - lr: 0.600000\n",
      "2022-08-31 00:08:30,568 epoch 1 - iter 30/67 - loss 0.57495958 - samples/sec: 93.40 - lr: 0.600000\n",
      "2022-08-31 00:08:33,851 epoch 1 - iter 36/67 - loss 0.57635448 - samples/sec: 93.66 - lr: 0.600000\n",
      "2022-08-31 00:08:37,190 epoch 1 - iter 42/67 - loss 0.58044316 - samples/sec: 92.00 - lr: 0.600000\n",
      "2022-08-31 00:08:40,300 epoch 1 - iter 48/67 - loss 0.57835934 - samples/sec: 98.68 - lr: 0.600000\n",
      "2022-08-31 00:08:43,237 epoch 1 - iter 54/67 - loss 0.57668174 - samples/sec: 104.42 - lr: 0.600000\n",
      "2022-08-31 00:08:46,684 epoch 1 - iter 60/67 - loss 0.57887696 - samples/sec: 88.68 - lr: 0.600000\n",
      "2022-08-31 00:08:50,281 epoch 1 - iter 66/67 - loss 0.59158150 - samples/sec: 84.84 - lr: 0.600000\n",
      "2022-08-31 00:08:50,775 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:08:50,776 EPOCH 1 done: loss 0.5922 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:08:53,059 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:08:53,093 DEV : loss 0.3848608136177063 - f1-score (micro avg)  0.8671\n",
      "2022-08-31 00:08:53,111 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:08:53,112 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:08:53,958 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:08:57,414 epoch 2 - iter 6/67 - loss 0.59063121 - samples/sec: 86.86 - lr: 0.600000\n",
      "2022-08-31 00:09:00,476 epoch 2 - iter 12/67 - loss 0.59194172 - samples/sec: 101.08 - lr: 0.600000\n",
      "2022-08-31 00:09:03,604 epoch 2 - iter 18/67 - loss 0.59587418 - samples/sec: 98.65 - lr: 0.600000\n",
      "2022-08-31 00:09:07,215 epoch 2 - iter 24/67 - loss 0.60145005 - samples/sec: 84.77 - lr: 0.600000\n",
      "2022-08-31 00:09:10,426 epoch 2 - iter 30/67 - loss 0.59691936 - samples/sec: 95.24 - lr: 0.600000\n",
      "2022-08-31 00:09:13,567 epoch 2 - iter 36/67 - loss 0.59268032 - samples/sec: 97.72 - lr: 0.600000\n",
      "2022-08-31 00:09:16,579 epoch 2 - iter 42/67 - loss 0.59506742 - samples/sec: 101.83 - lr: 0.600000\n",
      "2022-08-31 00:09:20,072 epoch 2 - iter 48/67 - loss 0.59212477 - samples/sec: 87.46 - lr: 0.600000\n",
      "2022-08-31 00:09:23,375 epoch 2 - iter 54/67 - loss 0.59008302 - samples/sec: 92.54 - lr: 0.600000\n",
      "2022-08-31 00:09:26,427 epoch 2 - iter 60/67 - loss 0.59029896 - samples/sec: 101.21 - lr: 0.600000\n",
      "2022-08-31 00:09:29,852 epoch 2 - iter 66/67 - loss 0.59033629 - samples/sec: 89.47 - lr: 0.600000\n",
      "2022-08-31 00:09:30,242 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:09:30,243 EPOCH 2 done: loss 0.5911 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:09:31,148 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:09:31,178 DEV : loss 0.3617054522037506 - f1-score (micro avg)  0.8759\n",
      "2022-08-31 00:09:31,193 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:09:31,194 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:09:32,081 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:09:35,385 epoch 3 - iter 6/67 - loss 0.57207231 - samples/sec: 90.88 - lr: 0.600000\n",
      "2022-08-31 00:09:38,833 epoch 3 - iter 12/67 - loss 0.57406460 - samples/sec: 88.99 - lr: 0.600000\n",
      "2022-08-31 00:09:42,033 epoch 3 - iter 18/67 - loss 0.57583371 - samples/sec: 95.60 - lr: 0.600000\n",
      "2022-08-31 00:09:45,985 epoch 3 - iter 24/67 - loss 0.57935449 - samples/sec: 77.15 - lr: 0.600000\n",
      "2022-08-31 00:09:48,985 epoch 3 - iter 30/67 - loss 0.57656270 - samples/sec: 102.01 - lr: 0.600000\n",
      "2022-08-31 00:09:52,300 epoch 3 - iter 36/67 - loss 0.57571010 - samples/sec: 92.19 - lr: 0.600000\n",
      "2022-08-31 00:09:55,799 epoch 3 - iter 42/67 - loss 0.57559870 - samples/sec: 88.21 - lr: 0.600000\n",
      "2022-08-31 00:09:58,966 epoch 3 - iter 48/67 - loss 0.57891119 - samples/sec: 96.65 - lr: 0.600000\n",
      "2022-08-31 00:10:02,193 epoch 3 - iter 54/67 - loss 0.57662023 - samples/sec: 94.88 - lr: 0.600000\n",
      "2022-08-31 00:10:05,613 epoch 3 - iter 60/67 - loss 0.57800825 - samples/sec: 89.34 - lr: 0.600000\n",
      "2022-08-31 00:10:08,987 epoch 3 - iter 66/67 - loss 0.57905336 - samples/sec: 90.80 - lr: 0.600000\n",
      "2022-08-31 00:10:09,451 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:10:09,452 EPOCH 3 done: loss 0.5792 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:10:10,402 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:10:10,440 DEV : loss 0.3720141649246216 - f1-score (micro avg)  0.8674\n",
      "2022-08-31 00:10:10,460 BAD EPOCHS (no improvement): 1\n",
      "2022-08-31 00:10:10,461 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:10:14,030 epoch 4 - iter 6/67 - loss 0.59708500 - samples/sec: 84.10 - lr: 0.600000\n",
      "2022-08-31 00:10:17,394 epoch 4 - iter 12/67 - loss 0.58894410 - samples/sec: 90.83 - lr: 0.600000\n",
      "2022-08-31 00:10:20,940 epoch 4 - iter 18/67 - loss 0.57786015 - samples/sec: 86.71 - lr: 0.600000\n",
      "2022-08-31 00:10:24,340 epoch 4 - iter 24/67 - loss 0.57463517 - samples/sec: 89.96 - lr: 0.600000\n",
      "2022-08-31 00:10:27,599 epoch 4 - iter 30/67 - loss 0.57529253 - samples/sec: 95.00 - lr: 0.600000\n",
      "2022-08-31 00:10:31,258 epoch 4 - iter 36/67 - loss 0.57940323 - samples/sec: 83.52 - lr: 0.600000\n",
      "2022-08-31 00:10:34,586 epoch 4 - iter 42/67 - loss 0.58742372 - samples/sec: 91.83 - lr: 0.600000\n",
      "2022-08-31 00:10:37,928 epoch 4 - iter 48/67 - loss 0.58686493 - samples/sec: 91.97 - lr: 0.600000\n",
      "2022-08-31 00:10:41,673 epoch 4 - iter 54/67 - loss 0.58845693 - samples/sec: 81.63 - lr: 0.600000\n",
      "2022-08-31 00:10:45,286 epoch 4 - iter 60/67 - loss 0.58711886 - samples/sec: 84.65 - lr: 0.600000\n",
      "2022-08-31 00:10:48,623 epoch 4 - iter 66/67 - loss 0.58486935 - samples/sec: 91.66 - lr: 0.600000\n",
      "2022-08-31 00:10:49,211 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:10:49,212 EPOCH 4 done: loss 0.5858 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:10:50,172 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:10:50,205 DEV : loss 0.3576456308364868 - f1-score (micro avg)  0.8715\n",
      "2022-08-31 00:10:50,223 BAD EPOCHS (no improvement): 2\n",
      "2022-08-31 00:10:50,224 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:10:53,648 epoch 5 - iter 6/67 - loss 0.57462255 - samples/sec: 87.64 - lr: 0.600000\n",
      "2022-08-31 00:10:57,197 epoch 5 - iter 12/67 - loss 0.56916769 - samples/sec: 86.24 - lr: 0.600000\n",
      "2022-08-31 00:11:00,588 epoch 5 - iter 18/67 - loss 0.57793766 - samples/sec: 90.12 - lr: 0.600000\n",
      "2022-08-31 00:11:03,910 epoch 5 - iter 24/67 - loss 0.57864271 - samples/sec: 92.33 - lr: 0.600000\n",
      "2022-08-31 00:11:07,257 epoch 5 - iter 30/67 - loss 0.57515948 - samples/sec: 91.38 - lr: 0.600000\n",
      "2022-08-31 00:11:10,471 epoch 5 - iter 36/67 - loss 0.57730725 - samples/sec: 95.21 - lr: 0.600000\n",
      "2022-08-31 00:11:13,806 epoch 5 - iter 42/67 - loss 0.57769561 - samples/sec: 91.80 - lr: 0.600000\n",
      "2022-08-31 00:11:16,993 epoch 5 - iter 48/67 - loss 0.57656695 - samples/sec: 95.89 - lr: 0.600000\n",
      "2022-08-31 00:11:19,918 epoch 5 - iter 54/67 - loss 0.57715381 - samples/sec: 104.60 - lr: 0.600000\n",
      "2022-08-31 00:11:23,261 epoch 5 - iter 60/67 - loss 0.57714879 - samples/sec: 91.41 - lr: 0.600000\n",
      "2022-08-31 00:11:26,631 epoch 5 - iter 66/67 - loss 0.57559051 - samples/sec: 90.71 - lr: 0.600000\n",
      "2022-08-31 00:11:27,079 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:11:27,080 EPOCH 5 done: loss 0.5758 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:11:28,038 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:11:28,072 DEV : loss 0.37016913294792175 - f1-score (micro avg)  0.871\n",
      "2022-08-31 00:11:28,088 BAD EPOCHS (no improvement): 3\n",
      "2022-08-31 00:11:28,089 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:11:31,369 epoch 6 - iter 6/67 - loss 0.58250138 - samples/sec: 91.52 - lr: 0.600000\n",
      "2022-08-31 00:11:34,639 epoch 6 - iter 12/67 - loss 0.57660457 - samples/sec: 94.19 - lr: 0.600000\n",
      "2022-08-31 00:11:38,088 epoch 6 - iter 18/67 - loss 0.58159104 - samples/sec: 88.57 - lr: 0.600000\n",
      "2022-08-31 00:11:41,835 epoch 6 - iter 24/67 - loss 0.58296261 - samples/sec: 81.43 - lr: 0.600000\n",
      "2022-08-31 00:11:44,968 epoch 6 - iter 30/67 - loss 0.58011472 - samples/sec: 98.26 - lr: 0.600000\n",
      "2022-08-31 00:11:48,068 epoch 6 - iter 36/67 - loss 0.58007349 - samples/sec: 98.76 - lr: 0.600000\n",
      "2022-08-31 00:11:51,117 epoch 6 - iter 42/67 - loss 0.57531827 - samples/sec: 100.63 - lr: 0.600000\n",
      "2022-08-31 00:11:54,771 epoch 6 - iter 48/67 - loss 0.57548283 - samples/sec: 83.53 - lr: 0.600000\n",
      "2022-08-31 00:11:57,992 epoch 6 - iter 54/67 - loss 0.57884892 - samples/sec: 95.06 - lr: 0.600000\n",
      "2022-08-31 00:12:01,073 epoch 6 - iter 60/67 - loss 0.58067262 - samples/sec: 99.30 - lr: 0.600000\n",
      "2022-08-31 00:12:04,255 epoch 6 - iter 66/67 - loss 0.58331646 - samples/sec: 96.15 - lr: 0.600000\n",
      "2022-08-31 00:12:04,653 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:12:04,653 EPOCH 6 done: loss 0.5829 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:12:05,554 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:12:05,588 DEV : loss 0.3870718777179718 - f1-score (micro avg)  0.8632\n",
      "2022-08-31 00:12:05,603 Epoch     6: reducing learning rate of group 0 to 3.0000e-01.\n",
      "2022-08-31 00:12:05,604 BAD EPOCHS (no improvement): 4\n",
      "2022-08-31 00:12:05,605 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:12:08,911 epoch 7 - iter 6/67 - loss 0.57265057 - samples/sec: 90.79 - lr: 0.300000\n",
      "2022-08-31 00:12:12,046 epoch 7 - iter 12/67 - loss 0.55821138 - samples/sec: 97.76 - lr: 0.300000\n",
      "2022-08-31 00:12:15,052 epoch 7 - iter 18/67 - loss 0.54140346 - samples/sec: 102.00 - lr: 0.300000\n",
      "2022-08-31 00:12:18,481 epoch 7 - iter 24/67 - loss 0.54631569 - samples/sec: 89.13 - lr: 0.300000\n",
      "2022-08-31 00:12:21,595 epoch 7 - iter 30/67 - loss 0.54539451 - samples/sec: 98.30 - lr: 0.300000\n",
      "2022-08-31 00:12:25,052 epoch 7 - iter 36/67 - loss 0.54288571 - samples/sec: 88.68 - lr: 0.300000\n",
      "2022-08-31 00:12:28,452 epoch 7 - iter 42/67 - loss 0.54670130 - samples/sec: 89.82 - lr: 0.300000\n",
      "2022-08-31 00:12:31,620 epoch 7 - iter 48/67 - loss 0.54741954 - samples/sec: 96.74 - lr: 0.300000\n",
      "2022-08-31 00:12:35,031 epoch 7 - iter 54/67 - loss 0.54463614 - samples/sec: 89.66 - lr: 0.300000\n",
      "2022-08-31 00:12:38,135 epoch 7 - iter 60/67 - loss 0.54726290 - samples/sec: 98.61 - lr: 0.300000\n",
      "2022-08-31 00:12:41,403 epoch 7 - iter 66/67 - loss 0.54616223 - samples/sec: 93.55 - lr: 0.300000\n",
      "2022-08-31 00:12:41,852 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:12:41,853 EPOCH 7 done: loss 0.5460 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:12:42,749 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:12:42,779 DEV : loss 0.32871147990226746 - f1-score (micro avg)  0.8817\n",
      "2022-08-31 00:12:42,799 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:12:42,800 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:12:43,713 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:12:46,971 epoch 8 - iter 6/67 - loss 0.56057297 - samples/sec: 92.17 - lr: 0.300000\n",
      "2022-08-31 00:12:50,583 epoch 8 - iter 12/67 - loss 0.55629035 - samples/sec: 84.44 - lr: 0.300000\n",
      "2022-08-31 00:12:53,941 epoch 8 - iter 18/67 - loss 0.55067801 - samples/sec: 91.35 - lr: 0.300000\n",
      "2022-08-31 00:12:57,125 epoch 8 - iter 24/67 - loss 0.54425114 - samples/sec: 96.11 - lr: 0.300000\n",
      "2022-08-31 00:13:00,436 epoch 8 - iter 30/67 - loss 0.54086711 - samples/sec: 92.32 - lr: 0.300000\n",
      "2022-08-31 00:13:04,000 epoch 8 - iter 36/67 - loss 0.54217985 - samples/sec: 86.23 - lr: 0.300000\n",
      "2022-08-31 00:13:07,321 epoch 8 - iter 42/67 - loss 0.54003979 - samples/sec: 91.97 - lr: 0.300000\n",
      "2022-08-31 00:13:10,553 epoch 8 - iter 48/67 - loss 0.53737126 - samples/sec: 95.54 - lr: 0.300000\n",
      "2022-08-31 00:13:13,338 epoch 8 - iter 54/67 - loss 0.53908943 - samples/sec: 110.21 - lr: 0.300000\n",
      "2022-08-31 00:13:16,459 epoch 8 - iter 60/67 - loss 0.53826306 - samples/sec: 99.20 - lr: 0.300000\n",
      "2022-08-31 00:13:20,035 epoch 8 - iter 66/67 - loss 0.53813134 - samples/sec: 85.40 - lr: 0.300000\n",
      "2022-08-31 00:13:20,421 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:13:20,423 EPOCH 8 done: loss 0.5382 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:13:21,379 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:13:21,411 DEV : loss 0.3352877199649811 - f1-score (micro avg)  0.8834\n",
      "2022-08-31 00:13:21,428 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:13:21,429 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:13:22,559 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:13:25,680 epoch 9 - iter 6/67 - loss 0.54765805 - samples/sec: 96.15 - lr: 0.300000\n",
      "2022-08-31 00:13:28,953 epoch 9 - iter 12/67 - loss 0.55266843 - samples/sec: 93.51 - lr: 0.300000\n",
      "2022-08-31 00:13:32,128 epoch 9 - iter 18/67 - loss 0.54421691 - samples/sec: 96.28 - lr: 0.300000\n",
      "2022-08-31 00:13:35,148 epoch 9 - iter 24/67 - loss 0.54535632 - samples/sec: 101.59 - lr: 0.300000\n",
      "2022-08-31 00:13:38,572 epoch 9 - iter 30/67 - loss 0.54199134 - samples/sec: 89.07 - lr: 0.300000\n",
      "2022-08-31 00:13:41,865 epoch 9 - iter 36/67 - loss 0.54121649 - samples/sec: 93.14 - lr: 0.300000\n",
      "2022-08-31 00:13:45,083 epoch 9 - iter 42/67 - loss 0.53866450 - samples/sec: 95.30 - lr: 0.300000\n",
      "2022-08-31 00:13:48,424 epoch 9 - iter 48/67 - loss 0.53703588 - samples/sec: 91.63 - lr: 0.300000\n",
      "2022-08-31 00:13:51,603 epoch 9 - iter 54/67 - loss 0.53788615 - samples/sec: 96.91 - lr: 0.300000\n",
      "2022-08-31 00:13:54,913 epoch 9 - iter 60/67 - loss 0.53809007 - samples/sec: 92.39 - lr: 0.300000\n",
      "2022-08-31 00:13:58,767 epoch 9 - iter 66/67 - loss 0.54024400 - samples/sec: 79.04 - lr: 0.300000\n",
      "2022-08-31 00:13:59,169 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:13:59,170 EPOCH 9 done: loss 0.5402 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:14:00,103 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:14:00,142 DEV : loss 0.344258189201355 - f1-score (micro avg)  0.879\n",
      "2022-08-31 00:14:00,161 BAD EPOCHS (no improvement): 1\n",
      "2022-08-31 00:14:00,162 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:14:03,699 epoch 10 - iter 6/67 - loss 0.54535711 - samples/sec: 84.87 - lr: 0.300000\n",
      "2022-08-31 00:14:07,429 epoch 10 - iter 12/67 - loss 0.54160515 - samples/sec: 81.86 - lr: 0.300000\n",
      "2022-08-31 00:14:10,654 epoch 10 - iter 18/67 - loss 0.53799812 - samples/sec: 95.12 - lr: 0.300000\n",
      "2022-08-31 00:14:13,808 epoch 10 - iter 24/67 - loss 0.53314701 - samples/sec: 97.21 - lr: 0.300000\n",
      "2022-08-31 00:14:16,972 epoch 10 - iter 30/67 - loss 0.53416112 - samples/sec: 96.53 - lr: 0.300000\n",
      "2022-08-31 00:14:20,163 epoch 10 - iter 36/67 - loss 0.52924686 - samples/sec: 95.94 - lr: 0.300000\n",
      "2022-08-31 00:14:23,398 epoch 10 - iter 42/67 - loss 0.52923587 - samples/sec: 94.52 - lr: 0.300000\n",
      "2022-08-31 00:14:26,711 epoch 10 - iter 48/67 - loss 0.53146318 - samples/sec: 92.48 - lr: 0.300000\n",
      "2022-08-31 00:14:29,705 epoch 10 - iter 54/67 - loss 0.53225201 - samples/sec: 102.50 - lr: 0.300000\n",
      "2022-08-31 00:14:33,001 epoch 10 - iter 60/67 - loss 0.53378099 - samples/sec: 92.75 - lr: 0.300000\n",
      "2022-08-31 00:14:36,738 epoch 10 - iter 66/67 - loss 0.53346390 - samples/sec: 81.70 - lr: 0.300000\n",
      "2022-08-31 00:14:37,122 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:14:37,123 EPOCH 10 done: loss 0.5331 - lr 0.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:14:38,051 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:14:38,081 DEV : loss 0.3357833921909332 - f1-score (micro avg)  0.885\n",
      "2022-08-31 00:14:38,101 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:14:38,103 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:14:39,647 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:14:39,648 loading file resources\\taggers\\language_model_testing\\best-model.pt\n",
      "2022-08-31 00:14:39,848 SequenceTagger predicts: Dictionary with 20 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, SCONJ, ADV, CCONJ, PRON, NUM, PART, X, INTJ, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:14:41,333 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:14:41,365 0.894\t0.894\t0.894\t0.894\n",
      "2022-08-31 00:14:41,366 \n",
      "Results:\n",
      "- F-score (micro) 0.894\n",
      "- F-score (macro) 0.8414\n",
      "- Accuracy 0.894\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN     0.8355    0.9120    0.8721      1353\n",
      "         ADJ     0.8156    0.8884    0.8504       672\n",
      "       PUNCT     1.0000    1.0000    1.0000       660\n",
      "         ADP     0.9920    0.9708    0.9813       514\n",
      "        VERB     0.8407    0.8463    0.8435       449\n",
      "         AUX     0.9909    0.9791    0.9850       335\n",
      "       PROPN     0.8214    0.6005    0.6938       383\n",
      "       CCONJ     0.9897    1.0000    0.9948       192\n",
      "       SCONJ     0.9892    0.9946    0.9919       184\n",
      "         DET     0.9154    0.7391    0.8179       161\n",
      "         ADV     0.7899    0.7219    0.7543       151\n",
      "        PRON     1.0000    0.9217    0.9593       115\n",
      "         NUM     0.9623    0.7183    0.8226        71\n",
      "        PART     1.0000    0.8095    0.8947        21\n",
      "           X     0.0000    0.0000    0.0000         2\n",
      "         SYM     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.8940      5264\n",
      "   macro avg     0.8714    0.8189    0.8414      5264\n",
      "weighted avg     0.8960    0.8940    0.8924      5264\n",
      "\n",
      "2022-08-31 00:14:41,367 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:14:41,369 loading file resources/taggers/optimized-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:14:41,865 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, PUNCT, ADJ, ADP, VERB, PROPN, AUX, DET, ADV, CCONJ, SCONJ, PRON, NUM, PART, X, INTJ, <START>, <STOP>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################################\n",
      "################ MODEL NUMBER 7 #######################\n",
      "#######################################################\n",
      "2022-08-31 00:17:14,704 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:17:14,705 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(91, 100)\n",
      "        (rnn): LSTM(100, 128)\n",
      "        (decoder): Linear(in_features=128, out_features=91, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=228, out_features=228, bias=True)\n",
      "  (rnn): LSTM(228, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-08-31 00:17:14,705 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:17:14,706 Corpus: \"Corpus: 3328 train + 274 dev + 247 test sentences\"\n",
      "2022-08-31 00:17:14,706 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:17:14,708 Parameters:\n",
      "2022-08-31 00:17:14,708  - learning_rate: \"0.600000\"\n",
      "2022-08-31 00:17:14,709  - mini_batch_size: \"50\"\n",
      "2022-08-31 00:17:14,709  - patience: \"3\"\n",
      "2022-08-31 00:17:14,710  - anneal_factor: \"0.5\"\n",
      "2022-08-31 00:17:14,711  - max_epochs: \"11\"\n",
      "2022-08-31 00:17:14,711  - shuffle: \"True\"\n",
      "2022-08-31 00:17:14,712  - train_with_dev: \"False\"\n",
      "2022-08-31 00:17:14,713  - batch_growth_annealing: \"False\"\n",
      "2022-08-31 00:17:14,714 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:17:14,714 Model training base path: \"resources\\taggers\\language_model_testing\"\n",
      "2022-08-31 00:17:14,715 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:17:14,715 Device: cpu\n",
      "2022-08-31 00:17:14,716 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:17:14,716 Embeddings storage mode: cpu\n",
      "2022-08-31 00:17:14,717 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vladimir\\anaconda3\\envs\\ML3\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:17:17,771 epoch 1 - iter 6/67 - loss 0.49369105 - samples/sec: 98.26 - lr: 0.600000\n",
      "2022-08-31 00:17:21,264 epoch 1 - iter 12/67 - loss 0.52893804 - samples/sec: 87.36 - lr: 0.600000\n",
      "2022-08-31 00:17:24,289 epoch 1 - iter 18/67 - loss 0.54003084 - samples/sec: 101.32 - lr: 0.600000\n",
      "2022-08-31 00:17:27,307 epoch 1 - iter 24/67 - loss 0.54485512 - samples/sec: 101.59 - lr: 0.600000\n",
      "2022-08-31 00:17:30,503 epoch 1 - iter 30/67 - loss 0.55125820 - samples/sec: 95.54 - lr: 0.600000\n",
      "2022-08-31 00:17:33,812 epoch 1 - iter 36/67 - loss 0.55423858 - samples/sec: 92.62 - lr: 0.600000\n",
      "2022-08-31 00:17:36,909 epoch 1 - iter 42/67 - loss 0.55556973 - samples/sec: 98.81 - lr: 0.600000\n",
      "2022-08-31 00:17:39,877 epoch 1 - iter 48/67 - loss 0.55704942 - samples/sec: 103.38 - lr: 0.600000\n",
      "2022-08-31 00:17:42,789 epoch 1 - iter 54/67 - loss 0.55734068 - samples/sec: 105.08 - lr: 0.600000\n",
      "2022-08-31 00:17:46,063 epoch 1 - iter 60/67 - loss 0.56075805 - samples/sec: 93.57 - lr: 0.600000\n",
      "2022-08-31 00:17:49,617 epoch 1 - iter 66/67 - loss 0.57295015 - samples/sec: 85.71 - lr: 0.600000\n",
      "2022-08-31 00:17:50,071 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:17:50,072 EPOCH 1 done: loss 0.5735 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:17:51,050 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:17:51,084 DEV : loss 0.37817034125328064 - f1-score (micro avg)  0.8689\n",
      "2022-08-31 00:17:51,101 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:17:51,102 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:17:51,806 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:17:54,791 epoch 2 - iter 6/67 - loss 0.57800426 - samples/sec: 100.54 - lr: 0.600000\n",
      "2022-08-31 00:17:57,982 epoch 2 - iter 12/67 - loss 0.56464822 - samples/sec: 95.79 - lr: 0.600000\n",
      "2022-08-31 00:18:01,865 epoch 2 - iter 18/67 - loss 0.56267722 - samples/sec: 78.60 - lr: 0.600000\n",
      "2022-08-31 00:18:05,352 epoch 2 - iter 24/67 - loss 0.56806344 - samples/sec: 87.54 - lr: 0.600000\n",
      "2022-08-31 00:18:08,864 epoch 2 - iter 30/67 - loss 0.56631333 - samples/sec: 88.34 - lr: 0.600000\n",
      "2022-08-31 00:18:11,846 epoch 2 - iter 36/67 - loss 0.56940335 - samples/sec: 102.77 - lr: 0.600000\n",
      "2022-08-31 00:18:15,500 epoch 2 - iter 42/67 - loss 0.56906964 - samples/sec: 83.61 - lr: 0.600000\n",
      "2022-08-31 00:18:18,727 epoch 2 - iter 48/67 - loss 0.56849163 - samples/sec: 95.15 - lr: 0.600000\n",
      "2022-08-31 00:18:21,931 epoch 2 - iter 54/67 - loss 0.57085735 - samples/sec: 95.36 - lr: 0.600000\n",
      "2022-08-31 00:18:24,850 epoch 2 - iter 60/67 - loss 0.57097673 - samples/sec: 105.34 - lr: 0.600000\n",
      "2022-08-31 00:18:27,941 epoch 2 - iter 66/67 - loss 0.56865159 - samples/sec: 99.04 - lr: 0.600000\n",
      "2022-08-31 00:18:28,391 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:18:28,392 EPOCH 2 done: loss 0.5688 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:18:29,273 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:18:29,304 DEV : loss 0.3577801585197449 - f1-score (micro avg)  0.8668\n",
      "2022-08-31 00:18:29,320 BAD EPOCHS (no improvement): 1\n",
      "2022-08-31 00:18:29,321 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:18:32,533 epoch 3 - iter 6/67 - loss 0.58682204 - samples/sec: 93.43 - lr: 0.600000\n",
      "2022-08-31 00:18:35,760 epoch 3 - iter 12/67 - loss 0.57439433 - samples/sec: 94.76 - lr: 0.600000\n",
      "2022-08-31 00:18:38,894 epoch 3 - iter 18/67 - loss 0.56741772 - samples/sec: 97.66 - lr: 0.600000\n",
      "2022-08-31 00:18:42,399 epoch 3 - iter 24/67 - loss 0.56814182 - samples/sec: 87.29 - lr: 0.600000\n",
      "2022-08-31 00:18:45,662 epoch 3 - iter 30/67 - loss 0.57040045 - samples/sec: 93.72 - lr: 0.600000\n",
      "2022-08-31 00:18:48,657 epoch 3 - iter 36/67 - loss 0.56630944 - samples/sec: 102.35 - lr: 0.600000\n",
      "2022-08-31 00:18:51,799 epoch 3 - iter 42/67 - loss 0.56879089 - samples/sec: 97.66 - lr: 0.600000\n",
      "2022-08-31 00:18:55,221 epoch 3 - iter 48/67 - loss 0.56648642 - samples/sec: 89.37 - lr: 0.600000\n",
      "2022-08-31 00:18:58,716 epoch 3 - iter 54/67 - loss 0.56384645 - samples/sec: 87.26 - lr: 0.600000\n",
      "2022-08-31 00:19:01,723 epoch 3 - iter 60/67 - loss 0.56690413 - samples/sec: 101.76 - lr: 0.600000\n",
      "2022-08-31 00:19:05,558 epoch 3 - iter 66/67 - loss 0.56976030 - samples/sec: 79.43 - lr: 0.600000\n",
      "2022-08-31 00:19:05,952 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:19:05,953 EPOCH 3 done: loss 0.5704 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:19:06,878 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:19:06,911 DEV : loss 0.36322659254074097 - f1-score (micro avg)  0.8733\n",
      "2022-08-31 00:19:06,929 BAD EPOCHS (no improvement): 0\n",
      "2022-08-31 00:19:06,930 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:19:07,700 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:19:10,768 epoch 4 - iter 6/67 - loss 0.55823734 - samples/sec: 97.88 - lr: 0.600000\n",
      "2022-08-31 00:19:13,903 epoch 4 - iter 12/67 - loss 0.55196272 - samples/sec: 97.53 - lr: 0.600000\n",
      "2022-08-31 00:19:17,321 epoch 4 - iter 18/67 - loss 0.56743029 - samples/sec: 89.31 - lr: 0.600000\n",
      "2022-08-31 00:19:20,920 epoch 4 - iter 24/67 - loss 0.57092301 - samples/sec: 85.69 - lr: 0.600000\n",
      "2022-08-31 00:19:24,470 epoch 4 - iter 30/67 - loss 0.57180092 - samples/sec: 86.06 - lr: 0.600000\n",
      "2022-08-31 00:19:27,507 epoch 4 - iter 36/67 - loss 0.57868739 - samples/sec: 101.49 - lr: 0.600000\n",
      "2022-08-31 00:19:31,287 epoch 4 - iter 42/67 - loss 0.57715406 - samples/sec: 81.41 - lr: 0.600000\n",
      "2022-08-31 00:19:34,612 epoch 4 - iter 48/67 - loss 0.57260808 - samples/sec: 91.94 - lr: 0.600000\n",
      "2022-08-31 00:19:38,010 epoch 4 - iter 54/67 - loss 0.57280043 - samples/sec: 90.17 - lr: 0.600000\n",
      "2022-08-31 00:19:41,257 epoch 4 - iter 60/67 - loss 0.57346805 - samples/sec: 94.34 - lr: 0.600000\n",
      "2022-08-31 00:19:44,627 epoch 4 - iter 66/67 - loss 0.57693725 - samples/sec: 90.72 - lr: 0.600000\n",
      "2022-08-31 00:19:45,042 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:19:45,043 EPOCH 4 done: loss 0.5775 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:19:46,024 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:19:46,061 DEV : loss 0.3649124205112457 - f1-score (micro avg)  0.8679\n",
      "2022-08-31 00:19:46,081 BAD EPOCHS (no improvement): 1\n",
      "2022-08-31 00:19:46,083 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:19:49,449 epoch 5 - iter 6/67 - loss 0.58328921 - samples/sec: 89.15 - lr: 0.600000\n",
      "2022-08-31 00:19:53,401 epoch 5 - iter 12/67 - loss 0.58341427 - samples/sec: 77.78 - lr: 0.600000\n",
      "2022-08-31 00:19:56,816 epoch 5 - iter 18/67 - loss 0.58213526 - samples/sec: 90.01 - lr: 0.600000\n",
      "2022-08-31 00:19:59,750 epoch 5 - iter 24/67 - loss 0.58104237 - samples/sec: 104.68 - lr: 0.600000\n",
      "2022-08-31 00:20:02,908 epoch 5 - iter 30/67 - loss 0.57886645 - samples/sec: 96.99 - lr: 0.600000\n",
      "2022-08-31 00:20:06,171 epoch 5 - iter 36/67 - loss 0.57692969 - samples/sec: 93.69 - lr: 0.600000\n",
      "2022-08-31 00:20:09,624 epoch 5 - iter 42/67 - loss 0.57226554 - samples/sec: 88.52 - lr: 0.600000\n",
      "2022-08-31 00:20:12,701 epoch 5 - iter 48/67 - loss 0.57213295 - samples/sec: 99.44 - lr: 0.600000\n",
      "2022-08-31 00:20:16,070 epoch 5 - iter 54/67 - loss 0.57066936 - samples/sec: 90.72 - lr: 0.600000\n",
      "2022-08-31 00:20:19,441 epoch 5 - iter 60/67 - loss 0.56834640 - samples/sec: 90.94 - lr: 0.600000\n",
      "2022-08-31 00:20:22,726 epoch 5 - iter 66/67 - loss 0.56800576 - samples/sec: 93.72 - lr: 0.600000\n",
      "2022-08-31 00:20:23,158 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:20:23,159 EPOCH 5 done: loss 0.5684 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:20:24,084 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:20:24,111 DEV : loss 0.3546248972415924 - f1-score (micro avg)  0.8705\n",
      "2022-08-31 00:20:24,132 BAD EPOCHS (no improvement): 2\n",
      "2022-08-31 00:20:24,133 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:20:27,040 epoch 6 - iter 6/67 - loss 0.59160487 - samples/sec: 103.23 - lr: 0.600000\n",
      "2022-08-31 00:20:30,125 epoch 6 - iter 12/67 - loss 0.58060023 - samples/sec: 99.21 - lr: 0.600000\n",
      "2022-08-31 00:20:33,657 epoch 6 - iter 18/67 - loss 0.57690947 - samples/sec: 86.53 - lr: 0.600000\n",
      "2022-08-31 00:20:36,919 epoch 6 - iter 24/67 - loss 0.58097784 - samples/sec: 93.66 - lr: 0.600000\n",
      "2022-08-31 00:20:40,038 epoch 6 - iter 30/67 - loss 0.57612271 - samples/sec: 98.14 - lr: 0.600000\n",
      "2022-08-31 00:20:43,428 epoch 6 - iter 36/67 - loss 0.57691989 - samples/sec: 90.20 - lr: 0.600000\n",
      "2022-08-31 00:20:47,122 epoch 6 - iter 42/67 - loss 0.57099050 - samples/sec: 82.69 - lr: 0.600000\n",
      "2022-08-31 00:20:50,546 epoch 6 - iter 48/67 - loss 0.57091592 - samples/sec: 89.29 - lr: 0.600000\n",
      "2022-08-31 00:20:53,766 epoch 6 - iter 54/67 - loss 0.56997360 - samples/sec: 95.00 - lr: 0.600000\n",
      "2022-08-31 00:20:56,999 epoch 6 - iter 60/67 - loss 0.56909756 - samples/sec: 94.67 - lr: 0.600000\n",
      "2022-08-31 00:21:00,209 epoch 6 - iter 66/67 - loss 0.56760942 - samples/sec: 95.18 - lr: 0.600000\n",
      "2022-08-31 00:21:00,864 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:21:00,865 EPOCH 6 done: loss 0.5681 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:21:01,795 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:21:01,829 DEV : loss 0.38438165187835693 - f1-score (micro avg)  0.864\n",
      "2022-08-31 00:21:01,847 BAD EPOCHS (no improvement): 3\n",
      "2022-08-31 00:21:01,848 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:21:05,041 epoch 7 - iter 6/67 - loss 0.57476657 - samples/sec: 93.99 - lr: 0.600000\n",
      "2022-08-31 00:21:08,447 epoch 7 - iter 12/67 - loss 0.57905932 - samples/sec: 89.63 - lr: 0.600000\n",
      "2022-08-31 00:21:11,811 epoch 7 - iter 18/67 - loss 0.57191022 - samples/sec: 90.99 - lr: 0.600000\n",
      "2022-08-31 00:21:14,883 epoch 7 - iter 24/67 - loss 0.57047345 - samples/sec: 99.63 - lr: 0.600000\n",
      "2022-08-31 00:21:18,074 epoch 7 - iter 30/67 - loss 0.56838901 - samples/sec: 95.88 - lr: 0.600000\n",
      "2022-08-31 00:21:21,125 epoch 7 - iter 36/67 - loss 0.56906419 - samples/sec: 100.30 - lr: 0.600000\n",
      "2022-08-31 00:21:24,223 epoch 7 - iter 42/67 - loss 0.57109135 - samples/sec: 98.81 - lr: 0.600000\n",
      "2022-08-31 00:21:27,683 epoch 7 - iter 48/67 - loss 0.56825945 - samples/sec: 88.18 - lr: 0.600000\n",
      "2022-08-31 00:21:30,956 epoch 7 - iter 54/67 - loss 0.56886531 - samples/sec: 93.23 - lr: 0.600000\n",
      "2022-08-31 00:21:34,226 epoch 7 - iter 60/67 - loss 0.56999744 - samples/sec: 93.57 - lr: 0.600000\n",
      "2022-08-31 00:21:37,661 epoch 7 - iter 66/67 - loss 0.56725786 - samples/sec: 88.86 - lr: 0.600000\n",
      "2022-08-31 00:21:38,033 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-31 00:21:38,034 EPOCH 7 done: loss 0.5669 - lr 0.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:21:38,962 Evaluating as a multi-label problem: False\n",
      "2022-08-31 00:21:38,995 DEV : loss 0.3661198019981384 - f1-score (micro avg)  0.8717\n",
      "2022-08-31 00:21:39,011 Epoch     7: reducing learning rate of group 0 to 3.0000e-01.\n",
      "2022-08-31 00:21:39,012 BAD EPOCHS (no improvement): 4\n",
      "2022-08-31 00:21:39,013 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 00:21:42,296 epoch 8 - iter 6/67 - loss 0.56305297 - samples/sec: 91.44 - lr: 0.300000\n",
      "2022-08-31 00:21:45,635 epoch 8 - iter 12/67 - loss 0.55491812 - samples/sec: 91.52 - lr: 0.300000\n",
      "2022-08-31 00:21:48,862 epoch 8 - iter 18/67 - loss 0.54469057 - samples/sec: 94.88 - lr: 0.300000\n",
      "2022-08-31 00:21:52,094 epoch 8 - iter 24/67 - loss 0.54422080 - samples/sec: 94.79 - lr: 0.300000\n",
      "2022-08-31 00:21:55,536 epoch 8 - iter 30/67 - loss 0.54466601 - samples/sec: 88.99 - lr: 0.300000\n",
      "2022-08-31 00:21:58,951 epoch 8 - iter 36/67 - loss 0.53967275 - samples/sec: 89.71 - lr: 0.300000\n",
      "2022-08-31 00:22:02,536 epoch 8 - iter 42/67 - loss 0.53730791 - samples/sec: 85.06 - lr: 0.300000\n",
      "2022-08-31 00:22:05,894 epoch 8 - iter 48/67 - loss 0.54140711 - samples/sec: 91.24 - lr: 0.300000\n",
      "2022-08-31 00:22:09,299 epoch 8 - iter 54/67 - loss 0.54125719 - samples/sec: 89.69 - lr: 0.300000\n"
     ]
    }
   ],
   "source": [
    "for i,lr in enumerate(param_learning_rates):\n",
    "    for j,mbs in enumerate(param_mini_batch_sizes):\n",
    "        for k,me in enumerate(max_epochs):\n",
    "                print('\\n\\n\\n')\n",
    "                print(\"#######################################################\")\n",
    "                print(f\"################ MODEL NUMBER {i}, {j}, {k} #######################\")\n",
    "                print(\"#######################################################\")\n",
    "                trainer.train('resources/taggers/language_model_testing',\n",
    "                              learning_rate=lr,\n",
    "                              mini_batch_size=int(mbs),\n",
    "                              max_epochs=int(me),\n",
    "                              write_weights = True)\n",
    "                model = SequenceTagger.load('resources/taggers/optimized-upos/final-model.pt')\n",
    "                actual= np.array([])\n",
    "                predicted = np.array([])\n",
    "\n",
    "                # Validiramo na drugoj \"polovini\" validacionog skupa/corpusa\n",
    "                # (onoj koja nije prosledjena ranijem traineru)\n",
    "                for actualSentence in corpus2.dev:\n",
    "\n",
    "                    for token in actualSentence:\n",
    "                        actual = np.append(actual, token.get_label('upos').value)\n",
    "\n",
    "                    predictedSentence = Sentence([token.text for token in actualSentence.tokens])\n",
    "                    model.predict(predictedSentence)\n",
    "                    for token in predictedSentence:\n",
    "                        predictedLabels = token.get_labels('upos')\n",
    "                        for predictedLabel in predictedLabels:\n",
    "                            predicted = np.append(predicted, predictedLabel.value)\n",
    "                score = metrics.accuracy_score(actual,predicted)\n",
    "\n",
    "                if score>best_score:\n",
    "                    best_params['learning_rate'] = lr\n",
    "                    best_params['param_mini_batch_sizes'] = mbs\n",
    "                    best_params['max_epochs'] = me\n",
    "\n",
    "                report = metrics.classification_report(actual,predicted)\n",
    "                params = {'learning_rate': lr, 'param_mini_batch_sizes': mbs,\n",
    "                          'max_epochs': me}\n",
    "                model_history.append({'params':params,'report':report})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Treniranje modela koji ima optimalne vrednosti hiperparametara\n",
    "trainer.train('resources/taggers/language_model_testing',\n",
    "                              learning_rate=best_params['learning_rate'],\n",
    "                              mini_batch_size=int(best_params['param_mini_batch_sizes']),\n",
    "                              max_epochs=int(best_params['max_epochs']),\n",
    "                              write_weights = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Učitavanje istreniranog modela\n",
    "model = SequenceTagger.load('resources/taggers/language_model_testing/final-model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actualSentenceExample = corpus2.dev[17]\n",
    "predictedSentenceExample = Sentence(actualSentenceExample.to_plain_string())\n",
    "model.predict(predictedSentenceExample)\n",
    "print(\"\\n\\n\")\n",
    "# Predvidi etikete i štampaj\n",
    "\n",
    "for i,token in enumerate(predictedSentenceExample):\n",
    "    predictedLabels = token.get_labels('upos')\n",
    "    actualLabels = actualSentenceExample[i].get_labels('upos')\n",
    "\n",
    "    for j, label in enumerate(predictedLabels):\n",
    "        token = label.data_point.form\n",
    "        predictedValue = label.value\n",
    "        actualValue = actualLabels[j].value\n",
    "\n",
    "        print(token, \"- predicted:\" ,predictedValue, \", actual:\", actualValue)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Konstrukcija matrice konfuzije"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actual= np.array([])\n",
    "predicted = np.array([])\n",
    "\n",
    "for actualSentence in corpus2.dev:\n",
    "    predictedSentence = Sentence(actualSentence.to_plain_string())\n",
    "    model.predict(predictedSentence)\n",
    "\n",
    "\n",
    "    numTokens = min(len(predictedSentence.tokens),len(actualSentence.tokens))\n",
    "    i=0\n",
    "    punctCount = 0\n",
    "\n",
    "    while i+punctCount<numTokens:\n",
    "        actualLabels = actualSentence[i].get_labels('upos')\n",
    "\n",
    "        if predictedSentence[i+punctCount].labels[0].data_point.form == \".\":\n",
    "            punctCount+=1\n",
    "\n",
    "        if i+punctCount >= numTokens:\n",
    "            break\n",
    "        predictedLabels = predictedSentence[i+punctCount].get_labels('upos')\n",
    "\n",
    "        numLabels = min(len(actualLabels),len(predictedLabels))\n",
    "        j=0\n",
    "        while j<numLabels:\n",
    "            predicted = np.append(predicted, predictedLabels[j].value)\n",
    "            actual = np.append(actual, actualLabels[j].value)\n",
    "            j+=1\n",
    "        i+=1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes = np.union1d(np.unique(actual), np.unique(predicted))\n",
    "cm = metrics.confusion_matrix(actual, predicted)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = classes,\n",
    "                     columns = classes)\n",
    "\n",
    "# Crtanje\n",
    "plt.figure(figsize=(15,13))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentence = Sentence('Srbija je tokom bombardovanja devedesetih izgubila mnoge kulturne znamenitosti.')\n",
    "model.predict(sentence)\n",
    "\n",
    "print(sentence.to_tagged_string())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}