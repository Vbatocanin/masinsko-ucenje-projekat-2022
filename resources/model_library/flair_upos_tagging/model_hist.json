[
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 10,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n       <unk>       0.00      0.00      0.00         0\n         ADJ       0.12      0.20      0.15       582\n         ADP       0.53      0.73      0.61       457\n         ADV       0.07      0.03      0.04       176\n         AUX       0.55      0.36      0.43       348\n       CCONJ       0.80      0.41      0.54       177\n         DET       0.17      0.01      0.02       170\n        NOUN       0.40      0.54      0.46      1176\n         NUM       0.00      0.00      0.00        88\n        PART       0.00      0.00      0.00        25\n        PRON       1.00      0.01      0.02       130\n       PROPN       0.09      0.10      0.10       334\n       PUNCT       0.73      0.97      0.83       622\n       SCONJ       0.77      0.31      0.44       199\n        VERB       0.20      0.05      0.09       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.41      4952\n   macro avg       0.34      0.23      0.23      4952\nweighted avg       0.41      0.41      0.37      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 10,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.26      0.40      0.32       582\n         ADP       0.84      0.83      0.83       457\n         ADV       0.07      0.02      0.03       176\n         AUX       0.71      0.75      0.73       348\n       CCONJ       0.81      0.80      0.80       177\n         DET       0.19      0.09      0.13       170\n        NOUN       0.46      0.59      0.52      1176\n         NUM       1.00      0.01      0.02        88\n        PART       0.00      0.00      0.00        25\n        PRON       0.70      0.34      0.46       130\n       PROPN       0.38      0.28      0.32       334\n       PUNCT       0.90      0.98      0.94       622\n       SCONJ       0.79      0.69      0.74       199\n        VERB       0.29      0.17      0.21       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.54      4952\n   macro avg       0.49      0.40      0.40      4952\nweighted avg       0.54      0.54      0.52      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 10,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.34      0.43      0.38       582\n         ADP       0.87      0.86      0.86       457\n         ADV       0.15      0.04      0.06       176\n         AUX       0.81      0.81      0.81       348\n       CCONJ       0.84      0.84      0.84       177\n         DET       0.33      0.18      0.23       170\n        NOUN       0.52      0.67      0.58      1176\n         NUM       1.00      0.08      0.15        88\n        PART       0.00      0.00      0.00        25\n        PRON       0.84      0.75      0.79       130\n       PROPN       0.65      0.60      0.62       334\n       PUNCT       0.94      0.99      0.97       622\n       SCONJ       0.85      0.72      0.78       199\n        VERB       0.40      0.30      0.34       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.62      4952\n   macro avg       0.57      0.48      0.49      4952\nweighted avg       0.62      0.62      0.61      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 30,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.37      0.45      0.40       582\n         ADP       0.88      0.86      0.87       457\n         ADV       0.13      0.04      0.06       176\n         AUX       0.82      0.83      0.82       348\n       CCONJ       0.83      0.84      0.84       177\n         DET       0.33      0.19      0.24       170\n        NOUN       0.55      0.67      0.61      1176\n         NUM       1.00      0.12      0.22        88\n        PART       0.00      0.00      0.00        25\n        PRON       0.84      0.75      0.80       130\n       PROPN       0.68      0.69      0.68       334\n       PUNCT       0.95      1.00      0.97       622\n       SCONJ       0.87      0.75      0.81       199\n        VERB       0.42      0.37      0.39       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.64      4952\n   macro avg       0.58      0.50      0.51      4952\nweighted avg       0.64      0.64      0.63      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 30,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.40      0.48      0.44       582\n         ADP       0.88      0.87      0.88       457\n         ADV       0.15      0.05      0.08       176\n         AUX       0.82      0.84      0.83       348\n       CCONJ       0.84      0.85      0.84       177\n         DET       0.36      0.22      0.27       170\n        NOUN       0.58      0.69      0.63      1176\n         NUM       1.00      0.14      0.24        88\n        PART       1.00      0.04      0.08        25\n        PRON       0.84      0.75      0.80       130\n       PROPN       0.70      0.76      0.73       334\n       PUNCT       0.96      1.00      0.98       622\n       SCONJ       0.87      0.76      0.81       199\n        VERB       0.45      0.41      0.43       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.66      4952\n   macro avg       0.66      0.52      0.53      4952\nweighted avg       0.66      0.66      0.65      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 30,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.42      0.50      0.46       582\n         ADP       0.88      0.87      0.88       457\n         ADV       0.18      0.06      0.09       176\n         AUX       0.82      0.86      0.84       348\n       CCONJ       0.86      0.85      0.86       177\n         DET       0.39      0.26      0.31       170\n        NOUN       0.61      0.70      0.65      1176\n         NUM       0.93      0.15      0.25        88\n        PART       1.00      0.04      0.08        25\n        PRON       0.84      0.76      0.80       130\n       PROPN       0.71      0.81      0.76       334\n       PUNCT       0.97      1.00      0.98       622\n       SCONJ       0.88      0.77      0.82       199\n        VERB       0.49      0.44      0.46       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.68      4952\n   macro avg       0.66      0.54      0.55      4952\nweighted avg       0.67      0.68      0.67      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 50,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.43      0.49      0.46       582\n         ADP       0.89      0.88      0.89       457\n         ADV       0.18      0.07      0.11       176\n         AUX       0.85      0.86      0.85       348\n       CCONJ       0.87      0.86      0.87       177\n         DET       0.43      0.32      0.37       170\n        NOUN       0.61      0.73      0.66      1176\n         NUM       1.00      0.16      0.27        88\n        PART       1.00      0.04      0.08        25\n        PRON       0.84      0.78      0.81       130\n       PROPN       0.74      0.81      0.77       334\n       PUNCT       0.97      1.00      0.98       622\n       SCONJ       0.88      0.79      0.83       199\n        VERB       0.50      0.45      0.47       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.69      4952\n   macro avg       0.68      0.55      0.56      4952\nweighted avg       0.69      0.69      0.68      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 50,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.43      0.50      0.47       582\n         ADP       0.90      0.89      0.89       457\n         ADV       0.19      0.07      0.11       176\n         AUX       0.85      0.86      0.85       348\n       CCONJ       0.91      0.87      0.89       177\n         DET       0.44      0.34      0.38       170\n        NOUN       0.62      0.73      0.67      1176\n         NUM       1.00      0.18      0.31        88\n        PART       0.33      0.04      0.07        25\n        PRON       0.85      0.79      0.82       130\n       PROPN       0.76      0.83      0.79       334\n       PUNCT       0.99      1.00      0.99       622\n       SCONJ       0.88      0.81      0.84       199\n        VERB       0.51      0.45      0.48       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.70      4952\n   macro avg       0.64      0.56      0.57      4952\nweighted avg       0.69      0.70      0.69      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 50,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.45      0.54      0.49       582\n         ADP       0.90      0.90      0.90       457\n         ADV       0.18      0.07      0.10       176\n         AUX       0.85      0.86      0.86       348\n       CCONJ       0.92      0.88      0.90       177\n         DET       0.49      0.32      0.39       170\n        NOUN       0.64      0.72      0.68      1176\n         NUM       0.95      0.22      0.35        88\n        PART       0.25      0.04      0.07        25\n        PRON       0.87      0.79      0.83       130\n       PROPN       0.76      0.85      0.80       334\n       PUNCT       0.99      1.00      0.99       622\n       SCONJ       0.87      0.82      0.85       199\n        VERB       0.51      0.50      0.50       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.71      4952\n   macro avg       0.64      0.57      0.58      4952\nweighted avg       0.70      0.71      0.70      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 70,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.46      0.54      0.50       582\n         ADP       0.91      0.90      0.90       457\n         ADV       0.18      0.07      0.11       176\n         AUX       0.88      0.87      0.87       348\n       CCONJ       0.93      0.89      0.91       177\n         DET       0.53      0.36      0.43       170\n        NOUN       0.64      0.73      0.69      1176\n         NUM       1.00      0.25      0.40        88\n        PART       0.25      0.04      0.07        25\n        PRON       0.87      0.79      0.83       130\n       PROPN       0.77      0.86      0.81       334\n       PUNCT       0.99      1.00      0.99       622\n       SCONJ       0.88      0.84      0.86       199\n        VERB       0.52      0.51      0.52       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.72      4952\n   macro avg       0.65      0.58      0.59      4952\nweighted avg       0.71      0.72      0.71      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 70,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.47      0.55      0.51       582\n         ADP       0.91      0.91      0.91       457\n         ADV       0.21      0.09      0.12       176\n         AUX       0.89      0.87      0.88       348\n       CCONJ       0.93      0.89      0.91       177\n         DET       0.53      0.37      0.44       170\n        NOUN       0.65      0.74      0.69      1176\n         NUM       1.00      0.28      0.44        88\n        PART       0.25      0.04      0.07        25\n        PRON       0.89      0.79      0.84       130\n       PROPN       0.76      0.87      0.81       334\n       PUNCT       0.99      1.00      0.99       622\n       SCONJ       0.86      0.85      0.86       199\n        VERB       0.53      0.53      0.53       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.72      4952\n   macro avg       0.66      0.58      0.60      4952\nweighted avg       0.72      0.72      0.71      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 70,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.48      0.55      0.52       582\n         ADP       0.92      0.91      0.91       457\n         ADV       0.19      0.08      0.11       176\n         AUX       0.90      0.89      0.89       348\n       CCONJ       0.95      0.89      0.92       177\n         DET       0.55      0.39      0.46       170\n        NOUN       0.66      0.75      0.70      1176\n         NUM       0.96      0.30      0.45        88\n        PART       0.40      0.08      0.13        25\n        PRON       0.89      0.80      0.84       130\n       PROPN       0.77      0.90      0.83       334\n       PUNCT       0.99      1.00      0.99       622\n       SCONJ       0.87      0.87      0.87       199\n        VERB       0.55      0.54      0.55       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.73      4952\n   macro avg       0.67      0.60      0.61      4952\nweighted avg       0.72      0.73      0.72      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 90,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.49      0.56      0.52       582\n         ADP       0.92      0.91      0.92       457\n         ADV       0.21      0.09      0.13       176\n         AUX       0.91      0.89      0.90       348\n       CCONJ       0.95      0.89      0.92       177\n         DET       0.56      0.40      0.47       170\n        NOUN       0.66      0.76      0.71      1176\n         NUM       0.97      0.32      0.48        88\n        PART       0.57      0.16      0.25        25\n        PRON       0.90      0.80      0.85       130\n       PROPN       0.77      0.91      0.83       334\n       PUNCT       0.99      1.00      0.99       622\n       SCONJ       0.88      0.88      0.88       199\n        VERB       0.57      0.54      0.55       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.74      4952\n   macro avg       0.69      0.61      0.63      4952\nweighted avg       0.73      0.74      0.73      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 90,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.49      0.57      0.52       582\n         ADP       0.92      0.91      0.92       457\n         ADV       0.23      0.09      0.13       176\n         AUX       0.92      0.89      0.90       348\n       CCONJ       0.95      0.89      0.92       177\n         DET       0.58      0.43      0.49       170\n        NOUN       0.67      0.76      0.71      1176\n         NUM       0.97      0.33      0.49        88\n        PART       0.67      0.24      0.35        25\n        PRON       0.92      0.80      0.86       130\n       PROPN       0.78      0.91      0.84       334\n       PUNCT       0.99      1.00      0.99       622\n       SCONJ       0.88      0.90      0.89       199\n        VERB       0.58      0.54      0.56       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.74      4952\n   macro avg       0.70      0.62      0.64      4952\nweighted avg       0.74      0.74      0.73      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.001,
            "param_mini_batch_sizes": 90,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.49      0.58      0.53       582\n         ADP       0.92      0.91      0.92       457\n         ADV       0.24      0.09      0.13       176\n         AUX       0.93      0.89      0.91       348\n       CCONJ       0.95      0.90      0.92       177\n         DET       0.63      0.45      0.53       170\n        NOUN       0.67      0.77      0.72      1176\n         NUM       0.94      0.38      0.54        88\n        PART       0.75      0.24      0.36        25\n        PRON       0.92      0.80      0.86       130\n       PROPN       0.78      0.91      0.84       334\n       PUNCT       0.99      1.00      1.00       622\n       SCONJ       0.88      0.91      0.90       199\n        VERB       0.59      0.54      0.56       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.75      4952\n   macro avg       0.71      0.62      0.65      4952\nweighted avg       0.74      0.75      0.74      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 10,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.82      0.59      0.69       582\n         ADP       1.00      0.97      0.98       457\n         ADV       0.65      0.60      0.62       176\n         AUX       1.00      0.99      0.99       348\n       CCONJ       0.98      0.97      0.98       177\n         DET       0.90      0.91      0.90       170\n        NOUN       0.82      0.83      0.83      1176\n         NUM       0.99      0.88      0.93        88\n        PART       0.85      0.92      0.88        25\n        PRON       0.93      0.95      0.94       130\n       PROPN       0.81      0.96      0.88       334\n       PUNCT       0.99      1.00      1.00       622\n       SCONJ       0.94      0.97      0.96       199\n        VERB       0.68      0.88      0.77       443\n           X       0.67      0.08      0.14        25\n\n    accuracy                           0.87      4952\n   macro avg       0.87      0.83      0.83      4952\nweighted avg       0.87      0.87      0.86      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 10,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.78      0.74      0.76       582\n         ADP       0.98      0.98      0.98       457\n         ADV       0.89      0.55      0.68       176\n         AUX       1.00      0.99      0.99       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.96      0.82      0.89       170\n        NOUN       0.84      0.85      0.85      1176\n         NUM       0.99      0.90      0.94        88\n        PART       0.91      0.80      0.85        25\n        PRON       0.97      0.94      0.95       130\n       PROPN       0.74      0.98      0.85       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.94      0.97      0.96       199\n        VERB       0.82      0.88      0.85       443\n           X       0.50      0.04      0.07        25\n\n    accuracy                           0.89      4952\n   macro avg       0.89      0.83      0.84      4952\nweighted avg       0.89      0.89      0.88      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 10,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.82      0.82      0.82       582\n         ADP       1.00      0.97      0.98       457\n         ADV       0.85      0.60      0.71       176\n         AUX       0.99      0.99      0.99       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.80      0.96      0.87       170\n        NOUN       0.88      0.88      0.88      1176\n         NUM       0.98      0.92      0.95        88\n        PART       0.90      0.72      0.80        25\n        PRON       0.98      0.98      0.98       130\n       PROPN       0.89      0.90      0.89       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.98       199\n        VERB       0.83      0.91      0.87       443\n           X       1.00      0.16      0.28        25\n\n    accuracy                           0.91      4952\n   macro avg       0.92      0.85      0.86      4952\nweighted avg       0.91      0.91      0.91      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 30,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.81      0.84       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.85      0.69      0.76       176\n         AUX       1.00      0.99      0.99       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.92      0.92      0.92       170\n        NOUN       0.88      0.93      0.90      1176\n         NUM       0.99      0.92      0.95        88\n        PART       0.80      0.80      0.80        25\n        PRON       0.97      0.96      0.97       130\n       PROPN       0.88      0.91      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.96      0.97      0.97       199\n        VERB       0.89      0.91      0.90       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.92      4952\n   macro avg       0.91      0.86      0.87      4952\nweighted avg       0.92      0.92      0.92      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 30,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.80      0.85       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.81      0.78      0.79       176\n         AUX       1.00      0.99      0.99       348\n       CCONJ       0.97      0.98      0.98       177\n         DET       0.92      0.93      0.93       170\n        NOUN       0.90      0.92      0.91      1176\n         NUM       0.99      0.93      0.96        88\n        PART       0.81      0.84      0.82        25\n        PRON       0.97      0.97      0.97       130\n       PROPN       0.89      0.93      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.86      0.94      0.90       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.93      4952\n   macro avg       0.91      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 30,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.82      0.87      0.84       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.81      0.77      0.79       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.93      0.93      0.93       170\n        NOUN       0.92      0.88      0.90      1176\n         NUM       0.97      0.95      0.96        88\n        PART       0.87      0.80      0.83        25\n        PRON       0.95      0.97      0.96       130\n       PROPN       0.87      0.95      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.96      0.96      0.96       199\n        VERB       0.89      0.92      0.90       443\n           X       0.60      0.12      0.20        25\n\n    accuracy                           0.92      4952\n   macro avg       0.90      0.87      0.88      4952\nweighted avg       0.92      0.92      0.92      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 50,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.86      0.86       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.85      0.78      0.81       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.97       177\n         DET       0.93      0.93      0.93       170\n        NOUN       0.92      0.90      0.91      1176\n         NUM       0.97      0.94      0.95        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.95      0.97      0.96       130\n       PROPN       0.88      0.95      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.96      0.96       199\n        VERB       0.88      0.93      0.90       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.93      4952\n   macro avg       0.92      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 50,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.84      0.86       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.80      0.78      0.79       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.92      0.93      0.93       170\n        NOUN       0.90      0.92      0.91      1176\n         NUM       0.97      0.95      0.96        88\n        PART       0.86      0.76      0.81        25\n        PRON       0.95      0.97      0.96       130\n       PROPN       0.89      0.92      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.96      0.96       199\n        VERB       0.91      0.92      0.92       443\n           X       0.33      0.04      0.07        25\n\n    accuracy                           0.93      4952\n   macro avg       0.89      0.86      0.87      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 50,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.88      0.87       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.86      0.78      0.82       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.92      0.94      0.93       170\n        NOUN       0.91      0.91      0.91      1176\n         NUM       0.97      0.94      0.95        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.95      0.97      0.96       130\n       PROPN       0.88      0.93      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.93      0.92      0.92       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.93      4952\n   macro avg       0.87      0.86      0.87      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 70,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.87      0.87       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.88      0.76      0.82       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.93      0.93      0.93       170\n        NOUN       0.92      0.92      0.92      1176\n         NUM       0.97      0.94      0.95        88\n        PART       0.95      0.80      0.87        25\n        PRON       0.95      0.99      0.97       130\n       PROPN       0.87      0.94      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.96      0.96       199\n        VERB       0.92      0.93      0.92       443\n           X       0.33      0.04      0.07        25\n\n    accuracy                           0.93      4952\n   macro avg       0.90      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 70,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.85      0.88      0.87       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.85      0.78      0.81       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.95      0.98      0.97       177\n         DET       0.95      0.93      0.94       170\n        NOUN       0.92      0.91      0.91      1176\n         NUM       0.97      0.94      0.95        88\n        PART       0.86      0.76      0.81        25\n        PRON       0.96      0.99      0.97       130\n       PROPN       0.88      0.95      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.96      0.97       199\n        VERB       0.92      0.91      0.92       443\n           X       0.50      0.04      0.07        25\n\n    accuracy                           0.93      4952\n   macro avg       0.90      0.87      0.87      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 70,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.85      0.88      0.87       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.85      0.76      0.80       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.92      0.94      0.93       170\n        NOUN       0.91      0.91      0.91      1176\n         NUM       0.95      0.94      0.95        88\n        PART       0.91      0.80      0.85        25\n        PRON       0.95      0.98      0.97       130\n       PROPN       0.88      0.94      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.96      0.97       199\n        VERB       0.91      0.91      0.91       443\n           X       0.67      0.08      0.14        25\n\n    accuracy                           0.93      4952\n   macro avg       0.92      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 90,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.85      0.86       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.84      0.76      0.79       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.97       177\n         DET       0.93      0.93      0.93       170\n        NOUN       0.91      0.92      0.91      1176\n         NUM       0.99      0.94      0.97        88\n        PART       0.95      0.76      0.84        25\n        PRON       0.95      0.99      0.97       130\n       PROPN       0.88      0.95      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.96      0.96       199\n        VERB       0.91      0.92      0.91       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.93      4952\n   macro avg       0.93      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 90,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.87      0.87       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.86      0.76      0.80       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.97       177\n         DET       0.93      0.95      0.94       170\n        NOUN       0.91      0.92      0.91      1176\n         NUM       0.98      0.94      0.96        88\n        PART       0.95      0.76      0.84        25\n        PRON       0.94      0.99      0.97       130\n       PROPN       0.88      0.94      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.95      0.97       199\n        VERB       0.91      0.92      0.92       443\n           X       1.00      0.04      0.08        25\n\n    accuracy                           0.93      4952\n   macro avg       0.94      0.87      0.87      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.20066666666666666,
            "param_mini_batch_sizes": 90,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.86      0.87       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.88      0.73      0.80       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.92      0.94      0.93       170\n        NOUN       0.90      0.93      0.91      1176\n         NUM       0.98      0.93      0.95        88\n        PART       0.95      0.80      0.87        25\n        PRON       0.95      0.98      0.97       130\n       PROPN       0.89      0.94      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.96      0.96       199\n        VERB       0.92      0.91      0.92       443\n           X       0.67      0.08      0.14        25\n\n    accuracy                           0.93      4952\n   macro avg       0.92      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 10,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.85      0.86       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.74      0.83      0.78       176\n         AUX       0.99      0.99      0.99       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.92      0.96      0.94       170\n        NOUN       0.92      0.91      0.91      1176\n         NUM       0.98      0.94      0.96        88\n        PART       0.79      0.76      0.78        25\n        PRON       0.96      0.98      0.97       130\n       PROPN       0.86      0.95      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.96      0.97       199\n        VERB       0.92      0.92      0.92       443\n           X       0.67      0.08      0.14        25\n\n    accuracy                           0.93      4952\n   macro avg       0.90      0.87      0.87      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 10,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.72      0.81       582\n         ADP       0.99      0.98      0.99       457\n         ADV       0.78      0.82      0.80       176\n         AUX       0.99      1.00      0.99       348\n       CCONJ       0.97      0.97      0.97       177\n         DET       0.91      0.92      0.92       170\n        NOUN       0.87      0.92      0.89      1176\n         NUM       1.00      0.91      0.95        88\n        PART       0.92      0.92      0.92        25\n        PRON       0.97      0.96      0.97       130\n       PROPN       0.88      0.93      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.96      0.99      0.98       199\n        VERB       0.86      0.95      0.90       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.92      4952\n   macro avg       0.87      0.87      0.87      4952\nweighted avg       0.92      0.92      0.92      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 10,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.85      0.88      0.86       582\n         ADP       1.00      0.98      0.99       457\n         ADV       0.75      0.81      0.78       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.94      0.93      0.93       170\n        NOUN       0.91      0.90      0.91      1176\n         NUM       0.95      0.95      0.95        88\n        PART       0.87      0.80      0.83        25\n        PRON       0.97      0.97      0.97       130\n       PROPN       0.88      0.91      0.89       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.91      0.91      0.91       443\n           X       1.00      0.08      0.15        25\n\n    accuracy                           0.93      4952\n   macro avg       0.93      0.87      0.87      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 30,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.85      0.87       582\n         ADP       1.00      0.99      1.00       457\n         ADV       0.80      0.78      0.79       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.89      0.95      0.92       170\n        NOUN       0.90      0.92      0.91      1176\n         NUM       0.98      0.93      0.95        88\n        PART       0.86      0.76      0.81        25\n        PRON       0.98      0.97      0.97       130\n       PROPN       0.89      0.90      0.89       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.89      0.92      0.91       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.93      4952\n   macro avg       0.92      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 30,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.85      0.88       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.82      0.81      0.82       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.97       177\n         DET       0.94      0.96      0.95       170\n        NOUN       0.92      0.93      0.92      1176\n         NUM       0.97      0.95      0.96        88\n        PART       0.91      0.84      0.87        25\n        PRON       0.96      0.99      0.98       130\n       PROPN       0.87      0.93      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.96      0.97       199\n        VERB       0.90      0.94      0.92       443\n           X       1.00      0.16      0.28        25\n\n    accuracy                           0.94      4952\n   macro avg       0.94      0.89      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 30,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.80      0.85       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.77      0.81      0.79       176\n         AUX       0.99      1.00      0.99       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.93      0.95      0.94       170\n        NOUN       0.89      0.92      0.91      1176\n         NUM       0.98      0.95      0.97        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.98      0.99      0.98       130\n       PROPN       0.89      0.92      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.96      0.98      0.97       199\n        VERB       0.89      0.94      0.91       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.93      4952\n   macro avg       0.92      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 50,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.87      0.87       582\n         ADP       1.00      0.99      1.00       457\n         ADV       0.83      0.81      0.82       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.92      0.96      0.94       170\n        NOUN       0.93      0.91      0.92      1176\n         NUM       0.98      0.94      0.96        88\n        PART       0.95      0.76      0.84        25\n        PRON       0.96      0.99      0.98       130\n       PROPN       0.88      0.95      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.98       199\n        VERB       0.90      0.95      0.93       443\n           X       1.00      0.08      0.15        25\n\n    accuracy                           0.94      4952\n   macro avg       0.94      0.88      0.88      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 50,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.86      0.88       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.81      0.82      0.82       176\n         AUX       0.99      1.00      0.99       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.95      0.95      0.95       170\n        NOUN       0.92      0.93      0.92      1176\n         NUM       0.99      0.94      0.97        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.96      0.99      0.97       130\n       PROPN       0.87      0.92      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.97       199\n        VERB       0.91      0.93      0.92       443\n           X       1.00      0.08      0.15        25\n\n    accuracy                           0.94      4952\n   macro avg       0.94      0.88      0.88      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 50,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.85      0.88       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.86      0.76      0.81       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.95      0.95      0.95       170\n        NOUN       0.89      0.94      0.92      1176\n         NUM       0.98      0.94      0.96        88\n        PART       0.83      0.76      0.79        25\n        PRON       0.96      0.99      0.97       130\n       PROPN       0.89      0.92      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.96      0.97       199\n        VERB       0.92      0.93      0.92       443\n           X       0.00      0.00      0.00        25\n\n    accuracy                           0.94      4952\n   macro avg       0.87      0.86      0.87      4952\nweighted avg       0.93      0.94      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 70,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.88      0.88       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.87      0.67      0.76       176\n         AUX       0.99      0.99      0.99       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.95      0.94      0.94       170\n        NOUN       0.90      0.94      0.92      1176\n         NUM       0.96      0.92      0.94        88\n        PART       0.79      0.76      0.78        25\n        PRON       0.93      0.98      0.96       130\n       PROPN       0.89      0.92      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.96      0.96      0.96       199\n        VERB       0.90      0.92      0.91       443\n           X       0.33      0.04      0.07        25\n\n    accuracy                           0.93      4952\n   macro avg       0.89      0.86      0.86      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 70,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.84      0.91      0.87       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.86      0.75      0.80       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.95      0.96      0.95       170\n        NOUN       0.91      0.90      0.90      1176\n         NUM       0.98      0.93      0.95        88\n        PART       0.83      0.76      0.79        25\n        PRON       0.98      0.96      0.97       130\n       PROPN       0.89      0.91      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.92      0.92      0.92       443\n           X       0.33      0.04      0.07        25\n\n    accuracy                           0.93      4952\n   macro avg       0.89      0.87      0.87      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 70,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.84      0.88       582\n         ADP       1.00      0.99      1.00       457\n         ADV       0.87      0.76      0.81       176\n         AUX       1.00      0.99      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.87      0.95      0.91       170\n        NOUN       0.88      0.95      0.91      1176\n         NUM       0.97      0.95      0.96        88\n        PART       0.86      0.76      0.81        25\n        PRON       0.96      0.98      0.97       130\n       PROPN       0.89      0.90      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.93      0.89      0.91       443\n           X       0.50      0.04      0.07        25\n\n    accuracy                           0.93      4952\n   macro avg       0.90      0.86      0.87      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 90,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.87      0.89       582\n         ADP       1.00      0.99      1.00       457\n         ADV       0.88      0.79      0.83       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.91      0.96      0.93       170\n        NOUN       0.92      0.93      0.92      1176\n         NUM       0.93      0.95      0.94        88\n        PART       0.86      0.76      0.81        25\n        PRON       0.97      0.98      0.98       130\n       PROPN       0.89      0.94      0.92       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.91      0.95      0.93       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.94      4952\n   macro avg       0.92      0.88      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 90,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.86      0.88       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.86      0.79      0.82       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.94      0.95      0.94       170\n        NOUN       0.92      0.93      0.92      1176\n         NUM       0.99      0.95      0.97        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.96      0.98      0.97       130\n       PROPN       0.87      0.93      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.98      0.98       199\n        VERB       0.90      0.94      0.92       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.94      4952\n   macro avg       0.93      0.88      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.4003333333333333,
            "param_mini_batch_sizes": 90,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.87      0.89       582\n         ADP       1.00      0.99      1.00       457\n         ADV       0.87      0.78      0.83       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.95      0.95      0.95       170\n        NOUN       0.91      0.93      0.92      1176\n         NUM       0.98      0.94      0.96        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.97      0.98      0.98       130\n       PROPN       0.88      0.93      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.91      0.94      0.92       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.94      4952\n   macro avg       0.93      0.88      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 10,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.93      0.78      0.85       582\n         ADP       1.00      0.98      0.99       457\n         ADV       0.90      0.66      0.76       176\n         AUX       1.00      1.00      1.00       348\n       CCONJ       0.97      0.98      0.97       177\n         DET       0.90      0.95      0.93       170\n        NOUN       0.88      0.93      0.90      1176\n         NUM       0.99      0.93      0.96        88\n        PART       0.84      0.84      0.84        25\n        PRON       0.97      0.98      0.97       130\n       PROPN       0.89      0.91      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.94      0.98      0.96       199\n        VERB       0.82      0.97      0.88       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.92      4952\n   macro avg       0.92      0.87      0.87      4952\nweighted avg       0.93      0.92      0.92      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 10,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.79      0.84       582\n         ADP       0.98      0.98      0.98       457\n         ADV       0.84      0.74      0.79       176\n         AUX       1.00      0.99      0.99       348\n       CCONJ       0.97      0.98      0.97       177\n         DET       0.96      0.91      0.93       170\n        NOUN       0.87      0.93      0.90      1176\n         NUM       0.94      0.92      0.93        88\n        PART       0.81      0.84      0.82        25\n        PRON       0.96      0.98      0.97       130\n       PROPN       0.88      0.93      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.96      0.97      0.97       199\n        VERB       0.90      0.89      0.90       443\n           X       0.87      0.52      0.65        25\n\n    accuracy                           0.92      4952\n   macro avg       0.92      0.89      0.90      4952\nweighted avg       0.92      0.92      0.92      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 10,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.80      0.86       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.81      0.78      0.79       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.88      0.95      0.91       170\n        NOUN       0.89      0.92      0.91      1176\n         NUM       0.95      0.94      0.95        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.96      0.99      0.97       130\n       PROPN       0.84      0.95      0.89       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.98       199\n        VERB       0.89      0.91      0.90       443\n           X       1.00      0.12      0.21        25\n\n    accuracy                           0.93      4952\n   macro avg       0.93      0.87      0.88      4952\nweighted avg       0.93      0.93      0.92      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 30,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.74      0.82       582\n         ADP       1.00      0.98      0.99       457\n         ADV       0.77      0.82      0.80       176\n         AUX       0.99      0.99      0.99       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.97      0.94      0.95       170\n        NOUN       0.85      0.93      0.89      1176\n         NUM       0.99      0.95      0.97        88\n        PART       0.91      0.80      0.85        25\n        PRON       0.95      0.99      0.97       130\n       PROPN       0.87      0.91      0.89       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.97       199\n        VERB       0.89      0.91      0.90       443\n           X       1.00      0.04      0.08        25\n\n    accuracy                           0.92      4952\n   macro avg       0.93      0.86      0.87      4952\nweighted avg       0.92      0.92      0.92      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 30,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.87      0.87       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.86      0.76      0.81       176\n         AUX       0.99      0.99      0.99       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.92      0.93      0.92       170\n        NOUN       0.90      0.93      0.91      1176\n         NUM       0.98      0.91      0.94        88\n        PART       0.83      0.80      0.82        25\n        PRON       0.95      0.98      0.96       130\n       PROPN       0.89      0.92      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.96      0.97       199\n        VERB       0.91      0.90      0.91       443\n           X       0.86      0.24      0.38        25\n\n    accuracy                           0.93      4952\n   macro avg       0.93      0.88      0.89      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 30,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.88      0.87       582\n         ADP       1.00      0.98      0.99       457\n         ADV       0.88      0.72      0.79       176\n         AUX       1.00      0.99      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.93      0.92      0.92       170\n        NOUN       0.90      0.93      0.92      1176\n         NUM       0.98      0.93      0.95        88\n        PART       0.86      0.76      0.81        25\n        PRON       0.96      0.98      0.97       130\n       PROPN       0.90      0.91      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.98       199\n        VERB       0.92      0.90      0.91       443\n           X       0.67      0.16      0.26        25\n\n    accuracy                           0.93      4952\n   macro avg       0.92      0.87      0.88      4952\nweighted avg       0.93      0.93      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 50,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.85      0.88       582\n         ADP       1.00      0.98      0.99       457\n         ADV       0.85      0.81      0.83       176\n         AUX       0.99      0.99      0.99       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.93      0.95      0.94       170\n        NOUN       0.90      0.93      0.92      1176\n         NUM       0.98      0.93      0.95        88\n        PART       0.91      0.80      0.85        25\n        PRON       0.97      0.98      0.97       130\n       PROPN       0.89      0.91      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.98      0.98       199\n        VERB       0.89      0.94      0.92       443\n           X       0.83      0.20      0.32        25\n\n    accuracy                           0.94      4952\n   macro avg       0.93      0.88      0.89      4952\nweighted avg       0.94      0.94      0.93      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 50,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.88      0.88       582\n         ADP       0.99      0.99      0.99       457\n         ADV       0.83      0.82      0.83       176\n         AUX       0.99      0.99      0.99       348\n       CCONJ       0.95      0.98      0.97       177\n         DET       0.93      0.95      0.94       170\n        NOUN       0.92      0.92      0.92      1176\n         NUM       0.94      0.95      0.95        88\n        PART       0.86      0.76      0.81        25\n        PRON       0.96      0.98      0.97       130\n       PROPN       0.88      0.91      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.98       199\n        VERB       0.93      0.93      0.93       443\n           X       0.62      0.20      0.30        25\n\n    accuracy                           0.94      4952\n   macro avg       0.91      0.88      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 50,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.81      0.90      0.85       582\n         ADP       1.00      0.98      0.99       457\n         ADV       0.85      0.71      0.77       176\n         AUX       0.99      0.98      0.99       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.96      0.91      0.93       170\n        NOUN       0.91      0.90      0.90      1176\n         NUM       0.95      0.93      0.94        88\n        PART       0.83      0.76      0.79        25\n        PRON       0.97      0.98      0.98       130\n       PROPN       0.87      0.95      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.92      0.89      0.91       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.93      4952\n   macro avg       0.92      0.86      0.87      4952\nweighted avg       0.93      0.93      0.92      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 70,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.85      0.89       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.83      0.81      0.82       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.95      0.94      0.94       170\n        NOUN       0.91      0.93      0.92      1176\n         NUM       0.97      0.95      0.96        88\n        PART       0.95      0.76      0.84        25\n        PRON       0.97      0.99      0.98       130\n       PROPN       0.90      0.92      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.98      0.98       199\n        VERB       0.86      0.95      0.91       443\n           X       0.83      0.20      0.32        25\n\n    accuracy                           0.94      4952\n   macro avg       0.93      0.88      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 70,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.85      0.89       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.85      0.82      0.83       176\n         AUX       0.99      0.99      0.99       348\n       CCONJ       0.96      0.98      0.97       177\n         DET       0.94      0.95      0.94       170\n        NOUN       0.92      0.93      0.92      1176\n         NUM       0.98      0.95      0.97        88\n        PART       0.88      0.88      0.88        25\n        PRON       0.97      0.98      0.98       130\n       PROPN       0.88      0.94      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.90      0.94      0.92       443\n           X       0.67      0.08      0.14        25\n\n    accuracy                           0.94      4952\n   macro avg       0.92      0.88      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 70,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.93      0.86      0.89       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.84      0.84      0.84       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.95      0.98      0.96       177\n         DET       0.96      0.94      0.95       170\n        NOUN       0.92      0.94      0.93      1176\n         NUM       0.97      0.95      0.96        88\n        PART       0.95      0.80      0.87        25\n        PRON       0.96      0.98      0.97       130\n       PROPN       0.88      0.93      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.98       199\n        VERB       0.90      0.95      0.92       443\n           X       0.75      0.12      0.21        25\n\n    accuracy                           0.94      4952\n   macro avg       0.93      0.88      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 90,
            "max_epochs": 10
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.85      0.88       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.87      0.82      0.84       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.95      0.95      0.95       170\n        NOUN       0.91      0.93      0.92      1176\n         NUM       0.98      0.94      0.96        88\n        PART       0.95      0.80      0.87        25\n        PRON       0.98      0.98      0.98       130\n       PROPN       0.89      0.92      0.90       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.89      0.95      0.92       443\n           X       0.83      0.20      0.32        25\n\n    accuracy                           0.94      4952\n   macro avg       0.94      0.89      0.90      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 90,
            "max_epochs": 11
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.90      0.90       582\n         ADP       1.00      0.99      1.00       457\n         ADV       0.84      0.82      0.83       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.96      0.95      0.95       170\n        NOUN       0.92      0.93      0.92      1176\n         NUM       0.97      0.97      0.97        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.98      0.98      0.98       130\n       PROPN       0.90      0.92      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.98      0.97      0.97       199\n        VERB       0.93      0.92      0.93       443\n           X       0.83      0.20      0.32        25\n\n    accuracy                           0.94      4952\n   macro avg       0.94      0.89      0.90      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    },
    {
        "params": {
            "learning_rate": 0.6,
            "param_mini_batch_sizes": 90,
            "max_epochs": 12
        },
        "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.85      0.89       582\n         ADP       1.00      0.99      0.99       457\n         ADV       0.84      0.81      0.82       176\n         AUX       0.99      1.00      1.00       348\n       CCONJ       0.94      0.98      0.96       177\n         DET       0.90      0.96      0.93       170\n        NOUN       0.92      0.93      0.92      1176\n         NUM       0.97      0.97      0.97        88\n        PART       0.90      0.76      0.83        25\n        PRON       0.98      0.99      0.98       130\n       PROPN       0.90      0.93      0.91       334\n       PUNCT       1.00      1.00      1.00       622\n       SCONJ       0.97      0.97      0.97       199\n        VERB       0.87      0.95      0.91       443\n           X       0.80      0.16      0.27        25\n\n    accuracy                           0.94      4952\n   macro avg       0.93      0.88      0.89      4952\nweighted avg       0.94      0.94      0.94      4952\n"
    }
]