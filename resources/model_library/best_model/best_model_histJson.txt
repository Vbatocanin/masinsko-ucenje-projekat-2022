[{"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.14      0.11      0.12       137\n         ADP       0.17      0.25      0.20       100\n         ADV       0.50      0.04      0.07        28\n         AUX       0.07      0.12      0.08        69\n       CCONJ       0.00      0.00      0.00        36\n         DET       0.00      0.00      0.00        44\n        NOUN       0.28      0.50      0.36       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.00      0.00      0.00        29\n       PROPN       0.50      0.01      0.03        68\n       PUNCT       0.58      0.60      0.59       137\n       SCONJ       0.00      0.00      0.00        29\n        VERB       0.00      0.00      0.00        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.24      1057\n   macro avg       0.15      0.11      0.10      1057\nweighted avg       0.23      0.24      0.21      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.12      0.11      0.11       137\n         ADP       0.34      0.67      0.45       100\n         ADV       1.00      0.04      0.07        28\n         AUX       0.30      0.35      0.32        69\n       CCONJ       0.00      0.00      0.00        36\n         DET       0.00      0.00      0.00        44\n        NOUN       0.39      0.62      0.48       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.00      0.00      0.00        29\n       PROPN       0.50      0.13      0.21        68\n       PUNCT       0.71      0.99      0.83       137\n       SCONJ       0.86      0.21      0.33        29\n        VERB       0.00      0.00      0.00        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.39      1057\n   macro avg       0.28      0.21      0.19      1057\nweighted avg       0.33      0.39      0.32      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.11      0.10      0.10       137\n         ADP       0.49      0.80      0.61       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.60      0.62      0.61        69\n       CCONJ       0.00      0.00      0.00        36\n         DET       0.00      0.00      0.00        44\n        NOUN       0.44      0.70      0.54       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.00      0.00      0.00        29\n       PROPN       0.20      0.18      0.19        68\n       PUNCT       0.74      0.99      0.85       137\n       SCONJ       0.86      0.41      0.56        29\n        VERB       0.06      0.01      0.02        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.45      1057\n   macro avg       0.23      0.25      0.23      1057\nweighted avg       0.34      0.45      0.38      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.09      0.09      0.09       137\n         ADP       0.62      0.82      0.70       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.67      0.77      0.72        69\n       CCONJ       0.33      0.08      0.13        36\n         DET       0.00      0.00      0.00        44\n        NOUN       0.44      0.69      0.53       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.00      0.00      0.00        29\n       PROPN       0.19      0.19      0.19        68\n       PUNCT       0.77      0.99      0.87       137\n       SCONJ       0.74      0.59      0.65        29\n        VERB       0.05      0.01      0.02        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.47      1057\n   macro avg       0.26      0.28      0.26      1057\nweighted avg       0.37      0.47      0.40      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.11      0.12      0.12       137\n         ADP       0.63      0.82      0.71       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.65      0.77      0.70        69\n       CCONJ       0.69      0.25      0.37        36\n         DET       0.00      0.00      0.00        44\n        NOUN       0.45      0.70      0.55       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.00      0.00      0.00        29\n       PROPN       0.21      0.19      0.20        68\n       PUNCT       0.80      0.99      0.88       137\n       SCONJ       0.78      0.62      0.69        29\n        VERB       0.09      0.03      0.05        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.48      1057\n   macro avg       0.29      0.30      0.28      1057\nweighted avg       0.39      0.48      0.42      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.12      0.12      0.12       137\n         ADP       0.63      0.86      0.73       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.66      0.78      0.72        69\n       CCONJ       0.79      0.42      0.55        36\n         DET       0.00      0.00      0.00        44\n        NOUN       0.46      0.70      0.55       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.17      0.03      0.06        29\n       PROPN       0.22      0.19      0.20        68\n       PUNCT       0.83      0.99      0.90       137\n       SCONJ       0.82      0.62      0.71        29\n        VERB       0.15      0.06      0.09        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.49      1057\n   macro avg       0.32      0.32      0.31      1057\nweighted avg       0.42      0.49      0.44      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.14      0.15      0.14       137\n         ADP       0.72      0.86      0.78       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.62      0.80      0.70        69\n       CCONJ       0.75      0.50      0.60        36\n         DET       0.50      0.02      0.04        44\n        NOUN       0.46      0.69      0.55       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.22      0.07      0.11        29\n       PROPN       0.24      0.21      0.22        68\n       PUNCT       0.86      0.99      0.92       137\n       SCONJ       0.76      0.66      0.70        29\n        VERB       0.17      0.07      0.10        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.50      1057\n   macro avg       0.36      0.33      0.32      1057\nweighted avg       0.45      0.50      0.46      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.16      0.18      0.17       137\n         ADP       0.71      0.85      0.78       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.61      0.80      0.69        69\n       CCONJ       0.75      0.50      0.60        36\n         DET       0.50      0.02      0.04        44\n        NOUN       0.46      0.68      0.55       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.14      0.03      0.06        29\n       PROPN       0.26      0.22      0.24        68\n       PUNCT       0.86      0.99      0.92       137\n       SCONJ       0.73      0.66      0.69        29\n        VERB       0.19      0.08      0.11        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.50      1057\n   macro avg       0.36      0.33      0.32      1057\nweighted avg       0.45      0.50      0.46      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.16      0.18      0.17       137\n         ADP       0.72      0.85      0.78       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.61      0.80      0.69        69\n       CCONJ       0.76      0.53      0.62        36\n         DET       0.50      0.02      0.04        44\n        NOUN       0.46      0.67      0.54       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.12      0.03      0.05        29\n       PROPN       0.27      0.22      0.24        68\n       PUNCT       0.87      0.99      0.92       137\n       SCONJ       0.73      0.66      0.69        29\n        VERB       0.19      0.08      0.11        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.51      1057\n   macro avg       0.36      0.34      0.33      1057\nweighted avg       0.46      0.51      0.46      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.20      0.23      0.21       137\n         ADP       0.74      0.85      0.79       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.62      0.80      0.70        69\n       CCONJ       0.81      0.58      0.68        36\n         DET       0.50      0.02      0.04        44\n        NOUN       0.47      0.67      0.55       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.25      0.07      0.11        29\n       PROPN       0.28      0.24      0.26        68\n       PUNCT       0.88      0.99      0.93       137\n       SCONJ       0.70      0.66      0.68        29\n        VERB       0.18      0.08      0.11        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.52      1057\n   macro avg       0.37      0.35      0.34      1057\nweighted avg       0.47      0.52      0.47      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.22      0.27      0.24       137\n         ADP       0.77      0.86      0.81       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.65      0.84      0.73        69\n       CCONJ       0.82      0.64      0.72        36\n         DET       0.33      0.02      0.04        44\n        NOUN       0.46      0.66      0.54       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.25      0.07      0.11        29\n       PROPN       0.31      0.26      0.29        68\n       PUNCT       0.89      0.99      0.94       137\n       SCONJ       0.69      0.69      0.69        29\n        VERB       0.15      0.06      0.09        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.52      1057\n   macro avg       0.37      0.36      0.35      1057\nweighted avg       0.47      0.52      0.48      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.23      0.30      0.26       137\n         ADP       0.77      0.84      0.80       100\n         ADV       0.00      0.00      0.00        28\n         AUX       0.64      0.84      0.72        69\n       CCONJ       0.83      0.69      0.76        36\n         DET       0.25      0.02      0.04        44\n        NOUN       0.48      0.67      0.56       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.30      0.10      0.15        29\n       PROPN       0.35      0.28      0.31        68\n       PUNCT       0.91      0.99      0.95       137\n       SCONJ       0.71      0.69      0.70        29\n        VERB       0.15      0.06      0.09        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.53      1057\n   macro avg       0.37      0.37      0.36      1057\nweighted avg       0.48      0.53      0.49      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.22      0.30      0.25       137\n         ADP       0.79      0.84      0.82       100\n         ADV       0.17      0.04      0.06        28\n         AUX       0.65      0.87      0.75        69\n       CCONJ       0.84      0.72      0.78        36\n         DET       0.25      0.02      0.04        44\n        NOUN       0.48      0.65      0.55       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.43      0.21      0.28        29\n       PROPN       0.39      0.31      0.34        68\n       PUNCT       0.91      0.99      0.95       137\n       SCONJ       0.71      0.69      0.70        29\n        VERB       0.17      0.07      0.10        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.54      1057\n   macro avg       0.40      0.38      0.37      1057\nweighted avg       0.49      0.54      0.50      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.23      0.31      0.27       137\n         ADP       0.78      0.84      0.81       100\n         ADV       0.12      0.04      0.06        28\n         AUX       0.65      0.87      0.75        69\n       CCONJ       0.85      0.78      0.81        36\n         DET       0.40      0.05      0.08        44\n        NOUN       0.48      0.66      0.56       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.50      0.24      0.33        29\n       PROPN       0.40      0.32      0.36        68\n       PUNCT       0.93      0.99      0.96       137\n       SCONJ       0.74      0.69      0.71        29\n        VERB       0.19      0.07      0.10        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.55      1057\n   macro avg       0.42      0.39      0.39      1057\nweighted avg       0.51      0.55      0.51      1057\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.24      0.31      0.27       137\n         ADP       0.79      0.83      0.81       100\n         ADV       0.12      0.04      0.06        28\n         AUX       0.64      0.87      0.74        69\n       CCONJ       0.85      0.78      0.81        36\n         DET       0.40      0.05      0.08        44\n        NOUN       0.49      0.65      0.56       254\n         NUM       0.00      0.00      0.00        14\n        PART       0.00      0.00      0.00         9\n        PRON       0.53      0.28      0.36        29\n       PROPN       0.43      0.38      0.40        68\n       PUNCT       0.93      0.99      0.96       137\n       SCONJ       0.77      0.69      0.73        29\n        VERB       0.20      0.08      0.12        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.55      1057\n   macro avg       0.43      0.40      0.39      1057\nweighted avg       0.51      0.55      0.52      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.66      0.39      0.49       137\n         ADP       1.00      0.94      0.97       100\n         ADV       0.86      0.21      0.34        28\n         AUX       0.93      0.99      0.96        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.89      0.70      0.78        44\n        NOUN       0.63      0.89      0.73       254\n         NUM       0.82      0.64      0.72        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.86      0.86      0.86        29\n       PROPN       0.80      0.88      0.84        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.76      0.97      0.85        29\n        VERB       0.79      0.61      0.69        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.79      1057\n   macro avg       0.80      0.72      0.74      1057\nweighted avg       0.80      0.79      0.78      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.45      0.58       137\n         ADP       0.99      0.94      0.96       100\n         ADV       0.87      0.46      0.60        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.38      0.91      0.53        44\n        NOUN       0.79      0.84      0.82       254\n         NUM       1.00      0.71      0.83        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.93      0.90      0.91        29\n       PROPN       0.81      0.96      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.78      0.77      0.77        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.83      1057\n   macro avg       0.82      0.78      0.78      1057\nweighted avg       0.85      0.83      0.83      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.64      0.87      0.73       137\n         ADP       1.00      0.95      0.97       100\n         ADV       0.88      0.75      0.81        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.84      0.88        44\n        NOUN       0.91      0.70      0.79       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.90      0.93      0.92        29\n       PROPN       0.82      0.97      0.89        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.93      0.97      0.95        29\n        VERB       0.77      0.88      0.82        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.87      1057\n   macro avg       0.85      0.83      0.84      1057\nweighted avg       0.88      0.87      0.87      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.79      0.69      0.74       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.88      0.79      0.83        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.91      0.89      0.90        44\n        NOUN       0.79      0.90      0.84       254\n         NUM       0.92      0.86      0.89        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.83      0.91      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.87      0.76      0.81        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.88      1057\n   macro avg       0.86      0.83      0.84      1057\nweighted avg       0.88      0.88      0.88      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.68      0.85      0.76       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.78      0.75      0.76        28\n         AUX       0.97      1.00      0.99        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.94      0.77      0.85        44\n        NOUN       0.93      0.80      0.86       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.90      0.90      0.90        29\n       PROPN       0.78      0.96      0.86        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.84      0.86      0.85        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.89      1057\n   macro avg       0.85      0.83      0.84      1057\nweighted avg       0.89      0.89      0.89      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.76      0.85      0.81       137\n         ADP       0.99      0.96      0.97       100\n         ADV       0.73      0.79      0.76        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.89      0.92        44\n        NOUN       0.89      0.84      0.87       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.90      0.95        29\n       PROPN       0.80      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.89      0.86      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.86      0.84      0.85      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.81      0.82      0.81       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.71      0.79      0.75        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.89      0.92        44\n        NOUN       0.90      0.85      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.85      0.91      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.86      0.85      0.85      1057\nweighted avg       0.90      0.91      0.90      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.77      0.82       137\n         ADP       1.00      0.98      0.99       100\n         ADV       0.72      0.75      0.74        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.91      0.93      0.92        44\n        NOUN       0.88      0.87      0.87       254\n         NUM       0.92      0.86      0.89        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.79      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.84      0.91      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.85      0.85      0.85      1057\nweighted avg       0.90      0.91      0.90      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.81      0.83      0.82       137\n         ADP       0.99      0.96      0.97       100\n         ADV       0.72      0.75      0.74        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.91      0.92        44\n        NOUN       0.90      0.84      0.87       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.78      0.99      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.86      0.87      0.86        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.85      0.85      0.85      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.81      0.80      0.81       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.64      0.75      0.69        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.84      0.89        44\n        NOUN       0.89      0.86      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.79      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.86      0.90      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.85      0.84      0.85      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.84      0.82      0.83       137\n         ADP       1.00      0.97      0.98       100\n         ADV       0.68      0.75      0.71        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.89      0.91        44\n        NOUN       0.89      0.85      0.87       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.84      0.90      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.85      0.85      0.85      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.80      0.82      0.81       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.84      0.57      0.68        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.91      0.93        44\n        NOUN       0.86      0.91      0.88       254\n         NUM       1.00      0.79      0.88        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.90      0.93        29\n       PROPN       0.82      0.90      0.86        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.86      0.85      0.86        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.86      0.82      0.84      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.84      0.84       137\n         ADP       0.99      0.97      0.98       100\n         ADV       0.69      0.71      0.70        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.93      0.93        44\n        NOUN       0.90      0.85      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.81      0.97      0.89        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.85      0.89      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.86      0.85      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.84      0.84      0.84       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.69      0.71      0.70        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.89      0.91        44\n        NOUN       0.89      0.86      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.86      0.87      0.86        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.85      0.84      0.85      1057\nweighted avg       0.90      0.91      0.90      1057\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.86      0.84       137\n         ADP       0.99      0.96      0.97       100\n         ADV       0.71      0.79      0.75        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.91      0.92        44\n        NOUN       0.91      0.84      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.87      0.90      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.86      0.85      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.77      0.72      0.75       137\n         ADP       0.99      0.98      0.98       100\n         ADV       0.83      0.68      0.75        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.82      0.93      0.87        44\n        NOUN       0.92      0.76      0.83       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.73      0.97      0.84        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.93      0.97      0.95        29\n        VERB       0.69      0.95      0.80        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.88      1057\n   macro avg       0.84      0.83      0.83      1057\nweighted avg       0.88      0.88      0.87      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.75      0.85      0.80       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.72      0.75      0.74        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.86      0.89        44\n        NOUN       0.90      0.82      0.86       254\n         NUM       0.92      0.86      0.89        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.88      0.89      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.85      0.84      0.84      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.73      0.83      0.78       137\n         ADP       0.97      0.97      0.97       100\n         ADV       0.56      0.71      0.63        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.97      0.66      0.78        44\n        NOUN       0.88      0.80      0.84       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.88      0.84        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.83      1.00      0.91        29\n        VERB       0.82      0.85      0.83        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.87      1057\n   macro avg       0.83      0.82      0.82      1057\nweighted avg       0.88      0.87      0.87      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.80      0.83      0.81       137\n         ADP       1.00      0.97      0.98       100\n         ADV       0.67      0.79      0.72        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.89      0.92        44\n        NOUN       0.90      0.85      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.78      0.96      0.86        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.90      0.88      0.89        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.86      0.85      0.85      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.80      0.84      0.82       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.61      0.79      0.69        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.89      0.92        44\n        NOUN       0.93      0.84      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.78      0.99      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.87      0.89      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.85      0.85      0.85      1057\nweighted avg       0.91      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.77      0.83       137\n         ADP       0.98      0.99      0.99       100\n         ADV       0.88      0.75      0.81        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.89      0.91        44\n        NOUN       0.86      0.90      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.78      0.96      0.86        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.97      1.00      0.98        29\n        VERB       0.84      0.88      0.86        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.84      0.86      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.87      0.85       137\n         ADP       0.99      0.98      0.98       100\n         ADV       0.70      0.75      0.72        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.89      0.92        44\n        NOUN       0.91      0.87      0.89       254\n         NUM       0.92      0.86      0.89        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.79      0.96      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.88      0.86      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.85      0.85      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.79      0.86      0.82       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.86      0.68      0.76        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.89      0.92        44\n        NOUN       0.90      0.86      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.80      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.88      0.89      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.84      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.81      0.82       137\n         ADP       0.99      0.99      0.99       100\n         ADV       0.77      0.71      0.74        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.91      0.91      0.91        44\n        NOUN       0.90      0.85      0.87       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.77      0.99      0.86        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.81      0.86      0.83        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.86      0.84      0.85      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.79      0.83      0.81       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.88      0.79      0.83        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.91      0.93        44\n        NOUN       0.91      0.85      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.76      0.99      0.86        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.97      1.00      0.98        29\n        VERB       0.86      0.90      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.85      0.86      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.73      0.90      0.80       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.83      0.71      0.77        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.86      0.90        44\n        NOUN       0.92      0.81      0.86       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.79      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.85      0.86      0.85        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.86      0.84      0.85      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.85      0.84       137\n         ADP       1.00      0.99      0.99       100\n         ADV       0.83      0.71      0.77        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.86      0.89        44\n        NOUN       0.89      0.89      0.89       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.81      0.93      0.86        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.88      0.88      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.84      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.82      0.85       137\n         ADP       1.00      0.98      0.99       100\n         ADV       0.83      0.71      0.77        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.84      0.88        44\n        NOUN       0.90      0.91      0.90       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.81      0.99      0.89        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.86      0.91      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.92      1057\n   macro avg       0.87      0.85      0.86      1057\nweighted avg       0.92      0.92      0.92      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.81      0.85      0.83       137\n         ADP       1.00      0.97      0.98       100\n         ADV       0.85      0.79      0.81        28\n         AUX       0.97      1.00      0.99        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.86      0.89        44\n        NOUN       0.89      0.88      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.81      0.97      0.89        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.89      0.87      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.85      0.86      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.85      0.84      0.84       137\n         ADP       1.00      0.99      0.99       100\n         ADV       0.76      0.79      0.77        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.84      0.88        44\n        NOUN       0.90      0.88      0.89       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       1.00      0.93      0.96        29\n       PROPN       0.80      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.86      0.90      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.85      0.86      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.79      0.84       137\n         ADP       0.99      1.00      1.00       100\n         ADV       0.61      0.71      0.66        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.89      0.91        44\n        NOUN       0.90      0.89      0.89       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.93      0.93      0.93        29\n       PROPN       0.80      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.83      0.88      0.85        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.85      0.85      0.84      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.72      0.79       137\n         ADP       0.99      0.98      0.98       100\n         ADV       0.78      0.75      0.76        28\n         AUX       0.97      0.99      0.98        69\n       CCONJ       1.00      1.00      1.00        36\n         DET       0.95      0.84      0.89        44\n        NOUN       0.87      0.89      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.93      0.93      0.93        29\n       PROPN       0.79      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.78      0.88      0.83        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.86      0.84      0.84      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.82      0.83      0.83       137\n         ADP       1.00      0.98      0.99       100\n         ADV       0.86      0.68      0.76        28\n         AUX       0.94      0.99      0.96        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.84      0.89        44\n        NOUN       0.87      0.90      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.93      0.93      0.93        29\n       PROPN       0.82      0.87      0.84        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.84      0.87      0.85        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.90      1057\n   macro avg       0.86      0.83      0.85      1057\nweighted avg       0.90      0.90      0.90      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.82      0.83       137\n         ADP       0.98      1.00      0.99       100\n         ADV       0.90      0.64      0.75        28\n         AUX       0.97      0.99      0.98        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.91      0.93        44\n        NOUN       0.89      0.87      0.88       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.79      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.84      0.90      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.84      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.85      0.82      0.84       137\n         ADP       0.98      0.97      0.97       100\n         ADV       0.76      0.79      0.77        28\n         AUX       0.96      0.99      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.89      0.91        44\n        NOUN       0.89      0.88      0.89       254\n         NUM       1.00      0.93      0.96        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.88      0.86      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.86      0.85      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.84      0.84       137\n         ADP       0.99      0.97      0.98       100\n         ADV       0.88      0.75      0.81        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       0.97      1.00      0.99        36\n         DET       0.93      0.91      0.92        44\n        NOUN       0.89      0.87      0.88       254\n         NUM       1.00      0.93      0.96        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.82      0.99      0.89        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.97      1.00      0.98        29\n        VERB       0.87      0.88      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.86      0.86      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.83      0.83      0.83       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.90      0.68      0.78        28\n         AUX       0.96      0.99      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.84      0.88        44\n        NOUN       0.88      0.89      0.89       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.78      0.99      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.97      1.00      0.98        29\n        VERB       0.85      0.87      0.86        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.84      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.82      0.84       137\n         ADP       0.97      0.98      0.98       100\n         ADV       0.79      0.82      0.81        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.90      0.86      0.88        44\n        NOUN       0.90      0.88      0.89       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.78      0.99      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.97      1.00      0.98        29\n        VERB       0.89      0.88      0.88        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.86      0.85      0.86      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.81      0.82      0.82       137\n         ADP       1.00      0.96      0.98       100\n         ADV       0.73      0.79      0.76        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.86      0.90        44\n        NOUN       0.91      0.87      0.89       254\n         NUM       1.00      0.93      0.96        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.78      0.99      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.87      0.87      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.86      0.85      0.85      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.82      0.85      0.83       137\n         ADP       0.99      0.99      0.99       100\n         ADV       0.81      0.79      0.80        28\n         AUX       0.96      0.99      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.95      0.86      0.90        44\n        NOUN       0.91      0.88      0.89       254\n         NUM       1.00      0.93      0.96        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.89      0.89      0.89        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.92      1057\n   macro avg       0.87      0.86      0.86      1057\nweighted avg       0.91      0.92      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.83      0.84       137\n         ADP       1.00      1.00      1.00       100\n         ADV       0.76      0.79      0.77        28\n         AUX       0.95      1.00      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.91      0.92        44\n        NOUN       0.90      0.87      0.89       254\n         NUM       1.00      0.93      0.96        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.81      0.96      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.85      0.89      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.86      0.86      0.86      1057\nweighted avg       0.91      0.91      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.82      0.85       137\n         ADP       0.98      0.99      0.99       100\n         ADV       0.79      0.82      0.81        28\n         AUX       0.96      1.00      0.98        69\n       CCONJ       0.97      0.97      0.97        36\n         DET       0.95      0.91      0.93        44\n        NOUN       0.90      0.88      0.89       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.87      0.91      0.89        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.92      1057\n   macro avg       0.87      0.86      0.86      1057\nweighted avg       0.91      0.92      0.91      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.82      0.85       137\n         ADP       1.00      0.99      0.99       100\n         ADV       0.81      0.79      0.80        28\n         AUX       0.93      0.99      0.96        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.86      0.89        44\n        NOUN       0.90      0.90      0.90       254\n         NUM       1.00      0.86      0.92        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.97      0.87        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.91      1.00      0.95        29\n        VERB       0.87      0.92      0.90        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.92      1057\n   macro avg       0.87      0.85      0.86      1057\nweighted avg       0.92      0.92      0.92      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.80      0.84       137\n         ADP       0.98      1.00      0.99       100\n         ADV       0.72      0.75      0.74        28\n         AUX       0.92      0.99      0.95        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.89      0.93      0.91        44\n        NOUN       0.93      0.84      0.88       254\n         NUM       1.00      0.93      0.96        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.90      0.93      0.92        29\n       PROPN       0.80      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.88      1.00      0.94        29\n        VERB       0.79      0.91      0.84        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.85      0.85      0.85      1057\nweighted avg       0.91      0.91      0.90      1057\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.85      0.84      0.84       137\n         ADP       0.99      0.98      0.98       100\n         ADV       0.92      0.79      0.85        28\n         AUX       0.96      0.99      0.97        69\n       CCONJ       1.00      0.97      0.99        36\n         DET       0.93      0.89      0.91        44\n        NOUN       0.89      0.87      0.88       254\n         NUM       1.00      0.93      0.96        14\n        PART       1.00      0.78      0.88         9\n        PRON       0.96      0.93      0.95        29\n       PROPN       0.80      0.99      0.88        68\n       PUNCT       1.00      1.00      1.00       137\n       SCONJ       0.94      1.00      0.97        29\n        VERB       0.86      0.89      0.87        98\n           X       0.00      0.00      0.00         5\n\n    accuracy                           0.91      1057\n   macro avg       0.87      0.86      0.86      1057\nweighted avg       0.91      0.91      0.91      1057\n"}]