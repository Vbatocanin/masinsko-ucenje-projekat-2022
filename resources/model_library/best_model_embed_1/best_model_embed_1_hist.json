[{"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.36      0.64      0.46       748\n         ADP       0.99      0.75      0.86       559\n         ADV       0.13      0.02      0.04       189\n         AUX       0.62      0.85      0.72       385\n       CCONJ       0.95      0.90      0.93       199\n         DET       0.82      0.04      0.08       214\n        INTJ       0.00      0.00      0.00         1\n        NOUN       0.63      0.58      0.60      1459\n         NUM       0.00      0.00      0.00        98\n        PART       0.00      0.00      0.00        31\n        PRON       1.00      0.64      0.78       151\n       PROPN       0.62      0.51      0.56       374\n       PUNCT       0.95      0.99      0.97       721\n       SCONJ       0.83      0.66      0.74       188\n        VERB       0.34      0.47      0.39       494\n           X       0.00      0.00      0.00        26\n\n    accuracy                           0.62      5837\n   macro avg       0.51      0.44      0.44      5837\nweighted avg       0.64      0.62      0.61      5837\n"}]