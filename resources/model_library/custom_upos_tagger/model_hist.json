[{"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.25      0.41      0.31       312\n         ADP       0.50      0.51      0.50       242\n         ADV       0.09      0.09      0.09        80\n         AUX       0.63      0.31      0.42       145\n       CCONJ       0.24      0.05      0.08        88\n         DET       0.00      0.00      0.00       109\n        NOUN       0.43      0.62      0.50       621\n         NUM       0.00      0.00      0.00        38\n        PART       0.00      0.00      0.00        14\n        PRON       0.15      0.07      0.10        57\n       PROPN       0.16      0.11      0.13       148\n       PUNCT       0.72      0.99      0.83       306\n       SCONJ       0.00      0.00      0.00        72\n        VERB       0.05      0.02      0.02       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.42      2434\n   macro avg       0.21      0.21      0.20      2434\nweighted avg       0.35      0.42      0.37      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.34      0.55      0.42       312\n         ADP       0.79      0.79      0.79       242\n         ADV       0.16      0.09      0.11        80\n         AUX       0.66      0.71      0.69       145\n       CCONJ       0.78      0.85      0.82        88\n         DET       0.00      0.00      0.00       109\n        NOUN       0.51      0.65      0.57       621\n         NUM       0.00      0.00      0.00        38\n        PART       0.00      0.00      0.00        14\n        PRON       0.32      0.11      0.16        57\n       PROPN       0.41      0.11      0.17       148\n       PUNCT       0.91      0.99      0.95       306\n       SCONJ       0.63      0.44      0.52        72\n        VERB       0.27      0.23      0.25       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.55      2434\n   macro avg       0.38      0.37      0.36      2434\nweighted avg       0.51      0.55      0.52      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.38      0.59      0.46       312\n         ADP       0.82      0.81      0.82       242\n         ADV       0.23      0.07      0.11        80\n         AUX       0.71      0.78      0.74       145\n       CCONJ       0.79      0.88      0.83        88\n         DET       0.67      0.06      0.10       109\n        NOUN       0.54      0.69      0.61       621\n         NUM       0.00      0.00      0.00        38\n        PART       0.00      0.00      0.00        14\n        PRON       0.61      0.44      0.51        57\n       PROPN       0.67      0.30      0.42       148\n       PUNCT       0.93      0.99      0.96       306\n       SCONJ       0.61      0.50      0.55        72\n        VERB       0.29      0.23      0.25       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.60      2434\n   macro avg       0.48      0.42      0.42      2434\nweighted avg       0.59      0.60      0.57      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.40      0.59      0.48       312\n         ADP       0.83      0.82      0.82       242\n         ADV       0.21      0.05      0.08        80\n         AUX       0.75      0.80      0.77       145\n       CCONJ       0.80      0.88      0.84        88\n         DET       0.62      0.09      0.16       109\n        NOUN       0.56      0.70      0.62       621\n         NUM       0.00      0.00      0.00        38\n        PART       0.00      0.00      0.00        14\n        PRON       0.72      0.67      0.69        57\n       PROPN       0.70      0.45      0.55       148\n       PUNCT       0.95      0.99      0.97       306\n       SCONJ       0.71      0.58      0.64        72\n        VERB       0.34      0.28      0.31       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.63      2434\n   macro avg       0.51      0.46      0.46      2434\nweighted avg       0.61      0.63      0.60      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.41      0.59      0.48       312\n         ADP       0.86      0.83      0.85       242\n         ADV       0.25      0.04      0.07        80\n         AUX       0.77      0.81      0.79       145\n       CCONJ       0.81      0.88      0.84        88\n         DET       0.65      0.14      0.23       109\n        NOUN       0.57      0.70      0.63       621\n         NUM       0.00      0.00      0.00        38\n        PART       0.14      0.07      0.10        14\n        PRON       0.75      0.72      0.73        57\n       PROPN       0.71      0.54      0.61       148\n       PUNCT       0.96      0.99      0.97       306\n       SCONJ       0.75      0.62      0.68        72\n        VERB       0.35      0.30      0.33       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.64      2434\n   macro avg       0.53      0.48      0.49      2434\nweighted avg       0.63      0.64      0.62      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.42      0.59      0.49       312\n         ADP       0.87      0.83      0.85       242\n         ADV       0.38      0.04      0.07        80\n         AUX       0.78      0.82      0.80       145\n       CCONJ       0.84      0.89      0.86        88\n         DET       0.66      0.19      0.30       109\n        NOUN       0.59      0.70      0.64       621\n         NUM       0.50      0.03      0.05        38\n        PART       0.14      0.07      0.10        14\n        PRON       0.79      0.72      0.75        57\n       PROPN       0.69      0.65      0.67       148\n       PUNCT       0.96      0.99      0.98       306\n       SCONJ       0.75      0.64      0.69        72\n        VERB       0.39      0.35      0.37       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.66      2434\n   macro avg       0.58      0.50      0.51      2434\nweighted avg       0.65      0.66      0.64      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.43      0.60      0.50       312\n         ADP       0.88      0.83      0.86       242\n         ADV       0.38      0.04      0.07        80\n         AUX       0.79      0.82      0.80       145\n       CCONJ       0.84      0.89      0.86        88\n         DET       0.59      0.20      0.30       109\n        NOUN       0.60      0.70      0.64       621\n         NUM       0.50      0.03      0.05        38\n        PART       0.14      0.07      0.10        14\n        PRON       0.81      0.74      0.77        57\n       PROPN       0.68      0.70      0.69       148\n       PUNCT       0.96      0.99      0.98       306\n       SCONJ       0.77      0.67      0.72        72\n        VERB       0.40      0.36      0.38       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.66      2434\n   macro avg       0.58      0.51      0.51      2434\nweighted avg       0.66      0.66      0.64      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.44      0.60      0.51       312\n         ADP       0.88      0.84      0.86       242\n         ADV       0.33      0.04      0.07        80\n         AUX       0.79      0.83      0.81       145\n       CCONJ       0.84      0.88      0.86        88\n         DET       0.62      0.23      0.34       109\n        NOUN       0.61      0.71      0.66       621\n         NUM       0.33      0.03      0.05        38\n        PART       0.17      0.07      0.10        14\n        PRON       0.81      0.74      0.77        57\n       PROPN       0.70      0.74      0.72       148\n       PUNCT       0.96      0.99      0.98       306\n       SCONJ       0.80      0.67      0.73        72\n        VERB       0.42      0.37      0.39       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.67      2434\n   macro avg       0.58      0.51      0.52      2434\nweighted avg       0.66      0.67      0.65      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.44      0.61      0.51       312\n         ADP       0.90      0.85      0.87       242\n         ADV       0.25      0.03      0.05        80\n         AUX       0.81      0.84      0.83       145\n       CCONJ       0.86      0.88      0.87        88\n         DET       0.64      0.28      0.38       109\n        NOUN       0.61      0.72      0.66       621\n         NUM       0.00      0.00      0.00        38\n        PART       0.17      0.07      0.10        14\n        PRON       0.82      0.74      0.78        57\n       PROPN       0.72      0.74      0.73       148\n       PUNCT       0.96      0.99      0.98       306\n       SCONJ       0.83      0.69      0.76        72\n        VERB       0.43      0.37      0.40       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.68      2434\n   macro avg       0.56      0.52      0.53      2434\nweighted avg       0.66      0.68      0.66      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.44      0.62      0.52       312\n         ADP       0.88      0.85      0.86       242\n         ADV       0.20      0.03      0.04        80\n         AUX       0.84      0.84      0.84       145\n       CCONJ       0.86      0.88      0.87        88\n         DET       0.64      0.29      0.40       109\n        NOUN       0.62      0.72      0.67       621\n         NUM       0.33      0.05      0.09        38\n        PART       0.17      0.07      0.10        14\n        PRON       0.86      0.74      0.79        57\n       PROPN       0.74      0.75      0.74       148\n       PUNCT       0.96      0.99      0.98       306\n       SCONJ       0.86      0.75      0.80        72\n        VERB       0.46      0.37      0.41       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.68      2434\n   macro avg       0.59      0.53      0.54      2434\nweighted avg       0.67      0.68      0.67      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.45      0.61      0.52       312\n         ADP       0.88      0.86      0.87       242\n         ADV       0.27      0.04      0.07        80\n         AUX       0.84      0.84      0.84       145\n       CCONJ       0.88      0.88      0.88        88\n         DET       0.62      0.32      0.42       109\n        NOUN       0.62      0.72      0.67       621\n         NUM       0.43      0.08      0.13        38\n        PART       0.17      0.07      0.10        14\n        PRON       0.84      0.74      0.79        57\n       PROPN       0.72      0.76      0.74       148\n       PUNCT       0.96      0.99      0.98       306\n       SCONJ       0.87      0.75      0.81        72\n        VERB       0.47      0.39      0.43       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.69      2434\n   macro avg       0.60      0.54      0.55      2434\nweighted avg       0.68      0.69      0.67      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.46      0.62      0.52       312\n         ADP       0.89      0.86      0.87       242\n         ADV       0.33      0.05      0.09        80\n         AUX       0.84      0.85      0.84       145\n       CCONJ       0.89      0.88      0.88        88\n         DET       0.66      0.35      0.46       109\n        NOUN       0.63      0.72      0.67       621\n         NUM       0.50      0.11      0.17        38\n        PART       0.17      0.07      0.10        14\n        PRON       0.84      0.75      0.80        57\n       PROPN       0.73      0.76      0.75       148\n       PUNCT       0.96      0.99      0.98       306\n       SCONJ       0.88      0.78      0.82        72\n        VERB       0.50      0.42      0.46       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.70      2434\n   macro avg       0.62      0.55      0.56      2434\nweighted avg       0.69      0.70      0.68      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.46      0.62      0.53       312\n         ADP       0.89      0.86      0.88       242\n         ADV       0.30      0.04      0.07        80\n         AUX       0.84      0.85      0.85       145\n       CCONJ       0.90      0.88      0.89        88\n         DET       0.65      0.34      0.45       109\n        NOUN       0.63      0.72      0.67       621\n         NUM       0.50      0.11      0.17        38\n        PART       0.17      0.07      0.10        14\n        PRON       0.83      0.75      0.79        57\n       PROPN       0.72      0.76      0.74       148\n       PUNCT       0.97      0.99      0.98       306\n       SCONJ       0.86      0.78      0.82        72\n        VERB       0.50      0.43      0.46       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.70      2434\n   macro avg       0.61      0.55      0.56      2434\nweighted avg       0.69      0.70      0.68      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.47      0.62      0.53       312\n         ADP       0.89      0.86      0.88       242\n         ADV       0.31      0.05      0.09        80\n         AUX       0.86      0.84      0.85       145\n       CCONJ       0.90      0.88      0.89        88\n         DET       0.64      0.35      0.45       109\n        NOUN       0.63      0.73      0.68       621\n         NUM       0.50      0.11      0.17        38\n        PART       0.17      0.07      0.10        14\n        PRON       0.83      0.75      0.79        57\n       PROPN       0.73      0.81      0.77       148\n       PUNCT       0.96      0.99      0.98       306\n       SCONJ       0.86      0.78      0.82        72\n        VERB       0.53      0.44      0.48       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.70      2434\n   macro avg       0.62      0.55      0.56      2434\nweighted avg       0.69      0.70      0.69      2434\n"}, {"params": {"learning_rate": 0.001, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.46      0.62      0.53       312\n         ADP       0.89      0.86      0.88       242\n         ADV       0.43      0.07      0.13        80\n         AUX       0.86      0.84      0.85       145\n       CCONJ       0.90      0.88      0.89        88\n         DET       0.66      0.35      0.46       109\n        NOUN       0.64      0.73      0.68       621\n         NUM       0.60      0.16      0.25        38\n        PART       0.17      0.07      0.10        14\n        PRON       0.83      0.75      0.79        57\n       PROPN       0.73      0.80      0.77       148\n       PUNCT       0.97      0.99      0.98       306\n       SCONJ       0.85      0.78      0.81        72\n        VERB       0.53      0.46      0.49       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.70      2434\n   macro avg       0.63      0.56      0.57      2434\nweighted avg       0.70      0.70      0.69      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.69      0.86      0.77       312\n         ADP       0.99      0.91      0.95       242\n         ADV       0.80      0.50      0.62        80\n         AUX       0.96      0.99      0.97       145\n       CCONJ       0.97      0.94      0.95        88\n         DET       0.94      0.70      0.80       109\n        NOUN       0.87      0.79      0.82       621\n         NUM       0.97      0.84      0.90        38\n        PART       0.91      0.71      0.80        14\n        PRON       0.82      0.98      0.90        57\n       PROPN       0.83      0.91      0.87       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.94      0.90      0.92        72\n        VERB       0.68      0.85      0.75       191\n           X       1.00      0.55      0.71        11\n\n    accuracy                           0.86      2434\n   macro avg       0.89      0.83      0.85      2434\nweighted avg       0.87      0.86      0.86      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.82      0.84       312\n         ADP       0.96      0.98      0.97       242\n         ADV       0.71      0.71      0.71        80\n         AUX       0.97      0.99      0.98       145\n       CCONJ       0.98      0.97      0.97        88\n         DET       0.92      0.89      0.91       109\n        NOUN       0.87      0.89      0.88       621\n         NUM       0.92      0.92      0.92        38\n        PART       0.92      0.79      0.85        14\n        PRON       0.78      0.98      0.87        57\n       PROPN       0.89      0.93      0.91       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.96      0.96      0.96        72\n        VERB       0.86      0.80      0.83       191\n           X       1.00      0.09      0.17        11\n\n    accuracy                           0.90      2434\n   macro avg       0.91      0.85      0.85      2434\nweighted avg       0.90      0.90      0.90      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.74      0.80       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.68      0.72      0.70        80\n         AUX       0.95      1.00      0.98       145\n       CCONJ       0.97      0.98      0.97        88\n         DET       0.85      0.90      0.88       109\n        NOUN       0.86      0.90      0.88       621\n         NUM       0.90      0.92      0.91        38\n        PART       1.00      0.86      0.92        14\n        PRON       0.93      0.98      0.96        57\n       PROPN       0.91      0.91      0.91       148\n       PUNCT       0.99      1.00      0.99       306\n       SCONJ       0.92      0.99      0.95        72\n        VERB       0.84      0.83      0.83       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.90      2434\n   macro avg       0.84      0.85      0.84      2434\nweighted avg       0.90      0.90      0.90      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.85      0.86       312\n         ADP       0.97      0.99      0.98       242\n         ADV       0.88      0.61      0.72        80\n         AUX       0.99      0.99      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.92      0.87      0.90       109\n        NOUN       0.87      0.93      0.90       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.92      0.93      0.93       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.95      0.99      0.97        72\n        VERB       0.88      0.86      0.87       191\n           X       1.00      0.27      0.43        11\n\n    accuracy                           0.92      2434\n   macro avg       0.94      0.86      0.89      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.87      0.87       312\n         ADP       0.99      0.98      0.99       242\n         ADV       0.89      0.69      0.77        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.92      0.91      0.91       109\n        NOUN       0.89      0.92      0.90       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.93      0.93      0.93       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.93      0.99      0.96        72\n        VERB       0.87      0.85      0.86       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.92      2434\n   macro avg       0.92      0.87      0.89      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.80      0.85       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.86      0.69      0.76        80\n         AUX       0.97      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.92      0.93       109\n        NOUN       0.86      0.93      0.89       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.93      0.98      0.96        57\n       PROPN       0.91      0.92      0.92       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.91      1.00      0.95        72\n        VERB       0.86      0.84      0.85       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.92      2434\n   macro avg       0.92      0.87      0.88      2434\nweighted avg       0.92      0.92      0.91      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.83      0.86       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.81      0.71      0.76        80\n         AUX       0.98      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.92      0.93      0.92       109\n        NOUN       0.87      0.91      0.89       621\n         NUM       0.90      0.92      0.91        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.90      0.92      0.91       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.95      1.00      0.97        72\n        VERB       0.85      0.83      0.84       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.92      2434\n   macro avg       0.92      0.87      0.88      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.85      0.86       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.81      0.70      0.75        80\n         AUX       0.98      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.96      0.89      0.92       109\n        NOUN       0.88      0.93      0.90       621\n         NUM       0.92      0.89      0.91        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.92      0.91      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.93      0.99      0.96        72\n        VERB       0.86      0.84      0.85       191\n           X       1.00      0.27      0.43        11\n\n    accuracy                           0.92      2434\n   macro avg       0.94      0.87      0.89      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.86      0.88       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.83      0.71      0.77        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.94      0.94       109\n        NOUN       0.88      0.93      0.90       621\n         NUM       0.92      0.92      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.95      0.98      0.97        57\n       PROPN       0.90      0.91      0.91       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.88      0.84      0.86       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.92      2434\n   macro avg       0.87      0.86      0.86      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.85      0.86       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.84      0.71      0.77        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.93      0.90      0.92       109\n        NOUN       0.88      0.92      0.90       621\n         NUM       0.94      0.89      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.90      0.93      0.91       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.86      0.84      0.85       191\n           X       1.00      0.27      0.43        11\n\n    accuracy                           0.92      2434\n   macro avg       0.94      0.87      0.89      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.86      0.86       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.80      0.71      0.75        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.95      0.88      0.91       109\n        NOUN       0.88      0.92      0.90       621\n         NUM       0.92      0.87      0.89        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.91      0.92      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      1.00      0.98        72\n        VERB       0.85      0.84      0.85       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.92      2434\n   macro avg       0.92      0.87      0.88      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.85      0.86       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.89      0.70      0.78        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.96      0.97      0.96        88\n         DET       0.93      0.90      0.92       109\n        NOUN       0.88      0.92      0.90       621\n         NUM       0.89      0.87      0.88        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.90      0.93      0.91       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.93      0.99      0.96        72\n        VERB       0.84      0.84      0.84       191\n           X       0.67      0.18      0.29        11\n\n    accuracy                           0.92      2434\n   macro avg       0.91      0.86      0.87      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.86      0.87       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.83      0.72      0.77        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.95      0.90      0.92       109\n        NOUN       0.89      0.92      0.90       621\n         NUM       0.89      0.89      0.89        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.91      0.93      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.85      0.85      0.85       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.92      2434\n   macro avg       0.92      0.87      0.89      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.88      0.87       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.83      0.69      0.75        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.97      0.96        88\n         DET       0.94      0.90      0.92       109\n        NOUN       0.88      0.91      0.90       621\n         NUM       0.89      0.89      0.89        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.90      0.93      0.91       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.95      0.99      0.97        72\n        VERB       0.87      0.83      0.85       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.92      2434\n   macro avg       0.92      0.87      0.88      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.20066666666666666, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.87      0.87       312\n         ADP       0.98      0.98      0.98       242\n         ADV       0.85      0.69      0.76        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.92      0.89      0.91       109\n        NOUN       0.88      0.91      0.89       621\n         NUM       0.92      0.87      0.89        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.90      0.92      0.91       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.85      0.83      0.84       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.92      2434\n   macro avg       0.92      0.86      0.88      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.84      0.88      0.86       312\n         ADP       0.98      0.99      0.98       242\n         ADV       0.75      0.72      0.74        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.95      0.98      0.96        88\n         DET       0.93      0.91      0.92       109\n        NOUN       0.91      0.90      0.91       621\n         NUM       0.97      0.84      0.90        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.93      0.91      0.92       148\n       PUNCT       0.99      1.00      0.99       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.87      0.86      0.87       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.92      2434\n   macro avg       0.87      0.85      0.86      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.84      0.87       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.82      0.74      0.78        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.97      0.98      0.97        88\n         DET       0.94      0.94      0.94       109\n        NOUN       0.88      0.92      0.90       621\n         NUM       0.92      0.87      0.89        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.90      0.93      0.92       148\n       PUNCT       0.98      1.00      0.99       306\n       SCONJ       0.95      0.99      0.97        72\n        VERB       0.86      0.83      0.84       191\n           X       0.86      0.55      0.67        11\n\n    accuracy                           0.92      2434\n   macro avg       0.93      0.89      0.90      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.87      0.89       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.83      0.71      0.77        80\n         AUX       0.97      1.00      0.99       145\n       CCONJ       0.97      0.98      0.97        88\n         DET       0.95      0.92      0.93       109\n        NOUN       0.89      0.93      0.91       621\n         NUM       0.94      0.89      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.93      0.91      0.92       148\n       PUNCT       0.98      1.00      0.99       306\n       SCONJ       0.92      0.99      0.95        72\n        VERB       0.88      0.87      0.88       191\n           X       1.00      0.55      0.71        11\n\n    accuracy                           0.93      2434\n   macro avg       0.94      0.89      0.91      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.82      0.86       312\n         ADP       0.98      1.00      0.99       242\n         ADV       0.82      0.70      0.76        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.90      0.95      0.93       109\n        NOUN       0.88      0.93      0.90       621\n         NUM       0.94      0.89      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.92      0.95      0.93       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.95      1.00      0.97        72\n        VERB       0.85      0.85      0.85       191\n           X       0.80      0.36      0.50        11\n\n    accuracy                           0.92      2434\n   macro avg       0.93      0.88      0.90      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.87      0.87       312\n         ADP       0.97      0.99      0.98       242\n         ADV       0.77      0.76      0.77        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.94      0.94       109\n        NOUN       0.90      0.91      0.90       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.92      0.91      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.87      0.89      0.88       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.93      2434\n   macro avg       0.87      0.86      0.87      2434\nweighted avg       0.92      0.93      0.92      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.86      0.87       312\n         ADP       0.99      0.99      0.99       242\n         ADV       0.86      0.74      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.93      0.91      0.92       109\n        NOUN       0.89      0.93      0.91       621\n         NUM       0.89      0.89      0.89        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.93      0.92      0.93       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.96      1.00      0.98        72\n        VERB       0.87      0.86      0.87       191\n           X       1.00      0.36      0.53        11\n\n    accuracy                           0.93      2434\n   macro avg       0.94      0.88      0.90      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.87      0.87       312\n         ADP       0.98      0.99      0.98       242\n         ADV       0.84      0.71      0.77        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.93      0.94       109\n        NOUN       0.87      0.93      0.90       621\n         NUM       0.92      0.92      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.95      0.98      0.97        57\n       PROPN       0.94      0.90      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.97      0.99      0.98        72\n        VERB       0.92      0.85      0.89       191\n           X       0.00      0.00      0.00        11\n\n    accuracy                           0.93      2434\n   macro avg       0.88      0.86      0.87      2434\nweighted avg       0.92      0.93      0.92      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.90      0.90       312\n         ADP       0.99      0.99      0.99       242\n         ADV       0.85      0.69      0.76        80\n         AUX       0.97      1.00      0.99       145\n       CCONJ       0.97      0.98      0.97        88\n         DET       0.96      0.95      0.96       109\n        NOUN       0.89      0.94      0.91       621\n         NUM       0.90      0.92      0.91        38\n        PART       1.00      0.86      0.92        14\n        PRON       1.00      0.98      0.99        57\n       PROPN       0.94      0.92      0.93       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.92      0.99      0.95        72\n        VERB       0.93      0.83      0.88       191\n           X       1.00      0.27      0.43        11\n\n    accuracy                           0.93      2434\n   macro avg       0.95      0.88      0.90      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.90      0.89       312\n         ADP       0.99      0.99      0.99       242\n         ADV       0.83      0.75      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.96      0.92      0.94       109\n        NOUN       0.90      0.92      0.91       621\n         NUM       0.92      0.92      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.92      0.93      0.93       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.89      0.85      0.87       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.93      2434\n   macro avg       0.93      0.88      0.90      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.90      0.89       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.86      0.71      0.78        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.95      0.94      0.95       109\n        NOUN       0.90      0.94      0.91       621\n         NUM       0.90      0.92      0.91        38\n        PART       1.00      0.79      0.88        14\n        PRON       1.00      0.98      0.99        57\n       PROPN       0.93      0.93      0.93       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.93      0.99      0.96        72\n        VERB       0.93      0.82      0.87       191\n           X       0.80      0.36      0.50        11\n\n    accuracy                           0.93      2434\n   macro avg       0.93      0.88      0.90      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.87      0.88       312\n         ADP       0.99      0.99      0.99       242\n         ADV       0.88      0.74      0.80        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.96      0.93      0.94       109\n        NOUN       0.89      0.93      0.91       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.91      0.92      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.95      0.99      0.97        72\n        VERB       0.88      0.86      0.87       191\n           X       1.00      0.18      0.31        11\n\n    accuracy                           0.93      2434\n   macro avg       0.95      0.87      0.89      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.88      0.88       312\n         ADP       0.98      1.00      0.99       242\n         ADV       0.80      0.75      0.77        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.94      0.94       109\n        NOUN       0.91      0.92      0.91       621\n         NUM       0.92      0.92      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.91      0.93      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.97      1.00      0.99        72\n        VERB       0.90      0.84      0.87       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.93      2434\n   macro avg       0.93      0.88      0.89      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.89      0.89       312\n         ADP       0.99      0.99      0.99       242\n         ADV       0.87      0.74      0.80        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.94      0.94       109\n        NOUN       0.90      0.92      0.91       621\n         NUM       0.92      0.92      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       1.00      0.96      0.98        57\n       PROPN       0.93      0.93      0.93       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      1.00      0.98        72\n        VERB       0.86      0.85      0.85       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.93      2434\n   macro avg       0.93      0.88      0.90      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.87      0.88       312\n         ADP       0.98      1.00      0.99       242\n         ADV       0.83      0.75      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.97      0.98      0.97        88\n         DET       0.94      0.94      0.94       109\n        NOUN       0.90      0.92      0.91       621\n         NUM       0.92      0.87      0.89        38\n        PART       1.00      0.86      0.92        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.92      0.93      0.92       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.93      0.99      0.96        72\n        VERB       0.90      0.85      0.87       191\n           X       1.00      0.45      0.62        11\n\n    accuracy                           0.93      2434\n   macro avg       0.94      0.89      0.91      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.4003333333333333, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.89      0.88       312\n         ADP       1.00      1.00      1.00       242\n         ADV       0.89      0.71      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.97      0.98      0.97        88\n         DET       0.93      0.91      0.92       109\n        NOUN       0.89      0.93      0.91       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.86      0.92        14\n        PRON       0.96      0.96      0.96        57\n       PROPN       0.92      0.93      0.93       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.86      0.82      0.84       191\n           X       1.00      0.27      0.43        11\n\n    accuracy                           0.93      2434\n   macro avg       0.95      0.88      0.90      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.86      0.87       312\n         ADP       0.97      0.99      0.98       242\n         ADV       0.84      0.72      0.78        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.98      0.98      0.98        88\n         DET       0.93      0.95      0.94       109\n        NOUN       0.90      0.91      0.90       621\n         NUM       0.92      0.89      0.91        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.89      0.95      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.95      1.00      0.97        72\n        VERB       0.86      0.87      0.86       191\n           X       1.00      0.55      0.71        11\n\n    accuracy                           0.93      2434\n   macro avg       0.94      0.90      0.91      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.87      0.88      0.87       312\n         ADP       1.00      0.98      0.99       242\n         ADV       0.72      0.80      0.76        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.96      0.86      0.91       109\n        NOUN       0.89      0.91      0.90       621\n         NUM       0.92      0.92      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.91      0.92      0.92       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.90      0.83      0.86       191\n           X       1.00      0.18      0.31        11\n\n    accuracy                           0.92      2434\n   macro avg       0.94      0.87      0.88      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 10, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.89      0.88       312\n         ADP       0.99      0.99      0.99       242\n         ADV       0.85      0.69      0.76        80\n         AUX       0.99      0.99      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.96      0.91      0.93       109\n        NOUN       0.90      0.91      0.91       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.86      0.94      0.90       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.92      1.00      0.96        72\n        VERB       0.87      0.86      0.86       191\n           X       1.00      0.18      0.31        11\n\n    accuracy                           0.93      2434\n   macro avg       0.94      0.87      0.88      2434\nweighted avg       0.93      0.93      0.92      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.86      0.90      0.88       312\n         ADP       0.99      0.99      0.99       242\n         ADV       0.83      0.69      0.75        80\n         AUX       0.98      0.99      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.96      0.92      0.94       109\n        NOUN       0.90      0.90      0.90       621\n         NUM       0.94      0.89      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.96      0.97        57\n       PROPN       0.93      0.91      0.92       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.94      1.00      0.97        72\n        VERB       0.86      0.89      0.88       191\n           X       0.75      0.27      0.40        11\n\n    accuracy                           0.93      2434\n   macro avg       0.93      0.87      0.89      2434\nweighted avg       0.92      0.93      0.92      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.87      0.88       312\n         ADP       0.98      0.99      0.98       242\n         ADV       0.80      0.70      0.75        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.99      0.97        88\n         DET       0.93      0.89      0.91       109\n        NOUN       0.90      0.92      0.91       621\n         NUM       0.95      0.95      0.95        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.95      0.98      0.97        57\n       PROPN       0.94      0.93      0.94       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.92      0.99      0.95        72\n        VERB       0.86      0.90      0.88       191\n           X       1.00      0.27      0.43        11\n\n    accuracy                           0.93      2434\n   macro avg       0.94      0.88      0.89      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 30, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.86      0.87       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.85      0.70      0.77        80\n         AUX       0.99      0.99      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.92      0.94      0.93       109\n        NOUN       0.90      0.90      0.90       621\n         NUM       0.94      0.89      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.90      0.97      0.93       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.94      1.00      0.97        72\n        VERB       0.84      0.90      0.87       191\n           X       1.00      0.18      0.31        11\n\n    accuracy                           0.92      2434\n   macro avg       0.94      0.87      0.88      2434\nweighted avg       0.92      0.92      0.92      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.89      0.89       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.88      0.72      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.97      0.98      0.97        88\n         DET       0.95      0.89      0.92       109\n        NOUN       0.89      0.93      0.91       621\n         NUM       0.97      0.87      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.97      0.98      0.97        57\n       PROPN       0.92      0.91      0.92       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.95      1.00      0.97        72\n        VERB       0.90      0.88      0.89       191\n           X       0.86      0.55      0.67        11\n\n    accuracy                           0.93      2434\n   macro avg       0.94      0.89      0.91      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.91      0.90       312\n         ADP       1.00      0.99      0.99       242\n         ADV       0.88      0.74      0.80        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.97      0.98      0.97        88\n         DET       0.94      0.93      0.94       109\n        NOUN       0.91      0.93      0.92       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.86      0.92        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.93      0.94      0.93       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.96      1.00      0.98        72\n        VERB       0.92      0.90      0.91       191\n           X       1.00      0.18      0.31        11\n\n    accuracy                           0.94      2434\n   macro avg       0.95      0.88      0.90      2434\nweighted avg       0.94      0.94      0.94      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 50, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.89      0.90      0.89       312\n         ADP       0.98      0.99      0.98       242\n         ADV       0.83      0.75      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.97      0.97      0.97        88\n         DET       0.95      0.92      0.93       109\n        NOUN       0.91      0.92      0.91       621\n         NUM       0.92      0.92      0.92        38\n        PART       1.00      0.86      0.92        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.93      0.94      0.94       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.95      0.99      0.97        72\n        VERB       0.88      0.88      0.88       191\n           X       1.00      0.45      0.62        11\n\n    accuracy                           0.93      2434\n   macro avg       0.95      0.90      0.91      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.92      0.92       312\n         ADP       0.99      0.99      0.99       242\n         ADV       0.92      0.76      0.84        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.96      0.91      0.93       109\n        NOUN       0.90      0.93      0.91       621\n         NUM       0.92      0.89      0.91        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.95      0.98      0.97        57\n       PROPN       0.90      0.93      0.91       148\n       PUNCT       0.99      1.00      0.99       306\n       SCONJ       0.95      1.00      0.97        72\n        VERB       0.91      0.88      0.89       191\n           X       1.00      0.18      0.31        11\n\n    accuracy                           0.94      2434\n   macro avg       0.95      0.88      0.89      2434\nweighted avg       0.94      0.94      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.90      0.89      0.89       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.82      0.76      0.79        80\n         AUX       0.99      1.00      0.99       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.94      0.94       109\n        NOUN       0.91      0.93      0.92       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.96      0.97        57\n       PROPN       0.92      0.93      0.93       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.95      1.00      0.97        72\n        VERB       0.91      0.86      0.88       191\n           X       0.80      0.36      0.50        11\n\n    accuracy                           0.93      2434\n   macro avg       0.93      0.89      0.90      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 70, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.85      0.90      0.88       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.83      0.75      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.95      0.95       109\n        NOUN       0.91      0.90      0.91       621\n         NUM       0.90      0.95      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.96      0.97        57\n       PROPN       0.91      0.93      0.92       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.96      1.00      0.98        72\n        VERB       0.91      0.84      0.87       191\n           X       1.00      0.45      0.62        11\n\n    accuracy                           0.93      2434\n   macro avg       0.94      0.89      0.91      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 10}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.92      0.88      0.90       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.89      0.71      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.91      0.96      0.93       109\n        NOUN       0.90      0.93      0.92       621\n         NUM       0.92      0.92      0.92        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.96      0.97        57\n       PROPN       0.92      0.93      0.92       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.95      1.00      0.97        72\n        VERB       0.88      0.88      0.88       191\n           X       1.00      0.45      0.62        11\n\n    accuracy                           0.94      2434\n   macro avg       0.95      0.89      0.91      2434\nweighted avg       0.94      0.94      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 11}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.88      0.92      0.90       312\n         ADP       0.98      0.99      0.98       242\n         ADV       0.89      0.74      0.81        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.94      0.94      0.94       109\n        NOUN       0.92      0.90      0.91       621\n         NUM       0.92      0.89      0.91        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.96      0.97        57\n       PROPN       0.89      0.95      0.92       148\n       PUNCT       0.99      1.00      1.00       306\n       SCONJ       0.96      0.99      0.97        72\n        VERB       0.89      0.89      0.89       191\n           X       1.00      0.45      0.62        11\n\n    accuracy                           0.93      2434\n   macro avg       0.95      0.89      0.91      2434\nweighted avg       0.93      0.93      0.93      2434\n"}, {"params": {"learning_rate": 0.6, "param_mini_batch_sizes": 90, "max_epochs": 12}, "report": "              precision    recall  f1-score   support\n\n         ADJ       0.91      0.89      0.90       312\n         ADP       0.98      0.99      0.99       242\n         ADV       0.89      0.71      0.79        80\n         AUX       0.99      1.00      1.00       145\n       CCONJ       0.96      0.98      0.97        88\n         DET       0.96      0.96      0.96       109\n        NOUN       0.89      0.93      0.91       621\n         NUM       0.95      0.92      0.93        38\n        PART       1.00      0.79      0.88        14\n        PRON       0.98      0.98      0.98        57\n       PROPN       0.94      0.93      0.94       148\n       PUNCT       1.00      1.00      1.00       306\n       SCONJ       0.95      1.00      0.97        72\n        VERB       0.91      0.86      0.88       191\n           X       0.88      0.64      0.74        11\n\n    accuracy                           0.94      2434\n   macro avg       0.95      0.91      0.92      2434\nweighted avg       0.94      0.94      0.94      2434\n"}]